[2017-05-31 16:34:09,790][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 16:34:09,790][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-05-31 16:34:09,790][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 16:34:09,790][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 16:34:09,791][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 16:34:09,791][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 16:34:09,791][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 16:34:09,791][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f407344afc8>
[2017-05-31 16:34:09,791][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 16:34:09,791][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-05-31 16:34:09,791][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f4073d5d1b8>
[2017-05-31 16:34:09,791][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 16:34:09,791][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 16:34:09,791][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-05-31 16:34:09,791][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-05-31 16:34:09,791][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-05-31 16:34:09,791][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-05-31 16:34:09,818][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 16:34:09,833][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 16:34:09,834][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 16:34:09,850][gdb3][DEBUG ] detect machine type
[2017-05-31 16:34:09,853][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 16:34:09,853][gdb3][INFO  ] Purging Ceph on gdb3
[2017-05-31 16:34:09,854][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-05-31 16:34:09,893][gdb3][DEBUG ] Reading package lists...
[2017-05-31 16:34:10,057][gdb3][DEBUG ] Building dependency tree...
[2017-05-31 16:34:10,057][gdb3][DEBUG ] Reading state information...
[2017-05-31 16:34:10,171][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-05-31 16:34:10,172][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-05-31 16:34:10,172][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-05-31 16:34:10,172][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-05-31 16:34:10,172][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-05-31 16:34:10,172][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-05-31 16:34:10,173][gdb3][DEBUG ]   linux-headers-4.4.0-1013-aws linux-image-4.4.0-1013-aws ntp python-blinker
[2017-05-31 16:34:10,173][gdb3][DEBUG ]   python-cephfs python-cffi-backend python-chardet python-cryptography
[2017-05-31 16:34:10,173][gdb3][DEBUG ]   python-enum34 python-flask python-idna python-ipaddress python-itsdangerous
[2017-05-31 16:34:10,173][gdb3][DEBUG ]   python-jinja2 python-markupsafe python-ndg-httpsclient python-openssl
[2017-05-31 16:34:10,173][gdb3][DEBUG ]   python-pyasn1 python-pyinotify python-rados python-rbd python-requests
[2017-05-31 16:34:10,173][gdb3][DEBUG ]   python-rgw python-six python-urllib3 python-werkzeug
[2017-05-31 16:34:10,173][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-05-31 16:34:10,173][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-05-31 16:34:10,174][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-05-31 16:34:10,288][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 35 not upgraded.
[2017-05-31 16:34:10,288][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-05-31 16:34:10,356][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 104522 files and directories currently installed.)
[2017-05-31 16:34:10,357][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-05-31 16:34:10,521][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-05-31 16:34:10,635][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-05-31 16:34:10,635][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-05-31 16:34:10,850][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-05-31 16:34:10,964][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-05-31 16:34:11,129][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-05-31 16:34:11,193][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-05-31 16:34:11,209][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-05-31 16:34:11,375][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-05-31 16:34:11,439][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-05-31 16:34:11,455][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-05-31 16:34:11,624][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-05-31 16:34:11,656][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-05-31 16:34:11,821][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-05-31 16:34:11,885][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-05-31 16:34:11,885][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-05-31 16:34:12,000][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu7) ...
[2017-05-31 16:34:12,816][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-05-31 16:34:12,983][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 16:34:12,984][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-05-31 16:34:12,984][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 16:34:12,984][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 16:34:12,984][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 16:34:12,984][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 16:34:12,984][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 16:34:12,984][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe8d7689710>
[2017-05-31 16:34:12,984][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 16:34:12,984][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-05-31 16:34:12,984][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7fe8d7f96230>
[2017-05-31 16:34:12,984][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 16:34:12,984][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 16:34:12,984][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-05-31 16:34:13,011][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 16:34:13,026][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 16:34:13,026][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 16:34:13,043][gdb3][DEBUG ] detect machine type
[2017-05-31 16:34:13,045][gdb3][DEBUG ] find the location of an executable
[2017-05-31 16:34:13,061][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 16:34:13,076][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 16:34:13,077][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 16:34:13,093][gdb3][DEBUG ] detect machine type
[2017-05-31 16:34:13,096][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 16:34:13,096][gdb3][INFO  ] purging data on gdb3
[2017-05-31 16:34:13,097][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-05-31 16:34:13,110][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-05-31 16:34:13,281][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 16:34:13,282][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-05-31 16:34:13,282][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 16:34:13,282][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 16:34:13,282][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 16:34:13,282][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 16:34:13,282][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 16:34:13,282][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f329227f9e0>
[2017-05-31 16:34:13,282][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 16:34:13,282][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7f3292b42848>
[2017-05-31 16:34:13,282][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 16:34:13,283][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 16:35:36,302][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 16:35:36,302][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-05-31 16:35:36,303][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 16:35:36,303][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 16:35:36,303][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 16:35:36,303][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 16:35:36,303][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 16:35:36,303][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6a720a6560>
[2017-05-31 16:35:36,303][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 16:35:36,303][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-05-31 16:35:36,304][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-05-31 16:35:36,304][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f6a7272a758>
[2017-05-31 16:35:36,304][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-05-31 16:35:36,304][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 16:35:36,304][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-05-31 16:35:36,304][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 16:35:36,304][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-05-31 16:35:36,304][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-05-31 16:35:36,305][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-05-31 16:35:36,331][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 16:35:36,345][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 16:35:36,345][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 16:35:36,362][gdb3][DEBUG ] detect machine type
[2017-05-31 16:35:36,364][gdb3][DEBUG ] find the location of an executable
[2017-05-31 16:35:36,365][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-05-31 16:35:36,377][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-05-31 16:35:36,383][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-05-31 16:35:36,383][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-05-31 16:35:36,383][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-05-31 16:35:36,384][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-05-31 16:35:36,384][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-05-31 16:35:36,384][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-05-31 16:35:36,384][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-05-31 16:35:36,384][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-05-31 16:35:36,550][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 16:35:36,550][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-05-31 16:35:36,550][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 16:35:36,550][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 16:35:36,551][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 16:35:36,551][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 16:35:36,551][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-05-31 16:35:36,551][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 16:35:36,551][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa11d0dce60>
[2017-05-31 16:35:36,551][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 16:35:36,551][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7fa11d0b1b18>
[2017-05-31 16:35:36,551][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 16:35:36,551][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-05-31 16:35:36,552][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 16:35:36,552][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-05-31 16:35:36,552][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-05-31 16:35:36,579][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 16:35:36,592][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 16:35:36,593][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 16:35:36,609][gdb3][DEBUG ] detect machine type
[2017-05-31 16:35:36,612][gdb3][DEBUG ] find the location of an executable
[2017-05-31 16:35:36,612][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-05-31 16:35:36,612][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-05-31 16:35:36,612][gdb3][DEBUG ] get remote short hostname
[2017-05-31 16:35:36,613][gdb3][DEBUG ] deploying mon to gdb3
[2017-05-31 16:35:36,613][gdb3][DEBUG ] get remote short hostname
[2017-05-31 16:35:36,613][gdb3][DEBUG ] remote hostname: gdb3
[2017-05-31 16:35:36,614][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 16:35:36,615][gdb3][DEBUG ] create the mon path if it does not exist
[2017-05-31 16:35:36,615][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-05-31 16:35:36,616][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-05-31 16:35:36,616][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-05-31 16:35:36,616][gdb3][DEBUG ] create the monitor keyring file
[2017-05-31 16:35:36,617][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-05-31 16:35:36,656][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-05-31 16:35:36,656][gdb3][DEBUG ] ceph-mon: set fsid to e52d1ea0-de58-48ed-b1fd-547c31561e69
[2017-05-31 16:35:36,663][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-05-31 16:35:36,663][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-05-31 16:35:36,664][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-05-31 16:35:36,664][gdb3][DEBUG ] create the init path if it does not exist
[2017-05-31 16:35:36,665][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-05-31 16:35:36,733][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-05-31 16:35:36,805][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-05-31 16:35:38,875][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 16:35:38,940][gdb3][DEBUG ] ********************************************************************************
[2017-05-31 16:35:38,940][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-05-31 16:35:38,940][gdb3][DEBUG ] {
[2017-05-31 16:35:38,940][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-05-31 16:35:38,941][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-05-31 16:35:38,941][gdb3][DEBUG ]   "features": {
[2017-05-31 16:35:38,941][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-05-31 16:35:38,941][gdb3][DEBUG ]     "quorum_mon": [
[2017-05-31 16:35:38,941][gdb3][DEBUG ]       "kraken", 
[2017-05-31 16:35:38,941][gdb3][DEBUG ]       "luminous"
[2017-05-31 16:35:38,941][gdb3][DEBUG ]     ], 
[2017-05-31 16:35:38,941][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-05-31 16:35:38,941][gdb3][DEBUG ]     "required_mon": [
[2017-05-31 16:35:38,941][gdb3][DEBUG ]       "kraken", 
[2017-05-31 16:35:38,941][gdb3][DEBUG ]       "luminous"
[2017-05-31 16:35:38,941][gdb3][DEBUG ]     ]
[2017-05-31 16:35:38,941][gdb3][DEBUG ]   }, 
[2017-05-31 16:35:38,941][gdb3][DEBUG ]   "monmap": {
[2017-05-31 16:35:38,941][gdb3][DEBUG ]     "created": "2017-05-31 16:35:36.641607", 
[2017-05-31 16:35:38,941][gdb3][DEBUG ]     "epoch": 2, 
[2017-05-31 16:35:38,942][gdb3][DEBUG ]     "features": {
[2017-05-31 16:35:38,942][gdb3][DEBUG ]       "optional": [], 
[2017-05-31 16:35:38,942][gdb3][DEBUG ]       "persistent": [
[2017-05-31 16:35:38,942][gdb3][DEBUG ]         "kraken", 
[2017-05-31 16:35:38,942][gdb3][DEBUG ]         "luminous"
[2017-05-31 16:35:38,942][gdb3][DEBUG ]       ]
[2017-05-31 16:35:38,942][gdb3][DEBUG ]     }, 
[2017-05-31 16:35:38,942][gdb3][DEBUG ]     "fsid": "e52d1ea0-de58-48ed-b1fd-547c31561e69", 
[2017-05-31 16:35:38,942][gdb3][DEBUG ]     "modified": "2017-05-31 16:35:36.894213", 
[2017-05-31 16:35:38,942][gdb3][DEBUG ]     "mons": [
[2017-05-31 16:35:38,942][gdb3][DEBUG ]       {
[2017-05-31 16:35:38,942][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-05-31 16:35:38,942][gdb3][DEBUG ]         "name": "gdb3", 
[2017-05-31 16:35:38,942][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-05-31 16:35:38,942][gdb3][DEBUG ]         "rank": 0
[2017-05-31 16:35:38,942][gdb3][DEBUG ]       }
[2017-05-31 16:35:38,943][gdb3][DEBUG ]     ]
[2017-05-31 16:35:38,943][gdb3][DEBUG ]   }, 
[2017-05-31 16:35:38,943][gdb3][DEBUG ]   "name": "gdb3", 
[2017-05-31 16:35:38,943][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-05-31 16:35:38,943][gdb3][DEBUG ]   "quorum": [
[2017-05-31 16:35:38,943][gdb3][DEBUG ]     0
[2017-05-31 16:35:38,943][gdb3][DEBUG ]   ], 
[2017-05-31 16:35:38,943][gdb3][DEBUG ]   "rank": 0, 
[2017-05-31 16:35:38,943][gdb3][DEBUG ]   "state": "leader", 
[2017-05-31 16:35:38,943][gdb3][DEBUG ]   "sync_provider": []
[2017-05-31 16:35:38,943][gdb3][DEBUG ] }
[2017-05-31 16:35:38,943][gdb3][DEBUG ] ********************************************************************************
[2017-05-31 16:35:38,943][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-05-31 16:35:38,944][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 16:35:39,009][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-05-31 16:35:39,025][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 16:35:39,039][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 16:35:39,039][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 16:35:39,056][gdb3][DEBUG ] detect machine type
[2017-05-31 16:35:39,058][gdb3][DEBUG ] find the location of an executable
[2017-05-31 16:35:39,060][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 16:35:39,125][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-05-31 16:35:39,125][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-05-31 16:35:39,125][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-05-31 16:35:39,127][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmphK0O18
[2017-05-31 16:35:39,143][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 16:35:39,158][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 16:35:39,158][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 16:35:39,175][gdb3][DEBUG ] detect machine type
[2017-05-31 16:35:39,177][gdb3][DEBUG ] get remote short hostname
[2017-05-31 16:35:39,177][gdb3][DEBUG ] fetch remote file
[2017-05-31 16:35:39,179][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 16:35:39,245][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-05-31 16:35:39,411][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-05-31 16:35:39,577][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-05-31 16:35:39,744][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-05-31 16:35:39,960][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-05-31 16:35:40,127][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-05-31 16:35:40,293][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-05-31 16:35:40,459][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-05-31 16:35:40,625][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-05-31 16:35:40,792][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-05-31 16:35:40,957][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-05-31 16:35:40,957][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-05-31 16:35:40,957][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mgr.keyring
[2017-05-31 16:35:40,958][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-05-31 16:35:40,958][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-05-31 16:35:40,958][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-05-31 16:35:40,958][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmphK0O18
[2017-05-31 16:35:41,140][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 16:35:41,140][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-05-31 16:35:41,141][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 16:35:41,141][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 16:35:41,141][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 16:35:41,141][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 16:35:41,141][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 16:35:41,141][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f8159351518>
[2017-05-31 16:35:41,141][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 16:35:41,141][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-05-31 16:35:41,141][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f8159c68938>
[2017-05-31 16:35:41,141][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 16:35:41,141][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 16:35:41,141][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-05-31 16:35:41,168][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 16:35:41,182][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 16:35:41,182][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 16:35:41,198][gdb3][DEBUG ] detect machine type
[2017-05-31 16:35:41,201][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 16:36:04,282][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 16:36:04,282][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf osd create --zap-disk --bluestore gdb0:/dev/xvdb
[2017-05-31 16:36:04,283][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 16:36:04,283][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 16:36:04,283][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 16:36:04,283][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/dev/xvdb', None)]
[2017-05-31 16:36:04,283][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 16:36:04,283][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 16:36:04,283][ceph_deploy.cli][INFO  ]  bluestore                     : True
[2017-05-31 16:36:04,283][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 16:36:04,283][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 16:36:04,283][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-05-31 16:36:04,283][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 16:36:04,283][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 16:36:04,283][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ff46122a908>
[2017-05-31 16:36:04,283][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 16:36:04,284][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 16:36:04,284][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7ff461480aa0>
[2017-05-31 16:36:04,284][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 16:36:04,284][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 16:36:04,284][ceph_deploy.cli][INFO  ]  zap_disk                      : True
[2017-05-31 16:36:04,284][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/dev/xvdb:
[2017-05-31 16:36:04,526][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 16:36:04,718][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 16:36:04,719][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 16:36:04,734][gdb0][DEBUG ] detect machine type
[2017-05-31 16:36:04,738][gdb0][DEBUG ] find the location of an executable
[2017-05-31 16:36:04,739][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 16:36:04,739][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 16:36:04,739][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 16:36:04,741][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /dev/xvdb journal None activate True
[2017-05-31 16:36:04,741][gdb0][DEBUG ] find the location of an executable
[2017-05-31 16:36:04,743][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --zap-disk --bluestore --cluster ceph --fs-type xfs -- /dev/xvdb
[2017-05-31 16:36:04,864][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 16:36:04,867][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:36:04,867][gdb0][WARNING] set_type: Will colocate block with data on /dev/xvdb
[2017-05-31 16:36:04,867][gdb0][WARNING] command: Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup bluestore_block_size
[2017-05-31 16:36:04,883][gdb0][WARNING] command: Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup bluestore_block_db_size
[2017-05-31 16:36:04,884][gdb0][WARNING] command: Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup bluestore_block_wal_size
[2017-05-31 16:36:04,900][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:36:04,900][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:36:04,900][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:36:04,900][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 16:36:04,901][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 16:36:04,901][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 16:36:04,901][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 16:36:04,901][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 16:36:04,901][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 16:36:04,901][gdb0][WARNING]     args.func(args)
[2017-05-31 16:36:04,901][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2029, in main
[2017-05-31 16:36:04,901][gdb0][WARNING]     Prepare.factory(args).prepare()
[2017-05-31 16:36:04,901][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2018, in prepare
[2017-05-31 16:36:04,901][gdb0][WARNING]     self.prepare_locked()
[2017-05-31 16:36:04,901][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2090, in prepare_locked
[2017-05-31 16:36:04,901][gdb0][WARNING]     self.data.prepare(*to_prepare_list)
[2017-05-31 16:36:04,901][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2816, in prepare
[2017-05-31 16:36:04,902][gdb0][WARNING]     self.prepare_device(*to_prepare_list)
[2017-05-31 16:36:04,902][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2984, in prepare_device
[2017-05-31 16:36:04,902][gdb0][WARNING]     super(PrepareBluestoreData, self).prepare_device(*to_prepare_list)
[2017-05-31 16:36:04,902][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2878, in prepare_device
[2017-05-31 16:36:04,902][gdb0][WARNING]     self.sanity_checks()
[2017-05-31 16:36:04,902][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2841, in sanity_checks
[2017-05-31 16:36:04,902][gdb0][WARNING]     check_partitions=not self.args.dmcrypt)
[2017-05-31 16:36:04,902][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 944, in verify_not_in_use
[2017-05-31 16:36:04,902][gdb0][WARNING]     raise Error('Device is mounted', partition)
[2017-05-31 16:36:04,902][gdb0][WARNING] ceph_disk.main.Error: Error: Device is mounted: /dev/xvdb1
[2017-05-31 16:36:04,906][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 16:36:04,906][ceph_deploy.osd][ERROR ] Failed to execute command: /usr/sbin/ceph-disk -v prepare --zap-disk --bluestore --cluster ceph --fs-type xfs -- /dev/xvdb
[2017-05-31 16:36:04,906][ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs

[2017-05-31 16:39:15,638][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 16:39:15,639][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf osd create --zap-disk --bluestore gdb0:/dev/xvdb
[2017-05-31 16:39:15,639][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 16:39:15,639][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 16:39:15,639][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 16:39:15,639][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/dev/xvdb', None)]
[2017-05-31 16:39:15,639][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 16:39:15,639][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 16:39:15,639][ceph_deploy.cli][INFO  ]  bluestore                     : True
[2017-05-31 16:39:15,639][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 16:39:15,639][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 16:39:15,639][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-05-31 16:39:15,639][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 16:39:15,639][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 16:39:15,640][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7ac7e0b908>
[2017-05-31 16:39:15,640][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 16:39:15,640][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 16:39:15,640][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f7ac8061aa0>
[2017-05-31 16:39:15,640][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 16:39:15,640][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 16:39:15,640][ceph_deploy.cli][INFO  ]  zap_disk                      : True
[2017-05-31 16:39:15,640][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/dev/xvdb:
[2017-05-31 16:39:15,875][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 16:39:16,106][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 16:39:16,106][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 16:39:16,122][gdb0][DEBUG ] detect machine type
[2017-05-31 16:39:16,126][gdb0][DEBUG ] find the location of an executable
[2017-05-31 16:39:16,126][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 16:39:16,126][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 16:39:16,127][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 16:39:16,129][gdb0][WARNING] osd keyring does not exist yet, creating one
[2017-05-31 16:39:16,129][gdb0][DEBUG ] create a keyring file
[2017-05-31 16:39:16,131][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /dev/xvdb journal None activate True
[2017-05-31 16:39:16,131][gdb0][DEBUG ] find the location of an executable
[2017-05-31 16:39:16,133][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --zap-disk --bluestore --cluster ceph --fs-type xfs -- /dev/xvdb
[2017-05-31 16:39:16,254][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 16:39:16,257][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:39:16,257][gdb0][WARNING] set_type: Will colocate block with data on /dev/xvdb
[2017-05-31 16:39:16,257][gdb0][WARNING] command: Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup bluestore_block_size
[2017-05-31 16:39:16,265][gdb0][WARNING] command: Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup bluestore_block_db_size
[2017-05-31 16:39:16,281][gdb0][WARNING] command: Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup bluestore_block_wal_size
[2017-05-31 16:39:16,282][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:39:16,282][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:39:16,282][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:39:16,282][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 16:39:16,282][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 16:39:16,283][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 16:39:16,283][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 16:39:16,283][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 16:39:16,283][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 16:39:16,283][gdb0][WARNING]     args.func(args)
[2017-05-31 16:39:16,284][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2029, in main
[2017-05-31 16:39:16,284][gdb0][WARNING]     Prepare.factory(args).prepare()
[2017-05-31 16:39:16,284][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2018, in prepare
[2017-05-31 16:39:16,284][gdb0][WARNING]     self.prepare_locked()
[2017-05-31 16:39:16,284][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2090, in prepare_locked
[2017-05-31 16:39:16,284][gdb0][WARNING]     self.data.prepare(*to_prepare_list)
[2017-05-31 16:39:16,285][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2816, in prepare
[2017-05-31 16:39:16,285][gdb0][WARNING]     self.prepare_device(*to_prepare_list)
[2017-05-31 16:39:16,285][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2984, in prepare_device
[2017-05-31 16:39:16,285][gdb0][WARNING]     super(PrepareBluestoreData, self).prepare_device(*to_prepare_list)
[2017-05-31 16:39:16,285][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2878, in prepare_device
[2017-05-31 16:39:16,285][gdb0][WARNING]     self.sanity_checks()
[2017-05-31 16:39:16,285][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2841, in sanity_checks
[2017-05-31 16:39:16,285][gdb0][WARNING]     check_partitions=not self.args.dmcrypt)
[2017-05-31 16:39:16,285][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 944, in verify_not_in_use
[2017-05-31 16:39:16,285][gdb0][WARNING]     raise Error('Device is mounted', partition)
[2017-05-31 16:39:16,286][gdb0][WARNING] ceph_disk.main.Error: Error: Device is mounted: /dev/xvdb1
[2017-05-31 16:39:16,293][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 16:39:16,293][ceph_deploy.osd][ERROR ] Failed to execute command: /usr/sbin/ceph-disk -v prepare --zap-disk --bluestore --cluster ceph --fs-type xfs -- /dev/xvdb
[2017-05-31 16:39:16,293][ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs

[2017-05-31 16:39:39,078][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 16:39:39,079][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf osd create --zap-disk --bluestore gdb0:/dev/xvdb
[2017-05-31 16:39:39,079][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 16:39:39,079][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 16:39:39,079][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 16:39:39,079][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/dev/xvdb', None)]
[2017-05-31 16:39:39,079][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 16:39:39,079][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 16:39:39,079][ceph_deploy.cli][INFO  ]  bluestore                     : True
[2017-05-31 16:39:39,079][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 16:39:39,079][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 16:39:39,079][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-05-31 16:39:39,079][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 16:39:39,080][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 16:39:39,080][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f5011019908>
[2017-05-31 16:39:39,080][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 16:39:39,080][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 16:39:39,080][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f501126faa0>
[2017-05-31 16:39:39,080][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 16:39:39,080][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 16:39:39,080][ceph_deploy.cli][INFO  ]  zap_disk                      : True
[2017-05-31 16:39:39,080][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/dev/xvdb:
[2017-05-31 16:39:39,322][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 16:39:39,549][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 16:39:39,550][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 16:39:39,565][gdb0][DEBUG ] detect machine type
[2017-05-31 16:39:39,569][gdb0][DEBUG ] find the location of an executable
[2017-05-31 16:39:39,570][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 16:39:39,570][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 16:39:39,570][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 16:39:39,572][gdb0][WARNING] osd keyring does not exist yet, creating one
[2017-05-31 16:39:39,572][gdb0][DEBUG ] create a keyring file
[2017-05-31 16:39:39,574][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /dev/xvdb journal None activate True
[2017-05-31 16:39:39,574][gdb0][DEBUG ] find the location of an executable
[2017-05-31 16:39:39,576][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --zap-disk --bluestore --cluster ceph --fs-type xfs -- /dev/xvdb
[2017-05-31 16:39:39,696][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 16:39:39,700][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:39:39,700][gdb0][WARNING] set_type: Will colocate block with data on /dev/xvdb
[2017-05-31 16:39:39,700][gdb0][WARNING] command: Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup bluestore_block_size
[2017-05-31 16:39:39,716][gdb0][WARNING] command: Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup bluestore_block_db_size
[2017-05-31 16:39:39,717][gdb0][WARNING] command: Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup bluestore_block_wal_size
[2017-05-31 16:39:39,733][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:39:39,733][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:39:39,733][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:39:39,733][gdb0][WARNING] command: Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2017-05-31 16:39:39,734][gdb0][WARNING] command: Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_fs_mkfs_options_xfs
[2017-05-31 16:39:39,742][gdb0][WARNING] command: Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2017-05-31 16:39:39,758][gdb0][WARNING] command: Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_fs_mount_options_xfs
[2017-05-31 16:39:39,759][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:39:39,759][gdb0][WARNING] zap: Writing zeros to existing partitions on /dev/xvdb
[2017-05-31 16:39:39,759][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:39:39,759][gdb0][WARNING] zap: Zapping partition table on /dev/xvdb
[2017-05-31 16:39:39,760][gdb0][WARNING] command_check_call: Running command: /sbin/sgdisk --zap-all -- /dev/xvdb
[2017-05-31 16:39:39,764][gdb0][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2017-05-31 16:39:39,764][gdb0][WARNING] backup header from main header.
[2017-05-31 16:39:39,764][gdb0][WARNING] 
[2017-05-31 16:39:40,831][gdb0][DEBUG ] ****************************************************************************
[2017-05-31 16:39:40,831][gdb0][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2017-05-31 16:39:40,832][gdb0][DEBUG ] verification and recovery are STRONGLY recommended.
[2017-05-31 16:39:40,832][gdb0][DEBUG ] ****************************************************************************
[2017-05-31 16:39:40,832][gdb0][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2017-05-31 16:39:40,832][gdb0][DEBUG ] other utilities.
[2017-05-31 16:39:40,832][gdb0][WARNING] command_check_call: Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/xvdb
[2017-05-31 16:39:41,849][gdb0][DEBUG ] Creating new GPT entries.
[2017-05-31 16:39:41,849][gdb0][DEBUG ] The operation has completed successfully.
[2017-05-31 16:39:41,850][gdb0][WARNING] update_partition: Calling partprobe on zapped device /dev/xvdb
[2017-05-31 16:39:41,850][gdb0][WARNING] command_check_call: Running command: /sbin/udevadm settle --timeout=600
[2017-05-31 16:39:41,853][gdb0][WARNING] command: Running command: /usr/bin/flock -s /dev/xvdb /sbin/partprobe /dev/xvdb
[2017-05-31 16:39:41,885][gdb0][WARNING] command_check_call: Running command: /sbin/udevadm settle --timeout=600
[2017-05-31 16:39:41,888][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:39:41,888][gdb0][WARNING] set_data_partition: Creating osd partition on /dev/xvdb
[2017-05-31 16:39:41,889][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:39:41,889][gdb0][WARNING] ptype_tobe_for_name: name = data
[2017-05-31 16:39:41,889][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:39:41,889][gdb0][WARNING] create_partition: Creating data partition num 1 size 100 on /dev/xvdb
[2017-05-31 16:39:41,889][gdb0][WARNING] command_check_call: Running command: /sbin/sgdisk --new=1:0:+100M --change-name=1:ceph data --partition-guid=1:7e7e4d4e-fb27-4154-a27a-e2f06d039b76 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be --mbrtogpt -- /dev/xvdb
[2017-05-31 16:39:42,906][gdb0][DEBUG ] Setting name!
[2017-05-31 16:39:42,906][gdb0][DEBUG ] partNum is 0
[2017-05-31 16:39:42,906][gdb0][DEBUG ] REALLY setting name!
[2017-05-31 16:39:42,906][gdb0][DEBUG ] The operation has completed successfully.
[2017-05-31 16:39:42,907][gdb0][WARNING] update_partition: Calling partprobe on created device /dev/xvdb
[2017-05-31 16:39:42,907][gdb0][WARNING] command_check_call: Running command: /sbin/udevadm settle --timeout=600
[2017-05-31 16:39:42,971][gdb0][WARNING] command: Running command: /usr/bin/flock -s /dev/xvdb /sbin/partprobe /dev/xvdb
[2017-05-31 16:39:43,085][gdb0][WARNING] command_check_call: Running command: /sbin/udevadm settle --timeout=600
[2017-05-31 16:39:43,117][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:39:43,117][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:39:43,117][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb1 uuid path is /sys/dev/block/202:17/dm/uuid
[2017-05-31 16:39:43,117][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:39:43,117][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:39:43,117][gdb0][WARNING] ptype_tobe_for_name: name = block
[2017-05-31 16:39:43,117][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:39:43,117][gdb0][WARNING] create_partition: Creating block partition num 2 size 0 on /dev/xvdb
[2017-05-31 16:39:43,117][gdb0][WARNING] command_check_call: Running command: /sbin/sgdisk --largest-new=2 --change-name=2:ceph block --partition-guid=2:8d4465c8-eb33-4fae-bb6c-98aeb5b9cc73 --typecode=2:cafecafe-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/xvdb
[2017-05-31 16:39:44,135][gdb0][DEBUG ] Setting name!
[2017-05-31 16:39:44,135][gdb0][DEBUG ] partNum is 1
[2017-05-31 16:39:44,135][gdb0][DEBUG ] REALLY setting name!
[2017-05-31 16:39:44,135][gdb0][DEBUG ] The operation has completed successfully.
[2017-05-31 16:39:44,135][gdb0][WARNING] update_partition: Calling partprobe on created device /dev/xvdb
[2017-05-31 16:39:44,135][gdb0][WARNING] command_check_call: Running command: /sbin/udevadm settle --timeout=600
[2017-05-31 16:39:44,350][gdb0][WARNING] command: Running command: /usr/bin/flock -s /dev/xvdb /sbin/partprobe /dev/xvdb
[2017-05-31 16:39:44,615][gdb0][WARNING] command_check_call: Running command: /sbin/udevadm settle --timeout=600
[2017-05-31 16:39:44,830][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:39:44,830][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:39:44,830][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb2 uuid path is /sys/dev/block/202:18/dm/uuid
[2017-05-31 16:39:44,830][gdb0][WARNING] prepare_device: Block is GPT partition /dev/disk/by-partuuid/8d4465c8-eb33-4fae-bb6c-98aeb5b9cc73
[2017-05-31 16:39:44,830][gdb0][WARNING] command_check_call: Running command: /sbin/sgdisk --typecode=2:cafecafe-9b03-4f30-b4c6-b4b80ceff106 -- /dev/xvdb
[2017-05-31 16:39:45,847][gdb0][DEBUG ] The operation has completed successfully.
[2017-05-31 16:39:45,848][gdb0][WARNING] update_partition: Calling partprobe on prepared device /dev/xvdb
[2017-05-31 16:39:45,848][gdb0][WARNING] command_check_call: Running command: /sbin/udevadm settle --timeout=600
[2017-05-31 16:39:46,062][gdb0][WARNING] command: Running command: /usr/bin/flock -s /dev/xvdb /sbin/partprobe /dev/xvdb
[2017-05-31 16:39:46,277][gdb0][WARNING] command_check_call: Running command: /sbin/udevadm settle --timeout=600
[2017-05-31 16:39:46,492][gdb0][WARNING] prepare_device: Block is GPT partition /dev/disk/by-partuuid/8d4465c8-eb33-4fae-bb6c-98aeb5b9cc73
[2017-05-31 16:39:46,492][gdb0][WARNING] populate_data_path_device: Creating xfs fs on /dev/xvdb1
[2017-05-31 16:39:46,492][gdb0][WARNING] command_check_call: Running command: /sbin/mkfs -t xfs -f -i size=2048 -- /dev/xvdb1
[2017-05-31 16:39:46,556][gdb0][DEBUG ] meta-data=/dev/xvdb1             isize=2048   agcount=4, agsize=6400 blks
[2017-05-31 16:39:46,556][gdb0][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=1
[2017-05-31 16:39:46,556][gdb0][DEBUG ]          =                       crc=1        finobt=1, sparse=0
[2017-05-31 16:39:46,556][gdb0][DEBUG ] data     =                       bsize=4096   blocks=25600, imaxpct=25
[2017-05-31 16:39:46,556][gdb0][DEBUG ]          =                       sunit=0      swidth=0 blks
[2017-05-31 16:39:46,556][gdb0][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
[2017-05-31 16:39:46,556][gdb0][DEBUG ] log      =internal log           bsize=4096   blocks=864, version=2
[2017-05-31 16:39:46,557][gdb0][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2017-05-31 16:39:46,557][gdb0][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2017-05-31 16:39:46,557][gdb0][WARNING] mount: Mounting /dev/xvdb1 on /var/lib/ceph/tmp/mnt.umpsaG with options noatime,inode64
[2017-05-31 16:39:46,557][gdb0][WARNING] command_check_call: Running command: /bin/mount -t xfs -o noatime,inode64 -- /dev/xvdb1 /var/lib/ceph/tmp/mnt.umpsaG
[2017-05-31 16:39:46,572][gdb0][WARNING] populate_data_path: Preparing osd data dir /var/lib/ceph/tmp/mnt.umpsaG
[2017-05-31 16:39:46,576][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /var/lib/ceph/tmp/mnt.umpsaG/ceph_fsid.8078.tmp
[2017-05-31 16:39:46,579][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /var/lib/ceph/tmp/mnt.umpsaG/fsid.8078.tmp
[2017-05-31 16:39:46,587][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /var/lib/ceph/tmp/mnt.umpsaG/magic.8078.tmp
[2017-05-31 16:39:46,587][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /var/lib/ceph/tmp/mnt.umpsaG/block_uuid.8078.tmp
[2017-05-31 16:39:46,588][gdb0][WARNING] adjust_symlink: Creating symlink /var/lib/ceph/tmp/mnt.umpsaG/block -> /dev/disk/by-partuuid/8d4465c8-eb33-4fae-bb6c-98aeb5b9cc73
[2017-05-31 16:39:46,589][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /var/lib/ceph/tmp/mnt.umpsaG/type.8078.tmp
[2017-05-31 16:39:46,591][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /var/lib/ceph/tmp/mnt.umpsaG
[2017-05-31 16:39:46,594][gdb0][WARNING] unmount: Unmounting /var/lib/ceph/tmp/mnt.umpsaG
[2017-05-31 16:39:46,594][gdb0][WARNING] command_check_call: Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.umpsaG
[2017-05-31 16:39:46,626][gdb0][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:39:46,626][gdb0][WARNING] command_check_call: Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/xvdb
[2017-05-31 16:39:47,693][gdb0][DEBUG ] The operation has completed successfully.
[2017-05-31 16:39:47,694][gdb0][WARNING] update_partition: Calling partprobe on prepared device /dev/xvdb
[2017-05-31 16:39:47,694][gdb0][WARNING] command_check_call: Running command: /sbin/udevadm settle --timeout=600
[2017-05-31 16:39:47,858][gdb0][WARNING] command: Running command: /usr/bin/flock -s /dev/xvdb /sbin/partprobe /dev/xvdb
[2017-05-31 16:39:48,073][gdb0][WARNING] command_check_call: Running command: /sbin/udevadm settle --timeout=600
[2017-05-31 16:39:48,338][gdb0][WARNING] command_check_call: Running command: /sbin/udevadm trigger --action=add --sysname-match xvdb1
[2017-05-31 16:39:48,340][gdb0][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-05-31 16:39:53,462][gdb0][INFO  ] checking OSD status...
[2017-05-31 16:39:53,462][gdb0][DEBUG ] find the location of an executable
[2017-05-31 16:39:53,465][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 16:39:53,530][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-05-31 16:40:00,896][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 16:40:00,897][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf osd create --zap-disk --bluestore gdb1:/dev/xvdb
[2017-05-31 16:40:00,897][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 16:40:00,897][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 16:40:00,897][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 16:40:00,897][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/dev/xvdb', None)]
[2017-05-31 16:40:00,897][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 16:40:00,897][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 16:40:00,897][ceph_deploy.cli][INFO  ]  bluestore                     : True
[2017-05-31 16:40:00,897][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 16:40:00,897][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 16:40:00,897][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-05-31 16:40:00,897][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 16:40:00,897][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 16:40:00,898][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6d2b948908>
[2017-05-31 16:40:00,898][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 16:40:00,898][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 16:40:00,898][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f6d2bb9eaa0>
[2017-05-31 16:40:00,898][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 16:40:00,898][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 16:40:00,898][ceph_deploy.cli][INFO  ]  zap_disk                      : True
[2017-05-31 16:40:00,898][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/dev/xvdb:
[2017-05-31 16:40:01,144][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 16:40:01,379][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 16:40:01,379][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 16:40:01,396][gdb1][DEBUG ] detect machine type
[2017-05-31 16:40:01,400][gdb1][DEBUG ] find the location of an executable
[2017-05-31 16:40:01,401][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 16:40:01,401][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-05-31 16:40:01,401][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 16:40:01,403][gdb1][WARNING] osd keyring does not exist yet, creating one
[2017-05-31 16:40:01,404][gdb1][DEBUG ] create a keyring file
[2017-05-31 16:40:01,405][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /dev/xvdb journal None activate True
[2017-05-31 16:40:01,405][gdb1][DEBUG ] find the location of an executable
[2017-05-31 16:40:01,407][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --zap-disk --bluestore --cluster ceph --fs-type xfs -- /dev/xvdb
[2017-05-31 16:40:01,578][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 16:40:01,578][gdb1][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:40:01,578][gdb1][WARNING] set_type: Will colocate block with data on /dev/xvdb
[2017-05-31 16:40:01,578][gdb1][WARNING] command: Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup bluestore_block_size
[2017-05-31 16:40:01,578][gdb1][WARNING] command: Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup bluestore_block_db_size
[2017-05-31 16:40:01,579][gdb1][WARNING] command: Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup bluestore_block_wal_size
[2017-05-31 16:40:01,579][gdb1][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:40:01,579][gdb1][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:40:01,579][gdb1][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:40:01,579][gdb1][WARNING] command: Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mkfs_options_xfs
[2017-05-31 16:40:01,579][gdb1][WARNING] command: Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_fs_mkfs_options_xfs
[2017-05-31 16:40:01,586][gdb1][WARNING] command: Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_mount_options_xfs
[2017-05-31 16:40:01,594][gdb1][WARNING] command: Running command: /usr/bin/ceph-conf --cluster=ceph --name=osd. --lookup osd_fs_mount_options_xfs
[2017-05-31 16:40:01,601][gdb1][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:40:01,602][gdb1][WARNING] zap: Writing zeros to existing partitions on /dev/xvdb
[2017-05-31 16:40:01,602][gdb1][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:40:01,602][gdb1][WARNING] zap: Zapping partition table on /dev/xvdb
[2017-05-31 16:40:01,602][gdb1][WARNING] command_check_call: Running command: /sbin/sgdisk --zap-all -- /dev/xvdb
[2017-05-31 16:40:01,605][gdb1][WARNING] Caution: invalid backup GPT header, but valid main header; regenerating
[2017-05-31 16:40:01,605][gdb1][WARNING] backup header from main header.
[2017-05-31 16:40:01,605][gdb1][WARNING] 
[2017-05-31 16:40:02,673][gdb1][DEBUG ] ****************************************************************************
[2017-05-31 16:40:02,673][gdb1][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk
[2017-05-31 16:40:02,673][gdb1][DEBUG ] verification and recovery are STRONGLY recommended.
[2017-05-31 16:40:02,673][gdb1][DEBUG ] ****************************************************************************
[2017-05-31 16:40:02,673][gdb1][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or
[2017-05-31 16:40:02,674][gdb1][DEBUG ] other utilities.
[2017-05-31 16:40:02,674][gdb1][WARNING] command_check_call: Running command: /sbin/sgdisk --clear --mbrtogpt -- /dev/xvdb
[2017-05-31 16:40:03,641][gdb1][DEBUG ] Creating new GPT entries.
[2017-05-31 16:40:03,641][gdb1][DEBUG ] The operation has completed successfully.
[2017-05-31 16:40:03,641][gdb1][WARNING] update_partition: Calling partprobe on zapped device /dev/xvdb
[2017-05-31 16:40:03,641][gdb1][WARNING] command_check_call: Running command: /sbin/udevadm settle --timeout=600
[2017-05-31 16:40:03,657][gdb1][WARNING] command: Running command: /usr/bin/flock -s /dev/xvdb /sbin/partprobe /dev/xvdb
[2017-05-31 16:40:03,689][gdb1][WARNING] command_check_call: Running command: /sbin/udevadm settle --timeout=600
[2017-05-31 16:40:03,692][gdb1][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:40:03,692][gdb1][WARNING] set_data_partition: Creating osd partition on /dev/xvdb
[2017-05-31 16:40:03,692][gdb1][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:40:03,693][gdb1][WARNING] ptype_tobe_for_name: name = data
[2017-05-31 16:40:03,693][gdb1][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:40:03,693][gdb1][WARNING] create_partition: Creating data partition num 1 size 100 on /dev/xvdb
[2017-05-31 16:40:03,693][gdb1][WARNING] command_check_call: Running command: /sbin/sgdisk --new=1:0:+100M --change-name=1:ceph data --partition-guid=1:03829711-0e84-467b-b718-52c76eb24320 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be --mbrtogpt -- /dev/xvdb
[2017-05-31 16:40:04,710][gdb1][DEBUG ] Setting name!
[2017-05-31 16:40:04,710][gdb1][DEBUG ] partNum is 0
[2017-05-31 16:40:04,710][gdb1][DEBUG ] REALLY setting name!
[2017-05-31 16:40:04,711][gdb1][DEBUG ] The operation has completed successfully.
[2017-05-31 16:40:04,711][gdb1][WARNING] update_partition: Calling partprobe on created device /dev/xvdb
[2017-05-31 16:40:04,711][gdb1][WARNING] command_check_call: Running command: /sbin/udevadm settle --timeout=600
[2017-05-31 16:40:04,775][gdb1][WARNING] command: Running command: /usr/bin/flock -s /dev/xvdb /sbin/partprobe /dev/xvdb
[2017-05-31 16:40:04,889][gdb1][WARNING] command_check_call: Running command: /sbin/udevadm settle --timeout=600
[2017-05-31 16:40:04,905][gdb1][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:40:04,905][gdb1][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:40:04,905][gdb1][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb1 uuid path is /sys/dev/block/202:17/dm/uuid
[2017-05-31 16:40:04,905][gdb1][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:40:04,905][gdb1][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:40:04,905][gdb1][WARNING] ptype_tobe_for_name: name = block
[2017-05-31 16:40:04,905][gdb1][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:40:04,905][gdb1][WARNING] create_partition: Creating block partition num 2 size 0 on /dev/xvdb
[2017-05-31 16:40:04,906][gdb1][WARNING] command_check_call: Running command: /sbin/sgdisk --largest-new=2 --change-name=2:ceph block --partition-guid=2:ac2260d3-0972-46d4-9786-44e431798028 --typecode=2:cafecafe-9b03-4f30-b4c6-b4b80ceff106 --mbrtogpt -- /dev/xvdb
[2017-05-31 16:40:05,923][gdb1][DEBUG ] Setting name!
[2017-05-31 16:40:05,923][gdb1][DEBUG ] partNum is 1
[2017-05-31 16:40:05,923][gdb1][DEBUG ] REALLY setting name!
[2017-05-31 16:40:05,923][gdb1][DEBUG ] The operation has completed successfully.
[2017-05-31 16:40:05,924][gdb1][WARNING] update_partition: Calling partprobe on created device /dev/xvdb
[2017-05-31 16:40:05,924][gdb1][WARNING] command_check_call: Running command: /sbin/udevadm settle --timeout=600
[2017-05-31 16:40:06,138][gdb1][WARNING] command: Running command: /usr/bin/flock -s /dev/xvdb /sbin/partprobe /dev/xvdb
[2017-05-31 16:40:06,353][gdb1][WARNING] command_check_call: Running command: /sbin/udevadm settle --timeout=600
[2017-05-31 16:40:06,567][gdb1][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:40:06,568][gdb1][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:40:06,568][gdb1][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb2 uuid path is /sys/dev/block/202:18/dm/uuid
[2017-05-31 16:40:06,568][gdb1][WARNING] prepare_device: Block is GPT partition /dev/disk/by-partuuid/ac2260d3-0972-46d4-9786-44e431798028
[2017-05-31 16:40:06,568][gdb1][WARNING] command_check_call: Running command: /sbin/sgdisk --typecode=2:cafecafe-9b03-4f30-b4c6-b4b80ceff106 -- /dev/xvdb
[2017-05-31 16:40:07,585][gdb1][DEBUG ] The operation has completed successfully.
[2017-05-31 16:40:07,585][gdb1][WARNING] update_partition: Calling partprobe on prepared device /dev/xvdb
[2017-05-31 16:40:07,585][gdb1][WARNING] command_check_call: Running command: /sbin/udevadm settle --timeout=600
[2017-05-31 16:40:07,800][gdb1][WARNING] command: Running command: /usr/bin/flock -s /dev/xvdb /sbin/partprobe /dev/xvdb
[2017-05-31 16:40:07,965][gdb1][WARNING] command_check_call: Running command: /sbin/udevadm settle --timeout=600
[2017-05-31 16:40:08,179][gdb1][WARNING] prepare_device: Block is GPT partition /dev/disk/by-partuuid/ac2260d3-0972-46d4-9786-44e431798028
[2017-05-31 16:40:08,179][gdb1][WARNING] populate_data_path_device: Creating xfs fs on /dev/xvdb1
[2017-05-31 16:40:08,179][gdb1][WARNING] command_check_call: Running command: /sbin/mkfs -t xfs -f -i size=2048 -- /dev/xvdb1
[2017-05-31 16:40:08,243][gdb1][DEBUG ] meta-data=/dev/xvdb1             isize=2048   agcount=4, agsize=6400 blks
[2017-05-31 16:40:08,244][gdb1][DEBUG ]          =                       sectsz=512   attr=2, projid32bit=1
[2017-05-31 16:40:08,244][gdb1][DEBUG ]          =                       crc=1        finobt=1, sparse=0
[2017-05-31 16:40:08,244][gdb1][DEBUG ] data     =                       bsize=4096   blocks=25600, imaxpct=25
[2017-05-31 16:40:08,244][gdb1][DEBUG ]          =                       sunit=0      swidth=0 blks
[2017-05-31 16:40:08,244][gdb1][DEBUG ] naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
[2017-05-31 16:40:08,244][gdb1][DEBUG ] log      =internal log           bsize=4096   blocks=864, version=2
[2017-05-31 16:40:08,244][gdb1][DEBUG ]          =                       sectsz=512   sunit=0 blks, lazy-count=1
[2017-05-31 16:40:08,244][gdb1][DEBUG ] realtime =none                   extsz=4096   blocks=0, rtextents=0
[2017-05-31 16:40:08,244][gdb1][WARNING] mount: Mounting /dev/xvdb1 on /var/lib/ceph/tmp/mnt.KBPkbB with options noatime,inode64
[2017-05-31 16:40:08,244][gdb1][WARNING] command_check_call: Running command: /bin/mount -t xfs -o noatime,inode64 -- /dev/xvdb1 /var/lib/ceph/tmp/mnt.KBPkbB
[2017-05-31 16:40:08,276][gdb1][WARNING] populate_data_path: Preparing osd data dir /var/lib/ceph/tmp/mnt.KBPkbB
[2017-05-31 16:40:08,276][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /var/lib/ceph/tmp/mnt.KBPkbB/ceph_fsid.11280.tmp
[2017-05-31 16:40:08,277][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /var/lib/ceph/tmp/mnt.KBPkbB/fsid.11280.tmp
[2017-05-31 16:40:08,278][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /var/lib/ceph/tmp/mnt.KBPkbB/magic.11280.tmp
[2017-05-31 16:40:08,281][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /var/lib/ceph/tmp/mnt.KBPkbB/block_uuid.11280.tmp
[2017-05-31 16:40:08,282][gdb1][WARNING] adjust_symlink: Creating symlink /var/lib/ceph/tmp/mnt.KBPkbB/block -> /dev/disk/by-partuuid/ac2260d3-0972-46d4-9786-44e431798028
[2017-05-31 16:40:08,283][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /var/lib/ceph/tmp/mnt.KBPkbB/type.11280.tmp
[2017-05-31 16:40:08,286][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /var/lib/ceph/tmp/mnt.KBPkbB
[2017-05-31 16:40:08,287][gdb1][WARNING] unmount: Unmounting /var/lib/ceph/tmp/mnt.KBPkbB
[2017-05-31 16:40:08,287][gdb1][WARNING] command_check_call: Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.KBPkbB
[2017-05-31 16:40:08,351][gdb1][WARNING] get_dm_uuid: get_dm_uuid /dev/xvdb uuid path is /sys/dev/block/202:16/dm/uuid
[2017-05-31 16:40:08,351][gdb1][WARNING] command_check_call: Running command: /sbin/sgdisk --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/xvdb
[2017-05-31 16:40:09,369][gdb1][DEBUG ] Warning: The kernel is still using the old partition table.
[2017-05-31 16:40:09,369][gdb1][DEBUG ] The new table will be used at the next reboot or after you
[2017-05-31 16:40:09,369][gdb1][DEBUG ] run partprobe(8) or kpartx(8)
[2017-05-31 16:40:09,369][gdb1][DEBUG ] The operation has completed successfully.
[2017-05-31 16:40:09,369][gdb1][WARNING] update_partition: Calling partprobe on prepared device /dev/xvdb
[2017-05-31 16:40:09,369][gdb1][WARNING] command_check_call: Running command: /sbin/udevadm settle --timeout=600
[2017-05-31 16:40:09,369][gdb1][WARNING] command: Running command: /usr/bin/flock -s /dev/xvdb /sbin/partprobe /dev/xvdb
[2017-05-31 16:40:09,534][gdb1][WARNING] command_check_call: Running command: /sbin/udevadm settle --timeout=600
[2017-05-31 16:40:09,537][gdb1][WARNING] command_check_call: Running command: /sbin/udevadm trigger --action=add --sysname-match xvdb1
[2017-05-31 16:40:09,555][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-05-31 16:40:14,677][gdb1][INFO  ] checking OSD status...
[2017-05-31 16:40:14,677][gdb1][DEBUG ] find the location of an executable
[2017-05-31 16:40:14,680][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 16:40:14,795][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-05-31 16:46:47,903][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 16:46:47,903][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-05-31 16:46:47,903][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 16:46:47,903][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 16:46:47,904][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 16:46:47,904][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 16:46:47,904][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 16:46:47,904][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7a17388fc8>
[2017-05-31 16:46:47,904][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 16:46:47,904][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-05-31 16:46:47,904][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f7a17c9b1b8>
[2017-05-31 16:46:47,904][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 16:46:47,904][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 16:46:47,904][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-05-31 16:46:47,904][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-05-31 16:46:47,904][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-05-31 16:46:47,904][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-05-31 16:46:47,931][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 16:46:47,945][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 16:46:47,946][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 16:46:47,962][gdb3][DEBUG ] detect machine type
[2017-05-31 16:46:47,965][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 16:46:47,965][gdb3][INFO  ] Purging Ceph on gdb3
[2017-05-31 16:46:47,966][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-05-31 16:46:48,004][gdb3][DEBUG ] Reading package lists...
[2017-05-31 16:46:48,168][gdb3][DEBUG ] Building dependency tree...
[2017-05-31 16:46:48,168][gdb3][DEBUG ] Reading state information...
[2017-05-31 16:46:48,232][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-05-31 16:46:48,233][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-05-31 16:46:48,233][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-05-31 16:46:48,233][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-05-31 16:46:48,233][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-05-31 16:46:48,233][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-05-31 16:46:48,233][gdb3][DEBUG ]   linux-headers-4.4.0-1013-aws linux-image-4.4.0-1013-aws ntp python-blinker
[2017-05-31 16:46:48,233][gdb3][DEBUG ]   python-cephfs python-cffi-backend python-chardet python-cryptography
[2017-05-31 16:46:48,233][gdb3][DEBUG ]   python-enum34 python-flask python-idna python-ipaddress python-itsdangerous
[2017-05-31 16:46:48,233][gdb3][DEBUG ]   python-jinja2 python-markupsafe python-ndg-httpsclient python-openssl
[2017-05-31 16:46:48,233][gdb3][DEBUG ]   python-pyasn1 python-pyinotify python-rados python-rbd python-requests
[2017-05-31 16:46:48,233][gdb3][DEBUG ]   python-rgw python-six python-urllib3 python-werkzeug
[2017-05-31 16:46:48,233][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-05-31 16:46:48,297][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-05-31 16:46:48,298][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-05-31 16:46:48,412][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 35 not upgraded.
[2017-05-31 16:46:48,412][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-05-31 16:46:48,444][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 104522 files and directories currently installed.)
[2017-05-31 16:46:48,444][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-05-31 16:46:48,608][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-05-31 16:46:48,722][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-05-31 16:46:48,754][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-05-31 16:46:48,972][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-05-31 16:46:49,091][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-05-31 16:46:49,258][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-05-31 16:46:49,322][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-05-31 16:46:49,338][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-05-31 16:46:49,502][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-05-31 16:46:49,617][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-05-31 16:46:49,619][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-05-31 16:46:49,787][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-05-31 16:46:49,787][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-05-31 16:46:49,951][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-05-31 16:46:50,017][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-05-31 16:46:50,017][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-05-31 16:46:50,131][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu7) ...
[2017-05-31 16:46:50,948][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-05-31 16:46:51,114][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 16:46:51,115][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-05-31 16:46:51,115][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 16:46:51,115][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 16:46:51,115][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 16:46:51,115][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 16:46:51,115][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 16:46:51,115][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fbea0df9710>
[2017-05-31 16:46:51,115][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 16:46:51,115][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-05-31 16:46:51,115][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7fbea1706230>
[2017-05-31 16:46:51,115][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 16:46:51,115][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 16:46:51,116][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-05-31 16:46:51,142][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 16:46:51,156][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 16:46:51,157][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 16:46:51,173][gdb3][DEBUG ] detect machine type
[2017-05-31 16:46:51,176][gdb3][DEBUG ] find the location of an executable
[2017-05-31 16:46:51,192][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 16:46:51,206][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 16:46:51,207][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 16:46:51,223][gdb3][DEBUG ] detect machine type
[2017-05-31 16:46:51,226][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 16:46:51,226][gdb3][INFO  ] purging data on gdb3
[2017-05-31 16:46:51,227][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-05-31 16:46:51,240][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-05-31 16:46:51,412][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 16:46:51,413][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-05-31 16:46:51,413][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 16:46:51,413][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 16:46:51,413][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 16:46:51,413][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 16:46:51,413][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 16:46:51,413][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fc825dd89e0>
[2017-05-31 16:46:51,413][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 16:46:51,413][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7fc82669b848>
[2017-05-31 16:46:51,413][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 16:46:51,413][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 16:47:19,509][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 16:47:19,509][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-05-31 16:47:19,510][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 16:47:19,510][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 16:47:19,510][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 16:47:19,510][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 16:47:19,510][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 16:47:19,510][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7bd7c8b560>
[2017-05-31 16:47:19,510][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 16:47:19,510][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-05-31 16:47:19,510][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-05-31 16:47:19,510][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f7bd830f758>
[2017-05-31 16:47:19,510][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-05-31 16:47:19,510][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 16:47:19,510][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-05-31 16:47:19,511][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 16:47:19,511][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-05-31 16:47:19,511][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-05-31 16:47:19,511][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-05-31 16:47:19,537][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 16:47:19,551][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 16:47:19,552][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 16:47:19,568][gdb3][DEBUG ] detect machine type
[2017-05-31 16:47:19,571][gdb3][DEBUG ] find the location of an executable
[2017-05-31 16:47:19,572][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-05-31 16:47:19,583][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-05-31 16:47:19,589][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-05-31 16:47:19,590][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-05-31 16:47:19,590][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-05-31 16:47:19,590][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-05-31 16:47:19,590][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-05-31 16:47:19,590][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-05-31 16:47:19,590][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-05-31 16:47:19,590][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-05-31 16:47:19,758][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 16:47:19,759][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-05-31 16:47:19,759][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 16:47:19,759][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 16:47:19,759][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 16:47:19,759][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 16:47:19,759][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-05-31 16:47:19,759][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 16:47:19,759][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f04d9566e60>
[2017-05-31 16:47:19,759][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 16:47:19,759][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f04d953bb18>
[2017-05-31 16:47:19,759][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 16:47:19,760][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-05-31 16:47:19,760][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 16:47:19,760][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-05-31 16:47:19,760][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-05-31 16:47:19,787][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 16:47:19,801][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 16:47:19,802][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 16:47:19,818][gdb3][DEBUG ] detect machine type
[2017-05-31 16:47:19,821][gdb3][DEBUG ] find the location of an executable
[2017-05-31 16:47:19,821][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-05-31 16:47:19,821][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-05-31 16:47:19,821][gdb3][DEBUG ] get remote short hostname
[2017-05-31 16:47:19,822][gdb3][DEBUG ] deploying mon to gdb3
[2017-05-31 16:47:19,822][gdb3][DEBUG ] get remote short hostname
[2017-05-31 16:47:19,822][gdb3][DEBUG ] remote hostname: gdb3
[2017-05-31 16:47:19,823][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 16:47:19,824][gdb3][DEBUG ] create the mon path if it does not exist
[2017-05-31 16:47:19,824][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-05-31 16:47:19,825][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-05-31 16:47:19,825][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-05-31 16:47:19,825][gdb3][DEBUG ] create the monitor keyring file
[2017-05-31 16:47:19,826][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-05-31 16:47:19,864][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-05-31 16:47:19,865][gdb3][DEBUG ] ceph-mon: set fsid to da581514-b214-4b7a-baef-020d0e69b258
[2017-05-31 16:47:19,868][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-05-31 16:47:19,871][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-05-31 16:47:19,872][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-05-31 16:47:19,872][gdb3][DEBUG ] create the init path if it does not exist
[2017-05-31 16:47:19,873][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-05-31 16:47:19,941][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-05-31 16:47:20,013][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-05-31 16:47:22,083][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 16:47:22,148][gdb3][DEBUG ] ********************************************************************************
[2017-05-31 16:47:22,149][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-05-31 16:47:22,149][gdb3][DEBUG ] {
[2017-05-31 16:47:22,149][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-05-31 16:47:22,149][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-05-31 16:47:22,150][gdb3][DEBUG ]   "features": {
[2017-05-31 16:47:22,150][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-05-31 16:47:22,150][gdb3][DEBUG ]     "quorum_mon": [
[2017-05-31 16:47:22,150][gdb3][DEBUG ]       "kraken", 
[2017-05-31 16:47:22,150][gdb3][DEBUG ]       "luminous"
[2017-05-31 16:47:22,150][gdb3][DEBUG ]     ], 
[2017-05-31 16:47:22,150][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-05-31 16:47:22,150][gdb3][DEBUG ]     "required_mon": [
[2017-05-31 16:47:22,150][gdb3][DEBUG ]       "kraken", 
[2017-05-31 16:47:22,150][gdb3][DEBUG ]       "luminous"
[2017-05-31 16:47:22,150][gdb3][DEBUG ]     ]
[2017-05-31 16:47:22,151][gdb3][DEBUG ]   }, 
[2017-05-31 16:47:22,151][gdb3][DEBUG ]   "monmap": {
[2017-05-31 16:47:22,151][gdb3][DEBUG ]     "created": "2017-05-31 16:47:19.850297", 
[2017-05-31 16:47:22,151][gdb3][DEBUG ]     "epoch": 2, 
[2017-05-31 16:47:22,151][gdb3][DEBUG ]     "features": {
[2017-05-31 16:47:22,151][gdb3][DEBUG ]       "optional": [], 
[2017-05-31 16:47:22,151][gdb3][DEBUG ]       "persistent": [
[2017-05-31 16:47:22,151][gdb3][DEBUG ]         "kraken", 
[2017-05-31 16:47:22,151][gdb3][DEBUG ]         "luminous"
[2017-05-31 16:47:22,152][gdb3][DEBUG ]       ]
[2017-05-31 16:47:22,152][gdb3][DEBUG ]     }, 
[2017-05-31 16:47:22,152][gdb3][DEBUG ]     "fsid": "da581514-b214-4b7a-baef-020d0e69b258", 
[2017-05-31 16:47:22,152][gdb3][DEBUG ]     "modified": "2017-05-31 16:47:20.102387", 
[2017-05-31 16:47:22,152][gdb3][DEBUG ]     "mons": [
[2017-05-31 16:47:22,152][gdb3][DEBUG ]       {
[2017-05-31 16:47:22,152][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-05-31 16:47:22,152][gdb3][DEBUG ]         "name": "gdb3", 
[2017-05-31 16:47:22,152][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-05-31 16:47:22,152][gdb3][DEBUG ]         "rank": 0
[2017-05-31 16:47:22,152][gdb3][DEBUG ]       }
[2017-05-31 16:47:22,152][gdb3][DEBUG ]     ]
[2017-05-31 16:47:22,152][gdb3][DEBUG ]   }, 
[2017-05-31 16:47:22,152][gdb3][DEBUG ]   "name": "gdb3", 
[2017-05-31 16:47:22,152][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-05-31 16:47:22,153][gdb3][DEBUG ]   "quorum": [
[2017-05-31 16:47:22,153][gdb3][DEBUG ]     0
[2017-05-31 16:47:22,153][gdb3][DEBUG ]   ], 
[2017-05-31 16:47:22,153][gdb3][DEBUG ]   "rank": 0, 
[2017-05-31 16:47:22,153][gdb3][DEBUG ]   "state": "leader", 
[2017-05-31 16:47:22,153][gdb3][DEBUG ]   "sync_provider": []
[2017-05-31 16:47:22,153][gdb3][DEBUG ] }
[2017-05-31 16:47:22,153][gdb3][DEBUG ] ********************************************************************************
[2017-05-31 16:47:22,153][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-05-31 16:47:22,154][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 16:47:22,219][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-05-31 16:47:22,234][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 16:47:22,249][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 16:47:22,249][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 16:47:22,266][gdb3][DEBUG ] detect machine type
[2017-05-31 16:47:22,269][gdb3][DEBUG ] find the location of an executable
[2017-05-31 16:47:22,270][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 16:47:22,335][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-05-31 16:47:22,335][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-05-31 16:47:22,335][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-05-31 16:47:22,337][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpUI2eIB
[2017-05-31 16:47:22,352][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 16:47:22,367][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 16:47:22,367][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 16:47:22,384][gdb3][DEBUG ] detect machine type
[2017-05-31 16:47:22,386][gdb3][DEBUG ] get remote short hostname
[2017-05-31 16:47:22,387][gdb3][DEBUG ] fetch remote file
[2017-05-31 16:47:22,388][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 16:47:22,454][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-05-31 16:47:22,620][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-05-31 16:47:22,786][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-05-31 16:47:22,952][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-05-31 16:47:23,120][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-05-31 16:47:23,286][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-05-31 16:47:23,452][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-05-31 16:47:23,618][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-05-31 16:47:23,785][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-05-31 16:47:23,951][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-05-31 16:47:24,116][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-05-31 16:47:24,116][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-05-31 16:47:24,116][ceph_deploy.gatherkeys][INFO  ] Replacing 'ceph.bootstrap-mgr.keyring' and backing up old key as 'ceph.bootstrap-mgr.keyring-20170531164724'
[2017-05-31 16:47:24,117][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-05-31 16:47:24,117][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-05-31 16:47:24,117][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-05-31 16:47:24,117][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpUI2eIB
[2017-05-31 16:47:24,301][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 16:47:24,301][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-05-31 16:47:24,301][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 16:47:24,302][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 16:47:24,302][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 16:47:24,302][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 16:47:24,302][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 16:47:24,302][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fcf888e5518>
[2017-05-31 16:47:24,302][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 16:47:24,302][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-05-31 16:47:24,302][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fcf891fc938>
[2017-05-31 16:47:24,302][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 16:47:24,302][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 16:47:24,302][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-05-31 16:47:24,329][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 16:47:24,343][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 16:47:24,344][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 16:47:24,360][gdb3][DEBUG ] detect machine type
[2017-05-31 16:47:24,363][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 16:47:32,107][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 16:47:32,107][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf osd create gdb0:/mnt/memstore
[2017-05-31 16:47:32,107][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 16:47:32,107][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 16:47:32,107][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 16:47:32,107][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 16:47:32,107][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 16:47:32,107][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 16:47:32,107][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 16:47:32,107][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 16:47:32,108][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 16:47:32,108][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-05-31 16:47:32,108][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 16:47:32,108][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 16:47:32,108][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f2b31291908>
[2017-05-31 16:47:32,108][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 16:47:32,108][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 16:47:32,108][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f2b314e7aa0>
[2017-05-31 16:47:32,108][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 16:47:32,108][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 16:47:32,108][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 16:47:32,108][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 16:47:32,350][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 16:47:32,578][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 16:47:32,578][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 16:47:32,594][gdb0][DEBUG ] detect machine type
[2017-05-31 16:47:32,598][gdb0][DEBUG ] find the location of an executable
[2017-05-31 16:47:32,598][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 16:47:32,599][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 16:47:32,599][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 16:47:32,601][gdb0][WARNING] osd keyring does not exist yet, creating one
[2017-05-31 16:47:32,601][gdb0][DEBUG ] create a keyring file
[2017-05-31 16:47:32,603][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate True
[2017-05-31 16:47:32,603][gdb0][DEBUG ] find the location of an executable
[2017-05-31 16:47:32,605][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 16:47:32,725][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 16:47:32,728][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 16:47:32,744][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 16:47:32,760][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 16:47:32,767][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 16:47:32,783][gdb0][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-05-31 16:47:32,791][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.9239.tmp
[2017-05-31 16:47:32,792][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.9239.tmp
[2017-05-31 16:47:32,795][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.9239.tmp
[2017-05-31 16:47:32,813][gdb0][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-05-31 16:47:37,885][gdb0][INFO  ] checking OSD status...
[2017-05-31 16:47:37,885][gdb0][DEBUG ] find the location of an executable
[2017-05-31 16:47:37,887][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 16:47:37,952][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-05-31 16:47:53,911][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 16:47:53,911][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf osd create gdb1:/mnt/memstore
[2017-05-31 16:47:53,911][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 16:47:53,911][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 16:47:53,911][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 16:47:53,911][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 16:47:53,911][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 16:47:53,912][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 16:47:53,912][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 16:47:53,912][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 16:47:53,912][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 16:47:53,912][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-05-31 16:47:53,912][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 16:47:53,912][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 16:47:53,912][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f15482da908>
[2017-05-31 16:47:53,912][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 16:47:53,912][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 16:47:53,912][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f1548530aa0>
[2017-05-31 16:47:53,912][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 16:47:53,912][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 16:47:53,912][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 16:47:53,913][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 16:47:54,155][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 16:47:54,383][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 16:47:54,383][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 16:47:54,400][gdb1][DEBUG ] detect machine type
[2017-05-31 16:47:54,404][gdb1][DEBUG ] find the location of an executable
[2017-05-31 16:47:54,405][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 16:47:54,405][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-05-31 16:47:54,405][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 16:47:54,407][gdb1][WARNING] osd keyring does not exist yet, creating one
[2017-05-31 16:47:54,407][gdb1][DEBUG ] create a keyring file
[2017-05-31 16:47:54,409][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate True
[2017-05-31 16:47:54,409][gdb1][DEBUG ] find the location of an executable
[2017-05-31 16:47:54,411][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 16:47:54,582][gdb1][WARNING] Traceback (most recent call last):
[2017-05-31 16:47:54,582][gdb1][WARNING]   File "/usr/local/bin/ceph-disk", line 9, in <module>
[2017-05-31 16:47:54,582][gdb1][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 16:47:54,582][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5653, in run
[2017-05-31 16:47:54,582][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5604, in main
[2017-05-31 16:47:54,582][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 2029, in main
[2017-05-31 16:47:54,582][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 2025, in factory
[2017-05-31 16:47:54,582][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 2037, in __init__
[2017-05-31 16:47:54,582][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 2739, in __init__
[2017-05-31 16:47:54,582][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 2747, in set_type
[2017-05-31 16:47:54,583][gdb1][WARNING] OSError: [Errno 2] No such file or directory: '/mnt/memstore'
[2017-05-31 16:47:54,583][gdb1][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 16:47:54,583][ceph_deploy.osd][ERROR ] Failed to execute command: /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 16:47:54,583][ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs

[2017-05-31 16:48:36,389][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 16:48:36,390][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf osd create gdb1:/mnt/memstore
[2017-05-31 16:48:36,390][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 16:48:36,390][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 16:48:36,390][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 16:48:36,390][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 16:48:36,390][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 16:48:36,390][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 16:48:36,390][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 16:48:36,390][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 16:48:36,390][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 16:48:36,390][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-05-31 16:48:36,390][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 16:48:36,390][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 16:48:36,390][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa51bbda908>
[2017-05-31 16:48:36,390][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 16:48:36,391][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 16:48:36,391][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fa51be30aa0>
[2017-05-31 16:48:36,391][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 16:48:36,391][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 16:48:36,391][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 16:48:36,391][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 16:48:36,632][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 16:48:36,862][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 16:48:36,863][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 16:48:36,879][gdb1][DEBUG ] detect machine type
[2017-05-31 16:48:36,883][gdb1][DEBUG ] find the location of an executable
[2017-05-31 16:48:36,884][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 16:48:36,884][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-05-31 16:48:36,885][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 16:48:36,887][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate True
[2017-05-31 16:48:36,887][gdb1][DEBUG ] find the location of an executable
[2017-05-31 16:48:36,889][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 16:48:37,009][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 16:48:37,025][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 16:48:37,041][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 16:48:37,056][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 16:48:37,064][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 16:48:37,080][gdb1][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-05-31 16:48:37,080][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.12243.tmp
[2017-05-31 16:48:37,081][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.12243.tmp
[2017-05-31 16:48:37,084][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.12243.tmp
[2017-05-31 16:48:37,102][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-05-31 16:48:42,174][gdb1][INFO  ] checking OSD status...
[2017-05-31 16:48:42,175][gdb1][DEBUG ] find the location of an executable
[2017-05-31 16:48:42,177][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 16:48:42,292][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-05-31 17:07:50,298][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:07:50,298][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-05-31 17:07:50,298][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:07:50,298][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:07:50,298][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:07:50,298][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:07:50,298][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:07:50,298][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fd029a82fc8>
[2017-05-31 17:07:50,298][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:07:50,298][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-05-31 17:07:50,299][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7fd02a3951b8>
[2017-05-31 17:07:50,299][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:07:50,299][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:07:50,299][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-05-31 17:07:50,299][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-05-31 17:07:50,299][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-05-31 17:07:50,299][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-05-31 17:07:50,325][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 17:07:50,339][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 17:07:50,339][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 17:07:50,356][gdb3][DEBUG ] detect machine type
[2017-05-31 17:07:50,358][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:07:50,358][gdb3][INFO  ] Purging Ceph on gdb3
[2017-05-31 17:07:50,359][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-05-31 17:07:50,397][gdb3][DEBUG ] Reading package lists...
[2017-05-31 17:07:50,562][gdb3][DEBUG ] Building dependency tree...
[2017-05-31 17:07:50,562][gdb3][DEBUG ] Reading state information...
[2017-05-31 17:07:50,626][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-05-31 17:07:50,626][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-05-31 17:07:50,626][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-05-31 17:07:50,626][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-05-31 17:07:50,627][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-05-31 17:07:50,627][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-05-31 17:07:50,627][gdb3][DEBUG ]   linux-headers-4.4.0-1013-aws linux-image-4.4.0-1013-aws ntp python-blinker
[2017-05-31 17:07:50,627][gdb3][DEBUG ]   python-cephfs python-cffi-backend python-chardet python-cryptography
[2017-05-31 17:07:50,627][gdb3][DEBUG ]   python-enum34 python-flask python-idna python-ipaddress python-itsdangerous
[2017-05-31 17:07:50,627][gdb3][DEBUG ]   python-jinja2 python-markupsafe python-ndg-httpsclient python-openssl
[2017-05-31 17:07:50,627][gdb3][DEBUG ]   python-pyasn1 python-pyinotify python-rados python-rbd python-requests
[2017-05-31 17:07:50,628][gdb3][DEBUG ]   python-rgw python-six python-urllib3 python-werkzeug
[2017-05-31 17:07:50,628][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-05-31 17:07:50,660][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-05-31 17:07:50,660][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-05-31 17:07:50,774][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 35 not upgraded.
[2017-05-31 17:07:50,774][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-05-31 17:07:50,838][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 104522 files and directories currently installed.)
[2017-05-31 17:07:50,838][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-05-31 17:07:51,003][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-05-31 17:07:51,066][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-05-31 17:07:51,131][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-05-31 17:07:51,346][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-05-31 17:07:51,410][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-05-31 17:07:51,574][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-05-31 17:07:51,639][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-05-31 17:07:51,671][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-05-31 17:07:51,836][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-05-31 17:07:51,900][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-05-31 17:07:51,916][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-05-31 17:07:52,080][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-05-31 17:07:52,112][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-05-31 17:07:52,276][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-05-31 17:07:52,308][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-05-31 17:07:52,316][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-05-31 17:07:52,430][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu7) ...
[2017-05-31 17:07:53,246][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-05-31 17:07:53,410][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:07:53,410][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-05-31 17:07:53,410][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:07:53,410][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:07:53,410][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:07:53,410][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:07:53,411][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:07:53,411][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f32ed785710>
[2017-05-31 17:07:53,411][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:07:53,411][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-05-31 17:07:53,411][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f32ee092230>
[2017-05-31 17:07:53,411][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:07:53,411][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:07:53,411][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-05-31 17:07:53,437][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 17:07:53,451][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 17:07:53,451][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 17:07:53,468][gdb3][DEBUG ] detect machine type
[2017-05-31 17:07:53,470][gdb3][DEBUG ] find the location of an executable
[2017-05-31 17:07:53,485][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 17:07:53,500][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 17:07:53,500][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 17:07:53,517][gdb3][DEBUG ] detect machine type
[2017-05-31 17:07:53,519][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:07:53,519][gdb3][INFO  ] purging data on gdb3
[2017-05-31 17:07:53,520][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-05-31 17:07:53,533][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-05-31 17:07:53,702][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:07:53,703][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-05-31 17:07:53,703][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:07:53,703][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:07:53,703][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:07:53,703][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:07:53,703][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:07:53,703][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fc6007329e0>
[2017-05-31 17:07:53,703][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:07:53,703][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7fc600ff5848>
[2017-05-31 17:07:53,703][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:07:53,703][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:08:11,875][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:08:11,875][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-05-31 17:08:11,875][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:08:11,875][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:08:11,875][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:08:11,875][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:08:11,875][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:08:11,876][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe3424ff560>
[2017-05-31 17:08:11,876][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:08:11,876][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-05-31 17:08:11,876][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-05-31 17:08:11,876][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7fe342b83758>
[2017-05-31 17:08:11,876][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-05-31 17:08:11,876][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:08:11,876][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-05-31 17:08:11,876][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:08:11,876][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-05-31 17:08:11,876][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-05-31 17:08:11,876][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-05-31 17:08:11,903][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 17:08:11,917][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 17:08:11,917][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 17:08:11,934][gdb3][DEBUG ] detect machine type
[2017-05-31 17:08:11,936][gdb3][DEBUG ] find the location of an executable
[2017-05-31 17:08:11,937][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-05-31 17:08:11,949][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-05-31 17:08:11,955][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-05-31 17:08:11,955][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-05-31 17:08:11,955][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-05-31 17:08:11,955][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-05-31 17:08:11,955][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-05-31 17:08:11,955][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-05-31 17:08:11,956][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-05-31 17:08:11,956][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-05-31 17:08:12,122][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:08:12,122][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-05-31 17:08:12,122][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:08:12,122][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:08:12,123][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:08:12,123][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:08:12,123][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-05-31 17:08:12,123][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:08:12,123][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f350509de60>
[2017-05-31 17:08:12,123][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:08:12,123][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f3505072b18>
[2017-05-31 17:08:12,123][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:08:12,123][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-05-31 17:08:12,123][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:08:12,124][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-05-31 17:08:12,124][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-05-31 17:08:12,150][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 17:08:12,164][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 17:08:12,165][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 17:08:12,181][gdb3][DEBUG ] detect machine type
[2017-05-31 17:08:12,183][gdb3][DEBUG ] find the location of an executable
[2017-05-31 17:08:12,184][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-05-31 17:08:12,184][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-05-31 17:08:12,184][gdb3][DEBUG ] get remote short hostname
[2017-05-31 17:08:12,184][gdb3][DEBUG ] deploying mon to gdb3
[2017-05-31 17:08:12,184][gdb3][DEBUG ] get remote short hostname
[2017-05-31 17:08:12,185][gdb3][DEBUG ] remote hostname: gdb3
[2017-05-31 17:08:12,185][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:08:12,186][gdb3][DEBUG ] create the mon path if it does not exist
[2017-05-31 17:08:12,187][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-05-31 17:08:12,187][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-05-31 17:08:12,187][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-05-31 17:08:12,188][gdb3][DEBUG ] create the monitor keyring file
[2017-05-31 17:08:12,189][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-05-31 17:08:12,227][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-05-31 17:08:12,227][gdb3][DEBUG ] ceph-mon: set fsid to ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 17:08:12,230][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-05-31 17:08:12,234][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-05-31 17:08:12,234][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-05-31 17:08:12,234][gdb3][DEBUG ] create the init path if it does not exist
[2017-05-31 17:08:12,235][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-05-31 17:08:12,305][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-05-31 17:08:12,373][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-05-31 17:08:14,443][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 17:08:14,508][gdb3][DEBUG ] ********************************************************************************
[2017-05-31 17:08:14,508][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-05-31 17:08:14,508][gdb3][DEBUG ] {
[2017-05-31 17:08:14,508][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-05-31 17:08:14,508][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-05-31 17:08:14,508][gdb3][DEBUG ]   "features": {
[2017-05-31 17:08:14,508][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-05-31 17:08:14,509][gdb3][DEBUG ]     "quorum_mon": [
[2017-05-31 17:08:14,509][gdb3][DEBUG ]       "kraken", 
[2017-05-31 17:08:14,509][gdb3][DEBUG ]       "luminous"
[2017-05-31 17:08:14,509][gdb3][DEBUG ]     ], 
[2017-05-31 17:08:14,509][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-05-31 17:08:14,509][gdb3][DEBUG ]     "required_mon": [
[2017-05-31 17:08:14,509][gdb3][DEBUG ]       "kraken", 
[2017-05-31 17:08:14,509][gdb3][DEBUG ]       "luminous"
[2017-05-31 17:08:14,509][gdb3][DEBUG ]     ]
[2017-05-31 17:08:14,509][gdb3][DEBUG ]   }, 
[2017-05-31 17:08:14,509][gdb3][DEBUG ]   "monmap": {
[2017-05-31 17:08:14,509][gdb3][DEBUG ]     "created": "2017-05-31 17:08:12.212153", 
[2017-05-31 17:08:14,509][gdb3][DEBUG ]     "epoch": 2, 
[2017-05-31 17:08:14,509][gdb3][DEBUG ]     "features": {
[2017-05-31 17:08:14,509][gdb3][DEBUG ]       "optional": [], 
[2017-05-31 17:08:14,509][gdb3][DEBUG ]       "persistent": [
[2017-05-31 17:08:14,510][gdb3][DEBUG ]         "kraken", 
[2017-05-31 17:08:14,510][gdb3][DEBUG ]         "luminous"
[2017-05-31 17:08:14,510][gdb3][DEBUG ]       ]
[2017-05-31 17:08:14,510][gdb3][DEBUG ]     }, 
[2017-05-31 17:08:14,510][gdb3][DEBUG ]     "fsid": "ca3e0a81-2fd3-4069-bf21-8407a86a4dd3", 
[2017-05-31 17:08:14,510][gdb3][DEBUG ]     "modified": "2017-05-31 17:08:12.455156", 
[2017-05-31 17:08:14,510][gdb3][DEBUG ]     "mons": [
[2017-05-31 17:08:14,510][gdb3][DEBUG ]       {
[2017-05-31 17:08:14,510][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-05-31 17:08:14,510][gdb3][DEBUG ]         "name": "gdb3", 
[2017-05-31 17:08:14,510][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-05-31 17:08:14,510][gdb3][DEBUG ]         "rank": 0
[2017-05-31 17:08:14,510][gdb3][DEBUG ]       }
[2017-05-31 17:08:14,510][gdb3][DEBUG ]     ]
[2017-05-31 17:08:14,510][gdb3][DEBUG ]   }, 
[2017-05-31 17:08:14,510][gdb3][DEBUG ]   "name": "gdb3", 
[2017-05-31 17:08:14,510][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-05-31 17:08:14,511][gdb3][DEBUG ]   "quorum": [
[2017-05-31 17:08:14,511][gdb3][DEBUG ]     0
[2017-05-31 17:08:14,511][gdb3][DEBUG ]   ], 
[2017-05-31 17:08:14,511][gdb3][DEBUG ]   "rank": 0, 
[2017-05-31 17:08:14,511][gdb3][DEBUG ]   "state": "leader", 
[2017-05-31 17:08:14,511][gdb3][DEBUG ]   "sync_provider": []
[2017-05-31 17:08:14,511][gdb3][DEBUG ] }
[2017-05-31 17:08:14,511][gdb3][DEBUG ] ********************************************************************************
[2017-05-31 17:08:14,511][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-05-31 17:08:14,512][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 17:08:14,577][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-05-31 17:08:14,592][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 17:08:14,607][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 17:08:14,607][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 17:08:14,624][gdb3][DEBUG ] detect machine type
[2017-05-31 17:08:14,627][gdb3][DEBUG ] find the location of an executable
[2017-05-31 17:08:14,628][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 17:08:14,693][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-05-31 17:08:14,693][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-05-31 17:08:14,693][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-05-31 17:08:14,695][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpU1Oj8a
[2017-05-31 17:08:14,710][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 17:08:14,724][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 17:08:14,724][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 17:08:14,740][gdb3][DEBUG ] detect machine type
[2017-05-31 17:08:14,743][gdb3][DEBUG ] get remote short hostname
[2017-05-31 17:08:14,743][gdb3][DEBUG ] fetch remote file
[2017-05-31 17:08:14,744][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 17:08:14,810][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-05-31 17:08:14,976][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-05-31 17:08:15,142][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-05-31 17:08:15,308][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-05-31 17:08:15,475][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-05-31 17:08:15,641][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-05-31 17:08:15,807][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-05-31 17:08:15,973][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-05-31 17:08:16,139][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-05-31 17:08:16,306][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-05-31 17:08:16,471][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-05-31 17:08:16,471][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-05-31 17:08:16,471][ceph_deploy.gatherkeys][INFO  ] Replacing 'ceph.bootstrap-mgr.keyring' and backing up old key as 'ceph.bootstrap-mgr.keyring-20170531170816'
[2017-05-31 17:08:16,472][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-05-31 17:08:16,472][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-05-31 17:08:16,472][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-05-31 17:08:16,472][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpU1Oj8a
[2017-05-31 17:08:16,654][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:08:16,654][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-05-31 17:08:16,654][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:08:16,655][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:08:16,655][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:08:16,655][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:08:16,655][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:08:16,655][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb6f184f518>
[2017-05-31 17:08:16,655][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:08:16,655][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-05-31 17:08:16,655][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fb6f2166938>
[2017-05-31 17:08:16,655][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:08:16,655][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:08:16,655][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-05-31 17:08:16,681][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 17:08:16,696][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 17:08:16,697][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 17:08:16,713][gdb3][DEBUG ] detect machine type
[2017-05-31 17:08:16,715][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:08:30,514][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:08:30,514][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-05-31 17:08:30,514][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:08:30,514][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:08:30,514][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 17:08:30,514][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:08:30,514][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 17:08:30,514][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:08:30,514][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 17:08:30,514][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 17:08:30,515][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:08:30,515][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 17:08:30,515][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 17:08:30,515][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:08:30,515][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0ee519a908>
[2017-05-31 17:08:30,515][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:08:30,515][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 17:08:30,515][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f0ee53f0aa0>
[2017-05-31 17:08:30,515][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:08:30,515][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:08:30,515][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 17:08:30,515][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:08:30,758][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:08:30,982][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:08:30,982][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:08:30,998][gdb0][DEBUG ] detect machine type
[2017-05-31 17:08:31,002][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:08:31,003][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:08:31,003][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 17:08:31,003][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:08:31,005][ceph_deploy.osd][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite
[2017-05-31 17:08:31,005][ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs

[2017-05-31 17:08:41,595][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:08:41,595][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf osd prepare gdb0:/mnt/memstore
[2017-05-31 17:08:41,595][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:08:41,595][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:08:41,595][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 17:08:41,595][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:08:41,595][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 17:08:41,595][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:08:41,595][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 17:08:41,595][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 17:08:41,596][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 17:08:41,596][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 17:08:41,596][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 17:08:41,596][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:08:41,596][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fd061813908>
[2017-05-31 17:08:41,596][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:08:41,596][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 17:08:41,596][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fd061a69aa0>
[2017-05-31 17:08:41,596][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:08:41,596][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:08:41,596][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 17:08:41,596][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:08:41,830][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:08:42,054][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:08:42,054][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:08:42,070][gdb0][DEBUG ] detect machine type
[2017-05-31 17:08:42,074][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:08:42,074][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:08:42,075][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 17:08:42,075][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:08:42,077][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-05-31 17:08:42,077][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:08:42,079][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 17:08:42,199][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:08:42,203][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:08:42,219][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:08:42,234][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:08:42,242][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 17:08:42,258][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-05-31 17:08:47,266][gdb0][INFO  ] checking OSD status...
[2017-05-31 17:08:47,267][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:08:47,269][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 17:08:47,334][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-05-31 17:08:58,043][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:08:58,044][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf osd activate gdb0:/mnt/memstore
[2017-05-31 17:08:58,044][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:08:58,044][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:08:58,044][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:08:58,044][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 17:08:58,044][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 17:08:58,044][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:08:58,044][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f59abf02908>
[2017-05-31 17:08:58,044][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:08:58,044][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f59ac158aa0>
[2017-05-31 17:08:58,044][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:08:58,044][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:08:58,044][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:08:58,045][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:08:58,282][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:08:58,469][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:08:58,470][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:08:58,486][gdb0][DEBUG ] detect machine type
[2017-05-31 17:08:58,489][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:08:58,490][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:08:58,490][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 17:08:58,490][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 17:08:58,491][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:08:58,492][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 17:08:58,612][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 17:08:58,613][gdb0][WARNING] activate: Cluster uuid is da581514-b214-4b7a-baef-020d0e69b258
[2017-05-31 17:08:58,613][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:08:58,614][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 17:08:58,614][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 17:08:58,614][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:08:58,615][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:08:58,615][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 17:08:58,615][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:08:58,615][gdb0][WARNING]     args.func(args)
[2017-05-31 17:08:58,616][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 17:08:58,616][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 17:08:58,616][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 17:08:58,616][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-05-31 17:08:58,616][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3609, in activate
[2017-05-31 17:08:58,617][gdb0][WARNING]     ' with fsid %s' % ceph_fsid)
[2017-05-31 17:08:58,617][gdb0][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid da581514-b214-4b7a-baef-020d0e69b258
[2017-05-31 17:08:58,624][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:08:58,625][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 17:21:03,164][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:21:03,165][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf osd activate gdb0:/mnt/memstore
[2017-05-31 17:21:03,165][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:21:03,165][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:21:03,165][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:21:03,165][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 17:21:03,165][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 17:21:03,165][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:21:03,165][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fae890dc908>
[2017-05-31 17:21:03,165][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:21:03,165][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fae89332aa0>
[2017-05-31 17:21:03,166][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:21:03,166][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:21:03,166][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:21:03,166][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:21:03,406][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:21:03,637][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:21:03,638][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:21:03,654][gdb0][DEBUG ] detect machine type
[2017-05-31 17:21:03,657][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:21:03,658][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:21:03,658][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 17:21:03,658][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 17:21:03,658][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:21:03,660][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 17:21:03,780][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 17:21:03,781][gdb0][WARNING] activate: Cluster uuid is ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 17:21:03,781][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:21:03,782][gdb0][WARNING] activate: Cluster name is ceph
[2017-05-31 17:21:03,782][gdb0][WARNING] activate: OSD uuid is 6a42016a-cb50-44b5-a78b-c0660b317c1f
[2017-05-31 17:21:03,782][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 17:21:03,782][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 6a42016a-cb50-44b5-a78b-c0660b317c1f
[2017-05-31 17:21:03,846][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 17:21:03,846][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 17:21:03,846][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:21:03,847][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:21:03,847][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 17:21:03,847][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:21:03,847][gdb0][WARNING]     args.func(args)
[2017-05-31 17:21:03,847][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 17:21:03,847][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 17:21:03,847][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 17:21:03,847][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-05-31 17:21:03,847][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3625, in activate
[2017-05-31 17:21:03,848][gdb0][WARNING]     keyring=keyring,
[2017-05-31 17:21:03,849][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 1075, in allocate_osd_id
[2017-05-31 17:21:03,849][gdb0][WARNING]     raise Error('ceph osd create failed', e, e.output)
[2017-05-31 17:21:03,849][gdb0][WARNING] ceph_disk.main.Error: Error: ceph osd create failed: Command '/usr/bin/ceph' returned non-zero exit status 1: 2017-05-31 17:21:03.832088 7f463d537700  0 librados: client.bootstrap-osd authentication error (1) Operation not permitted
[2017-05-31 17:21:03,849][gdb0][WARNING] error connecting to the cluster
[2017-05-31 17:21:03,849][gdb0][WARNING] 
[2017-05-31 17:21:03,856][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:21:03,857][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 17:21:24,941][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:21:24,942][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf osd prepare gdb0:/mnt/memstore
[2017-05-31 17:21:24,942][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:21:24,942][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:21:24,942][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 17:21:24,942][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:21:24,942][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 17:21:24,942][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:21:24,942][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 17:21:24,942][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 17:21:24,942][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 17:21:24,942][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 17:21:24,942][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 17:21:24,942][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:21:24,943][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe5b1696908>
[2017-05-31 17:21:24,943][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:21:24,943][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 17:21:24,943][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fe5b18ecaa0>
[2017-05-31 17:21:24,943][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:21:24,943][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:21:24,943][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 17:21:24,943][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:21:25,186][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:21:25,410][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:21:25,410][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:21:25,426][gdb0][DEBUG ] detect machine type
[2017-05-31 17:21:25,430][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:21:25,430][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:21:25,430][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 17:21:25,431][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:21:25,433][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-05-31 17:21:25,433][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:21:25,435][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 17:21:25,555][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:21:25,559][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:21:25,575][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:21:25,590][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:21:25,598][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 17:21:25,614][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-05-31 17:21:30,626][gdb0][INFO  ] checking OSD status...
[2017-05-31 17:21:30,627][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:21:30,629][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 17:21:30,694][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-05-31 17:21:37,853][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:21:37,853][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf osd activate gdb0:/mnt/memstore
[2017-05-31 17:21:37,853][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:21:37,853][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:21:37,853][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:21:37,853][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 17:21:37,853][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 17:21:37,853][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:21:37,854][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7faaaf868908>
[2017-05-31 17:21:37,854][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:21:37,854][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7faaafabeaa0>
[2017-05-31 17:21:37,854][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:21:37,854][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:21:37,854][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:21:37,854][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:21:38,098][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:21:38,325][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:21:38,326][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:21:38,342][gdb0][DEBUG ] detect machine type
[2017-05-31 17:21:38,345][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:21:38,346][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:21:38,346][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 17:21:38,346][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 17:21:38,346][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:21:38,348][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 17:21:38,469][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 17:21:38,469][gdb0][WARNING] activate: Cluster uuid is ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 17:21:38,469][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:21:38,472][gdb0][WARNING] activate: Cluster name is ceph
[2017-05-31 17:21:38,472][gdb0][WARNING] activate: OSD uuid is 6a42016a-cb50-44b5-a78b-c0660b317c1f
[2017-05-31 17:21:38,473][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 17:21:38,473][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 6a42016a-cb50-44b5-a78b-c0660b317c1f
[2017-05-31 17:21:38,537][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 17:21:38,537][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 17:21:38,537][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:21:38,537][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:21:38,537][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 17:21:38,537][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:21:38,537][gdb0][WARNING]     args.func(args)
[2017-05-31 17:21:38,537][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 17:21:38,537][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 17:21:38,537][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 17:21:38,537][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-05-31 17:21:38,538][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3625, in activate
[2017-05-31 17:21:38,538][gdb0][WARNING]     keyring=keyring,
[2017-05-31 17:21:38,538][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 1075, in allocate_osd_id
[2017-05-31 17:21:38,538][gdb0][WARNING]     raise Error('ceph osd create failed', e, e.output)
[2017-05-31 17:21:38,538][gdb0][WARNING] ceph_disk.main.Error: Error: ceph osd create failed: Command '/usr/bin/ceph' returned non-zero exit status 1: 2017-05-31 17:21:38.521237 7fad53326700  0 librados: client.bootstrap-osd authentication error (1) Operation not permitted
[2017-05-31 17:21:38,538][gdb0][WARNING] error connecting to the cluster
[2017-05-31 17:21:38,538][gdb0][WARNING] 
[2017-05-31 17:21:38,546][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:21:38,546][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 17:22:33,708][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:22:33,708][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf osd prepare gdb0:/mnt/memstore
[2017-05-31 17:22:33,709][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:22:33,709][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:22:33,709][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 17:22:33,709][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:22:33,709][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 17:22:33,709][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:22:33,709][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 17:22:33,709][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 17:22:33,710][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 17:22:33,710][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 17:22:33,710][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 17:22:33,710][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:22:33,710][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fc9a79d4908>
[2017-05-31 17:22:33,710][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:22:33,710][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 17:22:33,710][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fc9a7c2aaa0>
[2017-05-31 17:22:33,710][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:22:33,710][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:22:33,711][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 17:22:33,711][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:22:33,955][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:22:34,182][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:22:34,183][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:22:34,199][gdb0][DEBUG ] detect machine type
[2017-05-31 17:22:34,203][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:22:34,204][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:22:34,204][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 17:22:34,204][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:22:34,207][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-05-31 17:22:34,207][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:22:34,209][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 17:22:34,329][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 17:22:34,329][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 17:22:34,329][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:22:34,329][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:22:34,329][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 17:22:34,329][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:22:34,330][gdb0][WARNING]     args.func(args)
[2017-05-31 17:22:34,330][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2029, in main
[2017-05-31 17:22:34,330][gdb0][WARNING]     Prepare.factory(args).prepare()
[2017-05-31 17:22:34,330][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2025, in factory
[2017-05-31 17:22:34,330][gdb0][WARNING]     return PrepareFilestore(args)
[2017-05-31 17:22:34,330][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2037, in __init__
[2017-05-31 17:22:34,330][gdb0][WARNING]     self.data = PrepareFilestoreData(args)
[2017-05-31 17:22:34,330][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2739, in __init__
[2017-05-31 17:22:34,330][gdb0][WARNING]     self.set_type()
[2017-05-31 17:22:34,330][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2747, in set_type
[2017-05-31 17:22:34,330][gdb0][WARNING]     dmode = os.stat(self.args.data).st_mode
[2017-05-31 17:22:34,330][gdb0][WARNING] OSError: [Errno 2] No such file or directory: '/mnt/memstore'
[2017-05-31 17:22:34,334][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:22:34,334][ceph_deploy.osd][ERROR ] Failed to execute command: /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 17:22:34,334][ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs

[2017-05-31 17:23:25,827][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:23:25,827][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf osd prepare gdb0:/home/ubuntu/memstore/
[2017-05-31 17:23:25,827][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:23:25,827][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:23:25,827][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 17:23:25,827][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/home/ubuntu/memstore/', None)]
[2017-05-31 17:23:25,827][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 17:23:25,828][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:23:25,828][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 17:23:25,828][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 17:23:25,828][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 17:23:25,828][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 17:23:25,828][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 17:23:25,828][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:23:25,828][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7ac59bd908>
[2017-05-31 17:23:25,828][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:23:25,828][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 17:23:25,828][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f7ac5c13aa0>
[2017-05-31 17:23:25,828][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:23:25,828][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:23:25,828][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 17:23:25,829][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/home/ubuntu/memstore/:
[2017-05-31 17:23:26,067][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:23:26,291][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:23:26,291][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:23:26,307][gdb0][DEBUG ] detect machine type
[2017-05-31 17:23:26,311][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:23:26,312][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:23:26,312][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 17:23:26,312][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:23:26,315][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /home/ubuntu/memstore/ journal None activate False
[2017-05-31 17:23:26,315][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:23:26,317][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /home/ubuntu/memstore/
[2017-05-31 17:23:26,437][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:23:26,445][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:23:26,460][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:23:26,476][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:23:26,484][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 17:23:26,500][gdb0][WARNING] populate_data_path: Preparing osd data dir /home/ubuntu/memstore/
[2017-05-31 17:23:26,507][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /home/ubuntu/memstore/ceph_fsid.10517.tmp
[2017-05-31 17:23:26,508][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /home/ubuntu/memstore/fsid.10517.tmp
[2017-05-31 17:23:26,512][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /home/ubuntu/memstore/magic.10517.tmp
[2017-05-31 17:23:31,533][gdb0][INFO  ] checking OSD status...
[2017-05-31 17:23:31,533][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:23:31,535][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 17:23:31,600][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-05-31 17:23:41,212][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:23:41,212][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf osd activate gdb0:/home/ubuntu/memstore/
[2017-05-31 17:23:41,212][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:23:41,213][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:23:41,213][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:23:41,213][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 17:23:41,213][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 17:23:41,213][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:23:41,213][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9bd0d86908>
[2017-05-31 17:23:41,213][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:23:41,213][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f9bd0fdcaa0>
[2017-05-31 17:23:41,213][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:23:41,213][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:23:41,213][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/home/ubuntu/memstore/', None)]
[2017-05-31 17:23:41,213][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/home/ubuntu/memstore/:
[2017-05-31 17:23:41,459][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:23:41,686][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:23:41,687][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:23:41,703][gdb0][DEBUG ] detect machine type
[2017-05-31 17:23:41,707][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:23:41,707][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:23:41,707][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /home/ubuntu/memstore/
[2017-05-31 17:23:41,707][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 17:23:41,708][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:23:41,710][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /home/ubuntu/memstore/
[2017-05-31 17:23:41,830][gdb0][WARNING] main_activate: path = /home/ubuntu/memstore/
[2017-05-31 17:23:41,830][gdb0][WARNING] activate: Cluster uuid is ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 17:23:41,830][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:23:41,838][gdb0][WARNING] activate: Cluster name is ceph
[2017-05-31 17:23:41,838][gdb0][WARNING] activate: OSD uuid is c85613d8-2b0e-4250-af41-052f3f698198
[2017-05-31 17:23:41,838][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 17:23:41,838][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise c85613d8-2b0e-4250-af41-052f3f698198
[2017-05-31 17:23:41,952][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 17:23:41,953][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 17:23:41,953][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:23:41,953][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:23:41,953][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 17:23:41,953][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:23:41,953][gdb0][WARNING]     args.func(args)
[2017-05-31 17:23:41,953][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 17:23:41,953][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 17:23:41,953][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 17:23:41,953][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-05-31 17:23:41,953][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3625, in activate
[2017-05-31 17:23:41,953][gdb0][WARNING]     keyring=keyring,
[2017-05-31 17:23:41,954][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 1075, in allocate_osd_id
[2017-05-31 17:23:41,954][gdb0][WARNING]     raise Error('ceph osd create failed', e, e.output)
[2017-05-31 17:23:41,954][gdb0][WARNING] ceph_disk.main.Error: Error: ceph osd create failed: Command '/usr/bin/ceph' returned non-zero exit status 1: 2017-05-31 17:23:41.891883 7f56b0bc8700  0 librados: client.bootstrap-osd authentication error (1) Operation not permitted
[2017-05-31 17:23:41,954][gdb0][WARNING] error connecting to the cluster
[2017-05-31 17:23:41,954][gdb0][WARNING] 
[2017-05-31 17:23:41,954][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:23:41,954][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /home/ubuntu/memstore/

[2017-05-31 17:24:50,365][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:24:50,366][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb0
[2017-05-31 17:24:50,366][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:24:50,366][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:24:50,366][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:24:50,366][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:24:50,366][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:24:50,366][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fd46bc40518>
[2017-05-31 17:24:50,366][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:24:50,366][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-05-31 17:24:50,366][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fd46c557938>
[2017-05-31 17:24:50,366][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:24:50,367][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:24:50,367][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-05-31 17:24:50,611][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:24:50,835][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:24:50,835][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:24:50,851][gdb0][DEBUG ] detect machine type
[2017-05-31 17:24:50,855][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:24:55,871][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:24:55,871][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb1
[2017-05-31 17:24:55,871][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:24:55,871][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:24:55,872][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:24:55,872][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:24:55,872][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:24:55,872][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f68cdf29518>
[2017-05-31 17:24:55,872][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:24:55,872][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-05-31 17:24:55,872][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f68ce840938>
[2017-05-31 17:24:55,872][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:24:55,872][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:24:55,872][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-05-31 17:24:56,112][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 17:24:56,339][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 17:24:56,339][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 17:24:56,355][gdb1][DEBUG ] detect machine type
[2017-05-31 17:24:56,359][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:24:56,361][ceph_deploy.admin][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite
[2017-05-31 17:24:56,361][ceph_deploy][ERROR ] GenericError: Failed to configure 1 admin hosts

[2017-05-31 17:25:01,810][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:25:01,810][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf osd activate gdb0:/home/ubuntu/memstore/
[2017-05-31 17:25:01,810][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:25:01,811][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:25:01,811][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:25:01,811][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 17:25:01,811][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 17:25:01,811][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:25:01,811][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe68c37c908>
[2017-05-31 17:25:01,811][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:25:01,811][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fe68c5d2aa0>
[2017-05-31 17:25:01,811][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:25:01,811][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:25:01,811][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/home/ubuntu/memstore/', None)]
[2017-05-31 17:25:01,811][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/home/ubuntu/memstore/:
[2017-05-31 17:25:02,051][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:25:02,283][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:25:02,283][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:25:02,300][gdb0][DEBUG ] detect machine type
[2017-05-31 17:25:02,304][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:25:02,305][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:25:02,305][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /home/ubuntu/memstore/
[2017-05-31 17:25:02,305][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 17:25:02,305][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:25:02,307][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /home/ubuntu/memstore/
[2017-05-31 17:25:02,428][gdb0][WARNING] main_activate: path = /home/ubuntu/memstore/
[2017-05-31 17:25:02,428][gdb0][WARNING] activate: Cluster uuid is ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 17:25:02,428][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:25:02,436][gdb0][WARNING] activate: Cluster name is ceph
[2017-05-31 17:25:02,436][gdb0][WARNING] activate: OSD uuid is c85613d8-2b0e-4250-af41-052f3f698198
[2017-05-31 17:25:02,436][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 17:25:02,436][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise c85613d8-2b0e-4250-af41-052f3f698198
[2017-05-31 17:25:02,550][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 17:25:02,550][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 17:25:02,550][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:25:02,550][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:25:02,551][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 17:25:02,551][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:25:02,551][gdb0][WARNING]     args.func(args)
[2017-05-31 17:25:02,551][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 17:25:02,551][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 17:25:02,551][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 17:25:02,551][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-05-31 17:25:02,551][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3625, in activate
[2017-05-31 17:25:02,551][gdb0][WARNING]     keyring=keyring,
[2017-05-31 17:25:02,551][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 1075, in allocate_osd_id
[2017-05-31 17:25:02,551][gdb0][WARNING]     raise Error('ceph osd create failed', e, e.output)
[2017-05-31 17:25:02,551][gdb0][WARNING] ceph_disk.main.Error: Error: ceph osd create failed: Command '/usr/bin/ceph' returned non-zero exit status 1: 2017-05-31 17:25:02.489541 7f7c2ad08700  0 librados: client.bootstrap-osd authentication error (1) Operation not permitted
[2017-05-31 17:25:02,551][gdb0][WARNING] error connecting to the cluster
[2017-05-31 17:25:02,552][gdb0][WARNING] 
[2017-05-31 17:25:02,552][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:25:02,552][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /home/ubuntu/memstore/

[2017-05-31 17:26:09,147][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:26:09,428][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb1
[2017-05-31 17:26:09,428][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:26:09,428][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:26:09,428][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:26:09,428][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:26:09,429][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:26:09,429][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fedc15c8518>
[2017-05-31 17:26:09,429][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:26:09,429][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-05-31 17:26:09,429][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fedc1edf938>
[2017-05-31 17:26:09,429][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:26:09,429][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:26:09,429][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-05-31 17:26:09,675][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 17:26:09,867][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 17:26:09,867][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 17:26:09,883][gdb1][DEBUG ] detect machine type
[2017-05-31 17:26:09,887][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:26:09,889][ceph_deploy.admin][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite
[2017-05-31 17:26:09,889][ceph_deploy][ERROR ] GenericError: Failed to configure 1 admin hosts

[2017-05-31 17:26:13,872][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:26:13,872][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb0
[2017-05-31 17:26:13,872][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:26:13,873][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:26:13,873][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:26:13,873][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:26:13,873][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:26:13,873][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fbea7d08518>
[2017-05-31 17:26:13,873][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:26:13,873][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-05-31 17:26:13,873][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fbea861f938>
[2017-05-31 17:26:13,873][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:26:13,873][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:26:13,873][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-05-31 17:26:14,115][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:26:14,366][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:26:14,367][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:26:14,383][gdb0][DEBUG ] detect machine type
[2017-05-31 17:26:14,387][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:26:17,810][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:26:17,810][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb0
[2017-05-31 17:26:17,810][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:26:17,810][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:26:17,810][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:26:17,810][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:26:17,810][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:26:17,810][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7faa512c5518>
[2017-05-31 17:26:17,811][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:26:17,811][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-05-31 17:26:17,811][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7faa51bdc938>
[2017-05-31 17:26:17,811][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:26:17,811][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:26:17,811][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-05-31 17:26:18,051][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:26:18,282][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:26:18,283][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:26:18,299][gdb0][DEBUG ] detect machine type
[2017-05-31 17:26:18,302][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:26:31,577][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:26:31,577][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb1
[2017-05-31 17:26:31,577][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:26:31,577][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:26:31,577][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:26:31,577][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:26:31,577][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:26:31,577][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f82035a7518>
[2017-05-31 17:26:31,577][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:26:31,577][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-05-31 17:26:31,578][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f8203ebe938>
[2017-05-31 17:26:31,578][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:26:31,578][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:26:31,578][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-05-31 17:26:31,819][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 17:26:32,047][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 17:26:32,047][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 17:26:32,063][gdb1][DEBUG ] detect machine type
[2017-05-31 17:26:32,067][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:26:32,069][ceph_deploy.admin][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite
[2017-05-31 17:26:32,069][ceph_deploy][ERROR ] GenericError: Failed to configure 1 admin hosts

[2017-05-31 17:26:37,804][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:26:37,804][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb1
[2017-05-31 17:26:37,804][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:26:37,804][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:26:37,804][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:26:37,804][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 17:26:37,804][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:26:37,804][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f262edd4518>
[2017-05-31 17:26:37,804][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:26:37,805][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-05-31 17:26:37,805][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f262f6eb938>
[2017-05-31 17:26:37,805][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:26:37,805][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:26:37,805][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-05-31 17:26:38,048][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 17:26:38,275][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 17:26:38,275][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 17:26:38,291][gdb1][DEBUG ] detect machine type
[2017-05-31 17:26:38,295][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:26:41,218][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:26:41,219][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb1
[2017-05-31 17:26:41,219][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:26:41,219][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:26:41,219][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:26:41,219][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:26:41,219][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:26:41,219][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fbd2a5e0518>
[2017-05-31 17:26:41,219][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:26:41,219][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-05-31 17:26:41,219][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fbd2aef7938>
[2017-05-31 17:26:41,219][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:26:41,220][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:26:41,220][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-05-31 17:26:41,463][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 17:26:41,691][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 17:26:41,691][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 17:26:41,708][gdb1][DEBUG ] detect machine type
[2017-05-31 17:26:41,712][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:28:07,417][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:28:07,417][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd create --zap-disk gdb0:/mnt/memstore
[2017-05-31 17:28:07,417][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:28:07,417][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:28:07,417][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 17:28:07,418][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:28:07,418][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 17:28:07,418][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:28:07,418][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 17:28:07,418][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 17:28:07,418][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:28:07,418][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-05-31 17:28:07,418][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 17:28:07,418][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:28:07,418][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ff7512f6908>
[2017-05-31 17:28:07,418][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:28:07,418][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 17:28:07,418][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7ff75154caa0>
[2017-05-31 17:28:07,418][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:28:07,419][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:28:07,419][ceph_deploy.cli][INFO  ]  zap_disk                      : True
[2017-05-31 17:28:07,419][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:28:07,660][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:28:07,890][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:28:07,891][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:28:07,907][gdb0][DEBUG ] detect machine type
[2017-05-31 17:28:07,910][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:28:07,911][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:28:07,911][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 17:28:07,911][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:28:07,913][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate True
[2017-05-31 17:28:07,914][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:28:07,916][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 17:28:08,036][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 17:28:08,036][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 17:28:08,036][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:28:08,037][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:28:08,037][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 17:28:08,037][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:28:08,037][gdb0][WARNING]     args.func(args)
[2017-05-31 17:28:08,037][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2029, in main
[2017-05-31 17:28:08,037][gdb0][WARNING]     Prepare.factory(args).prepare()
[2017-05-31 17:28:08,037][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2025, in factory
[2017-05-31 17:28:08,037][gdb0][WARNING]     return PrepareFilestore(args)
[2017-05-31 17:28:08,037][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2037, in __init__
[2017-05-31 17:28:08,037][gdb0][WARNING]     self.data = PrepareFilestoreData(args)
[2017-05-31 17:28:08,037][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2739, in __init__
[2017-05-31 17:28:08,037][gdb0][WARNING]     self.set_type()
[2017-05-31 17:28:08,038][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2747, in set_type
[2017-05-31 17:28:08,038][gdb0][WARNING]     dmode = os.stat(self.args.data).st_mode
[2017-05-31 17:28:08,038][gdb0][WARNING] OSError: [Errno 2] No such file or directory: '/mnt/memstore'
[2017-05-31 17:28:08,039][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:28:08,039][ceph_deploy.osd][ERROR ] Failed to execute command: /usr/sbin/ceph-disk -v prepare --zap-disk --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 17:28:08,039][ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs

[2017-05-31 17:28:36,224][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:28:36,225][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd create gdb0:/mnt/memstore
[2017-05-31 17:28:36,225][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:28:36,225][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:28:36,225][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 17:28:36,225][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:28:36,225][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 17:28:36,225][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:28:36,225][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 17:28:36,225][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 17:28:36,225][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:28:36,225][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-05-31 17:28:36,225][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 17:28:36,226][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:28:36,226][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f304ebe3908>
[2017-05-31 17:28:36,226][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:28:36,226][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 17:28:36,226][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f304ee39aa0>
[2017-05-31 17:28:36,226][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:28:36,226][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:28:36,226][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 17:28:36,226][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:28:36,467][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:28:36,699][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:28:36,699][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:28:36,716][gdb0][DEBUG ] detect machine type
[2017-05-31 17:28:36,719][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:28:36,720][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:28:36,720][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 17:28:36,720][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:28:36,722][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate True
[2017-05-31 17:28:36,723][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:28:36,724][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 17:28:36,845][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 17:28:36,845][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 17:28:36,845][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:28:36,845][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:28:36,845][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 17:28:36,845][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:28:36,845][gdb0][WARNING]     args.func(args)
[2017-05-31 17:28:36,845][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2029, in main
[2017-05-31 17:28:36,845][gdb0][WARNING]     Prepare.factory(args).prepare()
[2017-05-31 17:28:36,845][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2025, in factory
[2017-05-31 17:28:36,845][gdb0][WARNING]     return PrepareFilestore(args)
[2017-05-31 17:28:36,846][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2037, in __init__
[2017-05-31 17:28:36,846][gdb0][WARNING]     self.data = PrepareFilestoreData(args)
[2017-05-31 17:28:36,846][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2739, in __init__
[2017-05-31 17:28:36,846][gdb0][WARNING]     self.set_type()
[2017-05-31 17:28:36,846][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2747, in set_type
[2017-05-31 17:28:36,846][gdb0][WARNING]     dmode = os.stat(self.args.data).st_mode
[2017-05-31 17:28:36,846][gdb0][WARNING] OSError: [Errno 2] No such file or directory: '/mnt/memstore'
[2017-05-31 17:28:36,850][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:28:36,850][ceph_deploy.osd][ERROR ] Failed to execute command: /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 17:28:36,850][ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs

[2017-05-31 17:29:39,243][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:29:39,243][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd create gdb0:/mnt/memstore1
[2017-05-31 17:29:39,243][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:29:39,243][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:29:39,243][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 17:29:39,243][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore1', None)]
[2017-05-31 17:29:39,243][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 17:29:39,243][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:29:39,244][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 17:29:39,244][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 17:29:39,244][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:29:39,244][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-05-31 17:29:39,244][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 17:29:39,244][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:29:39,244][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f8e4a597908>
[2017-05-31 17:29:39,244][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:29:39,244][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 17:29:39,244][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f8e4a7edaa0>
[2017-05-31 17:29:39,244][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:29:39,244][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:29:39,244][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 17:29:39,245][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore1:
[2017-05-31 17:29:39,484][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:29:39,714][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:29:39,715][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:29:39,731][gdb0][DEBUG ] detect machine type
[2017-05-31 17:29:39,734][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:29:39,735][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:29:39,735][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 17:29:39,736][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:29:39,738][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore1 journal None activate True
[2017-05-31 17:29:39,738][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:29:39,740][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore1
[2017-05-31 17:29:39,860][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 17:29:39,860][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 17:29:39,860][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:29:39,861][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:29:39,861][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 17:29:39,861][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:29:39,861][gdb0][WARNING]     args.func(args)
[2017-05-31 17:29:39,861][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2029, in main
[2017-05-31 17:29:39,861][gdb0][WARNING]     Prepare.factory(args).prepare()
[2017-05-31 17:29:39,861][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2025, in factory
[2017-05-31 17:29:39,861][gdb0][WARNING]     return PrepareFilestore(args)
[2017-05-31 17:29:39,861][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2037, in __init__
[2017-05-31 17:29:39,861][gdb0][WARNING]     self.data = PrepareFilestoreData(args)
[2017-05-31 17:29:39,861][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2739, in __init__
[2017-05-31 17:29:39,861][gdb0][WARNING]     self.set_type()
[2017-05-31 17:29:39,862][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2747, in set_type
[2017-05-31 17:29:39,862][gdb0][WARNING]     dmode = os.stat(self.args.data).st_mode
[2017-05-31 17:29:39,862][gdb0][WARNING] OSError: [Errno 2] No such file or directory: '/mnt/memstore1'
[2017-05-31 17:29:39,863][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:29:39,863][ceph_deploy.osd][ERROR ] Failed to execute command: /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore1
[2017-05-31 17:29:39,863][ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs

[2017-05-31 17:31:18,609][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:31:18,610][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore0
[2017-05-31 17:31:18,610][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:31:18,610][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:31:18,610][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 17:31:18,610][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore0', None)]
[2017-05-31 17:31:18,610][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 17:31:18,610][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:31:18,610][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 17:31:18,610][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 17:31:18,610][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:31:18,610][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 17:31:18,611][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 17:31:18,611][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:31:18,611][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f24ec147908>
[2017-05-31 17:31:18,611][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:31:18,611][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 17:31:18,611][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f24ec39daa0>
[2017-05-31 17:31:18,611][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:31:18,611][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:31:18,611][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 17:31:18,611][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore0:
[2017-05-31 17:31:18,850][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:31:19,077][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:31:19,078][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:31:19,093][gdb0][DEBUG ] detect machine type
[2017-05-31 17:31:19,096][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:31:19,097][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:31:19,097][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 17:31:19,097][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:31:19,100][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore0 journal None activate False
[2017-05-31 17:31:19,100][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:31:19,101][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore0
[2017-05-31 17:31:19,222][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 17:31:19,222][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 17:31:19,222][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:31:19,222][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:31:19,222][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 17:31:19,222][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:31:19,222][gdb0][WARNING]     args.func(args)
[2017-05-31 17:31:19,223][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2029, in main
[2017-05-31 17:31:19,223][gdb0][WARNING]     Prepare.factory(args).prepare()
[2017-05-31 17:31:19,223][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2025, in factory
[2017-05-31 17:31:19,223][gdb0][WARNING]     return PrepareFilestore(args)
[2017-05-31 17:31:19,223][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2037, in __init__
[2017-05-31 17:31:19,223][gdb0][WARNING]     self.data = PrepareFilestoreData(args)
[2017-05-31 17:31:19,223][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2739, in __init__
[2017-05-31 17:31:19,223][gdb0][WARNING]     self.set_type()
[2017-05-31 17:31:19,223][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2747, in set_type
[2017-05-31 17:31:19,223][gdb0][WARNING]     dmode = os.stat(self.args.data).st_mode
[2017-05-31 17:31:19,223][gdb0][WARNING] OSError: [Errno 2] No such file or directory: '/mnt/memstore0'
[2017-05-31 17:31:19,224][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:31:19,224][ceph_deploy.osd][ERROR ] Failed to execute command: /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore0
[2017-05-31 17:31:19,224][ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs

[2017-05-31 17:31:27,340][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:31:27,341][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-05-31 17:31:27,341][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:31:27,341][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:31:27,341][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 17:31:27,341][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:31:27,341][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 17:31:27,341][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:31:27,341][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 17:31:27,341][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 17:31:27,341][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:31:27,341][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 17:31:27,341][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 17:31:27,341][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:31:27,341][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0a00ca5908>
[2017-05-31 17:31:27,342][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:31:27,342][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 17:31:27,342][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f0a00efbaa0>
[2017-05-31 17:31:27,342][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:31:27,342][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:31:27,342][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 17:31:27,342][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:31:27,582][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:31:27,810][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:31:27,810][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:31:27,826][gdb0][DEBUG ] detect machine type
[2017-05-31 17:31:27,829][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:31:27,830][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:31:27,830][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 17:31:27,831][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:31:27,833][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-05-31 17:31:27,833][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:31:27,835][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 17:31:27,955][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 17:31:27,955][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 17:31:27,955][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:31:27,955][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:31:27,956][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 17:31:27,956][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:31:27,956][gdb0][WARNING]     args.func(args)
[2017-05-31 17:31:27,956][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2029, in main
[2017-05-31 17:31:27,956][gdb0][WARNING]     Prepare.factory(args).prepare()
[2017-05-31 17:31:27,956][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2025, in factory
[2017-05-31 17:31:27,956][gdb0][WARNING]     return PrepareFilestore(args)
[2017-05-31 17:31:27,956][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2037, in __init__
[2017-05-31 17:31:27,956][gdb0][WARNING]     self.data = PrepareFilestoreData(args)
[2017-05-31 17:31:27,956][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2739, in __init__
[2017-05-31 17:31:27,956][gdb0][WARNING]     self.set_type()
[2017-05-31 17:31:27,956][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2747, in set_type
[2017-05-31 17:31:27,956][gdb0][WARNING]     dmode = os.stat(self.args.data).st_mode
[2017-05-31 17:31:27,957][gdb0][WARNING] OSError: [Errno 2] No such file or directory: '/mnt/memstore'
[2017-05-31 17:31:27,957][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:31:27,957][ceph_deploy.osd][ERROR ] Failed to execute command: /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 17:31:27,957][ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs

[2017-05-31 17:31:45,369][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:31:45,369][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-05-31 17:31:45,369][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:31:45,369][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:31:45,370][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 17:31:45,370][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:31:45,370][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 17:31:45,370][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:31:45,370][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 17:31:45,370][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 17:31:45,370][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:31:45,370][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 17:31:45,370][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 17:31:45,370][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:31:45,370][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f511e360908>
[2017-05-31 17:31:45,370][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:31:45,370][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 17:31:45,370][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f511e5b6aa0>
[2017-05-31 17:31:45,370][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:31:45,371][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:31:45,371][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 17:31:45,371][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:31:45,606][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:31:45,834][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:31:45,834][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:31:45,850][gdb0][DEBUG ] detect machine type
[2017-05-31 17:31:45,853][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:31:45,854][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:31:45,854][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 17:31:45,854][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:31:45,857][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-05-31 17:31:45,857][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:31:45,859][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 17:31:45,979][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:31:45,983][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:31:45,999][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:31:46,014][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:31:46,022][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 17:31:46,038][gdb0][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-05-31 17:31:46,053][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.11500.tmp
[2017-05-31 17:31:46,054][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.11500.tmp
[2017-05-31 17:31:46,054][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.11500.tmp
[2017-05-31 17:31:51,071][gdb0][INFO  ] checking OSD status...
[2017-05-31 17:31:51,071][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:31:51,073][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 17:31:51,239][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-05-31 17:31:59,940][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:31:59,940][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 17:31:59,940][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:31:59,941][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:31:59,941][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:31:59,941][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:31:59,941][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 17:31:59,941][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:31:59,941][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fabd52b2908>
[2017-05-31 17:31:59,941][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:31:59,941][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fabd5508aa0>
[2017-05-31 17:31:59,941][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:31:59,941][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:31:59,941][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:31:59,942][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:32:00,183][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:32:00,410][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:32:00,410][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:32:00,426][gdb0][DEBUG ] detect machine type
[2017-05-31 17:32:00,429][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:32:00,430][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:32:00,430][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 17:32:00,430][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 17:32:00,430][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:32:00,432][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 17:32:00,552][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 17:32:00,553][gdb0][WARNING] activate: Cluster uuid is ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 17:32:00,553][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:32:00,556][gdb0][WARNING] activate: Cluster name is ceph
[2017-05-31 17:32:00,556][gdb0][WARNING] activate: OSD uuid is 1b3b5a35-7de7-489c-8108-1493f28b991b
[2017-05-31 17:32:00,556][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 17:32:00,556][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 1b3b5a35-7de7-489c-8108-1493f28b991b
[2017-05-31 17:32:00,671][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 17:32:00,671][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 17:32:00,671][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:32:00,671][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:32:00,671][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 17:32:00,671][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:32:00,671][gdb0][WARNING]     args.func(args)
[2017-05-31 17:32:00,671][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 17:32:00,671][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 17:32:00,671][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 17:32:00,672][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-05-31 17:32:00,672][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3625, in activate
[2017-05-31 17:32:00,672][gdb0][WARNING]     keyring=keyring,
[2017-05-31 17:32:00,672][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 1075, in allocate_osd_id
[2017-05-31 17:32:00,672][gdb0][WARNING]     raise Error('ceph osd create failed', e, e.output)
[2017-05-31 17:32:00,672][gdb0][WARNING] ceph_disk.main.Error: Error: ceph osd create failed: Command '/usr/bin/ceph' returned non-zero exit status 1: 2017-05-31 17:32:00.611189 7fd518948700  0 librados: client.bootstrap-osd authentication error (1) Operation not permitted
[2017-05-31 17:32:00,672][gdb0][WARNING] error connecting to the cluster
[2017-05-31 17:32:00,672][gdb0][WARNING] 
[2017-05-31 17:32:00,672][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:32:00,672][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 17:32:37,303][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:32:37,303][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 17:32:37,303][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:32:37,303][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:32:37,303][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:32:37,303][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:32:37,304][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 17:32:37,304][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:32:37,304][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb869074908>
[2017-05-31 17:32:37,304][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:32:37,304][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fb8692caaa0>
[2017-05-31 17:32:37,304][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:32:37,304][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:32:37,304][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:32:37,304][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:32:37,546][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:32:37,773][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:32:37,774][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:32:37,790][gdb0][DEBUG ] detect machine type
[2017-05-31 17:32:37,793][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:32:37,794][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:32:37,794][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 17:32:37,794][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 17:32:37,794][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:32:37,796][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 17:32:37,916][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 17:32:37,917][gdb0][WARNING] activate: Cluster uuid is ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 17:32:37,917][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:32:37,920][gdb0][WARNING] activate: Cluster name is ceph
[2017-05-31 17:32:37,920][gdb0][WARNING] activate: OSD uuid is 1b3b5a35-7de7-489c-8108-1493f28b991b
[2017-05-31 17:32:37,920][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 17:32:37,920][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 1b3b5a35-7de7-489c-8108-1493f28b991b
[2017-05-31 17:32:37,984][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 17:32:37,984][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 17:32:37,985][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:32:37,985][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:32:37,985][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 17:32:37,985][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:32:37,985][gdb0][WARNING]     args.func(args)
[2017-05-31 17:32:37,985][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 17:32:37,985][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 17:32:37,985][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 17:32:37,985][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-05-31 17:32:37,985][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3625, in activate
[2017-05-31 17:32:37,985][gdb0][WARNING]     keyring=keyring,
[2017-05-31 17:32:37,985][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 1075, in allocate_osd_id
[2017-05-31 17:32:37,986][gdb0][WARNING]     raise Error('ceph osd create failed', e, e.output)
[2017-05-31 17:32:37,986][gdb0][WARNING] ceph_disk.main.Error: Error: ceph osd create failed: Command '/usr/bin/ceph' returned non-zero exit status 1: 2017-05-31 17:32:37.970899 7f301d34a700  0 librados: client.bootstrap-osd authentication error (1) Operation not permitted
[2017-05-31 17:32:37,986][gdb0][WARNING] error connecting to the cluster
[2017-05-31 17:32:37,986][gdb0][WARNING] 
[2017-05-31 17:32:37,993][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:32:37,994][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 17:33:01,166][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:33:01,167][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 17:33:01,167][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:33:01,167][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:33:01,167][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:33:01,167][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:33:01,167][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 17:33:01,167][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:33:01,167][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f80bcdce908>
[2017-05-31 17:33:01,167][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:33:01,167][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f80bd024aa0>
[2017-05-31 17:33:01,167][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:33:01,167][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:33:01,167][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:33:01,168][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:33:01,407][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:33:01,630][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:33:01,631][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:33:01,647][gdb0][DEBUG ] detect machine type
[2017-05-31 17:33:01,651][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:33:01,652][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:33:01,652][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 17:33:01,652][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 17:33:01,652][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:33:01,654][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 17:33:01,775][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 17:33:01,775][gdb0][WARNING] activate: Cluster uuid is ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 17:33:01,775][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:33:01,778][gdb0][WARNING] activate: Cluster name is ceph
[2017-05-31 17:33:01,779][gdb0][WARNING] activate: OSD uuid is 1b3b5a35-7de7-489c-8108-1493f28b991b
[2017-05-31 17:33:01,779][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 17:33:01,779][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 1b3b5a35-7de7-489c-8108-1493f28b991b
[2017-05-31 17:33:01,843][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 17:33:01,843][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 17:33:01,843][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:33:01,843][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:33:01,843][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 17:33:01,844][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:33:01,844][gdb0][WARNING]     args.func(args)
[2017-05-31 17:33:01,844][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 17:33:01,844][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 17:33:01,844][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 17:33:01,844][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-05-31 17:33:01,845][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3625, in activate
[2017-05-31 17:33:01,846][gdb0][WARNING]     keyring=keyring,
[2017-05-31 17:33:01,846][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 1075, in allocate_osd_id
[2017-05-31 17:33:01,846][gdb0][WARNING]     raise Error('ceph osd create failed', e, e.output)
[2017-05-31 17:33:01,846][gdb0][WARNING] ceph_disk.main.Error: Error: ceph osd create failed: Command '/usr/bin/ceph' returned non-zero exit status 1: 2017-05-31 17:33:01.830834 7f8a312d6700  0 librados: client.bootstrap-osd authentication error (1) Operation not permitted
[2017-05-31 17:33:01,846][gdb0][WARNING] error connecting to the cluster
[2017-05-31 17:33:01,846][gdb0][WARNING] 
[2017-05-31 17:33:01,862][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:33:01,862][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 17:35:20,726][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:35:20,726][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 17:35:20,726][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:35:20,726][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:35:20,726][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:35:20,726][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:35:20,726][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 17:35:20,726][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:35:20,727][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f31fc0bf908>
[2017-05-31 17:35:20,727][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:35:20,727][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f31fc315aa0>
[2017-05-31 17:35:20,727][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:35:20,727][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:35:20,727][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:35:20,727][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:35:20,966][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:35:21,190][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:35:21,190][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:35:21,206][gdb0][DEBUG ] detect machine type
[2017-05-31 17:35:21,209][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:35:21,210][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:35:21,210][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 17:35:21,210][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 17:35:21,210][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:35:21,213][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 17:35:21,333][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 17:35:21,333][gdb0][WARNING] activate: Cluster uuid is ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 17:35:21,333][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:35:21,335][gdb0][WARNING] activate: Cluster name is ceph
[2017-05-31 17:35:21,335][gdb0][WARNING] activate: OSD uuid is 1b3b5a35-7de7-489c-8108-1493f28b991b
[2017-05-31 17:35:21,335][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 17:35:21,335][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 1b3b5a35-7de7-489c-8108-1493f28b991b
[2017-05-31 17:35:21,449][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 17:35:21,450][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 17:35:21,450][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:35:21,450][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:35:21,450][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 17:35:21,450][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:35:21,450][gdb0][WARNING]     args.func(args)
[2017-05-31 17:35:21,450][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 17:35:21,450][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 17:35:21,450][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 17:35:21,450][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-05-31 17:35:21,450][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3625, in activate
[2017-05-31 17:35:21,450][gdb0][WARNING]     keyring=keyring,
[2017-05-31 17:35:21,451][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 1075, in allocate_osd_id
[2017-05-31 17:35:21,451][gdb0][WARNING]     raise Error('ceph osd create failed', e, e.output)
[2017-05-31 17:35:21,451][gdb0][WARNING] ceph_disk.main.Error: Error: ceph osd create failed: Command '/usr/bin/ceph' returned non-zero exit status 1: 2017-05-31 17:35:21.391200 7fcb3940a700  0 librados: client.bootstrap-osd authentication error (1) Operation not permitted
[2017-05-31 17:35:21,451][gdb0][WARNING] error connecting to the cluster
[2017-05-31 17:35:21,451][gdb0][WARNING] 
[2017-05-31 17:35:21,451][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:35:21,451][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 17:35:43,815][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:35:43,816][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 17:35:43,816][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:35:43,816][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:35:43,816][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:35:43,816][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:35:43,816][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 17:35:43,816][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:35:43,816][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6ae6d2f908>
[2017-05-31 17:35:43,816][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:35:43,816][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f6ae6f85aa0>
[2017-05-31 17:35:43,816][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:35:43,817][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:35:43,817][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:35:43,817][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:35:44,054][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:35:44,281][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:35:44,282][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:35:44,298][gdb0][DEBUG ] detect machine type
[2017-05-31 17:35:44,301][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:35:44,302][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:35:44,302][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 17:35:44,302][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 17:35:44,302][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:35:44,304][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 17:35:44,424][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 17:35:44,424][gdb0][WARNING] activate: Cluster uuid is ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 17:35:44,425][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:35:44,426][gdb0][WARNING] activate: Cluster name is ceph
[2017-05-31 17:35:44,426][gdb0][WARNING] activate: OSD uuid is 1b3b5a35-7de7-489c-8108-1493f28b991b
[2017-05-31 17:35:44,426][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 17:35:44,426][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 1b3b5a35-7de7-489c-8108-1493f28b991b
[2017-05-31 17:35:44,490][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 17:35:44,490][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 17:35:44,491][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:35:44,491][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:35:44,491][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 17:35:44,491][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:35:44,491][gdb0][WARNING]     args.func(args)
[2017-05-31 17:35:44,491][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 17:35:44,491][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 17:35:44,491][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 17:35:44,491][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-05-31 17:35:44,491][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3625, in activate
[2017-05-31 17:35:44,491][gdb0][WARNING]     keyring=keyring,
[2017-05-31 17:35:44,491][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 1075, in allocate_osd_id
[2017-05-31 17:35:44,495][gdb0][WARNING]     raise Error('ceph osd create failed', e, e.output)
[2017-05-31 17:35:44,495][gdb0][WARNING] ceph_disk.main.Error: Error: ceph osd create failed: Command '/usr/bin/ceph' returned non-zero exit status 1: 2017-05-31 17:35:44.478096 7f0159824700  0 librados: client.bootstrap-osd authentication error (1) Operation not permitted
[2017-05-31 17:35:44,495][gdb0][WARNING] error connecting to the cluster
[2017-05-31 17:35:44,495][gdb0][WARNING] 
[2017-05-31 17:35:44,503][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:35:44,503][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 17:35:47,483][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:35:47,484][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-05-31 17:35:47,484][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:35:47,484][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:35:47,484][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 17:35:47,484][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:35:47,484][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 17:35:47,484][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:35:47,484][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 17:35:47,484][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 17:35:47,484][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:35:47,485][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 17:35:47,485][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 17:35:47,485][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:35:47,485][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f21d1e41908>
[2017-05-31 17:35:47,485][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:35:47,485][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 17:35:47,485][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f21d2097aa0>
[2017-05-31 17:35:47,485][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:35:47,485][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:35:47,485][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 17:35:47,485][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:35:47,722][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:35:47,949][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:35:47,950][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:35:47,965][gdb0][DEBUG ] detect machine type
[2017-05-31 17:35:47,969][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:35:47,970][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:35:47,970][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 17:35:47,970][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:35:47,972][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-05-31 17:35:47,972][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:35:47,974][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 17:35:48,095][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:35:48,098][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:35:48,114][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:35:48,130][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:35:48,137][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 17:35:48,145][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-05-31 17:35:53,166][gdb0][INFO  ] checking OSD status...
[2017-05-31 17:35:53,166][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:35:53,168][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 17:35:53,333][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-05-31 17:35:57,208][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:35:57,208][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 17:35:57,208][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:35:57,208][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:35:57,208][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:35:57,208][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:35:57,208][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 17:35:57,208][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:35:57,208][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb58bf81908>
[2017-05-31 17:35:57,208][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:35:57,209][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fb58c1d7aa0>
[2017-05-31 17:35:57,209][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:35:57,209][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:35:57,209][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:35:57,209][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:35:57,450][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:35:57,677][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:35:57,678][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:35:57,693][gdb0][DEBUG ] detect machine type
[2017-05-31 17:35:57,697][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:35:57,698][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:35:57,698][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 17:35:57,698][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 17:35:57,698][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:35:57,700][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 17:35:57,820][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 17:35:57,821][gdb0][WARNING] activate: Cluster uuid is ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 17:35:57,821][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:35:57,821][gdb0][WARNING] activate: Cluster name is ceph
[2017-05-31 17:35:57,821][gdb0][WARNING] activate: OSD uuid is 1b3b5a35-7de7-489c-8108-1493f28b991b
[2017-05-31 17:35:57,822][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 17:35:57,822][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 1b3b5a35-7de7-489c-8108-1493f28b991b
[2017-05-31 17:35:57,937][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 17:35:57,937][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 17:35:57,937][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:35:57,937][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:35:57,937][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 17:35:57,937][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:35:57,937][gdb0][WARNING]     args.func(args)
[2017-05-31 17:35:57,937][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 17:35:57,937][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 17:35:57,937][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 17:35:57,938][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-05-31 17:35:57,938][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3625, in activate
[2017-05-31 17:35:57,938][gdb0][WARNING]     keyring=keyring,
[2017-05-31 17:35:57,938][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 1075, in allocate_osd_id
[2017-05-31 17:35:57,938][gdb0][WARNING]     raise Error('ceph osd create failed', e, e.output)
[2017-05-31 17:35:57,938][gdb0][WARNING] ceph_disk.main.Error: Error: ceph osd create failed: Command '/usr/bin/ceph' returned non-zero exit status 1: 2017-05-31 17:35:57.877212 7f9978f6b700  0 librados: client.bootstrap-osd authentication error (1) Operation not permitted
[2017-05-31 17:35:57,938][gdb0][WARNING] error connecting to the cluster
[2017-05-31 17:35:57,938][gdb0][WARNING] 
[2017-05-31 17:35:57,938][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:35:57,938][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 17:37:04,926][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:37:04,926][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-05-31 17:37:04,926][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:37:04,926][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:37:04,926][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 17:37:04,926][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:37:04,926][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 17:37:04,926][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:37:04,927][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 17:37:04,927][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 17:37:04,927][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:37:04,927][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 17:37:04,927][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 17:37:04,927][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:37:04,927][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f67b3b90908>
[2017-05-31 17:37:04,927][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:37:04,927][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 17:37:04,927][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f67b3de6aa0>
[2017-05-31 17:37:04,927][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:37:04,927][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:37:04,927][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 17:37:04,928][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:37:05,166][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:37:05,393][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:37:05,394][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:37:05,409][gdb0][DEBUG ] detect machine type
[2017-05-31 17:37:05,412][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:37:05,413][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:37:05,413][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 17:37:05,413][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:37:05,416][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-05-31 17:37:05,416][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:37:05,418][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 17:37:05,538][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:37:05,541][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:37:05,557][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:37:05,573][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:37:05,580][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 17:37:05,596][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-05-31 17:37:10,605][gdb0][INFO  ] checking OSD status...
[2017-05-31 17:37:10,605][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:37:10,607][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 17:37:10,773][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-05-31 17:37:14,106][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:37:14,107][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 17:37:14,107][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:37:14,107][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:37:14,107][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:37:14,107][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:37:14,107][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 17:37:14,107][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:37:14,107][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fde7b9cf908>
[2017-05-31 17:37:14,107][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:37:14,107][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fde7bc25aa0>
[2017-05-31 17:37:14,107][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:37:14,107][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:37:14,107][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:37:14,108][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:37:14,346][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:37:14,577][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:37:14,578][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:37:14,594][gdb0][DEBUG ] detect machine type
[2017-05-31 17:37:14,597][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:37:14,598][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:37:14,598][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 17:37:14,598][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 17:37:14,598][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:37:14,600][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 17:37:14,721][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 17:37:14,721][gdb0][WARNING] activate: Cluster uuid is ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 17:37:14,721][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:37:14,722][gdb0][WARNING] activate: Cluster name is ceph
[2017-05-31 17:37:14,722][gdb0][WARNING] activate: OSD uuid is 1b3b5a35-7de7-489c-8108-1493f28b991b
[2017-05-31 17:37:14,722][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 17:37:14,722][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 1b3b5a35-7de7-489c-8108-1493f28b991b
[2017-05-31 17:37:14,786][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 17:37:14,786][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 17:37:14,787][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:37:14,787][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:37:14,787][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 17:37:14,787][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:37:14,787][gdb0][WARNING]     args.func(args)
[2017-05-31 17:37:14,787][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 17:37:14,787][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 17:37:14,787][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 17:37:14,787][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-05-31 17:37:14,787][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3625, in activate
[2017-05-31 17:37:14,787][gdb0][WARNING]     keyring=keyring,
[2017-05-31 17:37:14,787][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 1075, in allocate_osd_id
[2017-05-31 17:37:14,788][gdb0][WARNING]     raise Error('ceph osd create failed', e, e.output)
[2017-05-31 17:37:14,788][gdb0][WARNING] ceph_disk.main.Error: Error: ceph osd create failed: Command '/usr/bin/ceph' returned non-zero exit status 1: 2017-05-31 17:37:14.773746 7fd04a885700  0 librados: client.bootstrap-osd authentication error (1) Operation not permitted
[2017-05-31 17:37:14,788][gdb0][WARNING] error connecting to the cluster
[2017-05-31 17:37:14,788][gdb0][WARNING] 
[2017-05-31 17:37:14,795][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:37:14,795][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 17:37:26,260][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:37:26,261][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-05-31 17:37:26,261][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:37:26,261][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:37:26,261][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:37:26,261][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:37:26,261][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-05-31 17:37:26,261][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:37:26,261][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb120b14e60>
[2017-05-31 17:37:26,261][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:37:26,261][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7fb120ae9b18>
[2017-05-31 17:37:26,261][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:37:26,261][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-05-31 17:37:26,262][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:37:26,262][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-05-31 17:37:26,262][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-05-31 17:37:26,289][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 17:37:26,303][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 17:37:26,304][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 17:37:26,320][gdb3][DEBUG ] detect machine type
[2017-05-31 17:37:26,323][gdb3][DEBUG ] find the location of an executable
[2017-05-31 17:37:26,323][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-05-31 17:37:26,323][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-05-31 17:37:26,323][gdb3][DEBUG ] get remote short hostname
[2017-05-31 17:37:26,324][gdb3][DEBUG ] deploying mon to gdb3
[2017-05-31 17:37:26,324][gdb3][DEBUG ] get remote short hostname
[2017-05-31 17:37:26,324][gdb3][DEBUG ] remote hostname: gdb3
[2017-05-31 17:37:26,325][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:37:26,326][gdb3][DEBUG ] create the mon path if it does not exist
[2017-05-31 17:37:26,326][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-05-31 17:37:26,327][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-05-31 17:37:26,327][gdb3][DEBUG ] create the init path if it does not exist
[2017-05-31 17:37:26,328][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-05-31 17:37:26,401][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-05-31 17:37:26,469][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-05-31 17:37:28,482][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 17:37:28,547][gdb3][DEBUG ] ********************************************************************************
[2017-05-31 17:37:28,547][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-05-31 17:37:28,548][gdb3][DEBUG ] {
[2017-05-31 17:37:28,548][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-05-31 17:37:28,548][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-05-31 17:37:28,548][gdb3][DEBUG ]   "features": {
[2017-05-31 17:37:28,548][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-05-31 17:37:28,548][gdb3][DEBUG ]     "quorum_mon": [
[2017-05-31 17:37:28,548][gdb3][DEBUG ]       "kraken", 
[2017-05-31 17:37:28,548][gdb3][DEBUG ]       "luminous"
[2017-05-31 17:37:28,548][gdb3][DEBUG ]     ], 
[2017-05-31 17:37:28,548][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-05-31 17:37:28,548][gdb3][DEBUG ]     "required_mon": [
[2017-05-31 17:37:28,549][gdb3][DEBUG ]       "kraken", 
[2017-05-31 17:37:28,549][gdb3][DEBUG ]       "luminous"
[2017-05-31 17:37:28,549][gdb3][DEBUG ]     ]
[2017-05-31 17:37:28,549][gdb3][DEBUG ]   }, 
[2017-05-31 17:37:28,549][gdb3][DEBUG ]   "monmap": {
[2017-05-31 17:37:28,549][gdb3][DEBUG ]     "created": "2017-05-31 17:08:12.212153", 
[2017-05-31 17:37:28,549][gdb3][DEBUG ]     "epoch": 2, 
[2017-05-31 17:37:28,549][gdb3][DEBUG ]     "features": {
[2017-05-31 17:37:28,549][gdb3][DEBUG ]       "optional": [], 
[2017-05-31 17:37:28,549][gdb3][DEBUG ]       "persistent": [
[2017-05-31 17:37:28,549][gdb3][DEBUG ]         "kraken", 
[2017-05-31 17:37:28,549][gdb3][DEBUG ]         "luminous"
[2017-05-31 17:37:28,549][gdb3][DEBUG ]       ]
[2017-05-31 17:37:28,549][gdb3][DEBUG ]     }, 
[2017-05-31 17:37:28,549][gdb3][DEBUG ]     "fsid": "ca3e0a81-2fd3-4069-bf21-8407a86a4dd3", 
[2017-05-31 17:37:28,549][gdb3][DEBUG ]     "modified": "2017-05-31 17:08:12.455156", 
[2017-05-31 17:37:28,550][gdb3][DEBUG ]     "mons": [
[2017-05-31 17:37:28,550][gdb3][DEBUG ]       {
[2017-05-31 17:37:28,550][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-05-31 17:37:28,550][gdb3][DEBUG ]         "name": "gdb3", 
[2017-05-31 17:37:28,550][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-05-31 17:37:28,550][gdb3][DEBUG ]         "rank": 0
[2017-05-31 17:37:28,550][gdb3][DEBUG ]       }
[2017-05-31 17:37:28,550][gdb3][DEBUG ]     ]
[2017-05-31 17:37:28,550][gdb3][DEBUG ]   }, 
[2017-05-31 17:37:28,550][gdb3][DEBUG ]   "name": "gdb3", 
[2017-05-31 17:37:28,550][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-05-31 17:37:28,550][gdb3][DEBUG ]   "quorum": [
[2017-05-31 17:37:28,550][gdb3][DEBUG ]     0
[2017-05-31 17:37:28,550][gdb3][DEBUG ]   ], 
[2017-05-31 17:37:28,550][gdb3][DEBUG ]   "rank": 0, 
[2017-05-31 17:37:28,550][gdb3][DEBUG ]   "state": "leader", 
[2017-05-31 17:37:28,551][gdb3][DEBUG ]   "sync_provider": []
[2017-05-31 17:37:28,551][gdb3][DEBUG ] }
[2017-05-31 17:37:28,551][gdb3][DEBUG ] ********************************************************************************
[2017-05-31 17:37:28,551][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-05-31 17:37:28,552][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 17:37:28,617][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-05-31 17:37:28,634][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 17:37:28,649][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 17:37:28,649][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 17:37:28,666][gdb3][DEBUG ] detect machine type
[2017-05-31 17:37:28,668][gdb3][DEBUG ] find the location of an executable
[2017-05-31 17:37:28,669][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 17:37:28,734][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-05-31 17:37:28,735][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-05-31 17:37:28,735][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-05-31 17:37:28,737][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpVN2kfG
[2017-05-31 17:37:28,752][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 17:37:28,766][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 17:37:28,767][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 17:37:28,783][gdb3][DEBUG ] detect machine type
[2017-05-31 17:37:28,785][gdb3][DEBUG ] get remote short hostname
[2017-05-31 17:37:28,786][gdb3][DEBUG ] fetch remote file
[2017-05-31 17:37:28,787][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 17:37:28,853][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-05-31 17:37:29,019][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-05-31 17:37:29,185][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-05-31 17:37:29,351][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-05-31 17:37:29,518][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-05-31 17:37:29,683][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.client.admin.keyring' already exists
[2017-05-31 17:37:29,683][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.bootstrap-mds.keyring' already exists
[2017-05-31 17:37:29,683][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.bootstrap-mgr.keyring' already exists
[2017-05-31 17:37:29,684][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-05-31 17:37:29,684][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.bootstrap-osd.keyring' already exists
[2017-05-31 17:37:29,684][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.bootstrap-rgw.keyring' already exists
[2017-05-31 17:37:29,684][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpVN2kfG
[2017-05-31 17:37:37,308][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:37:37,308][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb0
[2017-05-31 17:37:37,308][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:37:37,308][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:37:37,308][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:37:37,308][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:37:37,309][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:37:37,309][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb432d88518>
[2017-05-31 17:37:37,309][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:37:37,309][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-05-31 17:37:37,309][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fb43369f938>
[2017-05-31 17:37:37,309][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:37:37,309][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:37:37,309][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-05-31 17:37:37,550][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:37:37,774][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:37:37,774][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:37:37,790][gdb0][DEBUG ] detect machine type
[2017-05-31 17:37:37,793][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:37:52,886][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:37:52,886][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-05-31 17:37:52,886][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:37:52,886][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:37:52,886][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 17:37:52,886][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:37:52,886][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 17:37:52,886][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:37:52,886][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 17:37:52,887][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 17:37:52,887][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:37:52,887][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 17:37:52,887][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 17:37:52,887][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:37:52,887][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f78bf918908>
[2017-05-31 17:37:52,887][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:37:52,887][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 17:37:52,887][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f78bfb6eaa0>
[2017-05-31 17:37:52,887][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:37:52,887][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:37:52,887][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 17:37:52,888][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:37:53,127][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:37:53,354][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:37:53,354][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:37:53,370][gdb0][DEBUG ] detect machine type
[2017-05-31 17:37:53,374][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:37:53,375][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:37:53,375][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 17:37:53,375][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:37:53,377][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-05-31 17:37:53,377][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:37:53,379][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 17:37:53,499][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:37:53,507][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:37:53,523][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:37:53,538][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:37:53,546][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 17:37:53,562][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-05-31 17:37:58,570][gdb0][INFO  ] checking OSD status...
[2017-05-31 17:37:58,571][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:37:58,573][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 17:37:58,738][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-05-31 17:38:04,191][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:38:04,191][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 17:38:04,192][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:38:04,192][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:38:04,192][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:38:04,192][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:38:04,192][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 17:38:04,192][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:38:04,192][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fd5b2840908>
[2017-05-31 17:38:04,192][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:38:04,192][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fd5b2a96aa0>
[2017-05-31 17:38:04,192][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:38:04,192][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:38:04,192][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:38:04,193][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:38:04,434][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:38:04,666][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:38:04,666][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:38:04,682][gdb0][DEBUG ] detect machine type
[2017-05-31 17:38:04,685][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:38:04,686][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:38:04,686][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 17:38:04,686][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 17:38:04,686][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:38:04,688][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 17:38:04,808][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 17:38:04,808][gdb0][WARNING] activate: Cluster uuid is ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 17:38:04,809][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:38:04,812][gdb0][WARNING] activate: Cluster name is ceph
[2017-05-31 17:38:04,812][gdb0][WARNING] activate: OSD uuid is 1b3b5a35-7de7-489c-8108-1493f28b991b
[2017-05-31 17:38:04,812][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 17:38:04,812][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 1b3b5a35-7de7-489c-8108-1493f28b991b
[2017-05-31 17:38:04,876][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 17:38:04,876][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 17:38:04,876][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:38:04,877][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:38:04,877][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 17:38:04,877][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:38:04,877][gdb0][WARNING]     args.func(args)
[2017-05-31 17:38:04,877][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 17:38:04,877][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 17:38:04,877][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 17:38:04,877][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-05-31 17:38:04,877][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3625, in activate
[2017-05-31 17:38:04,877][gdb0][WARNING]     keyring=keyring,
[2017-05-31 17:38:04,877][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 1075, in allocate_osd_id
[2017-05-31 17:38:04,877][gdb0][WARNING]     raise Error('ceph osd create failed', e, e.output)
[2017-05-31 17:38:04,878][gdb0][WARNING] ceph_disk.main.Error: Error: ceph osd create failed: Command '/usr/bin/ceph' returned non-zero exit status 1: 2017-05-31 17:38:04.863263 7fe323196700  0 librados: client.bootstrap-osd authentication error (1) Operation not permitted
[2017-05-31 17:38:04,878][gdb0][WARNING] error connecting to the cluster
[2017-05-31 17:38:04,878][gdb0][WARNING] 
[2017-05-31 17:38:04,885][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:38:04,885][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 17:38:38,724][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:38:38,724][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 17:38:38,724][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:38:38,724][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:38:38,724][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:38:38,724][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:38:38,724][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 17:38:38,724][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:38:38,724][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0cb5e89908>
[2017-05-31 17:38:38,725][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:38:38,725][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f0cb60dfaa0>
[2017-05-31 17:38:38,725][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:38:38,725][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:38:38,725][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:38:38,725][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:38:38,962][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:38:39,190][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:38:39,190][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:38:39,206][gdb0][DEBUG ] detect machine type
[2017-05-31 17:38:39,210][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:38:39,211][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:38:39,211][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 17:38:39,211][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 17:38:39,211][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:38:39,213][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 17:38:39,333][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 17:38:39,333][gdb0][WARNING] activate: Cluster uuid is ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 17:38:39,333][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:38:39,337][gdb0][WARNING] activate: Cluster name is ceph
[2017-05-31 17:38:39,337][gdb0][WARNING] activate: OSD uuid is 1b3b5a35-7de7-489c-8108-1493f28b991b
[2017-05-31 17:38:39,337][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 17:38:39,337][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 1b3b5a35-7de7-489c-8108-1493f28b991b
[2017-05-31 17:38:39,401][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 17:38:39,401][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 17:38:39,401][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:38:39,401][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:38:39,401][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 17:38:39,402][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:38:39,402][gdb0][WARNING]     args.func(args)
[2017-05-31 17:38:39,402][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 17:38:39,402][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 17:38:39,402][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 17:38:39,402][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-05-31 17:38:39,402][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3625, in activate
[2017-05-31 17:38:39,402][gdb0][WARNING]     keyring=keyring,
[2017-05-31 17:38:39,402][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 1075, in allocate_osd_id
[2017-05-31 17:38:39,402][gdb0][WARNING]     raise Error('ceph osd create failed', e, e.output)
[2017-05-31 17:38:39,402][gdb0][WARNING] ceph_disk.main.Error: Error: ceph osd create failed: Command '/usr/bin/ceph' returned non-zero exit status 1: 2017-05-31 17:38:39.386582 7f2459254700 -1 auth: unable to find a keyring on /var/lib/ceph/bootstrap-osd/ceph.keyring: (2) No such file or directory
[2017-05-31 17:38:39,402][gdb0][WARNING] 2017-05-31 17:38:39.386595 7f2459254700 -1 monclient: ERROR: missing keyring, cannot use cephx for authentication
[2017-05-31 17:38:39,402][gdb0][WARNING] 2017-05-31 17:38:39.386596 7f2459254700  0 librados: client.bootstrap-osd initialization error (2) No such file or directory
[2017-05-31 17:38:39,403][gdb0][WARNING] error connecting to the cluster
[2017-05-31 17:38:39,403][gdb0][WARNING] 
[2017-05-31 17:38:39,410][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:38:39,410][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 17:38:42,692][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:38:42,692][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-05-31 17:38:42,692][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:38:42,693][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:38:42,693][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 17:38:42,693][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:38:42,693][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 17:38:42,693][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:38:42,693][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 17:38:42,693][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 17:38:42,693][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:38:42,693][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 17:38:42,693][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 17:38:42,693][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:38:42,693][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa8cdb3a908>
[2017-05-31 17:38:42,693][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:38:42,693][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 17:38:42,693][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fa8cdd90aa0>
[2017-05-31 17:38:42,694][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:38:42,694][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:38:42,694][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 17:38:42,694][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:38:42,934][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:38:43,161][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:38:43,162][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:38:43,178][gdb0][DEBUG ] detect machine type
[2017-05-31 17:38:43,181][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:38:43,182][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:38:43,182][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 17:38:43,182][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:38:43,185][gdb0][WARNING] osd keyring does not exist yet, creating one
[2017-05-31 17:38:43,185][gdb0][DEBUG ] create a keyring file
[2017-05-31 17:38:43,187][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-05-31 17:38:43,187][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:38:43,189][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 17:38:43,309][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:38:43,313][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:38:43,328][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:38:43,344][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:38:43,352][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 17:38:43,359][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-05-31 17:38:48,380][gdb0][INFO  ] checking OSD status...
[2017-05-31 17:38:48,380][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:38:48,383][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 17:38:48,548][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-05-31 17:38:58,883][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:38:58,884][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 17:38:58,884][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:38:58,884][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:38:58,884][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:38:58,884][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:38:58,884][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 17:38:58,885][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:38:58,885][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fcc7933f908>
[2017-05-31 17:38:58,885][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:38:58,885][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fcc79595aa0>
[2017-05-31 17:38:58,885][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:38:58,885][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:38:58,885][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:38:58,886][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:38:59,126][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:38:59,358][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:38:59,358][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:38:59,374][gdb0][DEBUG ] detect machine type
[2017-05-31 17:38:59,378][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:38:59,378][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:38:59,378][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 17:38:59,379][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 17:38:59,379][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:38:59,381][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 17:38:59,501][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 17:38:59,501][gdb0][WARNING] activate: Cluster uuid is ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 17:38:59,501][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:38:59,505][gdb0][WARNING] activate: Cluster name is ceph
[2017-05-31 17:38:59,505][gdb0][WARNING] activate: OSD uuid is 1b3b5a35-7de7-489c-8108-1493f28b991b
[2017-05-31 17:38:59,505][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 17:38:59,505][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 1b3b5a35-7de7-489c-8108-1493f28b991b
[2017-05-31 17:38:59,670][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.13365.tmp
[2017-05-31 17:38:59,670][gdb0][WARNING] activate: OSD id is 0
[2017-05-31 17:38:59,670][gdb0][WARNING] activate: Initializing OSD...
[2017-05-31 17:38:59,670][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-05-31 17:38:59,784][gdb0][WARNING] got monmap epoch 2
[2017-05-31 17:38:59,800][gdb0][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 0 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid 1b3b5a35-7de7-489c-8108-1493f28b991b --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-05-31 17:38:59,832][gdb0][WARNING] activate: Marking with init system systemd
[2017-05-31 17:38:59,832][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-05-31 17:38:59,832][gdb0][WARNING] activate: Authorizing OSD key...
[2017-05-31 17:38:59,832][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.0 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-05-31 17:38:59,997][gdb0][WARNING] added key for osd.0
[2017-05-31 17:38:59,997][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.13365.tmp
[2017-05-31 17:38:59,997][gdb0][WARNING] activate: ceph osd.0 data dir is ready at /mnt/memstore
[2017-05-31 17:38:59,997][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 17:38:59,997][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 17:38:59,998][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:38:59,998][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:38:59,998][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 17:38:59,998][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:38:59,998][gdb0][WARNING]     args.func(args)
[2017-05-31 17:38:59,998][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 17:38:59,998][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 17:38:59,998][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3543, in activate_dir
[2017-05-31 17:38:59,999][gdb0][WARNING]     old = os.readlink(canonical)
[2017-05-31 17:38:59,999][gdb0][WARNING] OSError: [Errno 22] Invalid argument: '/var/lib/ceph/osd/ceph-0'
[2017-05-31 17:39:00,006][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:39:00,007][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 17:41:18,574][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:41:18,574][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-05-31 17:41:18,575][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:41:18,575][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:41:18,575][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 17:41:18,575][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:41:18,575][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 17:41:18,575][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:41:18,575][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 17:41:18,575][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 17:41:18,575][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:41:18,575][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 17:41:18,575][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 17:41:18,575][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:41:18,575][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fc749669908>
[2017-05-31 17:41:18,575][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:41:18,575][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 17:41:18,576][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fc7498bfaa0>
[2017-05-31 17:41:18,576][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:41:18,576][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:41:18,576][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 17:41:18,576][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:41:18,818][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:41:19,037][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:41:19,038][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:41:19,053][gdb0][DEBUG ] detect machine type
[2017-05-31 17:41:19,057][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:41:19,058][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:41:19,058][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 17:41:19,058][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:41:19,060][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-05-31 17:41:19,060][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:41:19,062][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 17:41:19,183][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:41:19,186][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:41:19,202][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:41:19,218][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:41:19,225][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 17:41:19,241][gdb0][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-05-31 17:41:19,241][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.13634.tmp
[2017-05-31 17:41:19,242][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.13634.tmp
[2017-05-31 17:41:19,246][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.13634.tmp
[2017-05-31 17:41:24,266][gdb0][INFO  ] checking OSD status...
[2017-05-31 17:41:24,267][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:41:24,269][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 17:41:24,435][gdb0][WARNING] there is 1 OSD down
[2017-05-31 17:41:24,435][gdb0][WARNING] there is 1 OSD out
[2017-05-31 17:41:24,435][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-05-31 17:41:36,573][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:41:36,574][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 17:41:36,574][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:41:36,574][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:41:36,574][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:41:36,574][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:41:36,574][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 17:41:36,574][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:41:36,574][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f5dc56f3908>
[2017-05-31 17:41:36,574][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:41:36,574][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f5dc5949aa0>
[2017-05-31 17:41:36,574][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:41:36,575][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:41:36,575][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:41:36,575][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:41:36,814][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:41:37,046][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:41:37,046][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:41:37,062][gdb0][DEBUG ] detect machine type
[2017-05-31 17:41:37,065][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:41:37,066][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:41:37,066][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 17:41:37,066][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 17:41:37,067][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:41:37,068][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 17:41:37,189][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 17:41:37,189][gdb0][WARNING] activate: Cluster uuid is ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 17:41:37,189][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:41:37,192][gdb0][WARNING] activate: Cluster name is ceph
[2017-05-31 17:41:37,193][gdb0][WARNING] activate: OSD uuid is a824912d-c2ff-4ce5-b541-4675a0141fef
[2017-05-31 17:41:37,193][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 17:41:37,193][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise a824912d-c2ff-4ce5-b541-4675a0141fef
[2017-05-31 17:41:37,407][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.13755.tmp
[2017-05-31 17:41:37,407][gdb0][WARNING] activate: OSD id is 1
[2017-05-31 17:41:37,407][gdb0][WARNING] activate: Initializing OSD...
[2017-05-31 17:41:37,408][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-05-31 17:41:37,572][gdb0][WARNING] got monmap epoch 2
[2017-05-31 17:41:37,572][gdb0][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 1 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid a824912d-c2ff-4ce5-b541-4675a0141fef --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-05-31 17:41:37,572][gdb0][WARNING] activate: Marking with init system systemd
[2017-05-31 17:41:37,572][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-05-31 17:41:37,572][gdb0][WARNING] activate: Authorizing OSD key...
[2017-05-31 17:41:37,572][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.1 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-05-31 17:41:37,737][gdb0][WARNING] added key for osd.1
[2017-05-31 17:41:37,737][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.13755.tmp
[2017-05-31 17:41:37,737][gdb0][WARNING] activate: ceph osd.1 data dir is ready at /mnt/memstore
[2017-05-31 17:41:37,737][gdb0][WARNING] activate_dir: Creating symlink /var/lib/ceph/osd/ceph-1 -> /mnt/memstore
[2017-05-31 17:41:37,737][gdb0][WARNING] start_daemon: Starting ceph osd.1...
[2017-05-31 17:41:37,737][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@1
[2017-05-31 17:41:37,737][gdb0][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@1.service.
[2017-05-31 17:41:37,801][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@1 --runtime
[2017-05-31 17:41:37,833][gdb0][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@1
[2017-05-31 17:41:37,833][gdb0][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@1.service to /lib/systemd/system/ceph-osd@.service.
[2017-05-31 17:41:37,897][gdb0][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@1
[2017-05-31 17:41:42,967][gdb0][INFO  ] checking OSD status...
[2017-05-31 17:41:42,967][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:41:42,969][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 17:41:43,135][gdb0][WARNING] there is 1 OSD down
[2017-05-31 17:41:43,135][gdb0][WARNING] there is 1 OSD out
[2017-05-31 17:41:43,137][gdb0][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-05-31 17:54:07,021][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:54:07,021][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 17:54:07,022][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:54:07,022][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:54:07,022][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:54:07,022][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:54:07,022][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 17:54:07,022][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:54:07,022][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa99b391908>
[2017-05-31 17:54:07,022][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:54:07,022][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fa99b5e7aa0>
[2017-05-31 17:54:07,022][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:54:07,022][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:54:07,022][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 17:54:07,023][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 17:54:07,263][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 17:54:07,490][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 17:54:07,490][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 17:54:07,506][gdb0][DEBUG ] detect machine type
[2017-05-31 17:54:07,510][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:54:07,511][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:54:07,511][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 17:54:07,511][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 17:54:07,511][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:54:07,513][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 17:54:07,634][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 17:54:07,634][gdb0][WARNING] activate: Cluster uuid is ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 17:54:07,634][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:54:07,638][gdb0][WARNING] activate: Cluster name is ceph
[2017-05-31 17:54:07,638][gdb0][WARNING] activate: OSD uuid is a824912d-c2ff-4ce5-b541-4675a0141fef
[2017-05-31 17:54:07,638][gdb0][WARNING] activate: OSD id is 1
[2017-05-31 17:54:07,638][gdb0][WARNING] activate: Marking with init system systemd
[2017-05-31 17:54:07,638][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-05-31 17:54:07,639][gdb0][WARNING] activate: ceph osd.1 data dir is ready at /mnt/memstore
[2017-05-31 17:54:07,639][gdb0][WARNING] start_daemon: Starting ceph osd.1...
[2017-05-31 17:54:07,639][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@1
[2017-05-31 17:54:07,655][gdb0][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@1.service.
[2017-05-31 17:54:07,719][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@1 --runtime
[2017-05-31 17:54:07,751][gdb0][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@1
[2017-05-31 17:54:07,751][gdb0][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@1.service to /lib/systemd/system/ceph-osd@.service.
[2017-05-31 17:54:07,815][gdb0][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@1
[2017-05-31 17:54:12,821][gdb0][INFO  ] checking OSD status...
[2017-05-31 17:54:12,821][gdb0][DEBUG ] find the location of an executable
[2017-05-31 17:54:12,823][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 17:54:12,989][gdb0][WARNING] there is 1 OSD down
[2017-05-31 17:54:12,989][gdb0][WARNING] there is 1 OSD out
[2017-05-31 17:54:12,991][gdb0][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-05-31 17:54:19,274][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:54:19,274][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-05-31 17:54:19,274][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:54:19,274][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:54:19,274][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 17:54:19,274][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 17:54:19,274][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 17:54:19,275][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:54:19,275][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 17:54:19,275][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 17:54:19,275][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:54:19,275][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 17:54:19,275][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 17:54:19,275][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:54:19,275][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0a43521908>
[2017-05-31 17:54:19,275][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:54:19,275][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 17:54:19,275][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f0a43777aa0>
[2017-05-31 17:54:19,275][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:54:19,275][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:54:19,275][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 17:54:19,276][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 17:54:19,523][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 17:54:19,755][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 17:54:19,755][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 17:54:19,772][gdb1][DEBUG ] detect machine type
[2017-05-31 17:54:19,776][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:54:19,776][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:54:19,777][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-05-31 17:54:19,777][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:54:19,779][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-05-31 17:54:19,779][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:54:19,782][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 17:54:19,952][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:54:19,952][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:54:19,952][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:54:19,953][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:54:19,960][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 17:54:19,968][gdb1][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-05-31 17:54:24,989][gdb1][INFO  ] checking OSD status...
[2017-05-31 17:54:24,989][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:54:24,991][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 17:54:25,157][gdb1][WARNING] there is 1 OSD down
[2017-05-31 17:54:25,157][gdb1][WARNING] there is 1 OSD out
[2017-05-31 17:54:25,157][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-05-31 17:55:02,565][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:55:02,565][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-05-31 17:55:02,566][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:55:02,566][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:55:02,566][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:55:02,566][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:55:02,566][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 17:55:02,566][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:55:02,566][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f4a8d45f908>
[2017-05-31 17:55:02,566][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:55:02,566][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f4a8d6b5aa0>
[2017-05-31 17:55:02,566][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:55:02,566][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:55:02,566][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 17:55:02,567][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 17:55:02,807][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 17:55:03,030][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 17:55:03,031][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 17:55:03,047][gdb1][DEBUG ] detect machine type
[2017-05-31 17:55:03,051][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:55:03,051][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:55:03,051][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-05-31 17:55:03,052][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 17:55:03,052][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:55:03,053][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 17:55:03,174][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 17:55:03,174][gdb1][WARNING] activate: Cluster uuid is da581514-b214-4b7a-baef-020d0e69b258
[2017-05-31 17:55:03,174][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:55:03,190][gdb1][WARNING] Traceback (most recent call last):
[2017-05-31 17:55:03,190][gdb1][WARNING]   File "/usr/local/bin/ceph-disk", line 9, in <module>
[2017-05-31 17:55:03,190][gdb1][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:55:03,190][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:55:03,190][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:55:03,190][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 17:55:03,190][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 17:55:03,190][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3609, in activate
[2017-05-31 17:55:03,190][gdb1][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid da581514-b214-4b7a-baef-020d0e69b258
[2017-05-31 17:55:03,192][gdb1][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:55:03,192][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 17:55:25,577][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:55:25,577][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb1
[2017-05-31 17:55:25,577][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:55:25,577][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:55:25,577][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:55:25,577][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:55:25,577][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:55:25,577][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7b0446a518>
[2017-05-31 17:55:25,577][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:55:25,578][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-05-31 17:55:25,578][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f7b04d81938>
[2017-05-31 17:55:25,578][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:55:25,578][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:55:25,578][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-05-31 17:55:25,819][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 17:55:26,051][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 17:55:26,052][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 17:55:26,068][gdb1][DEBUG ] detect machine type
[2017-05-31 17:55:26,072][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:55:27,598][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:55:27,599][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-05-31 17:55:27,599][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:55:27,599][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:55:27,599][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:55:27,599][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:55:27,599][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 17:55:27,599][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:55:27,599][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f2e1b214908>
[2017-05-31 17:55:27,599][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:55:27,599][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f2e1b46aaa0>
[2017-05-31 17:55:27,599][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:55:27,599][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:55:27,599][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 17:55:27,600][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 17:55:27,839][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 17:55:28,067][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 17:55:28,068][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 17:55:28,084][gdb1][DEBUG ] detect machine type
[2017-05-31 17:55:28,088][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:55:28,089][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:55:28,089][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-05-31 17:55:28,089][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 17:55:28,089][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:55:28,091][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 17:55:28,212][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 17:55:28,212][gdb1][WARNING] activate: Cluster uuid is da581514-b214-4b7a-baef-020d0e69b258
[2017-05-31 17:55:28,212][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:55:28,228][gdb1][WARNING] Traceback (most recent call last):
[2017-05-31 17:55:28,228][gdb1][WARNING]   File "/usr/local/bin/ceph-disk", line 9, in <module>
[2017-05-31 17:55:28,228][gdb1][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:55:28,228][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:55:28,228][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:55:28,228][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 17:55:28,228][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 17:55:28,228][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3609, in activate
[2017-05-31 17:55:28,229][gdb1][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid da581514-b214-4b7a-baef-020d0e69b258
[2017-05-31 17:55:28,236][gdb1][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:55:28,236][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 17:55:42,010][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:55:42,010][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-05-31 17:55:42,011][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:55:42,011][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:55:42,011][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 17:55:42,011][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 17:55:42,011][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 17:55:42,011][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:55:42,011][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 17:55:42,011][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 17:55:42,011][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:55:42,011][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 17:55:42,011][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 17:55:42,011][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:55:42,011][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fd366180908>
[2017-05-31 17:55:42,011][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:55:42,012][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 17:55:42,012][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fd3663d6aa0>
[2017-05-31 17:55:42,012][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:55:42,012][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:55:42,012][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 17:55:42,012][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 17:55:42,259][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 17:55:42,450][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 17:55:42,451][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 17:55:42,467][gdb1][DEBUG ] detect machine type
[2017-05-31 17:55:42,471][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:55:42,471][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:55:42,472][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-05-31 17:55:42,472][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:55:42,474][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-05-31 17:55:42,474][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:55:42,476][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 17:55:42,647][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:55:42,647][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:55:42,647][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:55:42,647][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:55:42,651][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 17:55:42,666][gdb1][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-05-31 17:55:47,679][gdb1][INFO  ] checking OSD status...
[2017-05-31 17:55:47,679][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:55:47,682][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 17:55:47,847][gdb1][WARNING] there is 1 OSD down
[2017-05-31 17:55:47,847][gdb1][WARNING] there is 1 OSD out
[2017-05-31 17:55:47,848][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-05-31 17:55:56,173][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:55:56,173][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-05-31 17:55:56,173][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:55:56,173][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:55:56,173][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:55:56,173][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:55:56,173][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 17:55:56,174][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:55:56,174][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7efc390cd908>
[2017-05-31 17:55:56,174][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:55:56,174][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7efc39323aa0>
[2017-05-31 17:55:56,174][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:55:56,174][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:55:56,174][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 17:55:56,174][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 17:55:56,419][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 17:55:56,619][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 17:55:56,620][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 17:55:56,636][gdb1][DEBUG ] detect machine type
[2017-05-31 17:55:56,640][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:55:56,641][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:55:56,641][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-05-31 17:55:56,641][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 17:55:56,641][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:55:56,643][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 17:55:56,813][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 17:55:56,814][gdb1][WARNING] activate: Cluster uuid is da581514-b214-4b7a-baef-020d0e69b258
[2017-05-31 17:55:56,814][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:55:56,814][gdb1][WARNING] Traceback (most recent call last):
[2017-05-31 17:55:56,814][gdb1][WARNING]   File "/usr/local/bin/ceph-disk", line 9, in <module>
[2017-05-31 17:55:56,814][gdb1][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:55:56,814][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:55:56,814][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:55:56,814][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 17:55:56,814][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 17:55:56,814][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3609, in activate
[2017-05-31 17:55:56,814][gdb1][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid da581514-b214-4b7a-baef-020d0e69b258
[2017-05-31 17:55:56,815][gdb1][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:55:56,815][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 17:57:12,883][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:57:12,883][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-05-31 17:57:12,883][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:57:12,883][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:57:12,884][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 17:57:12,884][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 17:57:12,884][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 17:57:12,884][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:57:12,884][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 17:57:12,884][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 17:57:12,884][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:57:12,884][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 17:57:12,884][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 17:57:12,884][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:57:12,884][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f98fa502908>
[2017-05-31 17:57:12,884][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:57:12,884][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 17:57:12,884][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f98fa758aa0>
[2017-05-31 17:57:12,884][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:57:12,885][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:57:12,885][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 17:57:12,885][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 17:57:13,127][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 17:57:13,363][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 17:57:13,363][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 17:57:13,380][gdb1][DEBUG ] detect machine type
[2017-05-31 17:57:13,384][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:57:13,384][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:57:13,384][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-05-31 17:57:13,385][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:57:13,387][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-05-31 17:57:13,387][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:57:13,389][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 17:57:13,509][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:57:13,525][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:57:13,541][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:57:13,548][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:57:13,564][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 17:57:13,580][gdb1][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-05-31 17:57:13,580][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.13708.tmp
[2017-05-31 17:57:13,580][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.13708.tmp
[2017-05-31 17:57:13,583][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.13708.tmp
[2017-05-31 17:57:18,604][gdb1][INFO  ] checking OSD status...
[2017-05-31 17:57:18,604][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:57:18,607][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 17:57:18,772][gdb1][WARNING] there is 1 OSD down
[2017-05-31 17:57:18,773][gdb1][WARNING] there is 1 OSD out
[2017-05-31 17:57:18,773][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-05-31 17:57:23,589][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:57:23,589][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-05-31 17:57:23,590][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:57:23,590][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:57:23,590][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:57:23,590][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:57:23,590][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 17:57:23,590][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:57:23,590][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f1db2621908>
[2017-05-31 17:57:23,590][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:57:23,590][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f1db2877aa0>
[2017-05-31 17:57:23,590][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:57:23,590][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:57:23,590][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 17:57:23,591][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 17:57:23,831][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 17:57:24,062][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 17:57:24,063][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 17:57:24,079][gdb1][DEBUG ] detect machine type
[2017-05-31 17:57:24,083][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:57:24,084][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:57:24,084][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-05-31 17:57:24,084][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 17:57:24,084][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:57:24,086][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 17:57:24,257][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 17:57:24,257][gdb1][WARNING] activate: Cluster uuid is ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 17:57:24,257][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:57:24,257][gdb1][WARNING] activate: Cluster name is ceph
[2017-05-31 17:57:24,257][gdb1][WARNING] activate: OSD uuid is 101ab77c-5335-474c-915b-a82ed5ca89ba
[2017-05-31 17:57:24,257][gdb1][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 17:57:24,258][gdb1][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 101ab77c-5335-474c-915b-a82ed5ca89ba
[2017-05-31 17:57:24,289][gdb1][WARNING] Traceback (most recent call last):
[2017-05-31 17:57:24,290][gdb1][WARNING]   File "/usr/local/bin/ceph-disk", line 9, in <module>
[2017-05-31 17:57:24,290][gdb1][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:57:24,290][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:57:24,290][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:57:24,290][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 17:57:24,290][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 17:57:24,290][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3625, in activate
[2017-05-31 17:57:24,290][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 1075, in allocate_osd_id
[2017-05-31 17:57:24,290][gdb1][WARNING] ceph_disk.main.Error: Error: ceph osd create failed: Command '/usr/bin/ceph' returned non-zero exit status 1: 2017-05-31 17:57:24.280299 7fa85e850700  0 librados: client.bootstrap-osd authentication error (1) Operation not permitted
[2017-05-31 17:57:24,290][gdb1][WARNING] error connecting to the cluster
[2017-05-31 17:57:24,290][gdb1][WARNING] 
[2017-05-31 17:57:24,298][gdb1][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:57:24,298][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 17:58:07,650][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:58:07,650][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-05-31 17:58:07,650][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:58:07,650][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:58:07,650][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:58:07,650][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:58:07,650][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 17:58:07,650][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:58:07,651][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa3a7716908>
[2017-05-31 17:58:07,651][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:58:07,651][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fa3a796caa0>
[2017-05-31 17:58:07,651][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:58:07,651][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:58:07,651][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 17:58:07,651][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 17:58:07,887][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 17:58:08,082][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 17:58:08,083][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 17:58:08,099][gdb1][DEBUG ] detect machine type
[2017-05-31 17:58:08,103][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:58:08,103][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:58:08,103][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-05-31 17:58:08,103][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 17:58:08,104][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:58:08,105][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 17:58:08,226][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 17:58:08,226][gdb1][WARNING] activate: Cluster uuid is ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 17:58:08,226][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:58:08,242][gdb1][WARNING] activate: Cluster name is ceph
[2017-05-31 17:58:08,242][gdb1][WARNING] activate: OSD uuid is 101ab77c-5335-474c-915b-a82ed5ca89ba
[2017-05-31 17:58:08,242][gdb1][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 17:58:08,242][gdb1][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 101ab77c-5335-474c-915b-a82ed5ca89ba
[2017-05-31 17:58:08,306][gdb1][WARNING] Traceback (most recent call last):
[2017-05-31 17:58:08,306][gdb1][WARNING]   File "/usr/local/bin/ceph-disk", line 9, in <module>
[2017-05-31 17:58:08,306][gdb1][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 17:58:08,307][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5653, in run
[2017-05-31 17:58:08,307][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5604, in main
[2017-05-31 17:58:08,307][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 17:58:08,307][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 17:58:08,307][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3625, in activate
[2017-05-31 17:58:08,307][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 1075, in allocate_osd_id
[2017-05-31 17:58:08,307][gdb1][WARNING] ceph_disk.main.Error: Error: ceph osd create failed: Command '/usr/bin/ceph' returned non-zero exit status 1: 2017-05-31 17:58:08.298544 7f68f30e8700  0 librados: client.bootstrap-osd authentication error (1) Operation not permitted
[2017-05-31 17:58:08,307][gdb1][WARNING] error connecting to the cluster
[2017-05-31 17:58:08,307][gdb1][WARNING] 
[2017-05-31 17:58:08,315][gdb1][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 17:58:08,315][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 17:59:27,881][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:59:27,881][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb1
[2017-05-31 17:59:27,882][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:59:27,882][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:59:27,882][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:59:27,882][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:59:27,882][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:59:27,882][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f4023cc6518>
[2017-05-31 17:59:27,882][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:59:27,882][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-05-31 17:59:27,882][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f40245dd938>
[2017-05-31 17:59:27,882][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:59:27,882][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:59:27,882][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-05-31 17:59:28,123][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 17:59:28,346][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 17:59:28,347][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 17:59:28,363][gdb1][DEBUG ] detect machine type
[2017-05-31 17:59:28,367][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:59:34,857][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:59:34,857][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-05-31 17:59:34,857][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:59:34,857][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:59:34,857][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 17:59:34,858][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 17:59:34,858][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 17:59:34,858][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:59:34,858][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 17:59:34,858][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 17:59:34,858][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:59:34,858][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 17:59:34,858][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 17:59:34,858][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:59:34,858][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ffbf28de908>
[2017-05-31 17:59:34,858][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:59:34,858][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 17:59:34,858][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7ffbf2b34aa0>
[2017-05-31 17:59:34,858][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:59:34,858][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:59:34,858][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 17:59:34,859][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 17:59:35,099][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 17:59:35,330][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 17:59:35,331][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 17:59:35,347][gdb1][DEBUG ] detect machine type
[2017-05-31 17:59:35,350][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:59:35,351][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:59:35,351][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-05-31 17:59:35,352][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 17:59:35,354][gdb1][WARNING] osd keyring does not exist yet, creating one
[2017-05-31 17:59:35,354][gdb1][DEBUG ] create a keyring file
[2017-05-31 17:59:35,356][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-05-31 17:59:35,356][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:59:35,358][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 17:59:35,479][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:59:35,494][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:59:35,510][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:59:35,518][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 17:59:35,533][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 17:59:35,541][gdb1][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-05-31 17:59:40,562][gdb1][INFO  ] checking OSD status...
[2017-05-31 17:59:40,562][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:59:40,565][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 17:59:40,730][gdb1][WARNING] there is 1 OSD down
[2017-05-31 17:59:40,730][gdb1][WARNING] there is 1 OSD out
[2017-05-31 17:59:40,730][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-05-31 17:59:53,587][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 17:59:53,587][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-05-31 17:59:53,587][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 17:59:53,587][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 17:59:53,587][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 17:59:53,587][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 17:59:53,587][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 17:59:53,587][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 17:59:53,588][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f1e2cdae908>
[2017-05-31 17:59:53,588][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 17:59:53,588][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f1e2d004aa0>
[2017-05-31 17:59:53,588][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 17:59:53,588][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 17:59:53,588][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 17:59:53,588][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 17:59:53,832][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 17:59:54,058][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 17:59:54,059][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 17:59:54,075][gdb1][DEBUG ] detect machine type
[2017-05-31 17:59:54,079][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:59:54,080][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 17:59:54,080][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-05-31 17:59:54,080][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 17:59:54,080][gdb1][DEBUG ] find the location of an executable
[2017-05-31 17:59:54,082][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 17:59:54,202][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 17:59:54,202][gdb1][WARNING] activate: Cluster uuid is ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 17:59:54,202][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 17:59:54,218][gdb1][WARNING] activate: Cluster name is ceph
[2017-05-31 17:59:54,218][gdb1][WARNING] activate: OSD uuid is 101ab77c-5335-474c-915b-a82ed5ca89ba
[2017-05-31 17:59:54,218][gdb1][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 17:59:54,218][gdb1][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 101ab77c-5335-474c-915b-a82ed5ca89ba
[2017-05-31 17:59:54,884][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.14229.tmp
[2017-05-31 17:59:54,884][gdb1][WARNING] activate: OSD id is 2
[2017-05-31 17:59:54,885][gdb1][WARNING] activate: Initializing OSD...
[2017-05-31 17:59:54,885][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-05-31 17:59:54,999][gdb1][WARNING] got monmap epoch 2
[2017-05-31 17:59:55,006][gdb1][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 2 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid 101ab77c-5335-474c-915b-a82ed5ca89ba --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-05-31 17:59:55,038][gdb1][WARNING] activate: Marking with init system systemd
[2017-05-31 17:59:55,038][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-05-31 17:59:55,040][gdb1][WARNING] activate: Authorizing OSD key...
[2017-05-31 17:59:55,040][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.2 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-05-31 17:59:55,204][gdb1][WARNING] added key for osd.2
[2017-05-31 17:59:55,204][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.14229.tmp
[2017-05-31 17:59:55,204][gdb1][WARNING] activate: ceph osd.2 data dir is ready at /mnt/memstore
[2017-05-31 17:59:55,204][gdb1][WARNING] activate_dir: Creating symlink /var/lib/ceph/osd/ceph-2 -> /mnt/memstore
[2017-05-31 17:59:55,204][gdb1][WARNING] start_daemon: Starting ceph osd.2...
[2017-05-31 17:59:55,205][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@2
[2017-05-31 17:59:55,212][gdb1][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@2.service.
[2017-05-31 17:59:55,276][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@2 --runtime
[2017-05-31 17:59:55,308][gdb1][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@2
[2017-05-31 17:59:55,309][gdb1][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@2.service to /lib/systemd/system/ceph-osd@.service.
[2017-05-31 17:59:55,373][gdb1][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@2
[2017-05-31 18:00:00,493][gdb1][INFO  ] checking OSD status...
[2017-05-31 18:00:00,493][gdb1][DEBUG ] find the location of an executable
[2017-05-31 18:00:00,495][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 18:00:00,661][gdb1][WARNING] there is 1 OSD down
[2017-05-31 18:00:00,661][gdb1][WARNING] there is 1 OSD out
[2017-05-31 18:00:00,663][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-05-31 18:45:31,589][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:45:31,589][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-05-31 18:45:31,589][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:45:31,589][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:45:31,589][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:45:31,590][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:45:31,590][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:45:31,590][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f84a3f46fc8>
[2017-05-31 18:45:31,590][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:45:31,590][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-05-31 18:45:31,590][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f84a48591b8>
[2017-05-31 18:45:31,590][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:45:31,590][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:45:31,590][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-05-31 18:45:31,590][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-05-31 18:45:31,590][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-05-31 18:45:31,590][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-05-31 18:45:31,617][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 18:45:31,631][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 18:45:31,631][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 18:45:31,648][gdb3][DEBUG ] detect machine type
[2017-05-31 18:45:31,650][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 18:45:31,650][gdb3][INFO  ] Purging Ceph on gdb3
[2017-05-31 18:45:31,652][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-05-31 18:45:31,690][gdb3][DEBUG ] Reading package lists...
[2017-05-31 18:45:31,854][gdb3][DEBUG ] Building dependency tree...
[2017-05-31 18:45:31,854][gdb3][DEBUG ] Reading state information...
[2017-05-31 18:45:31,969][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-05-31 18:45:31,969][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-05-31 18:45:31,969][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-05-31 18:45:31,969][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-05-31 18:45:31,969][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-05-31 18:45:31,969][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-05-31 18:45:31,969][gdb3][DEBUG ]   linux-headers-4.4.0-1013-aws linux-image-4.4.0-1013-aws ntp python-blinker
[2017-05-31 18:45:31,969][gdb3][DEBUG ]   python-cephfs python-cffi-backend python-chardet python-cryptography
[2017-05-31 18:45:31,970][gdb3][DEBUG ]   python-enum34 python-flask python-idna python-ipaddress python-itsdangerous
[2017-05-31 18:45:31,970][gdb3][DEBUG ]   python-jinja2 python-markupsafe python-ndg-httpsclient python-openssl
[2017-05-31 18:45:31,970][gdb3][DEBUG ]   python-pyasn1 python-pyinotify python-rados python-rbd python-requests
[2017-05-31 18:45:31,970][gdb3][DEBUG ]   python-rgw python-six python-urllib3 python-werkzeug
[2017-05-31 18:45:31,970][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-05-31 18:45:31,970][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-05-31 18:45:31,970][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-05-31 18:45:32,084][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 35 not upgraded.
[2017-05-31 18:45:32,084][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-05-31 18:45:32,149][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 104522 files and directories currently installed.)
[2017-05-31 18:45:32,149][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-05-31 18:45:32,313][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-05-31 18:45:32,427][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-05-31 18:45:32,459][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-05-31 18:45:32,675][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-05-31 18:45:32,791][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-05-31 18:45:32,960][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-05-31 18:45:33,026][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-05-31 18:45:33,029][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-05-31 18:45:33,200][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-05-31 18:45:33,264][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-05-31 18:45:33,279][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-05-31 18:45:33,447][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-05-31 18:45:33,478][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-05-31 18:45:33,643][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-05-31 18:45:33,675][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-05-31 18:45:33,690][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-05-31 18:45:33,805][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu7) ...
[2017-05-31 18:45:34,671][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-05-31 18:45:34,838][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:45:34,839][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-05-31 18:45:34,839][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:45:34,839][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:45:34,839][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:45:34,839][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:45:34,839][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:45:34,839][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f106bbfe710>
[2017-05-31 18:45:34,839][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:45:34,839][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-05-31 18:45:34,839][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f106c50b230>
[2017-05-31 18:45:34,839][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:45:34,839][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:45:34,839][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-05-31 18:45:34,866][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 18:45:34,880][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 18:45:34,881][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 18:45:34,897][gdb3][DEBUG ] detect machine type
[2017-05-31 18:45:34,900][gdb3][DEBUG ] find the location of an executable
[2017-05-31 18:45:34,916][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 18:45:34,931][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 18:45:34,931][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 18:45:34,948][gdb3][DEBUG ] detect machine type
[2017-05-31 18:45:34,950][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 18:45:34,950][gdb3][INFO  ] purging data on gdb3
[2017-05-31 18:45:34,951][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-05-31 18:45:34,964][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-05-31 18:45:35,137][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:45:35,137][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-05-31 18:45:35,137][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:45:35,137][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:45:35,137][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:45:35,137][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:45:35,137][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:45:35,137][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0d360b29e0>
[2017-05-31 18:45:35,137][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:45:35,138][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7f0d36975848>
[2017-05-31 18:45:35,138][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:45:35,138][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:45:56,148][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:45:56,148][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-05-31 18:45:56,148][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:45:56,148][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:45:56,149][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:45:56,149][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:45:56,149][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:45:56,149][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fc886d8f560>
[2017-05-31 18:45:56,149][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:45:56,149][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-05-31 18:45:56,149][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-05-31 18:45:56,149][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7fc887413758>
[2017-05-31 18:45:56,149][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-05-31 18:45:56,149][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:45:56,149][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-05-31 18:45:56,149][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:45:56,149][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-05-31 18:45:56,149][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-05-31 18:45:56,150][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-05-31 18:45:56,176][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 18:45:56,190][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 18:45:56,191][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 18:45:56,207][gdb3][DEBUG ] detect machine type
[2017-05-31 18:45:56,210][gdb3][DEBUG ] find the location of an executable
[2017-05-31 18:45:56,211][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-05-31 18:45:56,222][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-05-31 18:45:56,229][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-05-31 18:45:56,229][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-05-31 18:45:56,229][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-05-31 18:45:56,229][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-05-31 18:45:56,229][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-05-31 18:45:56,229][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-05-31 18:45:56,229][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-05-31 18:45:56,229][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-05-31 18:45:56,394][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:45:56,395][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-05-31 18:45:56,395][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:45:56,395][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:45:56,395][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:45:56,395][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:45:56,395][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-05-31 18:45:56,395][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:45:56,395][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6db4199e60>
[2017-05-31 18:45:56,395][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:45:56,395][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f6db416eb18>
[2017-05-31 18:45:56,395][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:45:56,395][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-05-31 18:45:56,396][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:45:56,396][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-05-31 18:45:56,396][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-05-31 18:45:56,422][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 18:45:56,437][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 18:45:56,437][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 18:45:56,454][gdb3][DEBUG ] detect machine type
[2017-05-31 18:45:56,457][gdb3][DEBUG ] find the location of an executable
[2017-05-31 18:45:56,457][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-05-31 18:45:56,457][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-05-31 18:45:56,457][gdb3][DEBUG ] get remote short hostname
[2017-05-31 18:45:56,457][gdb3][DEBUG ] deploying mon to gdb3
[2017-05-31 18:45:56,458][gdb3][DEBUG ] get remote short hostname
[2017-05-31 18:45:56,458][gdb3][DEBUG ] remote hostname: gdb3
[2017-05-31 18:45:56,458][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:45:56,460][gdb3][DEBUG ] create the mon path if it does not exist
[2017-05-31 18:45:56,460][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-05-31 18:45:56,460][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-05-31 18:45:56,461][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-05-31 18:45:56,461][gdb3][DEBUG ] create the monitor keyring file
[2017-05-31 18:45:56,462][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-05-31 18:45:56,500][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-05-31 18:45:56,500][gdb3][DEBUG ] ceph-mon: set fsid to c676bc10-14a8-4f7c-93e4-c9f0324506d5
[2017-05-31 18:45:56,504][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-05-31 18:45:56,505][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-05-31 18:45:56,506][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-05-31 18:45:56,506][gdb3][DEBUG ] create the init path if it does not exist
[2017-05-31 18:45:56,507][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-05-31 18:45:56,577][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-05-31 18:45:56,644][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-05-31 18:45:58,715][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 18:45:58,780][gdb3][DEBUG ] ********************************************************************************
[2017-05-31 18:45:58,780][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-05-31 18:45:58,781][gdb3][DEBUG ] {
[2017-05-31 18:45:58,781][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-05-31 18:45:58,781][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-05-31 18:45:58,782][gdb3][DEBUG ]   "features": {
[2017-05-31 18:45:58,782][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-05-31 18:45:58,782][gdb3][DEBUG ]     "quorum_mon": [
[2017-05-31 18:45:58,782][gdb3][DEBUG ]       "kraken", 
[2017-05-31 18:45:58,782][gdb3][DEBUG ]       "luminous"
[2017-05-31 18:45:58,782][gdb3][DEBUG ]     ], 
[2017-05-31 18:45:58,782][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-05-31 18:45:58,782][gdb3][DEBUG ]     "required_mon": [
[2017-05-31 18:45:58,782][gdb3][DEBUG ]       "kraken", 
[2017-05-31 18:45:58,783][gdb3][DEBUG ]       "luminous"
[2017-05-31 18:45:58,783][gdb3][DEBUG ]     ]
[2017-05-31 18:45:58,783][gdb3][DEBUG ]   }, 
[2017-05-31 18:45:58,783][gdb3][DEBUG ]   "monmap": {
[2017-05-31 18:45:58,783][gdb3][DEBUG ]     "created": "2017-05-31 18:45:56.486262", 
[2017-05-31 18:45:58,783][gdb3][DEBUG ]     "epoch": 2, 
[2017-05-31 18:45:58,783][gdb3][DEBUG ]     "features": {
[2017-05-31 18:45:58,783][gdb3][DEBUG ]       "optional": [], 
[2017-05-31 18:45:58,784][gdb3][DEBUG ]       "persistent": [
[2017-05-31 18:45:58,784][gdb3][DEBUG ]         "kraken", 
[2017-05-31 18:45:58,784][gdb3][DEBUG ]         "luminous"
[2017-05-31 18:45:58,784][gdb3][DEBUG ]       ]
[2017-05-31 18:45:58,784][gdb3][DEBUG ]     }, 
[2017-05-31 18:45:58,784][gdb3][DEBUG ]     "fsid": "c676bc10-14a8-4f7c-93e4-c9f0324506d5", 
[2017-05-31 18:45:58,784][gdb3][DEBUG ]     "modified": "2017-05-31 18:45:56.730163", 
[2017-05-31 18:45:58,784][gdb3][DEBUG ]     "mons": [
[2017-05-31 18:45:58,784][gdb3][DEBUG ]       {
[2017-05-31 18:45:58,784][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-05-31 18:45:58,785][gdb3][DEBUG ]         "name": "gdb3", 
[2017-05-31 18:45:58,785][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-05-31 18:45:58,785][gdb3][DEBUG ]         "rank": 0
[2017-05-31 18:45:58,785][gdb3][DEBUG ]       }
[2017-05-31 18:45:58,785][gdb3][DEBUG ]     ]
[2017-05-31 18:45:58,785][gdb3][DEBUG ]   }, 
[2017-05-31 18:45:58,785][gdb3][DEBUG ]   "name": "gdb3", 
[2017-05-31 18:45:58,785][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-05-31 18:45:58,785][gdb3][DEBUG ]   "quorum": [
[2017-05-31 18:45:58,785][gdb3][DEBUG ]     0
[2017-05-31 18:45:58,785][gdb3][DEBUG ]   ], 
[2017-05-31 18:45:58,785][gdb3][DEBUG ]   "rank": 0, 
[2017-05-31 18:45:58,785][gdb3][DEBUG ]   "state": "leader", 
[2017-05-31 18:45:58,785][gdb3][DEBUG ]   "sync_provider": []
[2017-05-31 18:45:58,785][gdb3][DEBUG ] }
[2017-05-31 18:45:58,785][gdb3][DEBUG ] ********************************************************************************
[2017-05-31 18:45:58,786][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-05-31 18:45:58,787][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 18:45:58,852][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-05-31 18:45:58,868][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 18:45:58,882][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 18:45:58,883][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 18:45:58,899][gdb3][DEBUG ] detect machine type
[2017-05-31 18:45:58,902][gdb3][DEBUG ] find the location of an executable
[2017-05-31 18:45:58,903][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 18:45:58,968][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-05-31 18:45:58,969][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-05-31 18:45:58,969][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-05-31 18:45:58,970][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpDGdpWF
[2017-05-31 18:45:58,986][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 18:45:59,001][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 18:45:59,002][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 18:45:59,018][gdb3][DEBUG ] detect machine type
[2017-05-31 18:45:59,021][gdb3][DEBUG ] get remote short hostname
[2017-05-31 18:45:59,021][gdb3][DEBUG ] fetch remote file
[2017-05-31 18:45:59,023][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 18:45:59,089][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-05-31 18:45:59,255][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-05-31 18:45:59,421][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-05-31 18:45:59,587][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-05-31 18:45:59,754][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-05-31 18:45:59,920][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-05-31 18:46:00,086][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-05-31 18:46:00,253][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-05-31 18:46:00,419][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-05-31 18:46:00,585][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-05-31 18:46:00,751][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-05-31 18:46:00,751][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-05-31 18:46:00,751][ceph_deploy.gatherkeys][INFO  ] Replacing 'ceph.bootstrap-mgr.keyring' and backing up old key as 'ceph.bootstrap-mgr.keyring-20170531184600'
[2017-05-31 18:46:00,751][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-05-31 18:46:00,751][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-05-31 18:46:00,752][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-05-31 18:46:00,752][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpDGdpWF
[2017-05-31 18:46:00,936][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:46:00,936][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-05-31 18:46:00,936][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:46:00,936][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:46:00,937][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:46:00,937][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:46:00,937][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:46:00,937][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fc602b75518>
[2017-05-31 18:46:00,937][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:46:00,937][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-05-31 18:46:00,937][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fc60348c938>
[2017-05-31 18:46:00,937][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:46:00,937][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:46:00,937][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-05-31 18:46:00,964][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 18:46:00,979][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 18:46:00,979][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 18:46:00,996][gdb3][DEBUG ] detect machine type
[2017-05-31 18:46:00,999][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:47:29,974][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:47:29,974][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb0
[2017-05-31 18:47:29,974][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:47:29,974][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:47:29,974][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:47:29,974][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:47:29,974][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:47:29,975][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9869f33518>
[2017-05-31 18:47:29,975][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:47:29,975][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-05-31 18:47:29,975][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f986a84a938>
[2017-05-31 18:47:29,975][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:47:29,975][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:47:29,975][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-05-31 18:47:30,222][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:47:30,449][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:47:30,450][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:47:30,466][gdb0][DEBUG ] detect machine type
[2017-05-31 18:47:30,469][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:47:30,471][ceph_deploy.admin][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite
[2017-05-31 18:47:30,471][ceph_deploy][ERROR ] GenericError: Failed to configure 1 admin hosts

[2017-05-31 18:47:30,649][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:47:30,650][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-05-31 18:47:30,650][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:47:30,650][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:47:30,650][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 18:47:30,650][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 18:47:30,650][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 18:47:30,650][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:47:30,650][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 18:47:30,650][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 18:47:30,650][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:47:30,650][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 18:47:30,650][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 18:47:30,650][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:47:30,650][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7faca145a908>
[2017-05-31 18:47:30,651][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:47:30,651][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 18:47:30,651][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7faca16b0aa0>
[2017-05-31 18:47:30,651][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:47:30,651][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:47:30,651][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 18:47:30,651][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 18:47:30,886][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:47:31,118][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:47:31,118][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:47:31,134][gdb0][DEBUG ] detect machine type
[2017-05-31 18:47:31,138][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:47:31,139][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 18:47:31,139][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 18:47:31,139][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:47:31,141][ceph_deploy.osd][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite
[2017-05-31 18:47:31,141][ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs

[2017-05-31 18:47:31,315][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:47:31,315][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 18:47:31,315][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:47:31,316][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:47:31,316][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:47:31,316][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:47:31,316][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 18:47:31,316][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:47:31,316][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0e1cda0908>
[2017-05-31 18:47:31,316][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:47:31,316][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f0e1cff6aa0>
[2017-05-31 18:47:31,316][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:47:31,316][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:47:31,316][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 18:47:31,317][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 18:47:31,554][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:47:31,782][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:47:31,782][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:47:31,799][gdb0][DEBUG ] detect machine type
[2017-05-31 18:47:31,802][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:47:31,803][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 18:47:31,803][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 18:47:31,803][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 18:47:31,803][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:47:31,806][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 18:47:31,926][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 18:47:31,926][gdb0][WARNING] activate: Cluster uuid is ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 18:47:31,926][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 18:47:31,928][gdb0][WARNING] activate: Cluster name is ceph
[2017-05-31 18:47:31,928][gdb0][WARNING] activate: OSD uuid is a824912d-c2ff-4ce5-b541-4675a0141fef
[2017-05-31 18:47:31,928][gdb0][WARNING] activate: OSD id is 1
[2017-05-31 18:47:31,928][gdb0][WARNING] activate: Marking with init system systemd
[2017-05-31 18:47:31,929][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-05-31 18:47:31,932][gdb0][WARNING] activate: ceph osd.1 data dir is ready at /mnt/memstore
[2017-05-31 18:47:31,932][gdb0][WARNING] start_daemon: Starting ceph osd.1...
[2017-05-31 18:47:31,932][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@1
[2017-05-31 18:47:31,936][gdb0][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@1.service.
[2017-05-31 18:47:32,000][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@1 --runtime
[2017-05-31 18:47:32,064][gdb0][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@1
[2017-05-31 18:47:32,064][gdb0][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@1.service to /lib/systemd/system/ceph-osd@.service.
[2017-05-31 18:47:32,096][gdb0][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@1
[2017-05-31 18:47:37,215][gdb0][INFO  ] checking OSD status...
[2017-05-31 18:47:37,216][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:47:37,218][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 18:47:37,335][gdb0][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-05-31 18:47:55,868][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:47:55,869][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb1
[2017-05-31 18:47:55,869][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:47:55,869][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:47:55,869][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:47:55,869][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:47:55,869][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:47:55,869][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0173bb3518>
[2017-05-31 18:47:55,869][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:47:55,869][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-05-31 18:47:55,869][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f01744ca938>
[2017-05-31 18:47:55,870][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:47:55,870][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:47:55,870][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-05-31 18:47:56,115][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 18:47:56,346][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 18:47:56,347][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 18:47:56,363][gdb1][DEBUG ] detect machine type
[2017-05-31 18:47:56,366][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:47:56,368][ceph_deploy.admin][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite
[2017-05-31 18:47:56,369][ceph_deploy][ERROR ] GenericError: Failed to configure 1 admin hosts

[2017-05-31 18:47:56,548][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:47:56,548][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-05-31 18:47:56,549][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:47:56,549][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:47:56,549][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 18:47:56,549][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 18:47:56,549][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 18:47:56,549][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:47:56,549][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 18:47:56,549][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 18:47:56,549][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:47:56,549][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 18:47:56,549][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 18:47:56,549][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:47:56,549][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb06843d908>
[2017-05-31 18:47:56,549][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:47:56,550][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 18:47:56,550][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fb068693aa0>
[2017-05-31 18:47:56,550][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:47:56,550][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:47:56,550][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 18:47:56,550][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 18:47:56,795][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 18:47:57,026][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 18:47:57,027][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 18:47:57,043][gdb1][DEBUG ] detect machine type
[2017-05-31 18:47:57,046][gdb1][DEBUG ] find the location of an executable
[2017-05-31 18:47:57,047][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 18:47:57,047][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-05-31 18:47:57,048][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:47:57,049][ceph_deploy.osd][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite
[2017-05-31 18:47:57,049][ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs

[2017-05-31 18:47:57,222][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:47:57,222][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-05-31 18:47:57,222][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:47:57,223][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:47:57,223][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:47:57,223][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:47:57,223][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 18:47:57,223][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:47:57,223][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7feedcb72908>
[2017-05-31 18:47:57,223][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:47:57,223][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7feedcdc8aa0>
[2017-05-31 18:47:57,223][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:47:57,223][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:47:57,223][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 18:47:57,224][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 18:47:57,463][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 18:47:57,695][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 18:47:57,696][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 18:47:57,712][gdb1][DEBUG ] detect machine type
[2017-05-31 18:47:57,716][gdb1][DEBUG ] find the location of an executable
[2017-05-31 18:47:57,716][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 18:47:57,717][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-05-31 18:47:57,717][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 18:47:57,717][gdb1][DEBUG ] find the location of an executable
[2017-05-31 18:47:57,719][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 18:47:57,839][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 18:47:57,840][gdb1][WARNING] activate: Cluster uuid is ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 18:47:57,840][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 18:47:57,855][gdb1][WARNING] activate: Cluster name is ceph
[2017-05-31 18:47:57,856][gdb1][WARNING] activate: OSD uuid is 101ab77c-5335-474c-915b-a82ed5ca89ba
[2017-05-31 18:47:57,856][gdb1][WARNING] activate: OSD id is 2
[2017-05-31 18:47:57,856][gdb1][WARNING] activate: Marking with init system systemd
[2017-05-31 18:47:57,856][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-05-31 18:47:57,856][gdb1][WARNING] activate: ceph osd.2 data dir is ready at /mnt/memstore
[2017-05-31 18:47:57,856][gdb1][WARNING] start_daemon: Starting ceph osd.2...
[2017-05-31 18:47:57,856][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@2
[2017-05-31 18:47:57,859][gdb1][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@2.service.
[2017-05-31 18:47:57,923][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@2 --runtime
[2017-05-31 18:47:58,038][gdb1][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@2
[2017-05-31 18:47:58,038][gdb1][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@2.service to /lib/systemd/system/ceph-osd@.service.
[2017-05-31 18:47:58,102][gdb1][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@2
[2017-05-31 18:48:03,222][gdb1][INFO  ] checking OSD status...
[2017-05-31 18:48:03,222][gdb1][DEBUG ] find the location of an executable
[2017-05-31 18:48:03,224][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 18:48:03,342][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-05-31 18:49:54,207][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:49:54,208][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb0 gdb1
[2017-05-31 18:49:54,208][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:49:54,208][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:49:54,208][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:49:54,208][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:49:54,208][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:49:54,208][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fceed5d2518>
[2017-05-31 18:49:54,208][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:49:54,208][ceph_deploy.cli][INFO  ]  client                        : ['gdb0', 'gdb1']
[2017-05-31 18:49:54,208][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fceedee9938>
[2017-05-31 18:49:54,208][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:49:54,208][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:49:54,208][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-05-31 18:49:54,446][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:49:54,678][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:49:54,678][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:49:54,694][gdb0][DEBUG ] detect machine type
[2017-05-31 18:49:54,697][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:49:54,699][ceph_deploy.admin][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite
[2017-05-31 18:49:54,699][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-05-31 18:49:54,931][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 18:49:55,160][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 18:49:55,160][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 18:49:55,177][gdb1][DEBUG ] detect machine type
[2017-05-31 18:49:55,181][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:49:55,182][ceph_deploy.admin][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite
[2017-05-31 18:49:55,183][ceph_deploy][ERROR ] GenericError: Failed to configure 2 admin hosts

[2017-05-31 18:50:28,701][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:50:28,701][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-05-31 18:50:28,701][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:50:28,701][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:50:28,702][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:50:28,702][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 18:50:28,702][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:50:28,702][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7d0e56e518>
[2017-05-31 18:50:28,702][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:50:28,702][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-05-31 18:50:28,702][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f7d0ee85938>
[2017-05-31 18:50:28,702][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:50:28,702][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:50:28,702][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-05-31 18:50:28,942][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:50:29,170][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:50:29,170][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:50:29,186][gdb0][DEBUG ] detect machine type
[2017-05-31 18:50:29,190][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:50:29,365][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:50:29,366][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-05-31 18:50:29,366][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:50:29,366][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:50:29,366][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 18:50:29,366][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 18:50:29,366][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 18:50:29,366][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:50:29,366][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 18:50:29,366][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 18:50:29,367][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:50:29,367][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 18:50:29,367][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 18:50:29,367][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:50:29,367][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe3e2b4a908>
[2017-05-31 18:50:29,367][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:50:29,367][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 18:50:29,367][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fe3e2da0aa0>
[2017-05-31 18:50:29,367][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:50:29,367][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:50:29,367][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 18:50:29,368][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 18:50:29,610][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:50:29,838][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:50:29,838][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:50:29,854][gdb0][DEBUG ] detect machine type
[2017-05-31 18:50:29,858][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:50:29,859][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 18:50:29,859][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 18:50:29,859][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:50:29,861][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-05-31 18:50:29,861][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:50:29,863][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 18:50:29,984][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 18:50:29,987][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 18:50:30,003][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 18:50:30,018][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 18:50:30,026][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 18:50:30,042][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-05-31 18:50:35,048][gdb0][INFO  ] checking OSD status...
[2017-05-31 18:50:35,049][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:50:35,051][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 18:50:35,217][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-05-31 18:50:35,382][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:50:35,382][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 18:50:35,382][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:50:35,383][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:50:35,383][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:50:35,383][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:50:35,383][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 18:50:35,383][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:50:35,383][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fc329b70908>
[2017-05-31 18:50:35,383][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:50:35,383][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fc329dc6aa0>
[2017-05-31 18:50:35,383][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:50:35,383][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:50:35,383][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 18:50:35,383][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 18:50:35,630][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:50:35,826][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:50:35,826][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:50:35,842][gdb0][DEBUG ] detect machine type
[2017-05-31 18:50:35,846][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:50:35,847][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 18:50:35,847][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 18:50:35,847][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 18:50:35,847][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:50:35,849][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 18:50:35,970][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 18:50:35,970][gdb0][WARNING] activate: Cluster uuid is ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 18:50:35,970][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 18:50:35,974][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 18:50:35,974][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 18:50:35,974][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 18:50:35,974][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 18:50:35,974][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 18:50:35,975][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 18:50:35,975][gdb0][WARNING]     args.func(args)
[2017-05-31 18:50:35,975][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 18:50:35,975][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 18:50:35,975][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 18:50:35,975][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-05-31 18:50:35,975][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3609, in activate
[2017-05-31 18:50:35,975][gdb0][WARNING]     ' with fsid %s' % ceph_fsid)
[2017-05-31 18:50:35,976][gdb0][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid ca3e0a81-2fd3-4069-bf21-8407a86a4dd3
[2017-05-31 18:50:35,983][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 18:50:35,983][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 18:51:44,351][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:51:44,351][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-05-31 18:51:44,351][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:51:44,351][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:51:44,352][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:51:44,352][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 18:51:44,352][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:51:44,352][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f80e4e73518>
[2017-05-31 18:51:44,352][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:51:44,352][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-05-31 18:51:44,352][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f80e578a938>
[2017-05-31 18:51:44,352][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:51:44,352][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:51:44,352][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-05-31 18:51:44,594][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:51:44,826][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:51:44,826][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:51:44,843][gdb0][DEBUG ] detect machine type
[2017-05-31 18:51:44,846][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:52:04,467][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:52:04,467][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memsto
[2017-05-31 18:52:04,467][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:52:04,467][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:52:04,467][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 18:52:04,467][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memsto', None)]
[2017-05-31 18:52:04,468][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 18:52:04,468][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:52:04,468][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 18:52:04,468][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 18:52:04,468][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:52:04,468][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 18:52:04,468][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 18:52:04,468][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:52:04,468][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fceef85e908>
[2017-05-31 18:52:04,468][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:52:04,468][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 18:52:04,468][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fceefab4aa0>
[2017-05-31 18:52:04,468][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:52:04,468][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:52:04,468][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 18:52:04,469][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memsto:
[2017-05-31 18:52:04,702][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:52:04,930][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:52:04,931][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:52:04,947][gdb0][DEBUG ] detect machine type
[2017-05-31 18:52:04,950][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:52:04,951][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 18:52:04,951][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 18:52:04,951][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:52:04,954][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memsto journal None activate False
[2017-05-31 18:52:04,954][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:52:04,956][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memsto
[2017-05-31 18:52:05,076][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 18:52:05,076][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 18:52:05,076][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 18:52:05,076][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 18:52:05,077][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 18:52:05,077][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 18:52:05,077][gdb0][WARNING]     args.func(args)
[2017-05-31 18:52:05,077][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2029, in main
[2017-05-31 18:52:05,077][gdb0][WARNING]     Prepare.factory(args).prepare()
[2017-05-31 18:52:05,077][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2025, in factory
[2017-05-31 18:52:05,077][gdb0][WARNING]     return PrepareFilestore(args)
[2017-05-31 18:52:05,077][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2037, in __init__
[2017-05-31 18:52:05,077][gdb0][WARNING]     self.data = PrepareFilestoreData(args)
[2017-05-31 18:52:05,077][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2739, in __init__
[2017-05-31 18:52:05,077][gdb0][WARNING]     self.set_type()
[2017-05-31 18:52:05,077][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2747, in set_type
[2017-05-31 18:52:05,077][gdb0][WARNING]     dmode = os.stat(self.args.data).st_mode
[2017-05-31 18:52:05,077][gdb0][WARNING] OSError: [Errno 2] No such file or directory: '/mnt/memsto'
[2017-05-31 18:52:05,078][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 18:52:05,078][ceph_deploy.osd][ERROR ] Failed to execute command: /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memsto
[2017-05-31 18:52:05,078][ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs

[2017-05-31 18:52:07,388][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:52:07,388][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-05-31 18:52:07,388][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:52:07,389][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:52:07,389][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 18:52:07,389][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 18:52:07,389][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 18:52:07,389][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:52:07,389][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 18:52:07,389][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 18:52:07,389][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:52:07,389][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 18:52:07,389][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 18:52:07,389][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:52:07,389][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fd0298fd908>
[2017-05-31 18:52:07,389][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:52:07,389][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 18:52:07,389][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fd029b53aa0>
[2017-05-31 18:52:07,390][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:52:07,390][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:52:07,390][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 18:52:07,390][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 18:52:07,630][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:52:07,822][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:52:07,822][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:52:07,838][gdb0][DEBUG ] detect machine type
[2017-05-31 18:52:07,842][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:52:07,843][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 18:52:07,843][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 18:52:07,843][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:52:07,845][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-05-31 18:52:07,846][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:52:07,847][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 18:52:07,968][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 18:52:07,971][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 18:52:07,987][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 18:52:08,003][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 18:52:08,018][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 18:52:08,026][gdb0][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-05-31 18:52:08,034][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.15711.tmp
[2017-05-31 18:52:08,037][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.15711.tmp
[2017-05-31 18:52:08,045][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.15711.tmp
[2017-05-31 18:52:13,057][gdb0][INFO  ] checking OSD status...
[2017-05-31 18:52:13,057][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:52:13,060][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 18:52:13,225][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-05-31 18:52:21,817][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:52:21,817][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 18:52:21,817][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:52:21,817][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:52:21,817][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:52:21,818][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:52:21,818][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 18:52:21,818][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:52:21,818][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa09dd7f908>
[2017-05-31 18:52:21,818][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:52:21,818][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fa09dfd5aa0>
[2017-05-31 18:52:21,818][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:52:21,818][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:52:21,818][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 18:52:21,818][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 18:52:22,050][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:52:22,278][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:52:22,278][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:52:22,294][gdb0][DEBUG ] detect machine type
[2017-05-31 18:52:22,298][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:52:22,298][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 18:52:22,299][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 18:52:22,299][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 18:52:22,299][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:52:22,301][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 18:52:22,421][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 18:52:22,421][gdb0][WARNING] activate: Cluster uuid is c676bc10-14a8-4f7c-93e4-c9f0324506d5
[2017-05-31 18:52:22,421][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 18:52:22,425][gdb0][WARNING] activate: Cluster name is ceph
[2017-05-31 18:52:22,425][gdb0][WARNING] activate: OSD uuid is c0f127b4-e253-45f0-9f51-71ce307580a4
[2017-05-31 18:52:22,425][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 18:52:22,425][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise c0f127b4-e253-45f0-9f51-71ce307580a4
[2017-05-31 18:52:22,489][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 18:52:22,489][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 18:52:22,489][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 18:52:22,489][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 18:52:22,489][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 18:52:22,489][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 18:52:22,490][gdb0][WARNING]     args.func(args)
[2017-05-31 18:52:22,490][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 18:52:22,490][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 18:52:22,490][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 18:52:22,490][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-05-31 18:52:22,490][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3625, in activate
[2017-05-31 18:52:22,490][gdb0][WARNING]     keyring=keyring,
[2017-05-31 18:52:22,490][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 1075, in allocate_osd_id
[2017-05-31 18:52:22,490][gdb0][WARNING]     raise Error('ceph osd create failed', e, e.output)
[2017-05-31 18:52:22,490][gdb0][WARNING] ceph_disk.main.Error: Error: ceph osd create failed: Command '/usr/bin/ceph' returned non-zero exit status 1: 2017-05-31 18:52:22.476913 7f087fdec700  0 librados: client.bootstrap-osd authentication error (1) Operation not permitted
[2017-05-31 18:52:22,490][gdb0][WARNING] error connecting to the cluster
[2017-05-31 18:52:22,490][gdb0][WARNING] 
[2017-05-31 18:52:22,498][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 18:52:22,498][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 18:52:40,085][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:52:40,086][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-05-31 18:52:40,086][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:52:40,086][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:52:40,086][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 18:52:40,086][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 18:52:40,086][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 18:52:40,086][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:52:40,086][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 18:52:40,086][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 18:52:40,086][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:52:40,086][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 18:52:40,086][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 18:52:40,086][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:52:40,087][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb19a84b908>
[2017-05-31 18:52:40,087][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:52:40,087][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 18:52:40,087][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fb19aaa1aa0>
[2017-05-31 18:52:40,087][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:52:40,087][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:52:40,087][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 18:52:40,087][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 18:52:40,326][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:52:40,558][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:52:40,558][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:52:40,574][gdb0][DEBUG ] detect machine type
[2017-05-31 18:52:40,578][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:52:40,579][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 18:52:40,579][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 18:52:40,579][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:52:40,581][gdb0][WARNING] osd keyring does not exist yet, creating one
[2017-05-31 18:52:40,581][gdb0][DEBUG ] create a keyring file
[2017-05-31 18:52:40,583][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-05-31 18:52:40,583][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:52:40,585][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 18:52:40,706][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 18:52:40,709][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 18:52:40,725][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 18:52:40,741][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 18:52:40,748][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 18:52:40,764][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-05-31 18:52:45,772][gdb0][INFO  ] checking OSD status...
[2017-05-31 18:52:45,773][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:52:45,775][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 18:52:45,940][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-05-31 18:52:48,018][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:52:48,018][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 18:52:48,018][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:52:48,018][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:52:48,018][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:52:48,019][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:52:48,019][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 18:52:48,019][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:52:48,019][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb44c146908>
[2017-05-31 18:52:48,019][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:52:48,019][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fb44c39caa0>
[2017-05-31 18:52:48,019][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:52:48,019][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:52:48,019][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 18:52:48,019][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 18:52:48,258][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:52:48,454][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:52:48,455][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:52:48,471][gdb0][DEBUG ] detect machine type
[2017-05-31 18:52:48,474][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:52:48,475][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 18:52:48,475][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 18:52:48,475][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 18:52:48,475][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:52:48,477][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 18:52:48,598][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 18:52:48,598][gdb0][WARNING] activate: Cluster uuid is c676bc10-14a8-4f7c-93e4-c9f0324506d5
[2017-05-31 18:52:48,598][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 18:52:48,606][gdb0][WARNING] activate: Cluster name is ceph
[2017-05-31 18:52:48,606][gdb0][WARNING] activate: OSD uuid is c0f127b4-e253-45f0-9f51-71ce307580a4
[2017-05-31 18:52:48,606][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 18:52:48,606][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise c0f127b4-e253-45f0-9f51-71ce307580a4
[2017-05-31 18:52:48,770][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.16053.tmp
[2017-05-31 18:52:48,771][gdb0][WARNING] activate: OSD id is 0
[2017-05-31 18:52:48,771][gdb0][WARNING] activate: Initializing OSD...
[2017-05-31 18:52:48,771][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-05-31 18:52:48,885][gdb0][WARNING] got monmap epoch 2
[2017-05-31 18:52:48,893][gdb0][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 0 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid c0f127b4-e253-45f0-9f51-71ce307580a4 --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-05-31 18:52:48,924][gdb0][WARNING] activate: Marking with init system systemd
[2017-05-31 18:52:48,925][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-05-31 18:52:48,928][gdb0][WARNING] activate: Authorizing OSD key...
[2017-05-31 18:52:48,928][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.0 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-05-31 18:52:49,092][gdb0][WARNING] added key for osd.0
[2017-05-31 18:52:49,093][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.16053.tmp
[2017-05-31 18:52:49,093][gdb0][WARNING] activate: ceph osd.0 data dir is ready at /mnt/memstore
[2017-05-31 18:52:49,093][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 18:52:49,093][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 18:52:49,093][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 18:52:49,093][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 18:52:49,093][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 18:52:49,093][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 18:52:49,093][gdb0][WARNING]     args.func(args)
[2017-05-31 18:52:49,093][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 18:52:49,093][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 18:52:49,094][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3543, in activate_dir
[2017-05-31 18:52:49,094][gdb0][WARNING]     old = os.readlink(canonical)
[2017-05-31 18:52:49,094][gdb0][WARNING] OSError: [Errno 22] Invalid argument: '/var/lib/ceph/osd/ceph-0'
[2017-05-31 18:52:49,094][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 18:52:49,094][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 18:53:23,583][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:53:23,583][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-05-31 18:53:23,584][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:53:23,584][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:53:23,584][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:53:23,584][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:53:23,584][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:53:23,584][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3854a70fc8>
[2017-05-31 18:53:23,584][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:53:23,584][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-05-31 18:53:23,584][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f38553831b8>
[2017-05-31 18:53:23,584][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:53:23,584][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:53:23,584][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-05-31 18:53:23,584][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-05-31 18:53:23,584][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-05-31 18:53:23,585][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-05-31 18:53:23,610][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 18:53:23,624][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 18:53:23,625][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 18:53:23,641][gdb3][DEBUG ] detect machine type
[2017-05-31 18:53:23,644][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 18:53:23,644][gdb3][INFO  ] Purging Ceph on gdb3
[2017-05-31 18:53:23,645][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-05-31 18:53:23,683][gdb3][DEBUG ] Reading package lists...
[2017-05-31 18:53:23,847][gdb3][DEBUG ] Building dependency tree...
[2017-05-31 18:53:23,847][gdb3][DEBUG ] Reading state information...
[2017-05-31 18:53:23,911][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-05-31 18:53:23,911][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-05-31 18:53:23,911][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-05-31 18:53:23,912][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-05-31 18:53:23,912][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-05-31 18:53:23,912][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-05-31 18:53:23,912][gdb3][DEBUG ]   linux-headers-4.4.0-1013-aws linux-image-4.4.0-1013-aws ntp python-blinker
[2017-05-31 18:53:23,912][gdb3][DEBUG ]   python-cephfs python-cffi-backend python-chardet python-cryptography
[2017-05-31 18:53:23,912][gdb3][DEBUG ]   python-enum34 python-flask python-idna python-ipaddress python-itsdangerous
[2017-05-31 18:53:23,912][gdb3][DEBUG ]   python-jinja2 python-markupsafe python-ndg-httpsclient python-openssl
[2017-05-31 18:53:23,912][gdb3][DEBUG ]   python-pyasn1 python-pyinotify python-rados python-rbd python-requests
[2017-05-31 18:53:23,912][gdb3][DEBUG ]   python-rgw python-six python-urllib3 python-werkzeug
[2017-05-31 18:53:23,912][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-05-31 18:53:23,976][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-05-31 18:53:23,976][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-05-31 18:53:24,091][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 35 not upgraded.
[2017-05-31 18:53:24,091][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-05-31 18:53:24,123][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 104522 files and directories currently installed.)
[2017-05-31 18:53:24,123][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-05-31 18:53:24,287][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-05-31 18:53:24,402][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-05-31 18:53:24,405][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-05-31 18:53:24,621][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-05-31 18:53:24,737][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-05-31 18:53:24,905][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-05-31 18:53:24,969][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-05-31 18:53:25,000][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-05-31 18:53:25,167][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-05-31 18:53:25,232][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-05-31 18:53:25,233][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-05-31 18:53:25,397][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-05-31 18:53:25,429][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-05-31 18:53:25,593][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-05-31 18:53:25,657][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-05-31 18:53:25,665][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-05-31 18:53:25,779][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu7) ...
[2017-05-31 18:53:26,595][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-05-31 18:53:26,761][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:53:26,761][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-05-31 18:53:26,761][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:53:26,761][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:53:26,761][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:53:26,762][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:53:26,762][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:53:26,762][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6c68cf3710>
[2017-05-31 18:53:26,762][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:53:26,762][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-05-31 18:53:26,762][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f6c69600230>
[2017-05-31 18:53:26,762][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:53:26,762][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:53:26,762][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-05-31 18:53:26,788][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 18:53:26,802][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 18:53:26,802][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 18:53:26,819][gdb3][DEBUG ] detect machine type
[2017-05-31 18:53:26,821][gdb3][DEBUG ] find the location of an executable
[2017-05-31 18:53:26,837][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 18:53:26,850][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 18:53:26,851][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 18:53:26,867][gdb3][DEBUG ] detect machine type
[2017-05-31 18:53:26,869][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 18:53:26,869][gdb3][INFO  ] purging data on gdb3
[2017-05-31 18:53:26,870][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-05-31 18:53:26,883][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-05-31 18:53:27,052][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:53:27,053][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-05-31 18:53:27,053][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:53:27,053][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:53:27,053][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:53:27,053][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:53:27,053][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:53:27,053][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa6a31b89e0>
[2017-05-31 18:53:27,053][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:53:27,053][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7fa6a3a7b848>
[2017-05-31 18:53:27,053][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:53:27,053][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:53:59,636][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:53:59,636][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-05-31 18:53:59,637][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:53:59,637][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:53:59,637][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:53:59,637][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:53:59,637][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:53:59,637][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f1af7e04560>
[2017-05-31 18:53:59,637][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:53:59,637][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-05-31 18:53:59,637][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-05-31 18:53:59,637][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f1af8488758>
[2017-05-31 18:53:59,637][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-05-31 18:53:59,637][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:53:59,637][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-05-31 18:53:59,638][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:53:59,638][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-05-31 18:53:59,638][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-05-31 18:53:59,638][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-05-31 18:53:59,664][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 18:53:59,678][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 18:53:59,678][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 18:53:59,695][gdb3][DEBUG ] detect machine type
[2017-05-31 18:53:59,697][gdb3][DEBUG ] find the location of an executable
[2017-05-31 18:53:59,698][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-05-31 18:53:59,710][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-05-31 18:53:59,716][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-05-31 18:53:59,716][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-05-31 18:53:59,716][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-05-31 18:53:59,716][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-05-31 18:53:59,716][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-05-31 18:53:59,716][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-05-31 18:53:59,717][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-05-31 18:53:59,717][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-05-31 18:53:59,881][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:53:59,882][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-05-31 18:53:59,882][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:53:59,882][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:53:59,882][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:53:59,882][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:53:59,882][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-05-31 18:53:59,882][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:53:59,882][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f73b3696e60>
[2017-05-31 18:53:59,882][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:53:59,882][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f73b366bb18>
[2017-05-31 18:53:59,882][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:53:59,882][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-05-31 18:53:59,882][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:53:59,883][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-05-31 18:53:59,883][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-05-31 18:53:59,909][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 18:53:59,923][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 18:53:59,924][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 18:53:59,940][gdb3][DEBUG ] detect machine type
[2017-05-31 18:53:59,942][gdb3][DEBUG ] find the location of an executable
[2017-05-31 18:53:59,943][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-05-31 18:53:59,943][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-05-31 18:53:59,943][gdb3][DEBUG ] get remote short hostname
[2017-05-31 18:53:59,943][gdb3][DEBUG ] deploying mon to gdb3
[2017-05-31 18:53:59,943][gdb3][DEBUG ] get remote short hostname
[2017-05-31 18:53:59,944][gdb3][DEBUG ] remote hostname: gdb3
[2017-05-31 18:53:59,944][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:53:59,946][gdb3][DEBUG ] create the mon path if it does not exist
[2017-05-31 18:53:59,946][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-05-31 18:53:59,946][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-05-31 18:53:59,947][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-05-31 18:53:59,947][gdb3][DEBUG ] create the monitor keyring file
[2017-05-31 18:53:59,948][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-05-31 18:53:59,986][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-05-31 18:53:59,986][gdb3][DEBUG ] ceph-mon: set fsid to cb3c2cda-b4dd-4a09-9b7a-a7dc594196ab
[2017-05-31 18:53:59,988][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-05-31 18:53:59,989][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-05-31 18:53:59,989][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-05-31 18:53:59,990][gdb3][DEBUG ] create the init path if it does not exist
[2017-05-31 18:53:59,991][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-05-31 18:54:00,060][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-05-31 18:54:00,129][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-05-31 18:54:02,171][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 18:54:02,236][gdb3][DEBUG ] ********************************************************************************
[2017-05-31 18:54:02,236][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-05-31 18:54:02,237][gdb3][DEBUG ] {
[2017-05-31 18:54:02,237][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-05-31 18:54:02,237][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-05-31 18:54:02,237][gdb3][DEBUG ]   "features": {
[2017-05-31 18:54:02,237][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-05-31 18:54:02,237][gdb3][DEBUG ]     "quorum_mon": [
[2017-05-31 18:54:02,237][gdb3][DEBUG ]       "kraken", 
[2017-05-31 18:54:02,237][gdb3][DEBUG ]       "luminous"
[2017-05-31 18:54:02,237][gdb3][DEBUG ]     ], 
[2017-05-31 18:54:02,237][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-05-31 18:54:02,237][gdb3][DEBUG ]     "required_mon": [
[2017-05-31 18:54:02,237][gdb3][DEBUG ]       "kraken", 
[2017-05-31 18:54:02,237][gdb3][DEBUG ]       "luminous"
[2017-05-31 18:54:02,238][gdb3][DEBUG ]     ]
[2017-05-31 18:54:02,238][gdb3][DEBUG ]   }, 
[2017-05-31 18:54:02,238][gdb3][DEBUG ]   "monmap": {
[2017-05-31 18:54:02,238][gdb3][DEBUG ]     "created": "2017-05-31 18:53:59.971511", 
[2017-05-31 18:54:02,238][gdb3][DEBUG ]     "epoch": 2, 
[2017-05-31 18:54:02,238][gdb3][DEBUG ]     "features": {
[2017-05-31 18:54:02,238][gdb3][DEBUG ]       "optional": [], 
[2017-05-31 18:54:02,238][gdb3][DEBUG ]       "persistent": [
[2017-05-31 18:54:02,238][gdb3][DEBUG ]         "kraken", 
[2017-05-31 18:54:02,238][gdb3][DEBUG ]         "luminous"
[2017-05-31 18:54:02,238][gdb3][DEBUG ]       ]
[2017-05-31 18:54:02,238][gdb3][DEBUG ]     }, 
[2017-05-31 18:54:02,238][gdb3][DEBUG ]     "fsid": "cb3c2cda-b4dd-4a09-9b7a-a7dc594196ab", 
[2017-05-31 18:54:02,238][gdb3][DEBUG ]     "modified": "2017-05-31 18:54:00.211295", 
[2017-05-31 18:54:02,238][gdb3][DEBUG ]     "mons": [
[2017-05-31 18:54:02,238][gdb3][DEBUG ]       {
[2017-05-31 18:54:02,238][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-05-31 18:54:02,239][gdb3][DEBUG ]         "name": "gdb3", 
[2017-05-31 18:54:02,239][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-05-31 18:54:02,239][gdb3][DEBUG ]         "rank": 0
[2017-05-31 18:54:02,239][gdb3][DEBUG ]       }
[2017-05-31 18:54:02,239][gdb3][DEBUG ]     ]
[2017-05-31 18:54:02,239][gdb3][DEBUG ]   }, 
[2017-05-31 18:54:02,239][gdb3][DEBUG ]   "name": "gdb3", 
[2017-05-31 18:54:02,239][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-05-31 18:54:02,239][gdb3][DEBUG ]   "quorum": [
[2017-05-31 18:54:02,239][gdb3][DEBUG ]     0
[2017-05-31 18:54:02,239][gdb3][DEBUG ]   ], 
[2017-05-31 18:54:02,239][gdb3][DEBUG ]   "rank": 0, 
[2017-05-31 18:54:02,239][gdb3][DEBUG ]   "state": "leader", 
[2017-05-31 18:54:02,239][gdb3][DEBUG ]   "sync_provider": []
[2017-05-31 18:54:02,239][gdb3][DEBUG ] }
[2017-05-31 18:54:02,239][gdb3][DEBUG ] ********************************************************************************
[2017-05-31 18:54:02,239][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-05-31 18:54:02,240][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 18:54:02,306][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-05-31 18:54:02,320][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 18:54:02,334][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 18:54:02,335][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 18:54:02,351][gdb3][DEBUG ] detect machine type
[2017-05-31 18:54:02,353][gdb3][DEBUG ] find the location of an executable
[2017-05-31 18:54:02,354][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 18:54:02,420][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-05-31 18:54:02,420][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-05-31 18:54:02,420][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-05-31 18:54:02,422][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpSV9u_P
[2017-05-31 18:54:02,437][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 18:54:02,451][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 18:54:02,452][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 18:54:02,468][gdb3][DEBUG ] detect machine type
[2017-05-31 18:54:02,470][gdb3][DEBUG ] get remote short hostname
[2017-05-31 18:54:02,471][gdb3][DEBUG ] fetch remote file
[2017-05-31 18:54:02,472][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-05-31 18:54:02,538][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-05-31 18:54:02,704][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-05-31 18:54:02,870][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-05-31 18:54:03,036][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-05-31 18:54:03,253][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-05-31 18:54:03,419][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-05-31 18:54:03,586][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-05-31 18:54:03,752][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-05-31 18:54:03,918][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-05-31 18:54:04,084][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-05-31 18:54:04,249][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-05-31 18:54:04,250][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-05-31 18:54:04,250][ceph_deploy.gatherkeys][INFO  ] Replacing 'ceph.bootstrap-mgr.keyring' and backing up old key as 'ceph.bootstrap-mgr.keyring-20170531185404'
[2017-05-31 18:54:04,250][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-05-31 18:54:04,250][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-05-31 18:54:04,250][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-05-31 18:54:04,250][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpSV9u_P
[2017-05-31 18:54:04,431][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:54:04,431][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-05-31 18:54:04,431][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:54:04,432][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:54:04,432][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:54:04,432][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:54:04,432][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:54:04,432][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fc3e268f518>
[2017-05-31 18:54:04,432][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:54:04,432][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-05-31 18:54:04,432][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fc3e2fa6938>
[2017-05-31 18:54:04,432][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:54:04,432][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:54:04,432][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-05-31 18:54:04,459][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 18:54:04,473][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 18:54:04,473][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 18:54:04,490][gdb3][DEBUG ] detect machine type
[2017-05-31 18:54:04,492][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:54:45,775][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:54:45,775][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-05-31 18:54:45,775][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:54:45,775][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:54:45,775][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:54:45,775][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:54:45,775][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:54:45,775][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f25debd2518>
[2017-05-31 18:54:45,776][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:54:45,776][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-05-31 18:54:45,776][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f25df4e9938>
[2017-05-31 18:54:45,776][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:54:45,776][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:54:45,776][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-05-31 18:54:45,803][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 18:54:45,818][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 18:54:45,818][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 18:54:45,835][gdb3][DEBUG ] detect machine type
[2017-05-31 18:54:45,838][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:55:44,967][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:55:44,968][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb0
[2017-05-31 18:55:44,968][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:55:44,968][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:55:44,968][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:55:44,968][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:55:44,968][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:55:44,968][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f83cffec518>
[2017-05-31 18:55:44,968][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:55:44,968][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-05-31 18:55:44,968][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f83d0903938>
[2017-05-31 18:55:44,968][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:55:44,968][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:55:44,969][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-05-31 18:55:45,210][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:55:45,442][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:55:45,442][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:55:45,458][gdb0][DEBUG ] detect machine type
[2017-05-31 18:55:45,461][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:55:45,463][ceph_deploy.admin][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite
[2017-05-31 18:55:45,464][ceph_deploy][ERROR ] GenericError: Failed to configure 1 admin hosts

[2017-05-31 18:55:56,020][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:55:56,020][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-05-31 18:55:56,020][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:55:56,020][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:55:56,020][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:55:56,020][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 18:55:56,020][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:55:56,020][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7551d43518>
[2017-05-31 18:55:56,021][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:55:56,021][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-05-31 18:55:56,021][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f755265a938>
[2017-05-31 18:55:56,021][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:55:56,021][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:55:56,021][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-05-31 18:55:56,262][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:55:56,494][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:55:56,494][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:55:56,510][gdb0][DEBUG ] detect machine type
[2017-05-31 18:55:56,513][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:56:09,705][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:56:09,705][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-05-31 18:56:09,705][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:56:09,705][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:56:09,705][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 18:56:09,705][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 18:56:09,706][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 18:56:09,706][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:56:09,706][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 18:56:09,706][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 18:56:09,706][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:56:09,706][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 18:56:09,706][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 18:56:09,706][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:56:09,706][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7feadbb8b908>
[2017-05-31 18:56:09,706][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:56:09,706][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 18:56:09,706][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7feadbde1aa0>
[2017-05-31 18:56:09,706][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:56:09,706][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:56:09,706][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 18:56:09,707][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 18:56:09,942][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:56:10,174][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:56:10,174][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:56:10,190][gdb0][DEBUG ] detect machine type
[2017-05-31 18:56:10,194][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:56:10,194][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 18:56:10,194][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 18:56:10,195][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:56:10,197][gdb0][WARNING] osd keyring does not exist yet, creating one
[2017-05-31 18:56:10,197][gdb0][DEBUG ] create a keyring file
[2017-05-31 18:56:10,199][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-05-31 18:56:10,199][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:56:10,201][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 18:56:10,322][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 18:56:10,323][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 18:56:10,339][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 18:56:10,355][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 18:56:10,362][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 18:56:10,378][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-05-31 18:56:15,387][gdb0][INFO  ] checking OSD status...
[2017-05-31 18:56:15,387][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:56:15,389][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 18:56:15,555][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-05-31 18:56:24,144][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:56:24,144][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 18:56:24,144][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:56:24,144][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:56:24,144][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:56:24,145][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:56:24,145][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 18:56:24,145][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:56:24,145][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f896b4a4908>
[2017-05-31 18:56:24,145][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:56:24,145][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f896b6faaa0>
[2017-05-31 18:56:24,145][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:56:24,145][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:56:24,145][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 18:56:24,145][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 18:56:24,386][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:56:24,610][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:56:24,610][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:56:24,626][gdb0][DEBUG ] detect machine type
[2017-05-31 18:56:24,629][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:56:24,630][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 18:56:24,630][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 18:56:24,630][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 18:56:24,631][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:56:24,632][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 18:56:24,753][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 18:56:24,753][gdb0][WARNING] activate: Cluster uuid is c676bc10-14a8-4f7c-93e4-c9f0324506d5
[2017-05-31 18:56:24,753][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 18:56:24,757][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 18:56:24,757][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 18:56:24,757][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 18:56:24,757][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 18:56:24,757][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 18:56:24,758][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 18:56:24,758][gdb0][WARNING]     args.func(args)
[2017-05-31 18:56:24,758][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 18:56:24,758][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 18:56:24,758][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 18:56:24,758][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-05-31 18:56:24,758][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3609, in activate
[2017-05-31 18:56:24,758][gdb0][WARNING]     ' with fsid %s' % ceph_fsid)
[2017-05-31 18:56:24,758][gdb0][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid c676bc10-14a8-4f7c-93e4-c9f0324506d5
[2017-05-31 18:56:24,766][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 18:56:24,766][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 18:56:52,810][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:56:52,810][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-05-31 18:56:52,811][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:56:52,811][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:56:52,811][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:56:52,811][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 18:56:52,811][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:56:52,811][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ff039de8518>
[2017-05-31 18:56:52,811][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:56:52,811][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-05-31 18:56:52,811][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7ff03a6ff938>
[2017-05-31 18:56:52,811][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:56:52,811][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:56:52,811][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-05-31 18:56:53,054][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:56:53,278][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:56:53,279][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:56:53,295][gdb0][DEBUG ] detect machine type
[2017-05-31 18:56:53,298][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:56:57,584][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:56:57,584][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 18:56:57,585][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:56:57,585][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:56:57,585][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:56:57,585][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:56:57,585][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 18:56:57,585][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:56:57,585][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0178db6908>
[2017-05-31 18:56:57,585][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:56:57,585][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f017900caa0>
[2017-05-31 18:56:57,585][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:56:57,585][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:56:57,585][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 18:56:57,586][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 18:56:57,826][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:56:58,053][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:56:58,054][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:56:58,069][gdb0][DEBUG ] detect machine type
[2017-05-31 18:56:58,073][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:56:58,074][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 18:56:58,074][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 18:56:58,074][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 18:56:58,075][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:56:58,076][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 18:56:58,197][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 18:56:58,197][gdb0][WARNING] activate: Cluster uuid is c676bc10-14a8-4f7c-93e4-c9f0324506d5
[2017-05-31 18:56:58,197][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 18:56:58,198][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 18:56:58,198][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 18:56:58,198][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 18:56:58,199][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 18:56:58,199][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 18:56:58,199][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 18:56:58,199][gdb0][WARNING]     args.func(args)
[2017-05-31 18:56:58,199][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 18:56:58,200][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 18:56:58,200][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 18:56:58,200][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-05-31 18:56:58,200][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3609, in activate
[2017-05-31 18:56:58,200][gdb0][WARNING]     ' with fsid %s' % ceph_fsid)
[2017-05-31 18:56:58,200][gdb0][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid c676bc10-14a8-4f7c-93e4-c9f0324506d5
[2017-05-31 18:56:58,216][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 18:56:58,216][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 18:57:09,851][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:57:09,851][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-05-31 18:57:09,852][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:57:09,852][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:57:09,852][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:57:09,852][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:57:09,852][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:57:09,852][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7c2bbe7518>
[2017-05-31 18:57:09,852][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:57:09,852][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-05-31 18:57:09,852][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f7c2c4fe938>
[2017-05-31 18:57:09,852][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:57:09,852][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:57:09,852][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-05-31 18:57:09,878][gdb3][DEBUG ] connection detected need for sudo
[2017-05-31 18:57:09,892][gdb3][DEBUG ] connected to host: gdb3 
[2017-05-31 18:57:09,893][gdb3][DEBUG ] detect platform information from remote host
[2017-05-31 18:57:09,909][gdb3][DEBUG ] detect machine type
[2017-05-31 18:57:09,911][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:57:16,149][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:57:16,150][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 18:57:16,150][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:57:16,150][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:57:16,150][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:57:16,150][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:57:16,150][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 18:57:16,150][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:57:16,150][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa7d3366908>
[2017-05-31 18:57:16,150][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:57:16,150][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fa7d35bcaa0>
[2017-05-31 18:57:16,150][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:57:16,150][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:57:16,150][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 18:57:16,151][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 18:57:16,386][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:57:16,613][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:57:16,614][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:57:16,629][gdb0][DEBUG ] detect machine type
[2017-05-31 18:57:16,633][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:57:16,633][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 18:57:16,634][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 18:57:16,634][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 18:57:16,634][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:57:16,636][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 18:57:16,756][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 18:57:16,756][gdb0][WARNING] activate: Cluster uuid is c676bc10-14a8-4f7c-93e4-c9f0324506d5
[2017-05-31 18:57:16,757][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 18:57:16,760][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 18:57:16,760][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 18:57:16,760][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 18:57:16,761][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 18:57:16,761][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 18:57:16,761][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 18:57:16,761][gdb0][WARNING]     args.func(args)
[2017-05-31 18:57:16,761][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 18:57:16,761][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 18:57:16,761][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 18:57:16,761][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-05-31 18:57:16,761][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3609, in activate
[2017-05-31 18:57:16,761][gdb0][WARNING]     ' with fsid %s' % ceph_fsid)
[2017-05-31 18:57:16,761][gdb0][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid c676bc10-14a8-4f7c-93e4-c9f0324506d5
[2017-05-31 18:57:16,769][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 18:57:16,769][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 18:57:21,647][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:57:21,647][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-05-31 18:57:21,647][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:57:21,647][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:57:21,648][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 18:57:21,648][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 18:57:21,648][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 18:57:21,648][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:57:21,648][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 18:57:21,648][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 18:57:21,648][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:57:21,648][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 18:57:21,648][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 18:57:21,648][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:57:21,648][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7efcda9f6908>
[2017-05-31 18:57:21,648][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:57:21,648][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 18:57:21,648][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7efcdac4caa0>
[2017-05-31 18:57:21,648][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:57:21,649][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:57:21,649][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 18:57:21,649][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 18:57:21,890][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:57:22,118][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:57:22,118][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:57:22,134][gdb0][DEBUG ] detect machine type
[2017-05-31 18:57:22,137][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:57:22,138][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 18:57:22,138][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 18:57:22,138][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:57:22,140][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-05-31 18:57:22,141][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:57:22,142][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 18:57:22,263][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 18:57:22,266][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 18:57:22,282][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 18:57:22,297][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 18:57:22,305][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 18:57:22,321][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-05-31 18:57:27,329][gdb0][INFO  ] checking OSD status...
[2017-05-31 18:57:27,330][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:57:27,332][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 18:57:27,497][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-05-31 18:57:29,326][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:57:29,326][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 18:57:29,326][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:57:29,326][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:57:29,326][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:57:29,326][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:57:29,327][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 18:57:29,327][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:57:29,327][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7efd3714f908>
[2017-05-31 18:57:29,327][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:57:29,327][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7efd373a5aa0>
[2017-05-31 18:57:29,327][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:57:29,327][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:57:29,327][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 18:57:29,327][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 18:57:29,562][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:57:29,786][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:57:29,786][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:57:29,802][gdb0][DEBUG ] detect machine type
[2017-05-31 18:57:29,805][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:57:29,806][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 18:57:29,806][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 18:57:29,806][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 18:57:29,806][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:57:29,808][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 18:57:29,929][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 18:57:29,929][gdb0][WARNING] activate: Cluster uuid is c676bc10-14a8-4f7c-93e4-c9f0324506d5
[2017-05-31 18:57:29,929][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 18:57:29,930][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 18:57:29,930][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 18:57:29,931][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 18:57:29,931][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 18:57:29,931][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 18:57:29,931][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 18:57:29,931][gdb0][WARNING]     args.func(args)
[2017-05-31 18:57:29,931][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 18:57:29,931][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 18:57:29,932][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 18:57:29,932][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-05-31 18:57:29,932][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3609, in activate
[2017-05-31 18:57:29,932][gdb0][WARNING]     ' with fsid %s' % ceph_fsid)
[2017-05-31 18:57:29,932][gdb0][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid c676bc10-14a8-4f7c-93e4-c9f0324506d5
[2017-05-31 18:57:29,948][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 18:57:29,948][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 18:58:02,594][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:58:02,595][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb0
[2017-05-31 18:58:02,595][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:58:02,595][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:58:02,595][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:58:02,595][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:58:02,595][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:58:02,595][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f37bf68c518>
[2017-05-31 18:58:02,595][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:58:02,595][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-05-31 18:58:02,595][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f37bffa3938>
[2017-05-31 18:58:02,595][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:58:02,595][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:58:02,596][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-05-31 18:58:02,838][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:58:03,062][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:58:03,062][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:58:03,078][gdb0][DEBUG ] detect machine type
[2017-05-31 18:58:03,082][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:58:05,043][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:58:05,043][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-05-31 18:58:05,043][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:58:05,044][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:58:05,044][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 18:58:05,044][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 18:58:05,044][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 18:58:05,044][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:58:05,044][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 18:58:05,044][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 18:58:05,044][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:58:05,044][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 18:58:05,044][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 18:58:05,044][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:58:05,044][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9982fa1908>
[2017-05-31 18:58:05,044][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:58:05,044][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 18:58:05,044][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f99831f7aa0>
[2017-05-31 18:58:05,044][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:58:05,045][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:58:05,045][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 18:58:05,045][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 18:58:05,286][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:58:05,509][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:58:05,510][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:58:05,526][gdb0][DEBUG ] detect machine type
[2017-05-31 18:58:05,529][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:58:05,530][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 18:58:05,530][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 18:58:05,530][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 18:58:05,533][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-05-31 18:58:05,533][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:58:05,534][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 18:58:05,655][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 18:58:05,658][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 18:58:05,674][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 18:58:05,690][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 18:58:05,697][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 18:58:05,713][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-05-31 18:58:10,722][gdb0][INFO  ] checking OSD status...
[2017-05-31 18:58:10,722][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:58:10,724][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 18:58:10,889][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-05-31 18:58:14,417][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 18:58:14,417][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 18:58:14,417][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 18:58:14,417][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 18:58:14,417][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 18:58:14,417][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 18:58:14,417][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 18:58:14,418][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 18:58:14,418][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fea3fd2a908>
[2017-05-31 18:58:14,418][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 18:58:14,418][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fea3ff80aa0>
[2017-05-31 18:58:14,418][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 18:58:14,418][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 18:58:14,418][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 18:58:14,418][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 18:58:14,658][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 18:58:14,881][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 18:58:14,882][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 18:58:14,898][gdb0][DEBUG ] detect machine type
[2017-05-31 18:58:14,901][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:58:14,902][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 18:58:14,902][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 18:58:14,902][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 18:58:14,902][gdb0][DEBUG ] find the location of an executable
[2017-05-31 18:58:14,904][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 18:58:15,025][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 18:58:15,025][gdb0][WARNING] activate: Cluster uuid is c676bc10-14a8-4f7c-93e4-c9f0324506d5
[2017-05-31 18:58:15,025][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 18:58:15,028][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 18:58:15,028][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 18:58:15,029][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 18:58:15,029][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 18:58:15,029][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 18:58:15,029][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 18:58:15,029][gdb0][WARNING]     args.func(args)
[2017-05-31 18:58:15,029][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 18:58:15,029][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 18:58:15,030][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 18:58:15,030][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-05-31 18:58:15,030][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3609, in activate
[2017-05-31 18:58:15,030][gdb0][WARNING]     ' with fsid %s' % ceph_fsid)
[2017-05-31 18:58:15,030][gdb0][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid c676bc10-14a8-4f7c-93e4-c9f0324506d5
[2017-05-31 18:58:15,046][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 18:58:15,046][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 19:00:23,548][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 19:00:23,548][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-05-31 19:00:23,548][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 19:00:23,548][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 19:00:23,548][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 19:00:23,548][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 19:00:23,548][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 19:00:23,548][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 19:00:23,548][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 19:00:23,549][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 19:00:23,549][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 19:00:23,549][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 19:00:23,549][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 19:00:23,549][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 19:00:23,549][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f2fbebd7908>
[2017-05-31 19:00:23,549][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 19:00:23,549][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 19:00:23,549][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f2fbee2daa0>
[2017-05-31 19:00:23,549][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 19:00:23,549][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 19:00:23,549][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 19:00:23,550][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 19:00:23,791][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 19:00:24,022][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 19:00:24,022][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 19:00:24,038][gdb0][DEBUG ] detect machine type
[2017-05-31 19:00:24,042][gdb0][DEBUG ] find the location of an executable
[2017-05-31 19:00:24,042][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 19:00:24,043][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 19:00:24,043][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 19:00:24,045][gdb0][WARNING] osd keyring does not exist yet, creating one
[2017-05-31 19:00:24,045][gdb0][DEBUG ] create a keyring file
[2017-05-31 19:00:24,047][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-05-31 19:00:24,047][gdb0][DEBUG ] find the location of an executable
[2017-05-31 19:00:24,049][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 19:00:24,169][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 19:00:24,171][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 19:00:24,186][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 19:00:24,202][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 19:00:24,210][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 19:00:24,225][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-05-31 19:00:29,234][gdb0][INFO  ] checking OSD status...
[2017-05-31 19:00:29,234][gdb0][DEBUG ] find the location of an executable
[2017-05-31 19:00:29,237][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 19:00:29,402][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-05-31 19:00:34,139][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 19:00:34,139][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 19:00:34,139][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 19:00:34,139][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 19:00:34,139][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 19:00:34,139][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 19:00:34,139][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 19:00:34,139][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 19:00:34,139][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ff7156d0908>
[2017-05-31 19:00:34,140][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 19:00:34,140][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7ff715926aa0>
[2017-05-31 19:00:34,140][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 19:00:34,140][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 19:00:34,140][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 19:00:34,140][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 19:00:34,378][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 19:00:34,605][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 19:00:34,606][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 19:00:34,621][gdb0][DEBUG ] detect machine type
[2017-05-31 19:00:34,625][gdb0][DEBUG ] find the location of an executable
[2017-05-31 19:00:34,626][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 19:00:34,626][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 19:00:34,626][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 19:00:34,626][gdb0][DEBUG ] find the location of an executable
[2017-05-31 19:00:34,628][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 19:00:34,748][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 19:00:34,749][gdb0][WARNING] activate: Cluster uuid is c676bc10-14a8-4f7c-93e4-c9f0324506d5
[2017-05-31 19:00:34,749][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 19:00:34,752][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 19:00:34,752][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 19:00:34,753][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 19:00:34,753][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 19:00:34,753][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 19:00:34,753][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 19:00:34,753][gdb0][WARNING]     args.func(args)
[2017-05-31 19:00:34,753][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 19:00:34,753][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 19:00:34,754][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 19:00:34,754][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-05-31 19:00:34,754][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3609, in activate
[2017-05-31 19:00:34,754][gdb0][WARNING]     ' with fsid %s' % ceph_fsid)
[2017-05-31 19:00:34,754][gdb0][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid c676bc10-14a8-4f7c-93e4-c9f0324506d5
[2017-05-31 19:00:34,762][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 19:00:34,762][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 19:01:30,099][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 19:01:30,100][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-05-31 19:01:30,100][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 19:01:30,100][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 19:01:30,100][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 19:01:30,100][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 19:01:30,100][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 19:01:30,100][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 19:01:30,100][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 19:01:30,100][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 19:01:30,100][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 19:01:30,101][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 19:01:30,101][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 19:01:30,101][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 19:01:30,101][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb097308908>
[2017-05-31 19:01:30,101][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 19:01:30,101][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 19:01:30,101][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fb09755eaa0>
[2017-05-31 19:01:30,101][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 19:01:30,101][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 19:01:30,101][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 19:01:30,101][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 19:01:30,348][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 19:01:30,579][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 19:01:30,579][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 19:01:30,596][gdb1][DEBUG ] detect machine type
[2017-05-31 19:01:30,600][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:01:30,600][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 19:01:30,601][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-05-31 19:01:30,601][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 19:01:30,603][ceph_deploy.osd][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite
[2017-05-31 19:01:30,603][ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs

[2017-05-31 19:01:40,792][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 19:01:40,792][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb1
[2017-05-31 19:01:40,793][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 19:01:40,793][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 19:01:40,793][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 19:01:40,793][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 19:01:40,793][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 19:01:40,793][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fbbd048a518>
[2017-05-31 19:01:40,793][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 19:01:40,793][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-05-31 19:01:40,793][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fbbd0da1938>
[2017-05-31 19:01:40,793][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 19:01:40,793][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 19:01:40,793][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-05-31 19:01:41,031][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 19:01:41,263][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 19:01:41,263][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 19:01:41,280][gdb1][DEBUG ] detect machine type
[2017-05-31 19:01:41,283][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 19:01:41,285][ceph_deploy.admin][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite
[2017-05-31 19:01:41,285][ceph_deploy][ERROR ] GenericError: Failed to configure 1 admin hosts

[2017-05-31 19:01:48,568][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 19:01:48,569][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb1
[2017-05-31 19:01:48,569][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 19:01:48,569][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 19:01:48,569][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 19:01:48,569][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 19:01:48,569][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 19:01:48,569][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0433916518>
[2017-05-31 19:01:48,569][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 19:01:48,569][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-05-31 19:01:48,569][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f043422d938>
[2017-05-31 19:01:48,569][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 19:01:48,569][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 19:01:48,569][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-05-31 19:01:48,811][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 19:01:49,047][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 19:01:49,047][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 19:01:49,063][gdb1][DEBUG ] detect machine type
[2017-05-31 19:01:49,067][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 19:01:52,711][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 19:01:52,711][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-05-31 19:01:52,711][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 19:01:52,711][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 19:01:52,711][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 19:01:52,711][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 19:01:52,711][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 19:01:52,711][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 19:01:52,712][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 19:01:52,712][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 19:01:52,712][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 19:01:52,712][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 19:01:52,712][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 19:01:52,712][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 19:01:52,712][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7a9172a908>
[2017-05-31 19:01:52,712][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 19:01:52,712][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 19:01:52,712][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f7a91980aa0>
[2017-05-31 19:01:52,712][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 19:01:52,712][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 19:01:52,712][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 19:01:52,713][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 19:01:52,959][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 19:01:53,190][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 19:01:53,191][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 19:01:53,207][gdb1][DEBUG ] detect machine type
[2017-05-31 19:01:53,211][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:01:53,211][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 19:01:53,211][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-05-31 19:01:53,212][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 19:01:53,214][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-05-31 19:01:53,214][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:01:53,216][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 19:01:53,336][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 19:01:53,352][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 19:01:53,368][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 19:01:53,383][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 19:01:53,391][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 19:01:53,407][gdb1][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-05-31 19:01:53,407][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.16092.tmp
[2017-05-31 19:01:53,407][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.16092.tmp
[2017-05-31 19:01:53,411][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.16092.tmp
[2017-05-31 19:01:58,432][gdb1][INFO  ] checking OSD status...
[2017-05-31 19:01:58,432][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:01:58,434][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 19:01:58,600][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-05-31 19:02:05,404][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 19:02:05,404][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-05-31 19:02:05,404][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 19:02:05,404][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 19:02:05,405][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 19:02:05,405][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 19:02:05,405][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 19:02:05,405][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 19:02:05,405][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fef4e246908>
[2017-05-31 19:02:05,405][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 19:02:05,405][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fef4e49caa0>
[2017-05-31 19:02:05,405][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 19:02:05,405][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 19:02:05,405][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 19:02:05,405][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 19:02:05,643][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 19:02:05,874][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 19:02:05,875][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 19:02:05,891][gdb1][DEBUG ] detect machine type
[2017-05-31 19:02:05,895][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:02:05,895][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 19:02:05,895][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-05-31 19:02:05,896][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 19:02:05,896][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:02:05,898][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 19:02:06,018][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 19:02:06,018][gdb1][WARNING] activate: Cluster uuid is cb3c2cda-b4dd-4a09-9b7a-a7dc594196ab
[2017-05-31 19:02:06,018][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 19:02:06,034][gdb1][WARNING] activate: Cluster name is ceph
[2017-05-31 19:02:06,034][gdb1][WARNING] activate: OSD uuid is 7c61a5ba-3130-4674-af68-e74e94fe90f6
[2017-05-31 19:02:06,034][gdb1][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 19:02:06,034][gdb1][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 7c61a5ba-3130-4674-af68-e74e94fe90f6
[2017-05-31 19:02:06,099][gdb1][WARNING] Traceback (most recent call last):
[2017-05-31 19:02:06,099][gdb1][WARNING]   File "/usr/local/bin/ceph-disk", line 9, in <module>
[2017-05-31 19:02:06,099][gdb1][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 19:02:06,099][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5653, in run
[2017-05-31 19:02:06,099][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5604, in main
[2017-05-31 19:02:06,099][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 19:02:06,100][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 19:02:06,100][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3625, in activate
[2017-05-31 19:02:06,100][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 1075, in allocate_osd_id
[2017-05-31 19:02:06,100][gdb1][WARNING] ceph_disk.main.Error: Error: ceph osd create failed: Command '/usr/bin/ceph' returned non-zero exit status 1: 2017-05-31 19:02:06.089590 7f162bcf1700  0 librados: client.bootstrap-osd authentication error (1) Operation not permitted
[2017-05-31 19:02:06,100][gdb1][WARNING] error connecting to the cluster
[2017-05-31 19:02:06,100][gdb1][WARNING] 
[2017-05-31 19:02:06,108][gdb1][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 19:02:06,108][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 19:02:26,603][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 19:02:26,603][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-05-31 19:02:26,603][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 19:02:26,603][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 19:02:26,603][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 19:02:26,603][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 19:02:26,604][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 19:02:26,604][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 19:02:26,604][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f31d72c1908>
[2017-05-31 19:02:26,604][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 19:02:26,604][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f31d7517aa0>
[2017-05-31 19:02:26,604][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 19:02:26,604][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 19:02:26,604][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 19:02:26,604][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 19:02:26,851][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 19:02:27,083][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 19:02:27,084][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 19:02:27,100][gdb1][DEBUG ] detect machine type
[2017-05-31 19:02:27,104][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:02:27,105][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 19:02:27,105][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-05-31 19:02:27,105][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 19:02:27,105][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:02:27,107][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 19:02:27,278][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 19:02:27,278][gdb1][WARNING] activate: Cluster uuid is cb3c2cda-b4dd-4a09-9b7a-a7dc594196ab
[2017-05-31 19:02:27,278][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 19:02:27,278][gdb1][WARNING] activate: Cluster name is ceph
[2017-05-31 19:02:27,278][gdb1][WARNING] activate: OSD uuid is 7c61a5ba-3130-4674-af68-e74e94fe90f6
[2017-05-31 19:02:27,278][gdb1][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 19:02:27,278][gdb1][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 7c61a5ba-3130-4674-af68-e74e94fe90f6
[2017-05-31 19:02:27,310][gdb1][WARNING] Traceback (most recent call last):
[2017-05-31 19:02:27,311][gdb1][WARNING]   File "/usr/local/bin/ceph-disk", line 9, in <module>
[2017-05-31 19:02:27,311][gdb1][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 19:02:27,311][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5653, in run
[2017-05-31 19:02:27,311][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5604, in main
[2017-05-31 19:02:27,312][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 19:02:27,312][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 19:02:27,312][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3625, in activate
[2017-05-31 19:02:27,312][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 1075, in allocate_osd_id
[2017-05-31 19:02:27,312][gdb1][WARNING] ceph_disk.main.Error: Error: ceph osd create failed: Command '/usr/bin/ceph' returned non-zero exit status 1: 2017-05-31 19:02:27.301230 7fc80c4df700  0 librados: client.bootstrap-osd authentication error (1) Operation not permitted
[2017-05-31 19:02:27,312][gdb1][WARNING] error connecting to the cluster
[2017-05-31 19:02:27,312][gdb1][WARNING] 
[2017-05-31 19:02:27,320][gdb1][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 19:02:27,320][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 19:02:38,060][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 19:02:38,060][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-05-31 19:02:38,061][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 19:02:38,061][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 19:02:38,061][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 19:02:38,061][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 19:02:38,061][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 19:02:38,061][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 19:02:38,061][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 19:02:38,061][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 19:02:38,061][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 19:02:38,061][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 19:02:38,061][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 19:02:38,061][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 19:02:38,061][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f14bb70e908>
[2017-05-31 19:02:38,061][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 19:02:38,061][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 19:02:38,062][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f14bb964aa0>
[2017-05-31 19:02:38,062][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 19:02:38,062][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 19:02:38,062][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 19:02:38,062][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 19:02:38,303][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 19:02:38,535][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 19:02:38,535][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 19:02:38,551][gdb1][DEBUG ] detect machine type
[2017-05-31 19:02:38,555][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:02:38,556][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 19:02:38,556][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-05-31 19:02:38,556][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 19:02:38,558][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-05-31 19:02:38,558][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:02:38,560][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 19:02:38,680][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 19:02:38,696][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 19:02:38,712][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 19:02:38,728][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 19:02:38,735][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 19:02:38,751][gdb1][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-05-31 19:02:43,760][gdb1][INFO  ] checking OSD status...
[2017-05-31 19:02:43,760][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:02:43,762][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 19:02:43,928][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-05-31 19:02:45,629][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 19:02:45,629][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-05-31 19:02:45,629][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 19:02:45,629][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 19:02:45,629][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 19:02:45,629][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 19:02:45,630][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 19:02:45,630][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 19:02:45,630][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f8b71056908>
[2017-05-31 19:02:45,630][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 19:02:45,630][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f8b712acaa0>
[2017-05-31 19:02:45,630][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 19:02:45,630][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 19:02:45,630][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 19:02:45,630][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 19:02:45,867][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 19:02:46,099][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 19:02:46,099][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 19:02:46,115][gdb1][DEBUG ] detect machine type
[2017-05-31 19:02:46,119][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:02:46,120][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 19:02:46,120][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-05-31 19:02:46,120][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 19:02:46,120][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:02:46,122][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 19:02:46,243][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 19:02:46,243][gdb1][WARNING] activate: Cluster uuid is cb3c2cda-b4dd-4a09-9b7a-a7dc594196ab
[2017-05-31 19:02:46,243][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 19:02:46,259][gdb1][WARNING] activate: Cluster name is ceph
[2017-05-31 19:02:46,259][gdb1][WARNING] activate: OSD uuid is 7c61a5ba-3130-4674-af68-e74e94fe90f6
[2017-05-31 19:02:46,259][gdb1][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 19:02:46,259][gdb1][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 7c61a5ba-3130-4674-af68-e74e94fe90f6
[2017-05-31 19:02:46,373][gdb1][WARNING] Traceback (most recent call last):
[2017-05-31 19:02:46,373][gdb1][WARNING]   File "/usr/local/bin/ceph-disk", line 9, in <module>
[2017-05-31 19:02:46,373][gdb1][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 19:02:46,374][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5653, in run
[2017-05-31 19:02:46,374][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5604, in main
[2017-05-31 19:02:46,374][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 19:02:46,374][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 19:02:46,374][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3625, in activate
[2017-05-31 19:02:46,374][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 1075, in allocate_osd_id
[2017-05-31 19:02:46,374][gdb1][WARNING] ceph_disk.main.Error: Error: ceph osd create failed: Command '/usr/bin/ceph' returned non-zero exit status 1: 2017-05-31 19:02:46.315195 7ff02b813700  0 librados: client.bootstrap-osd authentication error (1) Operation not permitted
[2017-05-31 19:02:46,374][gdb1][WARNING] error connecting to the cluster
[2017-05-31 19:02:46,374][gdb1][WARNING] 
[2017-05-31 19:02:46,374][gdb1][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 19:02:46,374][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 19:03:30,541][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 19:03:30,541][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-05-31 19:03:30,541][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 19:03:30,541][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 19:03:30,541][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 19:03:30,542][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 19:03:30,542][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 19:03:30,542][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 19:03:30,542][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 19:03:30,542][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 19:03:30,542][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 19:03:30,542][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 19:03:30,542][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 19:03:30,542][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 19:03:30,542][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fcc71562908>
[2017-05-31 19:03:30,542][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 19:03:30,542][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 19:03:30,542][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fcc717b8aa0>
[2017-05-31 19:03:30,542][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 19:03:30,542][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 19:03:30,542][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 19:03:30,543][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 19:03:30,783][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 19:03:31,015][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 19:03:31,015][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 19:03:31,031][gdb1][DEBUG ] detect machine type
[2017-05-31 19:03:31,035][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:03:31,035][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 19:03:31,036][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-05-31 19:03:31,036][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 19:03:31,038][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-05-31 19:03:31,038][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:03:31,040][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 19:03:31,160][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 19:03:31,176][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 19:03:31,192][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 19:03:31,208][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 19:03:31,215][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 19:03:31,231][gdb1][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-05-31 19:03:36,239][gdb1][INFO  ] checking OSD status...
[2017-05-31 19:03:36,240][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:03:36,242][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 19:03:36,408][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-05-31 19:03:41,172][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 19:03:41,172][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-05-31 19:03:41,173][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 19:03:41,173][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 19:03:41,173][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 19:03:41,173][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 19:03:41,173][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 19:03:41,173][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 19:03:41,173][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7d45f48908>
[2017-05-31 19:03:41,173][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 19:03:41,173][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f7d4619eaa0>
[2017-05-31 19:03:41,173][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 19:03:41,173][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 19:03:41,173][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 19:03:41,174][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 19:03:41,415][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 19:03:41,647][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 19:03:41,647][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 19:03:41,664][gdb1][DEBUG ] detect machine type
[2017-05-31 19:03:41,667][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:03:41,668][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 19:03:41,668][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-05-31 19:03:41,668][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 19:03:41,668][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:03:41,670][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 19:03:41,790][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 19:03:41,791][gdb1][WARNING] activate: Cluster uuid is cb3c2cda-b4dd-4a09-9b7a-a7dc594196ab
[2017-05-31 19:03:41,791][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 19:03:41,806][gdb1][WARNING] activate: Cluster name is ceph
[2017-05-31 19:03:41,806][gdb1][WARNING] activate: OSD uuid is 7c61a5ba-3130-4674-af68-e74e94fe90f6
[2017-05-31 19:03:41,807][gdb1][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 19:03:41,807][gdb1][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 7c61a5ba-3130-4674-af68-e74e94fe90f6
[2017-05-31 19:03:41,871][gdb1][WARNING] Traceback (most recent call last):
[2017-05-31 19:03:41,871][gdb1][WARNING]   File "/usr/local/bin/ceph-disk", line 9, in <module>
[2017-05-31 19:03:41,871][gdb1][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 19:03:41,871][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5653, in run
[2017-05-31 19:03:41,871][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5604, in main
[2017-05-31 19:03:41,871][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 19:03:41,871][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 19:03:41,871][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3625, in activate
[2017-05-31 19:03:41,871][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 1075, in allocate_osd_id
[2017-05-31 19:03:41,872][gdb1][WARNING] ceph_disk.main.Error: Error: ceph osd create failed: Command '/usr/bin/ceph' returned non-zero exit status 1: 2017-05-31 19:03:41.861160 7f9a5c447700  0 librados: client.bootstrap-osd authentication error (1) Operation not permitted
[2017-05-31 19:03:41,872][gdb1][WARNING] error connecting to the cluster
[2017-05-31 19:03:41,872][gdb1][WARNING] 
[2017-05-31 19:03:41,879][gdb1][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 19:03:41,880][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 19:04:13,941][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 19:04:13,941][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb1
[2017-05-31 19:04:13,941][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 19:04:13,942][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 19:04:13,942][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 19:04:13,942][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 19:04:13,942][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 19:04:13,942][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f24f8549518>
[2017-05-31 19:04:13,942][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 19:04:13,942][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-05-31 19:04:13,942][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f24f8e60938>
[2017-05-31 19:04:13,942][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 19:04:13,942][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 19:04:13,942][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-05-31 19:04:14,184][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 19:04:14,415][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 19:04:14,415][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 19:04:14,432][gdb1][DEBUG ] detect machine type
[2017-05-31 19:04:14,435][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 19:04:18,227][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 19:04:18,228][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-05-31 19:04:18,228][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 19:04:18,228][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 19:04:18,228][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 19:04:18,228][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 19:04:18,228][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 19:04:18,228][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 19:04:18,228][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 19:04:18,228][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 19:04:18,228][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 19:04:18,228][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 19:04:18,228][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 19:04:18,228][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 19:04:18,228][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa794a1a908>
[2017-05-31 19:04:18,229][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 19:04:18,229][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 19:04:18,229][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fa794c70aa0>
[2017-05-31 19:04:18,229][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 19:04:18,229][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 19:04:18,229][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 19:04:18,229][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 19:04:18,471][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 19:04:18,703][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 19:04:18,704][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 19:04:18,720][gdb1][DEBUG ] detect machine type
[2017-05-31 19:04:18,724][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:04:18,725][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 19:04:18,725][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-05-31 19:04:18,725][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 19:04:18,727][gdb1][WARNING] osd keyring does not exist yet, creating one
[2017-05-31 19:04:18,727][gdb1][DEBUG ] create a keyring file
[2017-05-31 19:04:18,729][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-05-31 19:04:18,729][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:04:18,731][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 19:04:18,901][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 19:04:18,902][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 19:04:18,902][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 19:04:18,902][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 19:04:18,909][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 19:04:18,925][gdb1][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-05-31 19:04:23,934][gdb1][INFO  ] checking OSD status...
[2017-05-31 19:04:23,934][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:04:23,936][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 19:04:24,102][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-05-31 19:04:27,131][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 19:04:27,131][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-05-31 19:04:27,131][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 19:04:27,131][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 19:04:27,131][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 19:04:27,131][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 19:04:27,131][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 19:04:27,131][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 19:04:27,131][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f10404af908>
[2017-05-31 19:04:27,132][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 19:04:27,132][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f1040705aa0>
[2017-05-31 19:04:27,132][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 19:04:27,132][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 19:04:27,132][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-05-31 19:04:27,132][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-05-31 19:04:27,375][gdb1][DEBUG ] connection detected need for sudo
[2017-05-31 19:04:27,606][gdb1][DEBUG ] connected to host: gdb1 
[2017-05-31 19:04:27,607][gdb1][DEBUG ] detect platform information from remote host
[2017-05-31 19:04:27,623][gdb1][DEBUG ] detect machine type
[2017-05-31 19:04:27,627][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:04:27,628][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 19:04:27,628][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-05-31 19:04:27,628][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 19:04:27,628][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:04:27,630][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 19:04:27,751][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 19:04:27,751][gdb1][WARNING] activate: Cluster uuid is cb3c2cda-b4dd-4a09-9b7a-a7dc594196ab
[2017-05-31 19:04:27,751][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 19:04:27,767][gdb1][WARNING] activate: Cluster name is ceph
[2017-05-31 19:04:27,767][gdb1][WARNING] activate: OSD uuid is 7c61a5ba-3130-4674-af68-e74e94fe90f6
[2017-05-31 19:04:27,767][gdb1][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 19:04:27,767][gdb1][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 7c61a5ba-3130-4674-af68-e74e94fe90f6
[2017-05-31 19:04:27,931][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.17048.tmp
[2017-05-31 19:04:27,931][gdb1][WARNING] activate: OSD id is 0
[2017-05-31 19:04:27,931][gdb1][WARNING] activate: Initializing OSD...
[2017-05-31 19:04:27,931][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-05-31 19:04:28,096][gdb1][WARNING] got monmap epoch 2
[2017-05-31 19:04:28,096][gdb1][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 0 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid 7c61a5ba-3130-4674-af68-e74e94fe90f6 --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-05-31 19:04:28,128][gdb1][WARNING] activate: Marking with init system systemd
[2017-05-31 19:04:28,128][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-05-31 19:04:28,128][gdb1][WARNING] activate: Authorizing OSD key...
[2017-05-31 19:04:28,128][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.0 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-05-31 19:04:28,292][gdb1][WARNING] added key for osd.0
[2017-05-31 19:04:28,293][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.17048.tmp
[2017-05-31 19:04:28,293][gdb1][WARNING] activate: ceph osd.0 data dir is ready at /mnt/memstore
[2017-05-31 19:04:28,293][gdb1][WARNING] activate_dir: Creating symlink /var/lib/ceph/osd/ceph-0 -> /mnt/memstore
[2017-05-31 19:04:28,293][gdb1][WARNING] start_daemon: Starting ceph osd.0...
[2017-05-31 19:04:28,293][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0
[2017-05-31 19:04:28,293][gdb1][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service.
[2017-05-31 19:04:28,357][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0 --runtime
[2017-05-31 19:04:28,389][gdb1][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@0
[2017-05-31 19:04:28,392][gdb1][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service to /lib/systemd/system/ceph-osd@.service.
[2017-05-31 19:04:28,456][gdb1][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@0
[2017-05-31 19:04:33,576][gdb1][INFO  ] checking OSD status...
[2017-05-31 19:04:33,576][gdb1][DEBUG ] find the location of an executable
[2017-05-31 19:04:33,578][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 19:04:33,746][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-05-31 19:04:48,602][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 19:04:48,602][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-05-31 19:04:48,602][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 19:04:48,602][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 19:04:48,602][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 19:04:48,602][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-05-31 19:04:48,602][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 19:04:48,602][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f2e86347518>
[2017-05-31 19:04:48,602][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 19:04:48,602][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-05-31 19:04:48,603][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f2e86c5e938>
[2017-05-31 19:04:48,603][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 19:04:48,603][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 19:04:48,603][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-05-31 19:04:48,842][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 19:04:49,070][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 19:04:49,070][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 19:04:49,086][gdb0][DEBUG ] detect machine type
[2017-05-31 19:04:49,090][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 19:05:02,677][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 19:05:02,677][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-05-31 19:05:02,677][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 19:05:02,677][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 19:05:02,677][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 19:05:02,677][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 19:05:02,677][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 19:05:02,678][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 19:05:02,678][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 19:05:02,678][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 19:05:02,678][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 19:05:02,678][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 19:05:02,678][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 19:05:02,678][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 19:05:02,678][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f56878ce908>
[2017-05-31 19:05:02,678][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 19:05:02,678][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 19:05:02,678][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f5687b24aa0>
[2017-05-31 19:05:02,678][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 19:05:02,678][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 19:05:02,678][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 19:05:02,679][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 19:05:02,919][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 19:05:03,150][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 19:05:03,151][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 19:05:03,167][gdb0][DEBUG ] detect machine type
[2017-05-31 19:05:03,170][gdb0][DEBUG ] find the location of an executable
[2017-05-31 19:05:03,171][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 19:05:03,171][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 19:05:03,171][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 19:05:03,174][gdb0][WARNING] osd keyring does not exist yet, creating one
[2017-05-31 19:05:03,174][gdb0][DEBUG ] create a keyring file
[2017-05-31 19:05:03,176][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-05-31 19:05:03,176][gdb0][DEBUG ] find the location of an executable
[2017-05-31 19:05:03,178][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 19:05:03,298][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 19:05:03,306][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 19:05:03,321][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 19:05:03,329][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 19:05:03,345][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 19:05:03,352][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-05-31 19:05:08,373][gdb0][INFO  ] checking OSD status...
[2017-05-31 19:05:08,373][gdb0][DEBUG ] find the location of an executable
[2017-05-31 19:05:08,376][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 19:05:08,541][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-05-31 19:05:18,167][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 19:05:18,167][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 19:05:18,167][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 19:05:18,167][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 19:05:18,168][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 19:05:18,168][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 19:05:18,168][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 19:05:18,168][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 19:05:18,168][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f46d5fcb908>
[2017-05-31 19:05:18,168][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 19:05:18,168][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f46d6221aa0>
[2017-05-31 19:05:18,168][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 19:05:18,168][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 19:05:18,168][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 19:05:18,168][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 19:05:18,406][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 19:05:18,630][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 19:05:18,630][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 19:05:18,646][gdb0][DEBUG ] detect machine type
[2017-05-31 19:05:18,649][gdb0][DEBUG ] find the location of an executable
[2017-05-31 19:05:18,650][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 19:05:18,650][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 19:05:18,650][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 19:05:18,651][gdb0][DEBUG ] find the location of an executable
[2017-05-31 19:05:18,652][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 19:05:18,773][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 19:05:18,773][gdb0][WARNING] activate: Cluster uuid is c676bc10-14a8-4f7c-93e4-c9f0324506d5
[2017-05-31 19:05:18,773][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 19:05:18,776][gdb0][WARNING] Traceback (most recent call last):
[2017-05-31 19:05:18,776][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-05-31 19:05:18,776][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-05-31 19:05:18,777][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-05-31 19:05:18,777][gdb0][WARNING]     main(sys.argv[1:])
[2017-05-31 19:05:18,777][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-05-31 19:05:18,777][gdb0][WARNING]     args.func(args)
[2017-05-31 19:05:18,777][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-05-31 19:05:18,777][gdb0][WARNING]     init=args.mark_init,
[2017-05-31 19:05:18,779][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-05-31 19:05:18,779][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-05-31 19:05:18,779][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3609, in activate
[2017-05-31 19:05:18,779][gdb0][WARNING]     ' with fsid %s' % ceph_fsid)
[2017-05-31 19:05:18,779][gdb0][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid c676bc10-14a8-4f7c-93e4-c9f0324506d5
[2017-05-31 19:05:18,787][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-05-31 19:05:18,787][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-05-31 19:08:02,744][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 19:08:02,744][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb0
[2017-05-31 19:08:02,745][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 19:08:02,745][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 19:08:02,745][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 19:08:02,745][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 19:08:02,745][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 19:08:02,745][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa2089aefc8>
[2017-05-31 19:08:02,745][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 19:08:02,745][ceph_deploy.cli][INFO  ]  host                          : ['gdb0']
[2017-05-31 19:08:02,745][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7fa2092c11b8>
[2017-05-31 19:08:02,745][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 19:08:02,745][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 19:08:02,745][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-05-31 19:08:02,745][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-05-31 19:08:02,745][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb0
[2017-05-31 19:08:02,745][ceph_deploy.install][DEBUG ] Detecting platform for host gdb0 ...
[2017-05-31 19:08:03,057][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 19:08:03,290][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 19:08:03,290][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 19:08:03,321][gdb0][DEBUG ] detect machine type
[2017-05-31 19:08:03,324][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 19:08:03,324][gdb0][INFO  ] Purging Ceph on gdb0
[2017-05-31 19:08:03,326][gdb0][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-05-31 19:08:03,647][gdb0][DEBUG ] Reading package lists...
[2017-05-31 19:08:03,761][gdb0][DEBUG ] Building dependency tree...
[2017-05-31 19:08:03,761][gdb0][DEBUG ] Reading state information...
[2017-05-31 19:08:03,825][gdb0][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-05-31 19:08:03,825][gdb0][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-05-31 19:08:03,825][gdb0][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-05-31 19:08:03,825][gdb0][DEBUG ]   ceph-fuse javascript-common libaio1 libcephfs2 libgoogle-perftools4
[2017-05-31 19:08:03,826][gdb0][DEBUG ]   libibverbs1 libjs-jquery libleveldb1v5 liblttng-ust-ctl2 liblttng-ust0
[2017-05-31 19:08:03,826][gdb0][DEBUG ]   libnspr4 libnss3 libnss3-nssdb libopts25 libpython2.7 librados2
[2017-05-31 19:08:03,826][gdb0][DEBUG ]   libradosstriper1 librbd1 librgw2 libsnappy1v5 libtcmalloc-minimal4
[2017-05-31 19:08:03,826][gdb0][DEBUG ]   libunwind8 liburcu4 linux-aws-headers-4.4.0-1013
[2017-05-31 19:08:03,826][gdb0][DEBUG ]   linux-headers-4.4.0-1013-aws linux-image-4.4.0-1013-aws ntp python-blinker
[2017-05-31 19:08:03,826][gdb0][DEBUG ]   python-cephfs python-cffi-backend python-chardet python-cryptography
[2017-05-31 19:08:03,826][gdb0][DEBUG ]   python-enum34 python-flask python-idna python-ipaddress python-itsdangerous
[2017-05-31 19:08:03,826][gdb0][DEBUG ]   python-jinja2 python-markupsafe python-ndg-httpsclient python-openssl
[2017-05-31 19:08:03,826][gdb0][DEBUG ]   python-pyasn1 python-pyinotify python-rados python-rbd python-requests
[2017-05-31 19:08:03,826][gdb0][DEBUG ]   python-rgw python-six python-urllib3 python-werkzeug
[2017-05-31 19:08:03,826][gdb0][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-05-31 19:08:03,858][gdb0][DEBUG ] The following packages will be REMOVED:
[2017-05-31 19:08:03,858][gdb0][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-05-31 19:08:04,173][gdb0][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 35 not upgraded.
[2017-05-31 19:08:04,173][gdb0][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-05-31 19:08:04,538][gdb0][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 104462 files and directories currently installed.)
[2017-05-31 19:08:04,539][gdb0][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-05-31 19:08:04,753][gdb0][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-05-31 19:08:04,817][gdb0][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-05-31 19:08:04,881][gdb0][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-05-31 19:08:05,146][gdb0][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-05-31 19:08:05,260][gdb0][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-05-31 19:08:05,425][gdb0][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-05-31 19:08:05,539][gdb0][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-05-31 19:08:05,703][gdb0][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-05-31 19:08:05,818][gdb0][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-05-31 19:08:05,982][gdb0][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-05-31 19:08:05,998][gdb0][DEBUG ] dpkg: warning: while removing ceph-base, directory '/var/lib/ceph/bootstrap-osd' not empty so not removed
[2017-05-31 19:08:05,998][gdb0][DEBUG ] dpkg: warning: while removing ceph-base, directory '/var/lib/ceph/tmp' not empty so not removed
[2017-05-31 19:08:06,062][gdb0][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-05-31 19:08:06,176][gdb0][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-05-31 19:08:06,290][gdb0][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-05-31 19:08:06,291][gdb0][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-05-31 19:08:06,455][gdb0][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu7) ...
[2017-05-31 19:08:07,522][gdb0][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-05-31 19:08:33,625][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 19:08:33,625][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb0
[2017-05-31 19:08:33,625][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 19:08:33,625][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 19:08:33,625][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 19:08:33,626][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 19:08:33,626][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 19:08:33,626][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ff824f26710>
[2017-05-31 19:08:33,626][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 19:08:33,626][ceph_deploy.cli][INFO  ]  host                          : ['gdb0']
[2017-05-31 19:08:33,626][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7ff825833230>
[2017-05-31 19:08:33,626][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 19:08:33,626][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 19:08:33,626][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb0
[2017-05-31 19:08:33,866][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 19:08:34,058][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 19:08:34,058][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 19:08:34,074][gdb0][DEBUG ] detect machine type
[2017-05-31 19:08:34,077][gdb0][DEBUG ] find the location of an executable
[2017-05-31 19:08:34,302][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 19:08:34,529][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 19:08:34,530][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 19:08:34,545][gdb0][DEBUG ] detect machine type
[2017-05-31 19:08:34,549][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 19:08:34,549][gdb0][INFO  ] purging data on gdb0
[2017-05-31 19:08:34,550][gdb0][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-05-31 19:08:34,564][gdb0][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-05-31 19:09:11,389][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 19:09:11,389][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb0
[2017-05-31 19:09:11,389][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 19:09:11,389][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 19:09:11,389][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 19:09:11,390][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 19:09:11,390][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 19:09:11,390][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb55bdce518>
[2017-05-31 19:09:11,390][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 19:09:11,390][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-05-31 19:09:11,390][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fb55c6e5938>
[2017-05-31 19:09:11,390][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 19:09:11,390][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 19:09:11,390][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-05-31 19:09:11,626][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 19:09:11,853][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 19:09:11,854][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 19:09:11,869][gdb0][DEBUG ] detect machine type
[2017-05-31 19:09:11,873][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 19:09:32,698][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 19:09:32,698][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-05-31 19:09:32,698][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 19:09:32,699][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 19:09:32,699][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-05-31 19:09:32,699][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 19:09:32,699][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-05-31 19:09:32,699][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 19:09:32,699][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-05-31 19:09:32,699][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-05-31 19:09:32,699][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 19:09:32,699][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-05-31 19:09:32,699][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-05-31 19:09:32,699][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 19:09:32,699][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fadccfdd908>
[2017-05-31 19:09:32,699][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 19:09:32,699][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-05-31 19:09:32,699][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fadcd233aa0>
[2017-05-31 19:09:32,700][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 19:09:32,700][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 19:09:32,700][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-05-31 19:09:32,700][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 19:09:32,938][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 19:09:33,162][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 19:09:33,162][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 19:09:33,178][gdb0][DEBUG ] detect machine type
[2017-05-31 19:09:33,182][gdb0][DEBUG ] find the location of an executable
[2017-05-31 19:09:33,182][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 19:09:33,182][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-05-31 19:09:33,183][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-05-31 19:09:33,185][gdb0][WARNING] osd keyring does not exist yet, creating one
[2017-05-31 19:09:33,185][gdb0][DEBUG ] create a keyring file
[2017-05-31 19:09:33,187][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-05-31 19:09:33,187][gdb0][DEBUG ] find the location of an executable
[2017-05-31 19:09:33,189][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-05-31 19:09:33,410][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 19:09:33,417][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 19:09:33,433][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 19:09:33,449][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-05-31 19:09:33,456][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-05-31 19:09:33,472][gdb0][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-05-31 19:09:33,488][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.3293.tmp
[2017-05-31 19:09:33,489][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.3293.tmp
[2017-05-31 19:09:33,492][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.3293.tmp
[2017-05-31 19:09:38,513][gdb0][INFO  ] checking OSD status...
[2017-05-31 19:09:38,513][gdb0][DEBUG ] find the location of an executable
[2017-05-31 19:09:38,516][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 19:09:38,882][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-05-31 19:09:44,982][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-05-31 19:09:44,982][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-05-31 19:09:44,982][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-05-31 19:09:44,982][ceph_deploy.cli][INFO  ]  username                      : None
[2017-05-31 19:09:44,982][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-05-31 19:09:44,982][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-05-31 19:09:44,982][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-05-31 19:09:44,982][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-05-31 19:09:44,982][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe13f609908>
[2017-05-31 19:09:44,982][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-05-31 19:09:44,982][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fe13f85faa0>
[2017-05-31 19:09:44,983][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-05-31 19:09:44,983][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-05-31 19:09:44,983][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-05-31 19:09:44,983][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-05-31 19:09:45,226][gdb0][DEBUG ] connection detected need for sudo
[2017-05-31 19:09:45,453][gdb0][DEBUG ] connected to host: gdb0 
[2017-05-31 19:09:45,454][gdb0][DEBUG ] detect platform information from remote host
[2017-05-31 19:09:45,470][gdb0][DEBUG ] detect machine type
[2017-05-31 19:09:45,473][gdb0][DEBUG ] find the location of an executable
[2017-05-31 19:09:45,474][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-05-31 19:09:45,474][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-05-31 19:09:45,474][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-05-31 19:09:45,474][gdb0][DEBUG ] find the location of an executable
[2017-05-31 19:09:45,477][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-05-31 19:09:45,597][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-05-31 19:09:45,597][gdb0][WARNING] activate: Cluster uuid is cb3c2cda-b4dd-4a09-9b7a-a7dc594196ab
[2017-05-31 19:09:45,597][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-05-31 19:09:45,601][gdb0][WARNING] activate: Cluster name is ceph
[2017-05-31 19:09:45,601][gdb0][WARNING] activate: OSD uuid is a397040a-60e7-423c-bb3e-a90280753962
[2017-05-31 19:09:45,601][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-05-31 19:09:45,601][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise a397040a-60e7-423c-bb3e-a90280753962
[2017-05-31 19:09:46,518][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.3415.tmp
[2017-05-31 19:09:46,518][gdb0][WARNING] activate: OSD id is 1
[2017-05-31 19:09:46,518][gdb0][WARNING] activate: Initializing OSD...
[2017-05-31 19:09:46,518][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-05-31 19:09:46,683][gdb0][WARNING] got monmap epoch 2
[2017-05-31 19:09:46,683][gdb0][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 1 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid a397040a-60e7-423c-bb3e-a90280753962 --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-05-31 19:09:46,698][gdb0][WARNING] activate: Marking with init system systemd
[2017-05-31 19:09:46,699][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-05-31 19:09:46,699][gdb0][WARNING] activate: Authorizing OSD key...
[2017-05-31 19:09:46,699][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.1 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-05-31 19:09:46,863][gdb0][WARNING] added key for osd.1
[2017-05-31 19:09:46,863][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.3415.tmp
[2017-05-31 19:09:46,863][gdb0][WARNING] activate: ceph osd.1 data dir is ready at /mnt/memstore
[2017-05-31 19:09:46,863][gdb0][WARNING] activate_dir: Creating symlink /var/lib/ceph/osd/ceph-1 -> /mnt/memstore
[2017-05-31 19:09:46,863][gdb0][WARNING] start_daemon: Starting ceph osd.1...
[2017-05-31 19:09:46,863][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@1
[2017-05-31 19:09:46,867][gdb0][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@1.service.
[2017-05-31 19:09:46,931][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@1 --runtime
[2017-05-31 19:09:46,995][gdb0][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@1
[2017-05-31 19:09:46,995][gdb0][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@1.service to /lib/systemd/system/ceph-osd@.service.
[2017-05-31 19:09:47,027][gdb0][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@1
[2017-05-31 19:09:52,096][gdb0][INFO  ] checking OSD status...
[2017-05-31 19:09:52,096][gdb0][DEBUG ] find the location of an executable
[2017-05-31 19:09:52,099][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-05-31 19:09:52,266][gdb0][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-06-11 00:09:24,868][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:09:24,870][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-06-11 00:09:24,870][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:09:24,870][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:09:24,870][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:09:24,870][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:09:24,870][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:09:24,870][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f8dbf6f80e0>
[2017-06-11 00:09:24,870][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:09:24,870][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-06-11 00:09:24,870][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f8dc00051b8>
[2017-06-11 00:09:24,870][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:09:24,871][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:09:24,871][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-06-11 00:09:24,871][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-06-11 00:09:24,871][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-06-11 00:09:24,871][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-06-11 00:09:24,907][gdb3][DEBUG ] connection detected need for sudo
[2017-06-11 00:09:24,934][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-11 00:09:24,935][gdb3][DEBUG ] detect platform information from remote host
[2017-06-11 00:09:24,951][gdb3][DEBUG ] detect machine type
[2017-06-11 00:09:24,953][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 00:09:24,953][gdb3][INFO  ] Purging Ceph on gdb3
[2017-06-11 00:09:24,955][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-06-11 00:09:24,994][gdb3][DEBUG ] Reading package lists...
[2017-06-11 00:09:25,159][gdb3][DEBUG ] Building dependency tree...
[2017-06-11 00:09:25,159][gdb3][DEBUG ] Reading state information...
[2017-06-11 00:09:25,223][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-06-11 00:09:25,223][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-06-11 00:09:25,223][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-06-11 00:09:25,223][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-06-11 00:09:25,223][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-06-11 00:09:25,223][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-06-11 00:09:25,224][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1016 linux-headers-4.4.0-1013-aws
[2017-06-11 00:09:25,224][gdb3][DEBUG ]   linux-headers-4.4.0-1016-aws linux-image-4.4.0-1013-aws
[2017-06-11 00:09:25,224][gdb3][DEBUG ]   linux-image-4.4.0-1016-aws ntp python-blinker python-cephfs
[2017-06-11 00:09:25,224][gdb3][DEBUG ]   python-cffi-backend python-chardet python-cryptography python-enum34
[2017-06-11 00:09:25,224][gdb3][DEBUG ]   python-flask python-idna python-ipaddress python-itsdangerous python-jinja2
[2017-06-11 00:09:25,224][gdb3][DEBUG ]   python-markupsafe python-ndg-httpsclient python-openssl python-pyasn1
[2017-06-11 00:09:25,224][gdb3][DEBUG ]   python-pyinotify python-rados python-rbd python-requests python-rgw
[2017-06-11 00:09:25,224][gdb3][DEBUG ]   python-six python-urllib3 python-werkzeug
[2017-06-11 00:09:25,224][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-06-11 00:09:25,288][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-06-11 00:09:25,288][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-06-11 00:09:25,553][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 40 not upgraded.
[2017-06-11 00:09:25,553][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-06-11 00:09:25,918][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 129562 files and directories currently installed.)
[2017-06-11 00:09:25,918][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-06-11 00:09:26,134][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-06-11 00:09:26,198][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-06-11 00:09:26,262][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-06-11 00:09:26,477][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-06-11 00:09:26,591][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-06-11 00:09:26,759][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-06-11 00:09:26,823][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-06-11 00:09:26,823][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-06-11 00:09:26,991][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-06-11 00:09:27,105][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-06-11 00:09:27,106][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-06-11 00:09:27,270][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-06-11 00:09:27,270][gdb3][DEBUG ] dpkg: warning: while removing ceph-base, directory '/var/lib/ceph/tmp' not empty so not removed
[2017-06-11 00:09:27,278][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-06-11 00:09:27,445][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-06-11 00:09:27,476][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-06-11 00:09:27,492][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-06-11 00:09:27,656][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu7) ...
[2017-06-11 00:09:28,473][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-06-11 00:09:28,641][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:09:28,642][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-06-11 00:09:28,642][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:09:28,642][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:09:28,642][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:09:28,642][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:09:28,642][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:09:28,642][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0cac286758>
[2017-06-11 00:09:28,642][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:09:28,642][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-06-11 00:09:28,642][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f0cacb93230>
[2017-06-11 00:09:28,642][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:09:28,643][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:09:28,643][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-06-11 00:09:28,669][gdb3][DEBUG ] connection detected need for sudo
[2017-06-11 00:09:28,683][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-11 00:09:28,683][gdb3][DEBUG ] detect platform information from remote host
[2017-06-11 00:09:28,700][gdb3][DEBUG ] detect machine type
[2017-06-11 00:09:28,702][gdb3][DEBUG ] find the location of an executable
[2017-06-11 00:09:28,718][gdb3][DEBUG ] connection detected need for sudo
[2017-06-11 00:09:28,731][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-11 00:09:28,732][gdb3][DEBUG ] detect platform information from remote host
[2017-06-11 00:09:28,748][gdb3][DEBUG ] detect machine type
[2017-06-11 00:09:28,751][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 00:09:28,751][gdb3][INFO  ] purging data on gdb3
[2017-06-11 00:09:28,752][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-06-11 00:09:28,765][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-06-11 00:09:28,934][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:09:28,935][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-06-11 00:09:28,935][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:09:28,935][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:09:28,935][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:09:28,935][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:09:28,935][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:09:28,935][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6dcc48ea28>
[2017-06-11 00:09:28,936][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:09:28,936][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7f6dccd51848>
[2017-06-11 00:09:28,936][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:09:28,936][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:10:12,282][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:10:12,282][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-06-11 00:10:12,282][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:10:12,282][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:10:12,282][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:10:12,282][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:10:12,283][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:10:12,283][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3b19d035a8>
[2017-06-11 00:10:12,283][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:10:12,283][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-06-11 00:10:12,283][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-06-11 00:10:12,283][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f3b1a387758>
[2017-06-11 00:10:12,283][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-06-11 00:10:12,283][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:10:12,283][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-06-11 00:10:12,283][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:10:12,283][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-06-11 00:10:12,283][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-06-11 00:10:12,284][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-06-11 00:10:12,309][gdb3][DEBUG ] connection detected need for sudo
[2017-06-11 00:10:12,323][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-11 00:10:12,323][gdb3][DEBUG ] detect platform information from remote host
[2017-06-11 00:10:12,340][gdb3][DEBUG ] detect machine type
[2017-06-11 00:10:12,342][gdb3][DEBUG ] find the location of an executable
[2017-06-11 00:10:12,344][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-06-11 00:10:12,355][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-06-11 00:10:12,361][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-06-11 00:10:12,361][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-06-11 00:10:12,361][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-06-11 00:10:12,361][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-06-11 00:10:12,362][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-06-11 00:10:12,362][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-06-11 00:10:12,362][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-06-11 00:10:12,362][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-06-11 00:10:12,528][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:10:12,528][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-06-11 00:10:12,528][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:10:12,528][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:10:12,529][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:10:12,529][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:10:12,529][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-06-11 00:10:12,529][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:10:12,529][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f08add22ea8>
[2017-06-11 00:10:12,529][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:10:12,529][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f08adcf6b18>
[2017-06-11 00:10:12,529][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:10:12,529][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-06-11 00:10:12,529][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:10:12,530][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-06-11 00:10:12,530][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-06-11 00:10:12,556][gdb3][DEBUG ] connection detected need for sudo
[2017-06-11 00:10:12,570][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-11 00:10:12,571][gdb3][DEBUG ] detect platform information from remote host
[2017-06-11 00:10:12,587][gdb3][DEBUG ] detect machine type
[2017-06-11 00:10:12,590][gdb3][DEBUG ] find the location of an executable
[2017-06-11 00:10:12,590][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-06-11 00:10:12,591][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-06-11 00:10:12,591][gdb3][DEBUG ] get remote short hostname
[2017-06-11 00:10:12,591][gdb3][DEBUG ] deploying mon to gdb3
[2017-06-11 00:10:12,591][gdb3][DEBUG ] get remote short hostname
[2017-06-11 00:10:12,591][gdb3][DEBUG ] remote hostname: gdb3
[2017-06-11 00:10:12,592][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-11 00:10:12,593][gdb3][DEBUG ] create the mon path if it does not exist
[2017-06-11 00:10:12,594][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-06-11 00:10:12,594][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-06-11 00:10:12,594][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-06-11 00:10:12,594][gdb3][DEBUG ] create the monitor keyring file
[2017-06-11 00:10:12,596][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-06-11 00:10:12,666][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-06-11 00:10:12,666][gdb3][DEBUG ] ceph-mon: set fsid to f4f36e31-c61f-42db-97ec-96a4b3bd98b7
[2017-06-11 00:10:12,666][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-06-11 00:10:12,666][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-06-11 00:10:12,667][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-06-11 00:10:12,667][gdb3][DEBUG ] create the init path if it does not exist
[2017-06-11 00:10:12,668][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-06-11 00:10:12,741][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-06-11 00:10:12,813][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-06-11 00:10:14,851][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-06-11 00:10:14,966][gdb3][DEBUG ] ********************************************************************************
[2017-06-11 00:10:14,966][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-06-11 00:10:14,966][gdb3][DEBUG ] {
[2017-06-11 00:10:14,966][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-06-11 00:10:14,966][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-06-11 00:10:14,967][gdb3][DEBUG ]   "features": {
[2017-06-11 00:10:14,967][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-06-11 00:10:14,967][gdb3][DEBUG ]     "quorum_mon": [
[2017-06-11 00:10:14,967][gdb3][DEBUG ]       "kraken", 
[2017-06-11 00:10:14,967][gdb3][DEBUG ]       "luminous"
[2017-06-11 00:10:14,967][gdb3][DEBUG ]     ], 
[2017-06-11 00:10:14,967][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-06-11 00:10:14,967][gdb3][DEBUG ]     "required_mon": [
[2017-06-11 00:10:14,967][gdb3][DEBUG ]       "kraken", 
[2017-06-11 00:10:14,967][gdb3][DEBUG ]       "luminous"
[2017-06-11 00:10:14,967][gdb3][DEBUG ]     ]
[2017-06-11 00:10:14,967][gdb3][DEBUG ]   }, 
[2017-06-11 00:10:14,967][gdb3][DEBUG ]   "monmap": {
[2017-06-11 00:10:14,967][gdb3][DEBUG ]     "created": "2017-06-11 00:10:12.642384", 
[2017-06-11 00:10:14,968][gdb3][DEBUG ]     "epoch": 2, 
[2017-06-11 00:10:14,968][gdb3][DEBUG ]     "features": {
[2017-06-11 00:10:14,968][gdb3][DEBUG ]       "optional": [], 
[2017-06-11 00:10:14,968][gdb3][DEBUG ]       "persistent": [
[2017-06-11 00:10:14,968][gdb3][DEBUG ]         "kraken", 
[2017-06-11 00:10:14,968][gdb3][DEBUG ]         "luminous"
[2017-06-11 00:10:14,968][gdb3][DEBUG ]       ]
[2017-06-11 00:10:14,968][gdb3][DEBUG ]     }, 
[2017-06-11 00:10:14,968][gdb3][DEBUG ]     "fsid": "f4f36e31-c61f-42db-97ec-96a4b3bd98b7", 
[2017-06-11 00:10:14,968][gdb3][DEBUG ]     "modified": "2017-06-11 00:10:12.894445", 
[2017-06-11 00:10:14,968][gdb3][DEBUG ]     "mons": [
[2017-06-11 00:10:14,968][gdb3][DEBUG ]       {
[2017-06-11 00:10:14,968][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-06-11 00:10:14,968][gdb3][DEBUG ]         "name": "gdb3", 
[2017-06-11 00:10:14,968][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-06-11 00:10:14,968][gdb3][DEBUG ]         "rank": 0
[2017-06-11 00:10:14,969][gdb3][DEBUG ]       }
[2017-06-11 00:10:14,969][gdb3][DEBUG ]     ]
[2017-06-11 00:10:14,969][gdb3][DEBUG ]   }, 
[2017-06-11 00:10:14,969][gdb3][DEBUG ]   "name": "gdb3", 
[2017-06-11 00:10:14,969][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-06-11 00:10:14,969][gdb3][DEBUG ]   "quorum": [
[2017-06-11 00:10:14,969][gdb3][DEBUG ]     0
[2017-06-11 00:10:14,969][gdb3][DEBUG ]   ], 
[2017-06-11 00:10:14,969][gdb3][DEBUG ]   "rank": 0, 
[2017-06-11 00:10:14,969][gdb3][DEBUG ]   "state": "leader", 
[2017-06-11 00:10:14,969][gdb3][DEBUG ]   "sync_provider": []
[2017-06-11 00:10:14,969][gdb3][DEBUG ] }
[2017-06-11 00:10:14,969][gdb3][DEBUG ] ********************************************************************************
[2017-06-11 00:10:14,969][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-06-11 00:10:14,970][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-06-11 00:10:15,035][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-06-11 00:10:15,051][gdb3][DEBUG ] connection detected need for sudo
[2017-06-11 00:10:15,064][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-11 00:10:15,065][gdb3][DEBUG ] detect platform information from remote host
[2017-06-11 00:10:15,081][gdb3][DEBUG ] detect machine type
[2017-06-11 00:10:15,084][gdb3][DEBUG ] find the location of an executable
[2017-06-11 00:10:15,085][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-06-11 00:10:15,150][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-06-11 00:10:15,150][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-06-11 00:10:15,150][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-06-11 00:10:15,152][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmp2yNmqZ
[2017-06-11 00:10:15,167][gdb3][DEBUG ] connection detected need for sudo
[2017-06-11 00:10:15,181][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-11 00:10:15,181][gdb3][DEBUG ] detect platform information from remote host
[2017-06-11 00:10:15,197][gdb3][DEBUG ] detect machine type
[2017-06-11 00:10:15,200][gdb3][DEBUG ] get remote short hostname
[2017-06-11 00:10:15,200][gdb3][DEBUG ] fetch remote file
[2017-06-11 00:10:15,201][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-06-11 00:10:15,267][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-06-11 00:10:15,433][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-06-11 00:10:15,599][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-06-11 00:10:15,765][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-06-11 00:10:15,932][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-06-11 00:10:16,098][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-06-11 00:10:16,264][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-06-11 00:10:16,430][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-06-11 00:10:16,596][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-06-11 00:10:16,762][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-06-11 00:10:16,928][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-06-11 00:10:16,928][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-06-11 00:10:16,929][ceph_deploy.gatherkeys][INFO  ] Replacing 'ceph.bootstrap-mgr.keyring' and backing up old key as 'ceph.bootstrap-mgr.keyring-20170611001016'
[2017-06-11 00:10:16,929][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-06-11 00:10:16,929][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-06-11 00:10:16,929][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-06-11 00:10:16,929][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmp2yNmqZ
[2017-06-11 00:10:17,112][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:10:17,112][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-06-11 00:10:17,112][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:10:17,112][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:10:17,112][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:10:17,112][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:10:17,112][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:10:17,112][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ff2a565f560>
[2017-06-11 00:10:17,113][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:10:17,113][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-06-11 00:10:17,113][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7ff2a5f76938>
[2017-06-11 00:10:17,113][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:10:17,113][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:10:17,113][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-06-11 00:10:17,139][gdb3][DEBUG ] connection detected need for sudo
[2017-06-11 00:10:17,153][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-11 00:10:17,154][gdb3][DEBUG ] detect platform information from remote host
[2017-06-11 00:10:17,170][gdb3][DEBUG ] detect machine type
[2017-06-11 00:10:17,173][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-11 00:12:58,042][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:12:58,042][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-06-11 00:12:58,042][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:12:58,042][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:12:58,042][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:12:58,042][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-06-11 00:12:58,042][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:12:58,042][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fab03053560>
[2017-06-11 00:12:58,043][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:12:58,043][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-06-11 00:12:58,043][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fab0396a938>
[2017-06-11 00:12:58,043][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:12:58,043][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:12:58,043][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-06-11 00:12:58,293][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:12:58,514][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:12:58,514][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:12:58,532][gdb0][DEBUG ] detect machine type
[2017-06-11 00:12:58,536][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-11 00:12:58,707][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:12:58,708][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-06-11 00:12:58,708][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:12:58,708][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:12:58,708][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-06-11 00:12:58,708][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-06-11 00:12:58,708][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-06-11 00:12:58,708][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:12:58,708][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-06-11 00:12:58,708][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-06-11 00:12:58,708][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:12:58,708][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-06-11 00:12:58,708][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-06-11 00:12:58,708][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:12:58,709][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe64d0ea950>
[2017-06-11 00:12:58,709][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:12:58,709][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-06-11 00:12:58,709][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fe64d340aa0>
[2017-06-11 00:12:58,709][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:12:58,709][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:12:58,709][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-06-11 00:12:58,709][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-06-11 00:12:58,950][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:12:59,177][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:12:59,178][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:12:59,194][gdb0][DEBUG ] detect machine type
[2017-06-11 00:12:59,198][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:12:59,199][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 00:12:59,199][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-06-11 00:12:59,199][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-11 00:12:59,202][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-06-11 00:12:59,202][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:12:59,204][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-06-11 00:12:59,325][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-06-11 00:12:59,332][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-11 00:12:59,348][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-11 00:12:59,356][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-11 00:12:59,371][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-06-11 00:12:59,379][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-06-11 00:13:04,400][gdb0][INFO  ] checking OSD status...
[2017-06-11 00:13:04,400][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:13:04,403][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-06-11 00:13:04,618][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-06-11 00:13:04,785][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:13:04,785][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-06-11 00:13:04,786][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:13:04,786][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:13:04,786][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:13:04,786][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:13:04,786][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-06-11 00:13:04,786][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:13:04,786][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fece470a950>
[2017-06-11 00:13:04,786][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:13:04,786][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fece4960aa0>
[2017-06-11 00:13:04,786][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:13:04,786][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:13:04,786][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-06-11 00:13:04,787][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-06-11 00:13:05,030][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:13:05,262][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:13:05,263][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:13:05,278][gdb0][DEBUG ] detect machine type
[2017-06-11 00:13:05,282][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:13:05,283][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 00:13:05,283][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-06-11 00:13:05,283][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-06-11 00:13:05,283][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:13:05,285][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-06-11 00:13:05,406][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-06-11 00:13:05,406][gdb0][WARNING] activate: Cluster uuid is cb3c2cda-b4dd-4a09-9b7a-a7dc594196ab
[2017-06-11 00:13:05,406][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-06-11 00:13:05,414][gdb0][WARNING] Traceback (most recent call last):
[2017-06-11 00:13:05,414][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-06-11 00:13:05,414][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-06-11 00:13:05,414][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-06-11 00:13:05,414][gdb0][WARNING]     main(sys.argv[1:])
[2017-06-11 00:13:05,415][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-06-11 00:13:05,415][gdb0][WARNING]     args.func(args)
[2017-06-11 00:13:05,415][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-06-11 00:13:05,415][gdb0][WARNING]     init=args.mark_init,
[2017-06-11 00:13:05,415][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-06-11 00:13:05,415][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-06-11 00:13:05,415][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3609, in activate
[2017-06-11 00:13:05,415][gdb0][WARNING]     ' with fsid %s' % ceph_fsid)
[2017-06-11 00:13:05,415][gdb0][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid cb3c2cda-b4dd-4a09-9b7a-a7dc594196ab
[2017-06-11 00:13:05,424][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-06-11 00:13:05,424][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-06-11 00:14:15,105][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:14:15,106][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-06-11 00:14:15,106][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:14:15,106][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:14:15,106][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:14:15,106][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-06-11 00:14:15,106][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:14:15,106][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f5b4b05c560>
[2017-06-11 00:14:15,106][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:14:15,106][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-06-11 00:14:15,106][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f5b4b973938>
[2017-06-11 00:14:15,107][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:14:15,107][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:14:15,107][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-06-11 00:14:15,342][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:14:15,538][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:14:15,539][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:14:15,554][gdb0][DEBUG ] detect machine type
[2017-06-11 00:14:15,558][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-11 00:14:15,730][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:14:15,730][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-06-11 00:14:15,731][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:14:15,731][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:14:15,731][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-06-11 00:14:15,731][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-06-11 00:14:15,731][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-06-11 00:14:15,731][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:14:15,731][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-06-11 00:14:15,731][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-06-11 00:14:15,731][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:14:15,731][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-06-11 00:14:15,731][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-06-11 00:14:15,731][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:14:15,731][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f61228b6950>
[2017-06-11 00:14:15,731][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:14:15,732][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-06-11 00:14:15,732][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f6122b0caa0>
[2017-06-11 00:14:15,732][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:14:15,732][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:14:15,732][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-06-11 00:14:15,732][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-06-11 00:14:15,979][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:14:16,214][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:14:16,215][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:14:16,231][gdb0][DEBUG ] detect machine type
[2017-06-11 00:14:16,235][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:14:16,236][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 00:14:16,236][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-06-11 00:14:16,236][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-11 00:14:16,238][gdb0][WARNING] osd keyring does not exist yet, creating one
[2017-06-11 00:14:16,238][gdb0][DEBUG ] create a keyring file
[2017-06-11 00:14:16,240][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-06-11 00:14:16,240][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:14:16,242][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-06-11 00:14:16,362][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-06-11 00:14:16,370][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-11 00:14:16,386][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-11 00:14:16,401][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-11 00:14:16,409][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-06-11 00:14:16,425][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-06-11 00:14:21,433][gdb0][INFO  ] checking OSD status...
[2017-06-11 00:14:21,434][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:14:21,436][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-06-11 00:14:21,602][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-06-11 00:14:21,767][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:14:21,767][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-06-11 00:14:21,767][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:14:21,767][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:14:21,768][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:14:21,768][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:14:21,768][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-06-11 00:14:21,768][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:14:21,768][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f87f2ff2950>
[2017-06-11 00:14:21,768][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:14:21,768][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f87f3248aa0>
[2017-06-11 00:14:21,768][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:14:21,768][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:14:21,768][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-06-11 00:14:21,768][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-06-11 00:14:22,011][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:14:22,242][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:14:22,242][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:14:22,258][gdb0][DEBUG ] detect machine type
[2017-06-11 00:14:22,262][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:14:22,263][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 00:14:22,264][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-06-11 00:14:22,264][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-06-11 00:14:22,264][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:14:22,267][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-06-11 00:14:22,387][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-06-11 00:14:22,387][gdb0][WARNING] activate: Cluster uuid is cb3c2cda-b4dd-4a09-9b7a-a7dc594196ab
[2017-06-11 00:14:22,387][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-06-11 00:14:22,395][gdb0][WARNING] Traceback (most recent call last):
[2017-06-11 00:14:22,395][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-06-11 00:14:22,395][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-06-11 00:14:22,395][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-06-11 00:14:22,395][gdb0][WARNING]     main(sys.argv[1:])
[2017-06-11 00:14:22,395][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-06-11 00:14:22,395][gdb0][WARNING]     args.func(args)
[2017-06-11 00:14:22,396][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-06-11 00:14:22,396][gdb0][WARNING]     init=args.mark_init,
[2017-06-11 00:14:22,396][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-06-11 00:14:22,396][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-06-11 00:14:22,396][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3609, in activate
[2017-06-11 00:14:22,396][gdb0][WARNING]     ' with fsid %s' % ceph_fsid)
[2017-06-11 00:14:22,396][gdb0][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid cb3c2cda-b4dd-4a09-9b7a-a7dc594196ab
[2017-06-11 00:14:22,404][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-06-11 00:14:22,404][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-06-11 00:14:32,489][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:14:32,490][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-06-11 00:14:32,490][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:14:32,490][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:14:32,490][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:14:32,490][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-06-11 00:14:32,490][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:14:32,490][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fc337d4e560>
[2017-06-11 00:14:32,490][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:14:32,490][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-06-11 00:14:32,490][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fc338665938>
[2017-06-11 00:14:32,490][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:14:32,490][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:14:32,490][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-06-11 00:14:32,734][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:14:32,966][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:14:32,966][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:14:32,982][gdb0][DEBUG ] detect machine type
[2017-06-11 00:14:32,986][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-11 00:14:33,166][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:14:33,166][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-06-11 00:14:33,166][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:14:33,166][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:14:33,166][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-06-11 00:14:33,166][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-06-11 00:14:33,166][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-06-11 00:14:33,166][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:14:33,166][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-06-11 00:14:33,166][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-06-11 00:14:33,167][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:14:33,167][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-06-11 00:14:33,167][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-06-11 00:14:33,167][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:14:33,167][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7efdceb02950>
[2017-06-11 00:14:33,167][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:14:33,167][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-06-11 00:14:33,167][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7efdced58aa0>
[2017-06-11 00:14:33,167][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:14:33,167][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:14:33,167][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-06-11 00:14:33,168][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-06-11 00:14:33,411][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:14:33,639][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:14:33,639][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:14:33,655][gdb0][DEBUG ] detect machine type
[2017-06-11 00:14:33,659][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:14:33,660][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 00:14:33,660][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-06-11 00:14:33,661][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-11 00:14:33,663][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-06-11 00:14:33,663][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:14:33,665][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-06-11 00:14:33,786][gdb0][WARNING] Traceback (most recent call last):
[2017-06-11 00:14:33,786][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-06-11 00:14:33,786][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-06-11 00:14:33,786][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-06-11 00:14:33,786][gdb0][WARNING]     main(sys.argv[1:])
[2017-06-11 00:14:33,786][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-06-11 00:14:33,786][gdb0][WARNING]     args.func(args)
[2017-06-11 00:14:33,786][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2029, in main
[2017-06-11 00:14:33,787][gdb0][WARNING]     Prepare.factory(args).prepare()
[2017-06-11 00:14:33,787][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2025, in factory
[2017-06-11 00:14:33,787][gdb0][WARNING]     return PrepareFilestore(args)
[2017-06-11 00:14:33,787][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2037, in __init__
[2017-06-11 00:14:33,787][gdb0][WARNING]     self.data = PrepareFilestoreData(args)
[2017-06-11 00:14:33,787][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2739, in __init__
[2017-06-11 00:14:33,787][gdb0][WARNING]     self.set_type()
[2017-06-11 00:14:33,787][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2747, in set_type
[2017-06-11 00:14:33,787][gdb0][WARNING]     dmode = os.stat(self.args.data).st_mode
[2017-06-11 00:14:33,787][gdb0][WARNING] OSError: [Errno 2] No such file or directory: '/mnt/memstore'
[2017-06-11 00:14:33,788][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-06-11 00:14:33,788][ceph_deploy.osd][ERROR ] Failed to execute command: /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-06-11 00:14:33,788][ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs

[2017-06-11 00:14:33,961][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:14:33,961][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-06-11 00:14:33,961][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:14:33,962][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:14:33,962][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:14:33,962][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:14:33,962][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-06-11 00:14:33,962][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:14:33,962][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f82706f4950>
[2017-06-11 00:14:33,962][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:14:33,962][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f827094aaa0>
[2017-06-11 00:14:33,962][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:14:33,962][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:14:33,962][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-06-11 00:14:33,963][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-06-11 00:14:34,203][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:14:34,433][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:14:34,434][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:14:34,450][gdb0][DEBUG ] detect machine type
[2017-06-11 00:14:34,454][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:14:34,455][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 00:14:34,455][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-06-11 00:14:34,455][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-06-11 00:14:34,455][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:14:34,457][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-06-11 00:14:34,577][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-06-11 00:14:34,578][gdb0][WARNING] Traceback (most recent call last):
[2017-06-11 00:14:34,578][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-06-11 00:14:34,578][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-06-11 00:14:34,578][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-06-11 00:14:34,578][gdb0][WARNING]     main(sys.argv[1:])
[2017-06-11 00:14:34,578][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-06-11 00:14:34,578][gdb0][WARNING]     args.func(args)
[2017-06-11 00:14:34,578][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3684, in main_activate
[2017-06-11 00:14:34,578][gdb0][WARNING]     raise Error('%s does not exist' % args.path)
[2017-06-11 00:14:34,578][gdb0][WARNING] ceph_disk.main.Error: Error: /mnt/memstore does not exist
[2017-06-11 00:14:34,579][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-06-11 00:14:34,579][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-06-11 00:15:11,999][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:15:11,999][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-06-11 00:15:11,999][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:15:12,000][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:15:12,000][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:15:12,000][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-06-11 00:15:12,000][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:15:12,000][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f02dd89e560>
[2017-06-11 00:15:12,000][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:15:12,000][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-06-11 00:15:12,000][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f02de1b5938>
[2017-06-11 00:15:12,000][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:15:12,000][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:15:12,000][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-06-11 00:15:12,243][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:15:12,474][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:15:12,475][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:15:12,491][gdb0][DEBUG ] detect machine type
[2017-06-11 00:15:12,495][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-11 00:15:12,667][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:15:12,668][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-06-11 00:15:12,668][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:15:12,668][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:15:12,668][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-06-11 00:15:12,668][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-06-11 00:15:12,668][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-06-11 00:15:12,668][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:15:12,668][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-06-11 00:15:12,668][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-06-11 00:15:12,668][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:15:12,668][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-06-11 00:15:12,668][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-06-11 00:15:12,668][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:15:12,668][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa670dcb950>
[2017-06-11 00:15:12,668][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:15:12,669][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-06-11 00:15:12,669][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fa671021aa0>
[2017-06-11 00:15:12,669][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:15:12,669][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:15:12,669][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-06-11 00:15:12,669][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-06-11 00:15:12,911][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:15:13,142][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:15:13,143][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:15:13,159][gdb0][DEBUG ] detect machine type
[2017-06-11 00:15:13,163][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:15:13,164][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 00:15:13,164][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-06-11 00:15:13,164][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-11 00:15:13,167][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-06-11 00:15:13,167][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:15:13,169][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-06-11 00:15:13,289][gdb0][WARNING] Traceback (most recent call last):
[2017-06-11 00:15:13,290][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-06-11 00:15:13,290][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-06-11 00:15:13,290][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-06-11 00:15:13,290][gdb0][WARNING]     main(sys.argv[1:])
[2017-06-11 00:15:13,290][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-06-11 00:15:13,290][gdb0][WARNING]     args.func(args)
[2017-06-11 00:15:13,290][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2029, in main
[2017-06-11 00:15:13,290][gdb0][WARNING]     Prepare.factory(args).prepare()
[2017-06-11 00:15:13,290][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2025, in factory
[2017-06-11 00:15:13,290][gdb0][WARNING]     return PrepareFilestore(args)
[2017-06-11 00:15:13,290][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2037, in __init__
[2017-06-11 00:15:13,291][gdb0][WARNING]     self.data = PrepareFilestoreData(args)
[2017-06-11 00:15:13,291][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2739, in __init__
[2017-06-11 00:15:13,291][gdb0][WARNING]     self.set_type()
[2017-06-11 00:15:13,291][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2747, in set_type
[2017-06-11 00:15:13,291][gdb0][WARNING]     dmode = os.stat(self.args.data).st_mode
[2017-06-11 00:15:13,291][gdb0][WARNING] OSError: [Errno 2] No such file or directory: '/mnt/memstore'
[2017-06-11 00:15:13,291][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-06-11 00:15:13,291][ceph_deploy.osd][ERROR ] Failed to execute command: /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-06-11 00:15:13,292][ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs

[2017-06-11 00:15:13,464][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:15:13,464][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-06-11 00:15:13,464][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:15:13,464][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:15:13,465][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:15:13,465][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:15:13,465][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-06-11 00:15:13,465][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:15:13,465][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f8a8a923950>
[2017-06-11 00:15:13,465][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:15:13,465][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f8a8ab79aa0>
[2017-06-11 00:15:13,465][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:15:13,465][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:15:13,465][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-06-11 00:15:13,465][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-06-11 00:15:13,711][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:15:13,942][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:15:13,943][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:15:13,959][gdb0][DEBUG ] detect machine type
[2017-06-11 00:15:13,963][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:15:13,963][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 00:15:13,964][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-06-11 00:15:13,964][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-06-11 00:15:13,964][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:15:13,966][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-06-11 00:15:14,086][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-06-11 00:15:14,087][gdb0][WARNING] Traceback (most recent call last):
[2017-06-11 00:15:14,087][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-06-11 00:15:14,087][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-06-11 00:15:14,087][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-06-11 00:15:14,087][gdb0][WARNING]     main(sys.argv[1:])
[2017-06-11 00:15:14,087][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-06-11 00:15:14,087][gdb0][WARNING]     args.func(args)
[2017-06-11 00:15:14,087][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3684, in main_activate
[2017-06-11 00:15:14,087][gdb0][WARNING]     raise Error('%s does not exist' % args.path)
[2017-06-11 00:15:14,087][gdb0][WARNING] ceph_disk.main.Error: Error: /mnt/memstore does not exist
[2017-06-11 00:15:14,089][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-06-11 00:15:14,089][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-06-11 00:15:33,532][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:15:33,532][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-06-11 00:15:33,532][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:15:33,532][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:15:33,532][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:15:33,532][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-06-11 00:15:33,532][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:15:33,532][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0a4f92d560>
[2017-06-11 00:15:33,533][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:15:33,533][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-06-11 00:15:33,533][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f0a50244938>
[2017-06-11 00:15:33,533][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:15:33,533][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:15:33,533][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-06-11 00:15:33,775][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:15:34,002][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:15:34,003][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:15:34,019][gdb0][DEBUG ] detect machine type
[2017-06-11 00:15:34,022][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-11 00:15:34,194][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:15:34,195][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-06-11 00:15:34,195][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:15:34,195][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:15:34,195][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-06-11 00:15:34,195][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-06-11 00:15:34,195][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-06-11 00:15:34,195][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:15:34,195][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-06-11 00:15:34,195][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-06-11 00:15:34,195][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:15:34,195][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-06-11 00:15:34,195][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-06-11 00:15:34,196][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:15:34,196][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f030023f950>
[2017-06-11 00:15:34,196][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:15:34,196][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-06-11 00:15:34,196][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f0300495aa0>
[2017-06-11 00:15:34,196][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:15:34,196][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:15:34,196][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-06-11 00:15:34,196][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-06-11 00:15:34,439][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:15:34,670][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:15:34,671][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:15:34,687][gdb0][DEBUG ] detect machine type
[2017-06-11 00:15:34,690][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:15:34,691][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 00:15:34,691][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-06-11 00:15:34,692][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-11 00:15:34,694][gdb0][WARNING] osd keyring does not exist yet, creating one
[2017-06-11 00:15:34,694][gdb0][DEBUG ] create a keyring file
[2017-06-11 00:15:34,696][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-06-11 00:15:34,696][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:15:34,698][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-06-11 00:15:34,818][gdb0][WARNING] Traceback (most recent call last):
[2017-06-11 00:15:34,818][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-06-11 00:15:34,818][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-06-11 00:15:34,818][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-06-11 00:15:34,819][gdb0][WARNING]     main(sys.argv[1:])
[2017-06-11 00:15:34,819][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-06-11 00:15:34,819][gdb0][WARNING]     args.func(args)
[2017-06-11 00:15:34,819][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2029, in main
[2017-06-11 00:15:34,819][gdb0][WARNING]     Prepare.factory(args).prepare()
[2017-06-11 00:15:34,819][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2025, in factory
[2017-06-11 00:15:34,819][gdb0][WARNING]     return PrepareFilestore(args)
[2017-06-11 00:15:34,819][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2037, in __init__
[2017-06-11 00:15:34,819][gdb0][WARNING]     self.data = PrepareFilestoreData(args)
[2017-06-11 00:15:34,819][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2739, in __init__
[2017-06-11 00:15:34,820][gdb0][WARNING]     self.set_type()
[2017-06-11 00:15:34,820][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2747, in set_type
[2017-06-11 00:15:34,820][gdb0][WARNING]     dmode = os.stat(self.args.data).st_mode
[2017-06-11 00:15:34,820][gdb0][WARNING] OSError: [Errno 2] No such file or directory: '/mnt/memstore'
[2017-06-11 00:15:34,820][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-06-11 00:15:34,820][ceph_deploy.osd][ERROR ] Failed to execute command: /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-06-11 00:15:34,820][ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs

[2017-06-11 00:15:34,993][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:15:34,993][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-06-11 00:15:34,993][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:15:34,993][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:15:34,993][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:15:34,993][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:15:34,993][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-06-11 00:15:34,994][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:15:34,994][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6aa5e11950>
[2017-06-11 00:15:34,994][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:15:34,994][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f6aa6067aa0>
[2017-06-11 00:15:34,994][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:15:34,994][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:15:34,994][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-06-11 00:15:34,994][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-06-11 00:15:35,239][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:15:35,462][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:15:35,463][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:15:35,479][gdb0][DEBUG ] detect machine type
[2017-06-11 00:15:35,483][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:15:35,483][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 00:15:35,484][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-06-11 00:15:35,484][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-06-11 00:15:35,484][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:15:35,486][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-06-11 00:15:35,606][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-06-11 00:15:35,606][gdb0][WARNING] Traceback (most recent call last):
[2017-06-11 00:15:35,606][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-06-11 00:15:35,606][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-06-11 00:15:35,606][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-06-11 00:15:35,606][gdb0][WARNING]     main(sys.argv[1:])
[2017-06-11 00:15:35,607][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-06-11 00:15:35,607][gdb0][WARNING]     args.func(args)
[2017-06-11 00:15:35,607][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3684, in main_activate
[2017-06-11 00:15:35,607][gdb0][WARNING]     raise Error('%s does not exist' % args.path)
[2017-06-11 00:15:35,607][gdb0][WARNING] ceph_disk.main.Error: Error: /mnt/memstore does not exist
[2017-06-11 00:15:35,607][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-06-11 00:15:35,607][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-06-11 00:16:29,599][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:16:29,599][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-06-11 00:16:29,599][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:16:29,599][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:16:29,600][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:16:29,600][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-06-11 00:16:29,600][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:16:29,600][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb9eadbd560>
[2017-06-11 00:16:29,600][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:16:29,600][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-06-11 00:16:29,600][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fb9eb6d4938>
[2017-06-11 00:16:29,600][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:16:29,600][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:16:29,600][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-06-11 00:16:29,839][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:16:30,071][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:16:30,071][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:16:30,088][gdb0][DEBUG ] detect machine type
[2017-06-11 00:16:30,092][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-11 00:16:30,265][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:16:30,265][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-06-11 00:16:30,265][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:16:30,265][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:16:30,265][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-06-11 00:16:30,265][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-06-11 00:16:30,265][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-06-11 00:16:30,265][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:16:30,266][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-06-11 00:16:30,266][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-06-11 00:16:30,266][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:16:30,266][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-06-11 00:16:30,266][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-06-11 00:16:30,266][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:16:30,266][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f68f0624950>
[2017-06-11 00:16:30,266][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:16:30,266][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-06-11 00:16:30,266][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f68f087aaa0>
[2017-06-11 00:16:30,266][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:16:30,266][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:16:30,266][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-06-11 00:16:30,267][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-06-11 00:16:30,507][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:16:30,734][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:16:30,735][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:16:30,751][gdb0][DEBUG ] detect machine type
[2017-06-11 00:16:30,755][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:16:30,756][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 00:16:30,756][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-06-11 00:16:30,756][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-11 00:16:30,758][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-06-11 00:16:30,759][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:16:30,761][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-06-11 00:16:30,881][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-06-11 00:16:30,889][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-11 00:16:30,904][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-11 00:16:30,912][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-11 00:16:30,928][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-06-11 00:16:30,943][gdb0][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-06-11 00:16:30,943][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.5726.tmp
[2017-06-11 00:16:30,944][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.5726.tmp
[2017-06-11 00:16:30,951][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.5726.tmp
[2017-06-11 00:16:35,964][gdb0][INFO  ] checking OSD status...
[2017-06-11 00:16:35,964][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:16:35,967][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-06-11 00:16:36,132][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-06-11 00:16:36,297][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:16:36,297][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-06-11 00:16:36,297][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:16:36,297][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:16:36,297][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:16:36,297][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:16:36,298][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-06-11 00:16:36,298][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:16:36,298][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fedbb592950>
[2017-06-11 00:16:36,298][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:16:36,298][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fedbb7e8aa0>
[2017-06-11 00:16:36,298][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:16:36,298][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:16:36,298][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-06-11 00:16:36,298][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-06-11 00:16:36,543][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:16:36,774][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:16:36,775][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:16:36,791][gdb0][DEBUG ] detect machine type
[2017-06-11 00:16:36,795][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:16:36,796][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 00:16:36,796][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-06-11 00:16:36,796][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-06-11 00:16:36,796][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:16:36,798][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-06-11 00:16:36,918][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-06-11 00:16:36,918][gdb0][WARNING] activate: Cluster uuid is f4f36e31-c61f-42db-97ec-96a4b3bd98b7
[2017-06-11 00:16:36,919][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-06-11 00:16:36,926][gdb0][WARNING] activate: Cluster name is ceph
[2017-06-11 00:16:36,926][gdb0][WARNING] activate: OSD uuid is db0fe94b-dc3b-488f-b03f-a33e5706669c
[2017-06-11 00:16:36,926][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-06-11 00:16:36,926][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise db0fe94b-dc3b-488f-b03f-a33e5706669c
[2017-06-11 00:16:37,091][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.5843.tmp
[2017-06-11 00:16:37,091][gdb0][WARNING] activate: OSD id is 0
[2017-06-11 00:16:37,091][gdb0][WARNING] activate: Initializing OSD...
[2017-06-11 00:16:37,091][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-06-11 00:16:37,255][gdb0][WARNING] got monmap epoch 2
[2017-06-11 00:16:37,256][gdb0][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 0 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid db0fe94b-dc3b-488f-b03f-a33e5706669c --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-06-11 00:16:37,271][gdb0][WARNING] activate: Marking with init system systemd
[2017-06-11 00:16:37,271][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-06-11 00:16:37,273][gdb0][WARNING] activate: Authorizing OSD key...
[2017-06-11 00:16:37,273][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.0 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-06-11 00:16:37,437][gdb0][WARNING] added key for osd.0
[2017-06-11 00:16:37,438][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.5843.tmp
[2017-06-11 00:16:37,438][gdb0][WARNING] activate: ceph osd.0 data dir is ready at /mnt/memstore
[2017-06-11 00:16:37,438][gdb0][WARNING] Traceback (most recent call last):
[2017-06-11 00:16:37,438][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-06-11 00:16:37,438][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-06-11 00:16:37,438][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-06-11 00:16:37,438][gdb0][WARNING]     main(sys.argv[1:])
[2017-06-11 00:16:37,438][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-06-11 00:16:37,438][gdb0][WARNING]     args.func(args)
[2017-06-11 00:16:37,438][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-06-11 00:16:37,438][gdb0][WARNING]     init=args.mark_init,
[2017-06-11 00:16:37,438][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3543, in activate_dir
[2017-06-11 00:16:37,439][gdb0][WARNING]     old = os.readlink(canonical)
[2017-06-11 00:16:37,439][gdb0][WARNING] OSError: [Errno 22] Invalid argument: '/var/lib/ceph/osd/ceph-0'
[2017-06-11 00:16:37,446][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-06-11 00:16:37,446][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-06-11 00:17:02,077][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:17:02,077][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-06-11 00:17:02,077][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:17:02,077][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:17:02,077][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:17:02,077][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-06-11 00:17:02,078][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:17:02,078][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7faa27ff3560>
[2017-06-11 00:17:02,078][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:17:02,078][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-06-11 00:17:02,078][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7faa2890a938>
[2017-06-11 00:17:02,078][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:17:02,078][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:17:02,078][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-06-11 00:17:02,319][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:17:02,551][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:17:02,552][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:17:02,568][gdb0][DEBUG ] detect machine type
[2017-06-11 00:17:02,572][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-11 00:17:02,745][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:17:02,745][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-06-11 00:17:02,745][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:17:02,745][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:17:02,745][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-06-11 00:17:02,746][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-06-11 00:17:02,746][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-06-11 00:17:02,746][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:17:02,746][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-06-11 00:17:02,746][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-06-11 00:17:02,746][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:17:02,746][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-06-11 00:17:02,746][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-06-11 00:17:02,746][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:17:02,746][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9f7325f950>
[2017-06-11 00:17:02,746][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:17:02,746][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-06-11 00:17:02,746][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f9f734b5aa0>
[2017-06-11 00:17:02,746][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:17:02,746][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:17:02,746][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-06-11 00:17:02,747][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-06-11 00:17:02,987][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:17:03,214][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:17:03,214][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:17:03,230][gdb0][DEBUG ] detect machine type
[2017-06-11 00:17:03,234][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:17:03,235][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 00:17:03,235][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-06-11 00:17:03,236][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-11 00:17:03,238][gdb0][WARNING] osd keyring does not exist yet, creating one
[2017-06-11 00:17:03,238][gdb0][DEBUG ] create a keyring file
[2017-06-11 00:17:03,240][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-06-11 00:17:03,240][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:17:03,242][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-06-11 00:17:03,363][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-06-11 00:17:03,370][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-11 00:17:03,386][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-11 00:17:03,402][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-11 00:17:03,409][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-06-11 00:17:03,425][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-06-11 00:17:08,432][gdb0][INFO  ] checking OSD status...
[2017-06-11 00:17:08,432][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:17:08,435][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-06-11 00:17:08,600][gdb0][WARNING] there is 1 OSD down
[2017-06-11 00:17:08,600][gdb0][WARNING] there is 1 OSD out
[2017-06-11 00:17:08,600][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-06-11 00:17:08,766][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:17:08,766][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-06-11 00:17:08,766][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:17:08,767][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:17:08,767][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:17:08,767][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:17:08,767][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-06-11 00:17:08,767][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:17:08,767][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f48d6cca950>
[2017-06-11 00:17:08,767][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:17:08,767][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f48d6f20aa0>
[2017-06-11 00:17:08,767][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:17:08,767][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:17:08,767][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-06-11 00:17:08,768][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-06-11 00:17:09,007][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:17:09,238][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:17:09,239][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:17:09,255][gdb0][DEBUG ] detect machine type
[2017-06-11 00:17:09,259][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:17:09,260][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 00:17:09,260][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-06-11 00:17:09,260][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-06-11 00:17:09,260][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:17:09,262][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-06-11 00:17:09,382][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-06-11 00:17:09,383][gdb0][WARNING] activate: Cluster uuid is f4f36e31-c61f-42db-97ec-96a4b3bd98b7
[2017-06-11 00:17:09,383][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-06-11 00:17:09,390][gdb0][WARNING] activate: Cluster name is ceph
[2017-06-11 00:17:09,391][gdb0][WARNING] activate: OSD uuid is db0fe94b-dc3b-488f-b03f-a33e5706669c
[2017-06-11 00:17:09,391][gdb0][WARNING] activate: OSD id is 0
[2017-06-11 00:17:09,391][gdb0][WARNING] activate: Marking with init system systemd
[2017-06-11 00:17:09,391][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-06-11 00:17:09,391][gdb0][WARNING] activate: ceph osd.0 data dir is ready at /mnt/memstore
[2017-06-11 00:17:09,392][gdb0][WARNING] Traceback (most recent call last):
[2017-06-11 00:17:09,392][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-06-11 00:17:09,392][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-06-11 00:17:09,392][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-06-11 00:17:09,392][gdb0][WARNING]     main(sys.argv[1:])
[2017-06-11 00:17:09,392][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-06-11 00:17:09,392][gdb0][WARNING]     args.func(args)
[2017-06-11 00:17:09,393][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-06-11 00:17:09,393][gdb0][WARNING]     init=args.mark_init,
[2017-06-11 00:17:09,393][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3543, in activate_dir
[2017-06-11 00:17:09,393][gdb0][WARNING]     old = os.readlink(canonical)
[2017-06-11 00:17:09,393][gdb0][WARNING] OSError: [Errno 22] Invalid argument: '/var/lib/ceph/osd/ceph-0'
[2017-06-11 00:17:09,401][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-06-11 00:17:09,401][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-06-11 00:19:30,321][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:19:30,321][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-06-11 00:19:30,321][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:19:30,322][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:19:30,322][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:19:30,322][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-06-11 00:19:30,322][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:19:30,322][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f5a94088560>
[2017-06-11 00:19:30,322][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:19:30,322][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-06-11 00:19:30,322][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f5a9499f938>
[2017-06-11 00:19:30,322][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:19:30,322][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:19:30,322][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-06-11 00:19:30,564][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:19:30,795][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:19:30,795][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:19:30,811][gdb0][DEBUG ] detect machine type
[2017-06-11 00:19:30,815][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-11 00:19:30,987][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:19:30,987][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-06-11 00:19:30,988][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:19:30,988][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:19:30,988][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-06-11 00:19:30,988][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-06-11 00:19:30,988][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-06-11 00:19:30,988][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:19:30,988][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-06-11 00:19:30,988][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-06-11 00:19:30,988][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:19:30,988][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-06-11 00:19:30,988][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-06-11 00:19:30,988][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:19:30,988][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb54454f950>
[2017-06-11 00:19:30,988][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:19:30,988][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-06-11 00:19:30,989][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fb5447a5aa0>
[2017-06-11 00:19:30,989][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:19:30,989][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:19:30,989][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-06-11 00:19:30,989][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-06-11 00:19:31,227][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:19:31,458][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:19:31,458][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:19:31,474][gdb0][DEBUG ] detect machine type
[2017-06-11 00:19:31,478][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:19:31,479][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 00:19:31,479][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-06-11 00:19:31,479][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-11 00:19:31,482][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-06-11 00:19:31,482][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:19:31,485][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-06-11 00:19:31,605][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-06-11 00:19:31,613][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-11 00:19:31,628][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-11 00:19:31,636][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-11 00:19:31,651][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-06-11 00:19:31,667][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-06-11 00:19:36,676][gdb0][INFO  ] checking OSD status...
[2017-06-11 00:19:36,676][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:19:36,679][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-06-11 00:19:36,844][gdb0][WARNING] there is 1 OSD down
[2017-06-11 00:19:36,844][gdb0][WARNING] there is 1 OSD out
[2017-06-11 00:19:36,844][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-06-11 00:19:37,009][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:19:37,010][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-06-11 00:19:37,010][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:19:37,010][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:19:37,010][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:19:37,010][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:19:37,010][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-06-11 00:19:37,010][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:19:37,010][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fd7485dd950>
[2017-06-11 00:19:37,010][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:19:37,010][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fd748833aa0>
[2017-06-11 00:19:37,011][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:19:37,011][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:19:37,011][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-06-11 00:19:37,011][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-06-11 00:19:37,255][gdb0][DEBUG ] connection detected need for sudo
[2017-06-11 00:19:37,482][gdb0][DEBUG ] connected to host: gdb0 
[2017-06-11 00:19:37,482][gdb0][DEBUG ] detect platform information from remote host
[2017-06-11 00:19:37,499][gdb0][DEBUG ] detect machine type
[2017-06-11 00:19:37,502][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:19:37,503][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 00:19:37,503][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-06-11 00:19:37,504][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-06-11 00:19:37,504][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:19:37,506][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-06-11 00:19:37,626][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-06-11 00:19:37,626][gdb0][WARNING] activate: Cluster uuid is f4f36e31-c61f-42db-97ec-96a4b3bd98b7
[2017-06-11 00:19:37,627][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-06-11 00:19:37,634][gdb0][WARNING] activate: Cluster name is ceph
[2017-06-11 00:19:37,634][gdb0][WARNING] activate: OSD uuid is db0fe94b-dc3b-488f-b03f-a33e5706669c
[2017-06-11 00:19:37,634][gdb0][WARNING] activate: OSD id is 0
[2017-06-11 00:19:37,634][gdb0][WARNING] activate: Marking with init system systemd
[2017-06-11 00:19:37,634][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-06-11 00:19:37,634][gdb0][WARNING] activate: ceph osd.0 data dir is ready at /mnt/memstore
[2017-06-11 00:19:37,634][gdb0][WARNING] activate_dir: Creating symlink /var/lib/ceph/osd/ceph-0 -> /mnt/memstore
[2017-06-11 00:19:37,635][gdb0][WARNING] start_daemon: Starting ceph osd.0...
[2017-06-11 00:19:37,635][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0
[2017-06-11 00:19:37,638][gdb0][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service.
[2017-06-11 00:19:37,702][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0 --runtime
[2017-06-11 00:19:37,766][gdb0][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@0
[2017-06-11 00:19:37,766][gdb0][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service to /lib/systemd/system/ceph-osd@.service.
[2017-06-11 00:19:37,830][gdb0][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@0
[2017-06-11 00:19:42,900][gdb0][INFO  ] checking OSD status...
[2017-06-11 00:19:42,900][gdb0][DEBUG ] find the location of an executable
[2017-06-11 00:19:42,903][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-06-11 00:19:43,070][gdb0][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-06-11 00:21:23,142][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:21:23,143][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb1
[2017-06-11 00:21:23,143][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:21:23,143][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:21:23,143][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:21:23,143][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-06-11 00:21:23,143][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:21:23,143][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f36ae470560>
[2017-06-11 00:21:23,143][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:21:23,143][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-06-11 00:21:23,143][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f36aed87938>
[2017-06-11 00:21:23,143][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:21:23,143][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:21:23,143][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-06-11 00:21:23,444][gdb1][DEBUG ] connection detected need for sudo
[2017-06-11 00:21:23,679][gdb1][DEBUG ] connected to host: gdb1 
[2017-06-11 00:21:23,679][gdb1][DEBUG ] detect platform information from remote host
[2017-06-11 00:21:23,697][gdb1][DEBUG ] detect machine type
[2017-06-11 00:21:23,700][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-11 00:21:23,871][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:21:23,871][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-06-11 00:21:23,871][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:21:23,872][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:21:23,872][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-06-11 00:21:23,872][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-06-11 00:21:23,872][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-06-11 00:21:23,872][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:21:23,872][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-06-11 00:21:23,872][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-06-11 00:21:23,872][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:21:23,872][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-06-11 00:21:23,872][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-06-11 00:21:23,872][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:21:23,872][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fabd4586950>
[2017-06-11 00:21:23,872][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:21:23,872][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-06-11 00:21:23,873][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fabd47dcaa0>
[2017-06-11 00:21:23,873][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:21:23,873][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:21:23,873][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-06-11 00:21:23,873][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-06-11 00:21:24,119][gdb1][DEBUG ] connection detected need for sudo
[2017-06-11 00:21:24,314][gdb1][DEBUG ] connected to host: gdb1 
[2017-06-11 00:21:24,314][gdb1][DEBUG ] detect platform information from remote host
[2017-06-11 00:21:24,331][gdb1][DEBUG ] detect machine type
[2017-06-11 00:21:24,335][gdb1][DEBUG ] find the location of an executable
[2017-06-11 00:21:24,335][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 00:21:24,335][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-06-11 00:21:24,336][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-11 00:21:24,339][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-06-11 00:21:24,339][gdb1][DEBUG ] find the location of an executable
[2017-06-11 00:21:24,341][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-06-11 00:21:24,511][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-06-11 00:21:24,512][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-11 00:21:24,519][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-11 00:21:24,535][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-11 00:21:24,542][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-06-11 00:21:24,558][gdb1][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-06-11 00:21:24,558][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.918.tmp
[2017-06-11 00:21:24,561][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.918.tmp
[2017-06-11 00:21:24,577][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.918.tmp
[2017-06-11 00:21:29,598][gdb1][INFO  ] checking OSD status...
[2017-06-11 00:21:29,598][gdb1][DEBUG ] find the location of an executable
[2017-06-11 00:21:29,601][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-06-11 00:21:29,917][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-06-11 00:21:30,082][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:21:30,083][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-06-11 00:21:30,083][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:21:30,083][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:21:30,083][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:21:30,083][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:21:30,083][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-06-11 00:21:30,083][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:21:30,083][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f74b7ac8950>
[2017-06-11 00:21:30,083][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:21:30,083][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f74b7d1eaa0>
[2017-06-11 00:21:30,083][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:21:30,083][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:21:30,083][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-06-11 00:21:30,084][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-06-11 00:21:30,327][gdb1][DEBUG ] connection detected need for sudo
[2017-06-11 00:21:30,554][gdb1][DEBUG ] connected to host: gdb1 
[2017-06-11 00:21:30,555][gdb1][DEBUG ] detect platform information from remote host
[2017-06-11 00:21:30,571][gdb1][DEBUG ] detect machine type
[2017-06-11 00:21:30,575][gdb1][DEBUG ] find the location of an executable
[2017-06-11 00:21:30,576][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 00:21:30,576][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-06-11 00:21:30,576][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-06-11 00:21:30,576][gdb1][DEBUG ] find the location of an executable
[2017-06-11 00:21:30,578][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-06-11 00:21:30,749][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-06-11 00:21:30,749][gdb1][WARNING] activate: Cluster uuid is f4f36e31-c61f-42db-97ec-96a4b3bd98b7
[2017-06-11 00:21:30,749][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-06-11 00:21:30,749][gdb1][WARNING] activate: Cluster name is ceph
[2017-06-11 00:21:30,749][gdb1][WARNING] activate: OSD uuid is 83154121-02fd-4e57-a1d6-f080dd469712
[2017-06-11 00:21:30,749][gdb1][WARNING] allocate_osd_id: Allocating OSD id...
[2017-06-11 00:21:30,749][gdb1][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 83154121-02fd-4e57-a1d6-f080dd469712
[2017-06-11 00:21:30,781][gdb1][WARNING] Traceback (most recent call last):
[2017-06-11 00:21:30,781][gdb1][WARNING]   File "/usr/local/bin/ceph-disk", line 9, in <module>
[2017-06-11 00:21:30,781][gdb1][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-06-11 00:21:30,781][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5653, in run
[2017-06-11 00:21:30,782][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5604, in main
[2017-06-11 00:21:30,782][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3713, in main_activate
[2017-06-11 00:21:30,782][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3533, in activate_dir
[2017-06-11 00:21:30,782][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3625, in activate
[2017-06-11 00:21:30,782][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 1075, in allocate_osd_id
[2017-06-11 00:21:30,782][gdb1][WARNING] ceph_disk.main.Error: Error: ceph osd create failed: Command '/usr/bin/ceph' returned non-zero exit status 1: 2017-06-11 00:21:30.770633 7f770c53c700  0 librados: client.bootstrap-osd authentication error (1) Operation not permitted
[2017-06-11 00:21:30,782][gdb1][WARNING] error connecting to the cluster
[2017-06-11 00:21:30,782][gdb1][WARNING] 
[2017-06-11 00:21:30,790][gdb1][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-06-11 00:21:30,790][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-06-11 00:21:58,875][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:21:58,875][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb1
[2017-06-11 00:21:58,875][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:21:58,875][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:21:58,875][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:21:58,875][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-06-11 00:21:58,876][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:21:58,876][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ff9b6787560>
[2017-06-11 00:21:58,876][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:21:58,876][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-06-11 00:21:58,876][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7ff9b709e938>
[2017-06-11 00:21:58,876][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:21:58,876][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:21:58,876][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-06-11 00:21:59,119][gdb1][DEBUG ] connection detected need for sudo
[2017-06-11 00:21:59,347][gdb1][DEBUG ] connected to host: gdb1 
[2017-06-11 00:21:59,347][gdb1][DEBUG ] detect platform information from remote host
[2017-06-11 00:21:59,363][gdb1][DEBUG ] detect machine type
[2017-06-11 00:21:59,367][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-11 00:21:59,542][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:21:59,542][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-06-11 00:21:59,542][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:21:59,542][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:21:59,542][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-06-11 00:21:59,542][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-06-11 00:21:59,542][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-06-11 00:21:59,542][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:21:59,542][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-06-11 00:21:59,542][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-06-11 00:21:59,543][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:21:59,543][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-06-11 00:21:59,543][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-06-11 00:21:59,543][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:21:59,543][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f1bdb3b9950>
[2017-06-11 00:21:59,543][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:21:59,543][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-06-11 00:21:59,543][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f1bdb60faa0>
[2017-06-11 00:21:59,543][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:21:59,543][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:21:59,543][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-06-11 00:21:59,544][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-06-11 00:21:59,787][gdb1][DEBUG ] connection detected need for sudo
[2017-06-11 00:22:00,023][gdb1][DEBUG ] connected to host: gdb1 
[2017-06-11 00:22:00,023][gdb1][DEBUG ] detect platform information from remote host
[2017-06-11 00:22:00,040][gdb1][DEBUG ] detect machine type
[2017-06-11 00:22:00,044][gdb1][DEBUG ] find the location of an executable
[2017-06-11 00:22:00,045][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 00:22:00,045][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-06-11 00:22:00,045][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-11 00:22:00,047][gdb1][WARNING] osd keyring does not exist yet, creating one
[2017-06-11 00:22:00,048][gdb1][DEBUG ] create a keyring file
[2017-06-11 00:22:00,049][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-06-11 00:22:00,049][gdb1][DEBUG ] find the location of an executable
[2017-06-11 00:22:00,051][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-06-11 00:22:00,222][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-06-11 00:22:00,222][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-11 00:22:00,222][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-11 00:22:00,222][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-11 00:22:00,226][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-06-11 00:22:00,241][gdb1][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-06-11 00:22:05,250][gdb1][INFO  ] checking OSD status...
[2017-06-11 00:22:05,250][gdb1][DEBUG ] find the location of an executable
[2017-06-11 00:22:05,253][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-06-11 00:22:05,418][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-06-11 00:22:05,583][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 00:22:05,584][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-06-11 00:22:05,584][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 00:22:05,584][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 00:22:05,584][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 00:22:05,584][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 00:22:05,584][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-06-11 00:22:05,584][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 00:22:05,584][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f2dce406950>
[2017-06-11 00:22:05,584][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 00:22:05,584][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f2dce65caa0>
[2017-06-11 00:22:05,584][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 00:22:05,584][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 00:22:05,584][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-06-11 00:22:05,585][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-06-11 00:22:05,823][gdb1][DEBUG ] connection detected need for sudo
[2017-06-11 00:22:06,051][gdb1][DEBUG ] connected to host: gdb1 
[2017-06-11 00:22:06,051][gdb1][DEBUG ] detect platform information from remote host
[2017-06-11 00:22:06,068][gdb1][DEBUG ] detect machine type
[2017-06-11 00:22:06,072][gdb1][DEBUG ] find the location of an executable
[2017-06-11 00:22:06,073][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 00:22:06,073][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-06-11 00:22:06,073][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-06-11 00:22:06,073][gdb1][DEBUG ] find the location of an executable
[2017-06-11 00:22:06,075][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-06-11 00:22:06,245][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-06-11 00:22:06,246][gdb1][WARNING] activate: Cluster uuid is f4f36e31-c61f-42db-97ec-96a4b3bd98b7
[2017-06-11 00:22:06,246][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-06-11 00:22:06,246][gdb1][WARNING] activate: Cluster name is ceph
[2017-06-11 00:22:06,246][gdb1][WARNING] activate: OSD uuid is 83154121-02fd-4e57-a1d6-f080dd469712
[2017-06-11 00:22:06,246][gdb1][WARNING] allocate_osd_id: Allocating OSD id...
[2017-06-11 00:22:06,246][gdb1][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 83154121-02fd-4e57-a1d6-f080dd469712
[2017-06-11 00:22:06,511][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.1382.tmp
[2017-06-11 00:22:06,511][gdb1][WARNING] activate: OSD id is 1
[2017-06-11 00:22:06,511][gdb1][WARNING] activate: Initializing OSD...
[2017-06-11 00:22:06,511][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-06-11 00:22:06,625][gdb1][WARNING] got monmap epoch 2
[2017-06-11 00:22:06,625][gdb1][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 1 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid 83154121-02fd-4e57-a1d6-f080dd469712 --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-06-11 00:22:06,657][gdb1][WARNING] activate: Marking with init system systemd
[2017-06-11 00:22:06,657][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-06-11 00:22:06,657][gdb1][WARNING] activate: Authorizing OSD key...
[2017-06-11 00:22:06,657][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.1 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-06-11 00:22:06,822][gdb1][WARNING] added key for osd.1
[2017-06-11 00:22:06,822][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.1382.tmp
[2017-06-11 00:22:06,822][gdb1][WARNING] activate: ceph osd.1 data dir is ready at /mnt/memstore
[2017-06-11 00:22:06,822][gdb1][WARNING] activate_dir: Creating symlink /var/lib/ceph/osd/ceph-1 -> /mnt/memstore
[2017-06-11 00:22:06,822][gdb1][WARNING] start_daemon: Starting ceph osd.1...
[2017-06-11 00:22:06,822][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@1
[2017-06-11 00:22:06,823][gdb1][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@1.service.
[2017-06-11 00:22:06,987][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@1 --runtime
[2017-06-11 00:22:07,019][gdb1][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@1
[2017-06-11 00:22:07,019][gdb1][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@1.service to /lib/systemd/system/ceph-osd@.service.
[2017-06-11 00:22:07,083][gdb1][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@1
[2017-06-11 00:22:12,152][gdb1][INFO  ] checking OSD status...
[2017-06-11 00:22:12,152][gdb1][DEBUG ] find the location of an executable
[2017-06-11 00:22:12,155][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-06-11 00:22:12,322][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-06-11 20:16:32,118][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 20:16:32,118][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-06-11 20:16:32,118][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 20:16:32,118][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 20:16:32,118][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 20:16:32,118][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 20:16:32,118][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 20:16:32,119][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f1a4165cfc8>
[2017-06-11 20:16:32,119][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 20:16:32,119][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-06-11 20:16:32,119][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f1a41f6f1b8>
[2017-06-11 20:16:32,119][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 20:16:32,119][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 20:16:32,119][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-06-11 20:16:32,119][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-06-11 20:16:32,119][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-06-11 20:16:32,119][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-06-11 20:16:32,146][gdb3][DEBUG ] connection detected need for sudo
[2017-06-11 20:16:32,160][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-11 20:16:32,161][gdb3][DEBUG ] detect platform information from remote host
[2017-06-11 20:16:32,177][gdb3][DEBUG ] detect machine type
[2017-06-11 20:16:32,180][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 20:16:32,180][gdb3][INFO  ] Purging Ceph on gdb3
[2017-06-11 20:16:32,181][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-06-11 20:16:32,219][gdb3][DEBUG ] Reading package lists...
[2017-06-11 20:16:32,383][gdb3][DEBUG ] Building dependency tree...
[2017-06-11 20:16:32,384][gdb3][DEBUG ] Reading state information...
[2017-06-11 20:16:32,448][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-06-11 20:16:32,448][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-06-11 20:16:32,448][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-06-11 20:16:32,448][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-06-11 20:16:32,448][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-06-11 20:16:32,448][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-06-11 20:16:32,449][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1016 linux-headers-4.4.0-1013-aws
[2017-06-11 20:16:32,449][gdb3][DEBUG ]   linux-headers-4.4.0-1016-aws linux-image-4.4.0-1013-aws
[2017-06-11 20:16:32,449][gdb3][DEBUG ]   linux-image-4.4.0-1016-aws ntp python-blinker python-cephfs
[2017-06-11 20:16:32,449][gdb3][DEBUG ]   python-cffi-backend python-chardet python-cryptography python-enum34
[2017-06-11 20:16:32,449][gdb3][DEBUG ]   python-flask python-idna python-ipaddress python-itsdangerous python-jinja2
[2017-06-11 20:16:32,449][gdb3][DEBUG ]   python-markupsafe python-ndg-httpsclient python-openssl python-pyasn1
[2017-06-11 20:16:32,449][gdb3][DEBUG ]   python-pyinotify python-rados python-rbd python-requests python-rgw
[2017-06-11 20:16:32,449][gdb3][DEBUG ]   python-six python-urllib3 python-werkzeug
[2017-06-11 20:16:32,450][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-06-11 20:16:32,481][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-06-11 20:16:32,482][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-06-11 20:16:32,646][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 40 not upgraded.
[2017-06-11 20:16:32,646][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-06-11 20:16:32,654][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 129562 files and directories currently installed.)
[2017-06-11 20:16:32,657][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-06-11 20:16:32,822][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-06-11 20:16:32,936][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-06-11 20:16:32,968][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-06-11 20:16:33,182][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-06-11 20:16:33,296][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-06-11 20:16:33,461][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-06-11 20:16:33,524][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-06-11 20:16:33,532][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-06-11 20:16:33,696][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-06-11 20:16:33,761][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-06-11 20:16:33,777][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-06-11 20:16:33,943][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-06-11 20:16:34,007][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-06-11 20:16:34,121][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-06-11 20:16:34,235][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-06-11 20:16:34,235][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-06-11 20:16:34,299][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu7) ...
[2017-06-11 20:16:35,166][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-06-11 20:16:35,332][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 20:16:35,332][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-06-11 20:16:35,333][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 20:16:35,333][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 20:16:35,333][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 20:16:35,333][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 20:16:35,333][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 20:16:35,333][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe142a53710>
[2017-06-11 20:16:35,333][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 20:16:35,333][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-06-11 20:16:35,333][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7fe143360230>
[2017-06-11 20:16:35,333][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 20:16:35,333][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 20:16:35,333][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-06-11 20:16:35,359][gdb3][DEBUG ] connection detected need for sudo
[2017-06-11 20:16:35,373][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-11 20:16:35,374][gdb3][DEBUG ] detect platform information from remote host
[2017-06-11 20:16:35,390][gdb3][DEBUG ] detect machine type
[2017-06-11 20:16:35,393][gdb3][DEBUG ] find the location of an executable
[2017-06-11 20:16:35,408][gdb3][DEBUG ] connection detected need for sudo
[2017-06-11 20:16:35,423][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-11 20:16:35,423][gdb3][DEBUG ] detect platform information from remote host
[2017-06-11 20:16:35,440][gdb3][DEBUG ] detect machine type
[2017-06-11 20:16:35,442][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-11 20:16:35,442][gdb3][INFO  ] purging data on gdb3
[2017-06-11 20:16:35,443][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-06-11 20:16:35,456][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-06-11 20:16:35,627][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 20:16:35,628][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-06-11 20:16:35,628][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 20:16:35,628][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 20:16:35,628][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 20:16:35,628][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 20:16:35,628][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 20:16:35,628][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fc0f7f579e0>
[2017-06-11 20:16:35,628][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 20:16:35,628][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7fc0f881a848>
[2017-06-11 20:16:35,628][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 20:16:35,628][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 20:17:04,392][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 20:17:04,392][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-06-11 20:17:04,392][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 20:17:04,392][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 20:17:04,392][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 20:17:04,392][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 20:17:04,392][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 20:17:04,392][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7feb54d2b560>
[2017-06-11 20:17:04,393][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 20:17:04,393][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-06-11 20:17:04,393][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-06-11 20:17:04,393][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7feb553af758>
[2017-06-11 20:17:04,393][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-06-11 20:17:04,393][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 20:17:04,393][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-06-11 20:17:04,393][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 20:17:04,393][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-06-11 20:17:04,393][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-06-11 20:17:04,393][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-06-11 20:17:04,420][gdb3][DEBUG ] connection detected need for sudo
[2017-06-11 20:17:04,434][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-11 20:17:04,435][gdb3][DEBUG ] detect platform information from remote host
[2017-06-11 20:17:04,451][gdb3][DEBUG ] detect machine type
[2017-06-11 20:17:04,454][gdb3][DEBUG ] find the location of an executable
[2017-06-11 20:17:04,455][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-06-11 20:17:04,466][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-06-11 20:17:04,473][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-06-11 20:17:04,473][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-06-11 20:17:04,473][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-06-11 20:17:04,473][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-06-11 20:17:04,473][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-06-11 20:17:04,473][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-06-11 20:17:04,473][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-06-11 20:17:04,474][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-06-11 20:17:04,639][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 20:17:04,640][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-06-11 20:17:04,640][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 20:17:04,640][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 20:17:04,640][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 20:17:04,640][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 20:17:04,640][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-06-11 20:17:04,640][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 20:17:04,640][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe6754a9e60>
[2017-06-11 20:17:04,640][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 20:17:04,640][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7fe67547eb18>
[2017-06-11 20:17:04,640][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 20:17:04,641][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-06-11 20:17:04,641][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 20:17:04,641][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-06-11 20:17:04,641][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-06-11 20:17:04,668][gdb3][DEBUG ] connection detected need for sudo
[2017-06-11 20:17:04,682][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-11 20:17:04,683][gdb3][DEBUG ] detect platform information from remote host
[2017-06-11 20:17:04,700][gdb3][DEBUG ] detect machine type
[2017-06-11 20:17:04,702][gdb3][DEBUG ] find the location of an executable
[2017-06-11 20:17:04,702][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-06-11 20:17:04,703][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-06-11 20:17:04,703][gdb3][DEBUG ] get remote short hostname
[2017-06-11 20:17:04,703][gdb3][DEBUG ] deploying mon to gdb3
[2017-06-11 20:17:04,703][gdb3][DEBUG ] get remote short hostname
[2017-06-11 20:17:04,703][gdb3][DEBUG ] remote hostname: gdb3
[2017-06-11 20:17:04,704][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-11 20:17:04,705][gdb3][DEBUG ] create the mon path if it does not exist
[2017-06-11 20:17:04,706][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-06-11 20:17:04,706][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-06-11 20:17:04,706][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-06-11 20:17:04,707][gdb3][DEBUG ] create the monitor keyring file
[2017-06-11 20:17:04,708][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-06-11 20:17:04,746][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-06-11 20:17:04,746][gdb3][DEBUG ] ceph-mon: set fsid to 9ccb7614-4874-4746-9634-d8f0080c96da
[2017-06-11 20:17:04,749][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-06-11 20:17:04,751][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-06-11 20:17:04,751][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-06-11 20:17:04,752][gdb3][DEBUG ] create the init path if it does not exist
[2017-06-11 20:17:04,753][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-06-11 20:17:04,824][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-06-11 20:17:04,897][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-06-11 20:17:06,935][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-06-11 20:17:07,000][gdb3][DEBUG ] ********************************************************************************
[2017-06-11 20:17:07,000][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-06-11 20:17:07,000][gdb3][DEBUG ] {
[2017-06-11 20:17:07,000][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-06-11 20:17:07,000][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-06-11 20:17:07,000][gdb3][DEBUG ]   "features": {
[2017-06-11 20:17:07,000][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-06-11 20:17:07,000][gdb3][DEBUG ]     "quorum_mon": [
[2017-06-11 20:17:07,000][gdb3][DEBUG ]       "kraken", 
[2017-06-11 20:17:07,000][gdb3][DEBUG ]       "luminous"
[2017-06-11 20:17:07,001][gdb3][DEBUG ]     ], 
[2017-06-11 20:17:07,001][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-06-11 20:17:07,001][gdb3][DEBUG ]     "required_mon": [
[2017-06-11 20:17:07,001][gdb3][DEBUG ]       "kraken", 
[2017-06-11 20:17:07,001][gdb3][DEBUG ]       "luminous"
[2017-06-11 20:17:07,001][gdb3][DEBUG ]     ]
[2017-06-11 20:17:07,001][gdb3][DEBUG ]   }, 
[2017-06-11 20:17:07,001][gdb3][DEBUG ]   "monmap": {
[2017-06-11 20:17:07,001][gdb3][DEBUG ]     "created": "2017-06-11 20:17:04.732069", 
[2017-06-11 20:17:07,001][gdb3][DEBUG ]     "epoch": 2, 
[2017-06-11 20:17:07,001][gdb3][DEBUG ]     "features": {
[2017-06-11 20:17:07,001][gdb3][DEBUG ]       "optional": [], 
[2017-06-11 20:17:07,001][gdb3][DEBUG ]       "persistent": [
[2017-06-11 20:17:07,001][gdb3][DEBUG ]         "kraken", 
[2017-06-11 20:17:07,001][gdb3][DEBUG ]         "luminous"
[2017-06-11 20:17:07,001][gdb3][DEBUG ]       ]
[2017-06-11 20:17:07,001][gdb3][DEBUG ]     }, 
[2017-06-11 20:17:07,002][gdb3][DEBUG ]     "fsid": "9ccb7614-4874-4746-9634-d8f0080c96da", 
[2017-06-11 20:17:07,002][gdb3][DEBUG ]     "modified": "2017-06-11 20:17:04.974670", 
[2017-06-11 20:17:07,002][gdb3][DEBUG ]     "mons": [
[2017-06-11 20:17:07,002][gdb3][DEBUG ]       {
[2017-06-11 20:17:07,002][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-06-11 20:17:07,002][gdb3][DEBUG ]         "name": "gdb3", 
[2017-06-11 20:17:07,002][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-06-11 20:17:07,002][gdb3][DEBUG ]         "rank": 0
[2017-06-11 20:17:07,002][gdb3][DEBUG ]       }
[2017-06-11 20:17:07,002][gdb3][DEBUG ]     ]
[2017-06-11 20:17:07,002][gdb3][DEBUG ]   }, 
[2017-06-11 20:17:07,002][gdb3][DEBUG ]   "name": "gdb3", 
[2017-06-11 20:17:07,002][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-06-11 20:17:07,002][gdb3][DEBUG ]   "quorum": [
[2017-06-11 20:17:07,002][gdb3][DEBUG ]     0
[2017-06-11 20:17:07,002][gdb3][DEBUG ]   ], 
[2017-06-11 20:17:07,002][gdb3][DEBUG ]   "rank": 0, 
[2017-06-11 20:17:07,003][gdb3][DEBUG ]   "state": "leader", 
[2017-06-11 20:17:07,003][gdb3][DEBUG ]   "sync_provider": []
[2017-06-11 20:17:07,003][gdb3][DEBUG ] }
[2017-06-11 20:17:07,003][gdb3][DEBUG ] ********************************************************************************
[2017-06-11 20:17:07,003][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-06-11 20:17:07,004][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-06-11 20:17:07,069][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-06-11 20:17:07,086][gdb3][DEBUG ] connection detected need for sudo
[2017-06-11 20:17:07,100][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-11 20:17:07,101][gdb3][DEBUG ] detect platform information from remote host
[2017-06-11 20:17:07,118][gdb3][DEBUG ] detect machine type
[2017-06-11 20:17:07,120][gdb3][DEBUG ] find the location of an executable
[2017-06-11 20:17:07,121][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-06-11 20:17:07,186][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-06-11 20:17:07,187][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-06-11 20:17:07,187][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-06-11 20:17:07,189][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpl8OhV4
[2017-06-11 20:17:07,204][gdb3][DEBUG ] connection detected need for sudo
[2017-06-11 20:17:07,218][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-11 20:17:07,219][gdb3][DEBUG ] detect platform information from remote host
[2017-06-11 20:17:07,235][gdb3][DEBUG ] detect machine type
[2017-06-11 20:17:07,237][gdb3][DEBUG ] get remote short hostname
[2017-06-11 20:17:07,238][gdb3][DEBUG ] fetch remote file
[2017-06-11 20:17:07,239][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-06-11 20:17:07,305][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-06-11 20:17:07,471][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-06-11 20:17:07,688][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-06-11 20:17:07,854][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-06-11 20:17:08,020][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-06-11 20:17:08,186][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-06-11 20:17:08,353][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-06-11 20:17:08,519][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-06-11 20:17:08,685][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-06-11 20:17:08,851][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-06-11 20:17:09,017][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-06-11 20:17:09,017][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-06-11 20:17:09,017][ceph_deploy.gatherkeys][INFO  ] Replacing 'ceph.bootstrap-mgr.keyring' and backing up old key as 'ceph.bootstrap-mgr.keyring-20170611201709'
[2017-06-11 20:17:09,018][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-06-11 20:17:09,018][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-06-11 20:17:09,018][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-06-11 20:17:09,018][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpl8OhV4
[2017-06-11 20:17:09,198][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-11 20:17:09,199][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-06-11 20:17:09,199][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-11 20:17:09,199][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-11 20:17:09,199][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-11 20:17:09,199][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-11 20:17:09,199][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-11 20:17:09,199][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f2dac57c518>
[2017-06-11 20:17:09,199][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-11 20:17:09,199][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-06-11 20:17:09,199][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f2dace93938>
[2017-06-11 20:17:09,200][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-11 20:17:09,200][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-11 20:17:09,200][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-06-11 20:17:09,226][gdb3][DEBUG ] connection detected need for sudo
[2017-06-11 20:17:09,240][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-11 20:17:09,241][gdb3][DEBUG ] detect platform information from remote host
[2017-06-11 20:17:09,257][gdb3][DEBUG ] detect machine type
[2017-06-11 20:17:09,259][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-20 20:59:57,344][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 20:59:57,346][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-06-20 20:59:57,346][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 20:59:57,346][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 20:59:57,346][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 20:59:57,346][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-20 20:59:57,346][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 20:59:57,346][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb32b9bc0e0>
[2017-06-20 20:59:57,346][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 20:59:57,346][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-06-20 20:59:57,346][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7fb32c2c91b8>
[2017-06-20 20:59:57,346][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 20:59:57,346][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 20:59:57,346][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-06-20 20:59:57,347][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-06-20 20:59:57,347][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-06-20 20:59:57,347][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-06-20 20:59:57,384][gdb3][DEBUG ] connection detected need for sudo
[2017-06-20 20:59:57,397][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-20 20:59:57,398][gdb3][DEBUG ] detect platform information from remote host
[2017-06-20 20:59:57,414][gdb3][DEBUG ] detect machine type
[2017-06-20 20:59:57,417][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-20 20:59:57,417][gdb3][INFO  ] Purging Ceph on gdb3
[2017-06-20 20:59:57,418][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-06-20 20:59:57,457][gdb3][DEBUG ] Reading package lists...
[2017-06-20 20:59:57,622][gdb3][DEBUG ] Building dependency tree...
[2017-06-20 20:59:57,622][gdb3][DEBUG ] Reading state information...
[2017-06-20 20:59:57,686][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-06-20 20:59:57,686][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-06-20 20:59:57,686][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-06-20 20:59:57,686][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-06-20 20:59:57,686][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-06-20 20:59:57,687][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-06-20 20:59:57,687][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1016 linux-aws-headers-4.4.0-1017
[2017-06-20 20:59:57,687][gdb3][DEBUG ]   linux-headers-4.4.0-1013-aws linux-headers-4.4.0-1016-aws
[2017-06-20 20:59:57,687][gdb3][DEBUG ]   linux-headers-4.4.0-1017-aws linux-image-4.4.0-1013-aws
[2017-06-20 20:59:57,687][gdb3][DEBUG ]   linux-image-4.4.0-1016-aws linux-image-4.4.0-1017-aws ntp python-blinker
[2017-06-20 20:59:57,687][gdb3][DEBUG ]   python-cephfs python-cffi-backend python-chardet python-cryptography
[2017-06-20 20:59:57,687][gdb3][DEBUG ]   python-enum34 python-flask python-idna python-ipaddress python-itsdangerous
[2017-06-20 20:59:57,687][gdb3][DEBUG ]   python-jinja2 python-markupsafe python-ndg-httpsclient python-openssl
[2017-06-20 20:59:57,688][gdb3][DEBUG ]   python-pyasn1 python-pyinotify python-rados python-rbd python-requests
[2017-06-20 20:59:57,688][gdb3][DEBUG ]   python-rgw python-six python-urllib3 python-werkzeug
[2017-06-20 20:59:57,688][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-06-20 20:59:57,704][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-06-20 20:59:57,704][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-06-20 20:59:57,818][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 45 not upgraded.
[2017-06-20 20:59:57,818][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-06-20 20:59:57,882][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 154602 files and directories currently installed.)
[2017-06-20 20:59:57,884][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-06-20 20:59:58,049][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-06-20 20:59:58,163][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-06-20 20:59:58,195][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-06-20 20:59:58,460][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-06-20 20:59:58,526][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-06-20 20:59:58,691][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-06-20 20:59:58,755][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-06-20 20:59:58,787][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-06-20 20:59:58,953][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-06-20 20:59:59,017][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-06-20 20:59:59,049][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-06-20 20:59:59,214][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-06-20 20:59:59,214][gdb3][DEBUG ] dpkg: warning: while removing ceph-base, directory '/var/lib/ceph/tmp' not empty so not removed
[2017-06-20 20:59:59,222][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-06-20 20:59:59,386][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-06-20 20:59:59,452][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-06-20 20:59:59,452][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-06-20 20:59:59,566][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu9) ...
[2017-06-20 21:00:00,382][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-06-20 21:00:00,548][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 21:00:00,549][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-06-20 21:00:00,549][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 21:00:00,549][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 21:00:00,549][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 21:00:00,549][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-20 21:00:00,549][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 21:00:00,549][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f5efc468758>
[2017-06-20 21:00:00,549][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 21:00:00,549][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-06-20 21:00:00,549][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f5efcd75230>
[2017-06-20 21:00:00,549][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 21:00:00,549][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 21:00:00,549][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-06-20 21:00:00,576][gdb3][DEBUG ] connection detected need for sudo
[2017-06-20 21:00:00,590][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-20 21:00:00,590][gdb3][DEBUG ] detect platform information from remote host
[2017-06-20 21:00:00,607][gdb3][DEBUG ] detect machine type
[2017-06-20 21:00:00,609][gdb3][DEBUG ] find the location of an executable
[2017-06-20 21:00:00,625][gdb3][DEBUG ] connection detected need for sudo
[2017-06-20 21:00:00,640][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-20 21:00:00,640][gdb3][DEBUG ] detect platform information from remote host
[2017-06-20 21:00:00,657][gdb3][DEBUG ] detect machine type
[2017-06-20 21:00:00,660][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-20 21:00:00,660][gdb3][INFO  ] purging data on gdb3
[2017-06-20 21:00:00,661][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-06-20 21:00:00,674][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-06-20 21:00:00,845][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 21:00:00,845][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-06-20 21:00:00,846][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 21:00:00,846][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 21:00:00,846][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 21:00:00,846][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-20 21:00:00,846][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 21:00:00,846][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3571901a28>
[2017-06-20 21:00:00,846][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 21:00:00,846][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7f35721c4848>
[2017-06-20 21:00:00,846][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 21:00:00,846][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 21:00:19,908][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 21:00:19,908][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-06-20 21:00:19,908][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 21:00:19,908][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 21:00:19,908][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 21:00:19,908][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-20 21:00:19,908][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 21:00:19,908][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fd4178735a8>
[2017-06-20 21:00:19,909][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 21:00:19,909][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-06-20 21:00:19,909][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-06-20 21:00:19,909][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7fd417ef7758>
[2017-06-20 21:00:19,909][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-06-20 21:00:19,909][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 21:00:19,909][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-06-20 21:00:19,909][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 21:00:19,909][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-06-20 21:00:19,909][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-06-20 21:00:19,909][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-06-20 21:00:19,935][gdb3][DEBUG ] connection detected need for sudo
[2017-06-20 21:00:19,949][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-20 21:00:19,950][gdb3][DEBUG ] detect platform information from remote host
[2017-06-20 21:00:19,966][gdb3][DEBUG ] detect machine type
[2017-06-20 21:00:19,969][gdb3][DEBUG ] find the location of an executable
[2017-06-20 21:00:19,970][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-06-20 21:00:19,981][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-06-20 21:00:19,987][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-06-20 21:00:19,987][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-06-20 21:00:19,987][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-06-20 21:00:19,987][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-06-20 21:00:19,987][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-06-20 21:00:19,987][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-06-20 21:00:19,988][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-06-20 21:00:19,988][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-06-20 21:00:20,155][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 21:00:20,155][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-06-20 21:00:20,155][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 21:00:20,155][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 21:00:20,155][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 21:00:20,155][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-20 21:00:20,155][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-06-20 21:00:20,155][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 21:00:20,155][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fcf22250ea8>
[2017-06-20 21:00:20,155][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 21:00:20,156][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7fcf22224b18>
[2017-06-20 21:00:20,156][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 21:00:20,156][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-06-20 21:00:20,156][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 21:00:20,156][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-06-20 21:00:20,156][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-06-20 21:00:20,182][gdb3][DEBUG ] connection detected need for sudo
[2017-06-20 21:00:20,196][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-20 21:00:20,197][gdb3][DEBUG ] detect platform information from remote host
[2017-06-20 21:00:20,213][gdb3][DEBUG ] detect machine type
[2017-06-20 21:00:20,215][gdb3][DEBUG ] find the location of an executable
[2017-06-20 21:00:20,216][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-06-20 21:00:20,216][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-06-20 21:00:20,216][gdb3][DEBUG ] get remote short hostname
[2017-06-20 21:00:20,216][gdb3][DEBUG ] deploying mon to gdb3
[2017-06-20 21:00:20,216][gdb3][DEBUG ] get remote short hostname
[2017-06-20 21:00:20,217][gdb3][DEBUG ] remote hostname: gdb3
[2017-06-20 21:00:20,217][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-20 21:00:20,219][gdb3][DEBUG ] create the mon path if it does not exist
[2017-06-20 21:00:20,219][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-06-20 21:00:20,219][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-06-20 21:00:20,220][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-06-20 21:00:20,220][gdb3][DEBUG ] create the monitor keyring file
[2017-06-20 21:00:20,221][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-06-20 21:00:20,259][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-06-20 21:00:20,259][gdb3][DEBUG ] ceph-mon: set fsid to 9e56305c-0f98-46a9-9f1a-45e2c1ff15da
[2017-06-20 21:00:20,262][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-06-20 21:00:20,266][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-06-20 21:00:20,266][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-06-20 21:00:20,267][gdb3][DEBUG ] create the init path if it does not exist
[2017-06-20 21:00:20,268][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-06-20 21:00:20,335][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-06-20 21:00:20,403][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-06-20 21:00:22,442][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-06-20 21:00:22,507][gdb3][DEBUG ] ********************************************************************************
[2017-06-20 21:00:22,508][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-06-20 21:00:22,508][gdb3][DEBUG ] {
[2017-06-20 21:00:22,508][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-06-20 21:00:22,508][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-06-20 21:00:22,508][gdb3][DEBUG ]   "features": {
[2017-06-20 21:00:22,508][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-06-20 21:00:22,508][gdb3][DEBUG ]     "quorum_mon": [
[2017-06-20 21:00:22,508][gdb3][DEBUG ]       "kraken", 
[2017-06-20 21:00:22,508][gdb3][DEBUG ]       "luminous"
[2017-06-20 21:00:22,508][gdb3][DEBUG ]     ], 
[2017-06-20 21:00:22,508][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-06-20 21:00:22,508][gdb3][DEBUG ]     "required_mon": [
[2017-06-20 21:00:22,508][gdb3][DEBUG ]       "kraken", 
[2017-06-20 21:00:22,509][gdb3][DEBUG ]       "luminous"
[2017-06-20 21:00:22,509][gdb3][DEBUG ]     ]
[2017-06-20 21:00:22,509][gdb3][DEBUG ]   }, 
[2017-06-20 21:00:22,509][gdb3][DEBUG ]   "monmap": {
[2017-06-20 21:00:22,509][gdb3][DEBUG ]     "created": "2017-06-20 21:00:20.243794", 
[2017-06-20 21:00:22,509][gdb3][DEBUG ]     "epoch": 2, 
[2017-06-20 21:00:22,509][gdb3][DEBUG ]     "features": {
[2017-06-20 21:00:22,509][gdb3][DEBUG ]       "optional": [], 
[2017-06-20 21:00:22,509][gdb3][DEBUG ]       "persistent": [
[2017-06-20 21:00:22,509][gdb3][DEBUG ]         "kraken", 
[2017-06-20 21:00:22,509][gdb3][DEBUG ]         "luminous"
[2017-06-20 21:00:22,509][gdb3][DEBUG ]       ]
[2017-06-20 21:00:22,509][gdb3][DEBUG ]     }, 
[2017-06-20 21:00:22,509][gdb3][DEBUG ]     "fsid": "9e56305c-0f98-46a9-9f1a-45e2c1ff15da", 
[2017-06-20 21:00:22,509][gdb3][DEBUG ]     "modified": "2017-06-20 21:00:20.484930", 
[2017-06-20 21:00:22,509][gdb3][DEBUG ]     "mons": [
[2017-06-20 21:00:22,509][gdb3][DEBUG ]       {
[2017-06-20 21:00:22,510][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-06-20 21:00:22,510][gdb3][DEBUG ]         "name": "gdb3", 
[2017-06-20 21:00:22,510][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-06-20 21:00:22,510][gdb3][DEBUG ]         "rank": 0
[2017-06-20 21:00:22,510][gdb3][DEBUG ]       }
[2017-06-20 21:00:22,510][gdb3][DEBUG ]     ]
[2017-06-20 21:00:22,510][gdb3][DEBUG ]   }, 
[2017-06-20 21:00:22,510][gdb3][DEBUG ]   "name": "gdb3", 
[2017-06-20 21:00:22,510][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-06-20 21:00:22,510][gdb3][DEBUG ]   "quorum": [
[2017-06-20 21:00:22,510][gdb3][DEBUG ]     0
[2017-06-20 21:00:22,510][gdb3][DEBUG ]   ], 
[2017-06-20 21:00:22,510][gdb3][DEBUG ]   "rank": 0, 
[2017-06-20 21:00:22,510][gdb3][DEBUG ]   "state": "leader", 
[2017-06-20 21:00:22,510][gdb3][DEBUG ]   "sync_provider": []
[2017-06-20 21:00:22,510][gdb3][DEBUG ] }
[2017-06-20 21:00:22,510][gdb3][DEBUG ] ********************************************************************************
[2017-06-20 21:00:22,511][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-06-20 21:00:22,511][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-06-20 21:00:22,576][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-06-20 21:00:22,591][gdb3][DEBUG ] connection detected need for sudo
[2017-06-20 21:00:22,606][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-20 21:00:22,607][gdb3][DEBUG ] detect platform information from remote host
[2017-06-20 21:00:22,623][gdb3][DEBUG ] detect machine type
[2017-06-20 21:00:22,626][gdb3][DEBUG ] find the location of an executable
[2017-06-20 21:00:22,627][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-06-20 21:00:22,692][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-06-20 21:00:22,692][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-06-20 21:00:22,692][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-06-20 21:00:22,694][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpF7VL0x
[2017-06-20 21:00:22,709][gdb3][DEBUG ] connection detected need for sudo
[2017-06-20 21:00:22,723][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-20 21:00:22,723][gdb3][DEBUG ] detect platform information from remote host
[2017-06-20 21:00:22,740][gdb3][DEBUG ] detect machine type
[2017-06-20 21:00:22,742][gdb3][DEBUG ] get remote short hostname
[2017-06-20 21:00:22,742][gdb3][DEBUG ] fetch remote file
[2017-06-20 21:00:22,743][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-06-20 21:00:22,809][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-06-20 21:00:22,975][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-06-20 21:00:23,142][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-06-20 21:00:23,308][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-06-20 21:00:23,524][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-06-20 21:00:23,690][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-06-20 21:00:23,856][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-06-20 21:00:24,023][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-06-20 21:00:24,189][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-06-20 21:00:24,355][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-06-20 21:00:24,520][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-06-20 21:00:24,521][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-06-20 21:00:24,521][ceph_deploy.gatherkeys][INFO  ] Replacing 'ceph.bootstrap-mgr.keyring' and backing up old key as 'ceph.bootstrap-mgr.keyring-20170620210024'
[2017-06-20 21:00:24,522][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-06-20 21:00:24,522][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-06-20 21:00:24,522][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-06-20 21:00:24,522][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpF7VL0x
[2017-06-20 21:00:24,707][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 21:00:24,707][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-06-20 21:00:24,707][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 21:00:24,707][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 21:00:24,708][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 21:00:24,708][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-20 21:00:24,708][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 21:00:24,708][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f98bb559560>
[2017-06-20 21:00:24,708][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 21:00:24,708][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-06-20 21:00:24,708][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f98bbe70938>
[2017-06-20 21:00:24,708][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 21:00:24,708][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 21:00:24,708][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-06-20 21:00:24,734][gdb3][DEBUG ] connection detected need for sudo
[2017-06-20 21:00:24,748][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-20 21:00:24,749][gdb3][DEBUG ] detect platform information from remote host
[2017-06-20 21:00:24,765][gdb3][DEBUG ] detect machine type
[2017-06-20 21:00:24,767][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-20 22:02:12,586][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 22:02:12,587][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-06-20 22:02:12,587][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 22:02:12,587][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 22:02:12,587][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 22:02:12,587][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-06-20 22:02:12,587][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 22:02:12,587][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f8cecb93560>
[2017-06-20 22:02:12,587][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 22:02:12,587][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-06-20 22:02:12,587][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f8ced4aa938>
[2017-06-20 22:02:12,587][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 22:02:12,587][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 22:02:12,588][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-06-20 22:02:15,613][ceph_deploy.admin][ERROR ] connecting to host: gdb0 resulted in errors: HostNotFound gdb0
[2017-06-20 22:02:15,613][ceph_deploy][ERROR ] GenericError: Failed to configure 1 admin hosts

[2017-06-20 22:02:15,783][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 22:02:15,783][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-06-20 22:02:15,783][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 22:02:15,783][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 22:02:15,783][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-06-20 22:02:15,783][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-06-20 22:02:15,783][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-06-20 22:02:15,783][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 22:02:15,784][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-06-20 22:02:15,784][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-06-20 22:02:15,784][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-20 22:02:15,784][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-06-20 22:02:15,784][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-06-20 22:02:15,784][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 22:02:15,784][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3b287d7950>
[2017-06-20 22:02:15,784][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 22:02:15,784][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-06-20 22:02:15,784][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f3b28a2daa0>
[2017-06-20 22:02:15,784][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 22:02:15,784][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 22:02:15,784][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-06-20 22:02:15,785][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-06-20 22:02:18,613][ceph_deploy.osd][ERROR ] connecting to host: gdb0 resulted in errors: HostNotFound gdb0
[2017-06-20 22:02:18,614][ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs

[2017-06-20 22:02:18,779][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 22:02:18,779][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-06-20 22:02:18,779][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 22:02:18,779][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 22:02:18,779][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 22:02:18,780][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-20 22:02:18,780][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-06-20 22:02:18,780][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 22:02:18,780][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f469f50c950>
[2017-06-20 22:02:18,780][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 22:02:18,780][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f469f762aa0>
[2017-06-20 22:02:18,780][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 22:02:18,780][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 22:02:18,780][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-06-20 22:02:18,780][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-06-20 22:02:21,613][ceph_deploy][ERROR ] RuntimeError: connecting to host: gdb0 resulted in errors: HostNotFound gdb0

[2017-06-20 22:04:14,299][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 22:04:14,299][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb1
[2017-06-20 22:04:14,299][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 22:04:14,299][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 22:04:14,299][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 22:04:14,299][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-06-20 22:04:14,299][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 22:04:14,299][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f08e1132560>
[2017-06-20 22:04:14,299][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 22:04:14,300][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-06-20 22:04:14,300][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f08e1a49938>
[2017-06-20 22:04:14,300][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 22:04:14,300][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 22:04:14,300][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-06-20 22:04:14,652][gdb1][DEBUG ] connection detected need for sudo
[2017-06-20 22:04:14,879][gdb1][DEBUG ] connected to host: gdb1 
[2017-06-20 22:04:14,880][gdb1][DEBUG ] detect platform information from remote host
[2017-06-20 22:04:14,919][gdb1][DEBUG ] detect machine type
[2017-06-20 22:04:14,923][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-20 22:04:15,097][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 22:04:15,097][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-06-20 22:04:15,097][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 22:04:15,097][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 22:04:15,097][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-06-20 22:04:15,097][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-06-20 22:04:15,097][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-06-20 22:04:15,097][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 22:04:15,097][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-06-20 22:04:15,097][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-06-20 22:04:15,098][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-20 22:04:15,098][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-06-20 22:04:15,098][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-06-20 22:04:15,098][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 22:04:15,098][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ff8b9b57950>
[2017-06-20 22:04:15,098][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 22:04:15,098][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-06-20 22:04:15,098][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7ff8b9dadaa0>
[2017-06-20 22:04:15,098][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 22:04:15,098][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 22:04:15,098][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-06-20 22:04:15,098][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-06-20 22:04:15,345][gdb1][DEBUG ] connection detected need for sudo
[2017-06-20 22:04:15,572][gdb1][DEBUG ] connected to host: gdb1 
[2017-06-20 22:04:15,573][gdb1][DEBUG ] detect platform information from remote host
[2017-06-20 22:04:15,589][gdb1][DEBUG ] detect machine type
[2017-06-20 22:04:15,593][gdb1][DEBUG ] find the location of an executable
[2017-06-20 22:04:15,594][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-20 22:04:15,594][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-06-20 22:04:15,595][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-20 22:04:15,600][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-06-20 22:04:15,600][gdb1][DEBUG ] find the location of an executable
[2017-06-20 22:04:15,602][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-06-20 22:04:15,873][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-06-20 22:04:16,038][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-20 22:04:16,045][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-20 22:04:16,061][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-20 22:04:16,069][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-06-20 22:04:16,084][gdb1][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-06-20 22:04:21,097][gdb1][INFO  ] checking OSD status...
[2017-06-20 22:04:21,097][gdb1][DEBUG ] find the location of an executable
[2017-06-20 22:04:21,100][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-06-20 22:04:21,416][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-06-20 22:04:21,581][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 22:04:21,581][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-06-20 22:04:21,581][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 22:04:21,581][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 22:04:21,581][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 22:04:21,581][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-20 22:04:21,581][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-06-20 22:04:21,581][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 22:04:21,581][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f121a2d1950>
[2017-06-20 22:04:21,581][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 22:04:21,582][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f121a527aa0>
[2017-06-20 22:04:21,582][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 22:04:21,582][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 22:04:21,582][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-06-20 22:04:21,582][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-06-20 22:04:21,820][gdb1][DEBUG ] connection detected need for sudo
[2017-06-20 22:04:22,052][gdb1][DEBUG ] connected to host: gdb1 
[2017-06-20 22:04:22,052][gdb1][DEBUG ] detect platform information from remote host
[2017-06-20 22:04:22,069][gdb1][DEBUG ] detect machine type
[2017-06-20 22:04:22,073][gdb1][DEBUG ] find the location of an executable
[2017-06-20 22:04:22,074][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-20 22:04:22,074][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-06-20 22:04:22,074][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-06-20 22:04:22,074][gdb1][DEBUG ] find the location of an executable
[2017-06-20 22:04:22,077][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-06-20 22:04:22,197][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-06-20 22:04:22,198][gdb1][WARNING] activate: Cluster uuid is f4f36e31-c61f-42db-97ec-96a4b3bd98b7
[2017-06-20 22:04:22,198][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-06-20 22:04:22,214][gdb1][WARNING] Traceback (most recent call last):
[2017-06-20 22:04:22,214][gdb1][WARNING]   File "/usr/local/bin/ceph-disk", line 9, in <module>
[2017-06-20 22:04:22,214][gdb1][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-06-20 22:04:22,215][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5653, in run
[2017-06-20 22:04:22,215][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5604, in main
[2017-06-20 22:04:22,215][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3713, in main_activate
[2017-06-20 22:04:22,215][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3533, in activate_dir
[2017-06-20 22:04:22,215][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3609, in activate
[2017-06-20 22:04:22,215][gdb1][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid f4f36e31-c61f-42db-97ec-96a4b3bd98b7
[2017-06-20 22:04:22,219][gdb1][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-06-20 22:04:22,219][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-06-20 22:28:29,290][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 22:28:29,290][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-06-20 22:28:29,291][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 22:28:29,291][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 22:28:29,291][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 22:28:29,291][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-20 22:28:29,291][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 22:28:29,291][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9c49f540e0>
[2017-06-20 22:28:29,291][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 22:28:29,291][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-06-20 22:28:29,291][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f9c4a8611b8>
[2017-06-20 22:28:29,291][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 22:28:29,291][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 22:28:29,291][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-06-20 22:28:29,291][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-06-20 22:28:29,291][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-06-20 22:28:29,291][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-06-20 22:28:29,317][gdb3][DEBUG ] connection detected need for sudo
[2017-06-20 22:28:29,331][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-20 22:28:29,331][gdb3][DEBUG ] detect platform information from remote host
[2017-06-20 22:28:29,347][gdb3][DEBUG ] detect machine type
[2017-06-20 22:28:29,350][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-20 22:28:29,350][gdb3][INFO  ] Purging Ceph on gdb3
[2017-06-20 22:28:29,351][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-06-20 22:28:29,389][gdb3][DEBUG ] Reading package lists...
[2017-06-20 22:28:29,553][gdb3][DEBUG ] Building dependency tree...
[2017-06-20 22:28:29,554][gdb3][DEBUG ] Reading state information...
[2017-06-20 22:28:29,618][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-06-20 22:28:29,618][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-06-20 22:28:29,618][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-06-20 22:28:29,618][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-06-20 22:28:29,618][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-06-20 22:28:29,619][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-06-20 22:28:29,619][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1016 linux-aws-headers-4.4.0-1017
[2017-06-20 22:28:29,619][gdb3][DEBUG ]   linux-headers-4.4.0-1013-aws linux-headers-4.4.0-1016-aws
[2017-06-20 22:28:29,619][gdb3][DEBUG ]   linux-headers-4.4.0-1017-aws linux-image-4.4.0-1013-aws
[2017-06-20 22:28:29,619][gdb3][DEBUG ]   linux-image-4.4.0-1016-aws linux-image-4.4.0-1017-aws ntp python-blinker
[2017-06-20 22:28:29,619][gdb3][DEBUG ]   python-cephfs python-cffi-backend python-chardet python-cryptography
[2017-06-20 22:28:29,619][gdb3][DEBUG ]   python-enum34 python-flask python-idna python-ipaddress python-itsdangerous
[2017-06-20 22:28:29,620][gdb3][DEBUG ]   python-jinja2 python-markupsafe python-ndg-httpsclient python-openssl
[2017-06-20 22:28:29,620][gdb3][DEBUG ]   python-pyasn1 python-pyinotify python-rados python-rbd python-requests
[2017-06-20 22:28:29,620][gdb3][DEBUG ]   python-rgw python-six python-urllib3 python-werkzeug
[2017-06-20 22:28:29,620][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-06-20 22:28:29,652][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-06-20 22:28:29,652][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-06-20 22:28:29,766][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 45 not upgraded.
[2017-06-20 22:28:29,766][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-06-20 22:28:29,830][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 154602 files and directories currently installed.)
[2017-06-20 22:28:29,831][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-06-20 22:28:29,995][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-06-20 22:28:30,109][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-06-20 22:28:30,141][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-06-20 22:28:30,405][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-06-20 22:28:30,470][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-06-20 22:28:30,637][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-06-20 22:28:30,701][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-06-20 22:28:30,733][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-06-20 22:28:30,899][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-06-20 22:28:30,963][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-06-20 22:28:30,995][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-06-20 22:28:31,166][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-06-20 22:28:31,182][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-06-20 22:28:31,346][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-06-20 22:28:31,412][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-06-20 22:28:31,420][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-06-20 22:28:31,534][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu9) ...
[2017-06-20 22:28:32,350][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-06-20 22:28:32,516][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 22:28:32,516][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-06-20 22:28:32,517][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 22:28:32,517][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 22:28:32,517][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 22:28:32,517][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-20 22:28:32,517][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 22:28:32,517][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f2c64f48758>
[2017-06-20 22:28:32,517][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 22:28:32,517][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-06-20 22:28:32,517][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f2c65855230>
[2017-06-20 22:28:32,517][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 22:28:32,517][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 22:28:32,517][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-06-20 22:28:32,543][gdb3][DEBUG ] connection detected need for sudo
[2017-06-20 22:28:32,557][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-20 22:28:32,558][gdb3][DEBUG ] detect platform information from remote host
[2017-06-20 22:28:32,575][gdb3][DEBUG ] detect machine type
[2017-06-20 22:28:32,577][gdb3][DEBUG ] find the location of an executable
[2017-06-20 22:28:32,593][gdb3][DEBUG ] connection detected need for sudo
[2017-06-20 22:28:32,608][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-20 22:28:32,608][gdb3][DEBUG ] detect platform information from remote host
[2017-06-20 22:28:32,625][gdb3][DEBUG ] detect machine type
[2017-06-20 22:28:32,628][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-20 22:28:32,628][gdb3][INFO  ] purging data on gdb3
[2017-06-20 22:28:32,629][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-06-20 22:28:32,642][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-06-20 22:28:32,813][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 22:28:32,813][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-06-20 22:28:32,813][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 22:28:32,813][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 22:28:32,814][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 22:28:32,814][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-20 22:28:32,814][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 22:28:32,814][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f780739fa28>
[2017-06-20 22:28:32,814][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 22:28:32,814][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7f7807c62848>
[2017-06-20 22:28:32,814][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 22:28:32,814][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 22:28:50,628][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 22:28:50,628][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-06-20 22:28:50,628][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 22:28:50,629][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 22:28:50,629][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 22:28:50,629][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-20 22:28:50,629][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 22:28:50,629][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fabc84ed5a8>
[2017-06-20 22:28:50,629][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 22:28:50,629][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-06-20 22:28:50,629][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-06-20 22:28:50,629][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7fabc8b71758>
[2017-06-20 22:28:50,629][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-06-20 22:28:50,629][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 22:28:50,629][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-06-20 22:28:50,629][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 22:28:50,629][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-06-20 22:28:50,630][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-06-20 22:28:50,630][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-06-20 22:28:50,656][gdb3][DEBUG ] connection detected need for sudo
[2017-06-20 22:28:50,670][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-20 22:28:50,670][gdb3][DEBUG ] detect platform information from remote host
[2017-06-20 22:28:50,687][gdb3][DEBUG ] detect machine type
[2017-06-20 22:28:50,689][gdb3][DEBUG ] find the location of an executable
[2017-06-20 22:28:50,690][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-06-20 22:28:50,701][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-06-20 22:28:50,708][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-06-20 22:28:50,708][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-06-20 22:28:50,708][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-06-20 22:28:50,708][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-06-20 22:28:50,708][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-06-20 22:28:50,708][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-06-20 22:28:50,708][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-06-20 22:28:50,709][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-06-20 22:28:50,875][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 22:28:50,875][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-06-20 22:28:50,875][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 22:28:50,875][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 22:28:50,875][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 22:28:50,876][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-20 22:28:50,876][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-06-20 22:28:50,876][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 22:28:50,876][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f96c553bea8>
[2017-06-20 22:28:50,876][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 22:28:50,876][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f96c550fb18>
[2017-06-20 22:28:50,876][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 22:28:50,876][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-06-20 22:28:50,876][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 22:28:50,877][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-06-20 22:28:50,877][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-06-20 22:28:50,903][gdb3][DEBUG ] connection detected need for sudo
[2017-06-20 22:28:50,918][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-20 22:28:50,918][gdb3][DEBUG ] detect platform information from remote host
[2017-06-20 22:28:50,935][gdb3][DEBUG ] detect machine type
[2017-06-20 22:28:50,937][gdb3][DEBUG ] find the location of an executable
[2017-06-20 22:28:50,938][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-06-20 22:28:50,938][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-06-20 22:28:50,938][gdb3][DEBUG ] get remote short hostname
[2017-06-20 22:28:50,938][gdb3][DEBUG ] deploying mon to gdb3
[2017-06-20 22:28:50,938][gdb3][DEBUG ] get remote short hostname
[2017-06-20 22:28:50,939][gdb3][DEBUG ] remote hostname: gdb3
[2017-06-20 22:28:50,939][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-20 22:28:50,941][gdb3][DEBUG ] create the mon path if it does not exist
[2017-06-20 22:28:50,941][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-06-20 22:28:50,941][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-06-20 22:28:50,942][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-06-20 22:28:50,942][gdb3][DEBUG ] create the monitor keyring file
[2017-06-20 22:28:50,943][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-06-20 22:28:50,981][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-06-20 22:28:50,981][gdb3][DEBUG ] ceph-mon: set fsid to 382eeac0-7e10-4bdc-98d7-53d22201d56d
[2017-06-20 22:28:50,985][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-06-20 22:28:50,988][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-06-20 22:28:50,989][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-06-20 22:28:50,989][gdb3][DEBUG ] create the init path if it does not exist
[2017-06-20 22:28:50,990][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-06-20 22:28:51,058][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-06-20 22:28:51,125][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-06-20 22:28:53,196][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-06-20 22:28:53,261][gdb3][DEBUG ] ********************************************************************************
[2017-06-20 22:28:53,265][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-06-20 22:28:53,265][gdb3][DEBUG ] {
[2017-06-20 22:28:53,265][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-06-20 22:28:53,265][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-06-20 22:28:53,265][gdb3][DEBUG ]   "features": {
[2017-06-20 22:28:53,265][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-06-20 22:28:53,265][gdb3][DEBUG ]     "quorum_mon": [
[2017-06-20 22:28:53,265][gdb3][DEBUG ]       "kraken", 
[2017-06-20 22:28:53,265][gdb3][DEBUG ]       "luminous"
[2017-06-20 22:28:53,265][gdb3][DEBUG ]     ], 
[2017-06-20 22:28:53,266][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-06-20 22:28:53,266][gdb3][DEBUG ]     "required_mon": [
[2017-06-20 22:28:53,266][gdb3][DEBUG ]       "kraken", 
[2017-06-20 22:28:53,266][gdb3][DEBUG ]       "luminous"
[2017-06-20 22:28:53,266][gdb3][DEBUG ]     ]
[2017-06-20 22:28:53,266][gdb3][DEBUG ]   }, 
[2017-06-20 22:28:53,266][gdb3][DEBUG ]   "monmap": {
[2017-06-20 22:28:53,266][gdb3][DEBUG ]     "created": "2017-06-20 22:28:50.966279", 
[2017-06-20 22:28:53,266][gdb3][DEBUG ]     "epoch": 2, 
[2017-06-20 22:28:53,266][gdb3][DEBUG ]     "features": {
[2017-06-20 22:28:53,266][gdb3][DEBUG ]       "optional": [], 
[2017-06-20 22:28:53,266][gdb3][DEBUG ]       "persistent": [
[2017-06-20 22:28:53,266][gdb3][DEBUG ]         "kraken", 
[2017-06-20 22:28:53,266][gdb3][DEBUG ]         "luminous"
[2017-06-20 22:28:53,266][gdb3][DEBUG ]       ]
[2017-06-20 22:28:53,266][gdb3][DEBUG ]     }, 
[2017-06-20 22:28:53,266][gdb3][DEBUG ]     "fsid": "382eeac0-7e10-4bdc-98d7-53d22201d56d", 
[2017-06-20 22:28:53,267][gdb3][DEBUG ]     "modified": "2017-06-20 22:28:51.215704", 
[2017-06-20 22:28:53,267][gdb3][DEBUG ]     "mons": [
[2017-06-20 22:28:53,267][gdb3][DEBUG ]       {
[2017-06-20 22:28:53,267][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-06-20 22:28:53,267][gdb3][DEBUG ]         "name": "gdb3", 
[2017-06-20 22:28:53,267][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-06-20 22:28:53,267][gdb3][DEBUG ]         "rank": 0
[2017-06-20 22:28:53,267][gdb3][DEBUG ]       }
[2017-06-20 22:28:53,267][gdb3][DEBUG ]     ]
[2017-06-20 22:28:53,267][gdb3][DEBUG ]   }, 
[2017-06-20 22:28:53,267][gdb3][DEBUG ]   "name": "gdb3", 
[2017-06-20 22:28:53,267][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-06-20 22:28:53,267][gdb3][DEBUG ]   "quorum": [
[2017-06-20 22:28:53,267][gdb3][DEBUG ]     0
[2017-06-20 22:28:53,267][gdb3][DEBUG ]   ], 
[2017-06-20 22:28:53,267][gdb3][DEBUG ]   "rank": 0, 
[2017-06-20 22:28:53,267][gdb3][DEBUG ]   "state": "leader", 
[2017-06-20 22:28:53,268][gdb3][DEBUG ]   "sync_provider": []
[2017-06-20 22:28:53,268][gdb3][DEBUG ] }
[2017-06-20 22:28:53,268][gdb3][DEBUG ] ********************************************************************************
[2017-06-20 22:28:53,268][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-06-20 22:28:53,269][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-06-20 22:28:53,334][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-06-20 22:28:53,349][gdb3][DEBUG ] connection detected need for sudo
[2017-06-20 22:28:53,362][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-20 22:28:53,363][gdb3][DEBUG ] detect platform information from remote host
[2017-06-20 22:28:53,379][gdb3][DEBUG ] detect machine type
[2017-06-20 22:28:53,382][gdb3][DEBUG ] find the location of an executable
[2017-06-20 22:28:53,383][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-06-20 22:28:53,448][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-06-20 22:28:53,448][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-06-20 22:28:53,448][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-06-20 22:28:53,450][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpWU4E8L
[2017-06-20 22:28:53,465][gdb3][DEBUG ] connection detected need for sudo
[2017-06-20 22:28:53,479][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-20 22:28:53,480][gdb3][DEBUG ] detect platform information from remote host
[2017-06-20 22:28:53,496][gdb3][DEBUG ] detect machine type
[2017-06-20 22:28:53,499][gdb3][DEBUG ] get remote short hostname
[2017-06-20 22:28:53,499][gdb3][DEBUG ] fetch remote file
[2017-06-20 22:28:53,500][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-06-20 22:28:53,566][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-06-20 22:28:53,732][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-06-20 22:28:53,898][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-06-20 22:28:54,065][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-06-20 22:28:54,231][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-06-20 22:28:54,397][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-06-20 22:28:54,563][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-06-20 22:28:54,729][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-06-20 22:28:54,946][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-06-20 22:28:55,112][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-06-20 22:28:55,277][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-06-20 22:28:55,277][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-06-20 22:28:55,277][ceph_deploy.gatherkeys][INFO  ] Replacing 'ceph.bootstrap-mgr.keyring' and backing up old key as 'ceph.bootstrap-mgr.keyring-20170620222855'
[2017-06-20 22:28:55,278][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-06-20 22:28:55,278][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-06-20 22:28:55,278][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-06-20 22:28:55,278][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpWU4E8L
[2017-06-20 22:28:55,458][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 22:28:55,458][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-06-20 22:28:55,458][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 22:28:55,458][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 22:28:55,458][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 22:28:55,458][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-20 22:28:55,458][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 22:28:55,458][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9901629560>
[2017-06-20 22:28:55,458][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 22:28:55,459][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-06-20 22:28:55,459][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f9901f40938>
[2017-06-20 22:28:55,459][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 22:28:55,459][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 22:28:55,459][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-06-20 22:28:55,485][gdb3][DEBUG ] connection detected need for sudo
[2017-06-20 22:28:55,500][gdb3][DEBUG ] connected to host: gdb3 
[2017-06-20 22:28:55,500][gdb3][DEBUG ] detect platform information from remote host
[2017-06-20 22:28:55,517][gdb3][DEBUG ] detect machine type
[2017-06-20 22:28:55,519][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-20 22:29:27,435][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 22:29:27,436][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb1
[2017-06-20 22:29:27,436][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 22:29:27,436][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 22:29:27,436][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 22:29:27,436][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-06-20 22:29:27,436][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 22:29:27,436][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f48d721a560>
[2017-06-20 22:29:27,436][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 22:29:27,436][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-06-20 22:29:27,436][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f48d7b31938>
[2017-06-20 22:29:27,436][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 22:29:27,436][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 22:29:27,436][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-06-20 22:29:27,685][gdb1][DEBUG ] connection detected need for sudo
[2017-06-20 22:29:27,925][gdb1][DEBUG ] connected to host: gdb1 
[2017-06-20 22:29:27,926][gdb1][DEBUG ] detect platform information from remote host
[2017-06-20 22:29:27,943][gdb1][DEBUG ] detect machine type
[2017-06-20 22:29:27,947][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-20 22:29:28,120][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 22:29:28,120][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-06-20 22:29:28,120][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 22:29:28,120][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 22:29:28,120][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-06-20 22:29:28,121][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-06-20 22:29:28,121][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-06-20 22:29:28,121][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 22:29:28,121][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-06-20 22:29:28,121][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-06-20 22:29:28,121][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-20 22:29:28,121][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-06-20 22:29:28,121][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-06-20 22:29:28,121][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 22:29:28,121][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f78e97a6950>
[2017-06-20 22:29:28,121][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 22:29:28,121][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-06-20 22:29:28,121][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f78e99fcaa0>
[2017-06-20 22:29:28,121][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 22:29:28,121][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 22:29:28,122][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-06-20 22:29:28,122][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-06-20 22:29:28,373][gdb1][DEBUG ] connection detected need for sudo
[2017-06-20 22:29:28,613][gdb1][DEBUG ] connected to host: gdb1 
[2017-06-20 22:29:28,613][gdb1][DEBUG ] detect platform information from remote host
[2017-06-20 22:29:28,630][gdb1][DEBUG ] detect machine type
[2017-06-20 22:29:28,634][gdb1][DEBUG ] find the location of an executable
[2017-06-20 22:29:28,635][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-20 22:29:28,635][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-06-20 22:29:28,635][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-20 22:29:28,638][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-06-20 22:29:28,638][gdb1][DEBUG ] find the location of an executable
[2017-06-20 22:29:28,640][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-06-20 22:29:28,761][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-06-20 22:29:28,776][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-20 22:29:28,792][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-20 22:29:28,800][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-20 22:29:28,816][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-06-20 22:29:28,823][gdb1][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-06-20 22:29:33,860][gdb1][INFO  ] checking OSD status...
[2017-06-20 22:29:33,861][gdb1][DEBUG ] find the location of an executable
[2017-06-20 22:29:33,863][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-06-20 22:29:34,028][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-06-20 22:29:34,193][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 22:29:34,193][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-06-20 22:29:34,194][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 22:29:34,194][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 22:29:34,194][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 22:29:34,194][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-20 22:29:34,194][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-06-20 22:29:34,194][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 22:29:34,194][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6bef132950>
[2017-06-20 22:29:34,194][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 22:29:34,194][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f6bef388aa0>
[2017-06-20 22:29:34,194][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 22:29:34,194][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 22:29:34,194][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-06-20 22:29:34,195][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-06-20 22:29:34,445][gdb1][DEBUG ] connection detected need for sudo
[2017-06-20 22:29:34,656][gdb1][DEBUG ] connected to host: gdb1 
[2017-06-20 22:29:34,657][gdb1][DEBUG ] detect platform information from remote host
[2017-06-20 22:29:34,673][gdb1][DEBUG ] detect machine type
[2017-06-20 22:29:34,677][gdb1][DEBUG ] find the location of an executable
[2017-06-20 22:29:34,678][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-20 22:29:34,678][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-06-20 22:29:34,678][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-06-20 22:29:34,678][gdb1][DEBUG ] find the location of an executable
[2017-06-20 22:29:34,680][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-06-20 22:29:34,801][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-06-20 22:29:34,801][gdb1][WARNING] activate: Cluster uuid is f4f36e31-c61f-42db-97ec-96a4b3bd98b7
[2017-06-20 22:29:34,801][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-06-20 22:29:34,833][gdb1][WARNING] Traceback (most recent call last):
[2017-06-20 22:29:34,833][gdb1][WARNING]   File "/usr/local/bin/ceph-disk", line 9, in <module>
[2017-06-20 22:29:34,833][gdb1][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-06-20 22:29:34,834][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5653, in run
[2017-06-20 22:29:34,834][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5604, in main
[2017-06-20 22:29:34,834][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3713, in main_activate
[2017-06-20 22:29:34,834][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3533, in activate_dir
[2017-06-20 22:29:34,834][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3609, in activate
[2017-06-20 22:29:34,834][gdb1][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid f4f36e31-c61f-42db-97ec-96a4b3bd98b7
[2017-06-20 22:29:34,834][gdb1][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-06-20 22:29:34,834][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-06-20 22:35:45,993][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 22:35:45,993][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb1
[2017-06-20 22:35:45,993][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 22:35:45,994][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 22:35:45,994][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 22:35:45,994][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-06-20 22:35:45,994][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 22:35:45,994][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3cdd66f560>
[2017-06-20 22:35:45,994][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 22:35:45,994][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-06-20 22:35:45,994][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f3cddf86938>
[2017-06-20 22:35:45,994][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 22:35:45,994][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 22:35:45,994][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-06-20 22:35:46,245][gdb1][DEBUG ] connection detected need for sudo
[2017-06-20 22:35:46,445][gdb1][DEBUG ] connected to host: gdb1 
[2017-06-20 22:35:46,445][gdb1][DEBUG ] detect platform information from remote host
[2017-06-20 22:35:46,462][gdb1][DEBUG ] detect machine type
[2017-06-20 22:35:46,466][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-20 22:35:46,639][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 22:35:46,639][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-06-20 22:35:46,639][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 22:35:46,639][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 22:35:46,639][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-06-20 22:35:46,640][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-06-20 22:35:46,640][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-06-20 22:35:46,640][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 22:35:46,640][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-06-20 22:35:46,640][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-06-20 22:35:46,640][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-20 22:35:46,640][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-06-20 22:35:46,640][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-06-20 22:35:46,640][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 22:35:46,640][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f33cfad7950>
[2017-06-20 22:35:46,640][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 22:35:46,640][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-06-20 22:35:46,640][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f33cfd2daa0>
[2017-06-20 22:35:46,640][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 22:35:46,641][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 22:35:46,641][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-06-20 22:35:46,641][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-06-20 22:35:46,889][gdb1][DEBUG ] connection detected need for sudo
[2017-06-20 22:35:47,096][gdb1][DEBUG ] connected to host: gdb1 
[2017-06-20 22:35:47,096][gdb1][DEBUG ] detect platform information from remote host
[2017-06-20 22:35:47,113][gdb1][DEBUG ] detect machine type
[2017-06-20 22:35:47,117][gdb1][DEBUG ] find the location of an executable
[2017-06-20 22:35:47,117][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-20 22:35:47,117][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-06-20 22:35:47,118][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-20 22:35:47,120][gdb1][WARNING] osd keyring does not exist yet, creating one
[2017-06-20 22:35:47,120][gdb1][DEBUG ] create a keyring file
[2017-06-20 22:35:47,122][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-06-20 22:35:47,122][gdb1][DEBUG ] find the location of an executable
[2017-06-20 22:35:47,124][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-06-20 22:35:47,294][gdb1][WARNING] Traceback (most recent call last):
[2017-06-20 22:35:47,295][gdb1][WARNING]   File "/usr/local/bin/ceph-disk", line 9, in <module>
[2017-06-20 22:35:47,295][gdb1][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-06-20 22:35:47,295][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5653, in run
[2017-06-20 22:35:47,295][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5604, in main
[2017-06-20 22:35:47,295][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 2029, in main
[2017-06-20 22:35:47,295][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 2025, in factory
[2017-06-20 22:35:47,295][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 2037, in __init__
[2017-06-20 22:35:47,295][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 2739, in __init__
[2017-06-20 22:35:47,295][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 2747, in set_type
[2017-06-20 22:35:47,295][gdb1][WARNING] OSError: [Errno 2] No such file or directory: '/mnt/memstore'
[2017-06-20 22:35:47,296][gdb1][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-06-20 22:35:47,296][ceph_deploy.osd][ERROR ] Failed to execute command: /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-06-20 22:35:47,296][ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs

[2017-06-20 22:35:47,466][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 22:35:47,466][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-06-20 22:35:47,466][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 22:35:47,467][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 22:35:47,467][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 22:35:47,467][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-20 22:35:47,467][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-06-20 22:35:47,467][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 22:35:47,467][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f74dbd5e950>
[2017-06-20 22:35:47,467][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 22:35:47,467][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f74dbfb4aa0>
[2017-06-20 22:35:47,467][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 22:35:47,467][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 22:35:47,467][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-06-20 22:35:47,468][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-06-20 22:35:47,717][gdb1][DEBUG ] connection detected need for sudo
[2017-06-20 22:35:47,957][gdb1][DEBUG ] connected to host: gdb1 
[2017-06-20 22:35:47,957][gdb1][DEBUG ] detect platform information from remote host
[2017-06-20 22:35:47,974][gdb1][DEBUG ] detect machine type
[2017-06-20 22:35:47,978][gdb1][DEBUG ] find the location of an executable
[2017-06-20 22:35:47,978][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-20 22:35:47,978][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-06-20 22:35:47,979][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-06-20 22:35:47,979][gdb1][DEBUG ] find the location of an executable
[2017-06-20 22:35:47,981][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-06-20 22:35:48,101][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-06-20 22:35:48,102][gdb1][WARNING] Traceback (most recent call last):
[2017-06-20 22:35:48,102][gdb1][WARNING]   File "/usr/local/bin/ceph-disk", line 9, in <module>
[2017-06-20 22:35:48,102][gdb1][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-06-20 22:35:48,102][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5653, in run
[2017-06-20 22:35:48,102][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5604, in main
[2017-06-20 22:35:48,102][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3684, in main_activate
[2017-06-20 22:35:48,102][gdb1][WARNING] ceph_disk.main.Error: Error: /mnt/memstore does not exist
[2017-06-20 22:35:48,134][gdb1][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-06-20 22:35:48,135][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-06-20 22:36:20,089][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 22:36:20,089][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb1
[2017-06-20 22:36:20,089][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 22:36:20,089][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 22:36:20,089][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 22:36:20,089][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-06-20 22:36:20,089][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 22:36:20,090][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f8323ba4560>
[2017-06-20 22:36:20,090][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 22:36:20,090][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-06-20 22:36:20,090][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f83244bb938>
[2017-06-20 22:36:20,090][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 22:36:20,090][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 22:36:20,090][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-06-20 22:36:20,342][gdb1][DEBUG ] connection detected need for sudo
[2017-06-20 22:36:20,581][gdb1][DEBUG ] connected to host: gdb1 
[2017-06-20 22:36:20,582][gdb1][DEBUG ] detect platform information from remote host
[2017-06-20 22:36:20,598][gdb1][DEBUG ] detect machine type
[2017-06-20 22:36:20,602][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-20 22:36:20,774][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 22:36:20,774][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-06-20 22:36:20,774][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 22:36:20,774][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 22:36:20,774][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-06-20 22:36:20,774][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-06-20 22:36:20,774][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-06-20 22:36:20,775][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 22:36:20,775][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-06-20 22:36:20,775][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-06-20 22:36:20,775][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-20 22:36:20,775][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-06-20 22:36:20,775][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-06-20 22:36:20,775][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 22:36:20,775][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f5e87495950>
[2017-06-20 22:36:20,775][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 22:36:20,775][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-06-20 22:36:20,775][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f5e876ebaa0>
[2017-06-20 22:36:20,775][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 22:36:20,775][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 22:36:20,775][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-06-20 22:36:20,776][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-06-20 22:36:21,025][gdb1][DEBUG ] connection detected need for sudo
[2017-06-20 22:36:21,229][gdb1][DEBUG ] connected to host: gdb1 
[2017-06-20 22:36:21,230][gdb1][DEBUG ] detect platform information from remote host
[2017-06-20 22:36:21,246][gdb1][DEBUG ] detect machine type
[2017-06-20 22:36:21,250][gdb1][DEBUG ] find the location of an executable
[2017-06-20 22:36:21,251][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-20 22:36:21,251][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-06-20 22:36:21,251][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-06-20 22:36:21,254][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-06-20 22:36:21,254][gdb1][DEBUG ] find the location of an executable
[2017-06-20 22:36:21,256][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-06-20 22:36:21,376][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-06-20 22:36:21,392][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-20 22:36:21,408][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-20 22:36:21,416][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-06-20 22:36:21,431][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-06-20 22:36:21,439][gdb1][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-06-20 22:36:21,442][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.2599.tmp
[2017-06-20 22:36:21,446][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.2599.tmp
[2017-06-20 22:36:21,462][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.2599.tmp
[2017-06-20 22:36:26,499][gdb1][INFO  ] checking OSD status...
[2017-06-20 22:36:26,499][gdb1][DEBUG ] find the location of an executable
[2017-06-20 22:36:26,503][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-06-20 22:36:26,668][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-06-20 22:36:26,834][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-06-20 22:36:26,834][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-06-20 22:36:26,834][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-06-20 22:36:26,834][ceph_deploy.cli][INFO  ]  username                      : None
[2017-06-20 22:36:26,834][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-06-20 22:36:26,835][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-06-20 22:36:26,835][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-06-20 22:36:26,835][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-06-20 22:36:26,835][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0c796cb950>
[2017-06-20 22:36:26,835][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-06-20 22:36:26,835][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f0c79921aa0>
[2017-06-20 22:36:26,835][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-06-20 22:36:26,835][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-06-20 22:36:26,835][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-06-20 22:36:26,835][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-06-20 22:36:27,089][gdb1][DEBUG ] connection detected need for sudo
[2017-06-20 22:36:27,329][gdb1][DEBUG ] connected to host: gdb1 
[2017-06-20 22:36:27,329][gdb1][DEBUG ] detect platform information from remote host
[2017-06-20 22:36:27,346][gdb1][DEBUG ] detect machine type
[2017-06-20 22:36:27,350][gdb1][DEBUG ] find the location of an executable
[2017-06-20 22:36:27,351][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-06-20 22:36:27,351][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-06-20 22:36:27,351][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-06-20 22:36:27,351][gdb1][DEBUG ] find the location of an executable
[2017-06-20 22:36:27,353][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-06-20 22:36:27,524][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-06-20 22:36:27,524][gdb1][WARNING] activate: Cluster uuid is 382eeac0-7e10-4bdc-98d7-53d22201d56d
[2017-06-20 22:36:27,524][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-06-20 22:36:27,524][gdb1][WARNING] activate: Cluster name is ceph
[2017-06-20 22:36:27,524][gdb1][WARNING] activate: OSD uuid is b1e22da6-1558-4766-87c3-7118d8079782
[2017-06-20 22:36:27,524][gdb1][WARNING] allocate_osd_id: Allocating OSD id...
[2017-06-20 22:36:27,524][gdb1][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise b1e22da6-1558-4766-87c3-7118d8079782
[2017-06-20 22:36:27,688][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.2717.tmp
[2017-06-20 22:36:27,689][gdb1][WARNING] activate: OSD id is 0
[2017-06-20 22:36:27,689][gdb1][WARNING] activate: Initializing OSD...
[2017-06-20 22:36:27,689][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-06-20 22:36:27,803][gdb1][WARNING] got monmap epoch 2
[2017-06-20 22:36:27,804][gdb1][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 0 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid b1e22da6-1558-4766-87c3-7118d8079782 --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-06-20 22:36:27,868][gdb1][WARNING] activate: Marking with init system systemd
[2017-06-20 22:36:27,868][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-06-20 22:36:27,868][gdb1][WARNING] activate: Authorizing OSD key...
[2017-06-20 22:36:27,868][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.0 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-06-20 22:36:28,033][gdb1][WARNING] added key for osd.0
[2017-06-20 22:36:28,033][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.2717.tmp
[2017-06-20 22:36:28,033][gdb1][WARNING] activate: ceph osd.0 data dir is ready at /mnt/memstore
[2017-06-20 22:36:28,033][gdb1][WARNING] activate_dir: Creating symlink /var/lib/ceph/osd/ceph-0 -> /mnt/memstore
[2017-06-20 22:36:28,033][gdb1][WARNING] start_daemon: Starting ceph osd.0...
[2017-06-20 22:36:28,033][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0
[2017-06-20 22:36:28,033][gdb1][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service.
[2017-06-20 22:36:28,248][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0 --runtime
[2017-06-20 22:36:28,312][gdb1][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@0
[2017-06-20 22:36:28,312][gdb1][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service to /lib/systemd/system/ceph-osd@.service.
[2017-06-20 22:36:28,426][gdb1][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@0
[2017-06-20 22:36:33,545][gdb1][INFO  ] checking OSD status...
[2017-06-20 22:36:33,546][gdb1][DEBUG ] find the location of an executable
[2017-06-20 22:36:33,555][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-06-20 22:36:33,923][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 02:18:52,098][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 02:18:52,100][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-07-06 02:18:52,100][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 02:18:52,100][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 02:18:52,100][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 02:18:52,100][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 02:18:52,100][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 02:18:52,100][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f01331b6fc8>
[2017-07-06 02:18:52,100][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 02:18:52,100][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-06 02:18:52,100][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f0133ac91b8>
[2017-07-06 02:18:52,101][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 02:18:52,101][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 02:18:52,101][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-07-06 02:18:52,101][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-07-06 02:18:52,101][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-07-06 02:18:52,101][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-07-06 02:18:52,139][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 02:18:52,165][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 02:18:52,167][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 02:18:52,183][gdb3][DEBUG ] detect machine type
[2017-07-06 02:18:52,185][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 02:18:52,185][gdb3][INFO  ] Purging Ceph on gdb3
[2017-07-06 02:18:52,186][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-07-06 02:18:52,226][gdb3][DEBUG ] Reading package lists...
[2017-07-06 02:18:52,390][gdb3][DEBUG ] Building dependency tree...
[2017-07-06 02:18:52,391][gdb3][DEBUG ] Reading state information...
[2017-07-06 02:18:52,454][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-07-06 02:18:52,455][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-07-06 02:18:52,455][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-07-06 02:18:52,455][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-07-06 02:18:52,455][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-07-06 02:18:52,455][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-07-06 02:18:52,455][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1016 linux-aws-headers-4.4.0-1017
[2017-07-06 02:18:52,455][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1018 linux-headers-4.4.0-1013-aws
[2017-07-06 02:18:52,455][gdb3][DEBUG ]   linux-headers-4.4.0-1016-aws linux-headers-4.4.0-1017-aws
[2017-07-06 02:18:52,455][gdb3][DEBUG ]   linux-headers-4.4.0-1018-aws linux-image-4.4.0-1013-aws
[2017-07-06 02:18:52,455][gdb3][DEBUG ]   linux-image-4.4.0-1016-aws linux-image-4.4.0-1017-aws
[2017-07-06 02:18:52,455][gdb3][DEBUG ]   linux-image-4.4.0-1018-aws ntp python-blinker python-cephfs
[2017-07-06 02:18:52,455][gdb3][DEBUG ]   python-cffi-backend python-chardet python-cryptography python-enum34
[2017-07-06 02:18:52,456][gdb3][DEBUG ]   python-flask python-idna python-ipaddress python-itsdangerous python-jinja2
[2017-07-06 02:18:52,456][gdb3][DEBUG ]   python-markupsafe python-ndg-httpsclient python-openssl python-pyasn1
[2017-07-06 02:18:52,456][gdb3][DEBUG ]   python-pyinotify python-rados python-rbd python-requests python-rgw
[2017-07-06 02:18:52,456][gdb3][DEBUG ]   python-six python-urllib3 python-werkzeug
[2017-07-06 02:18:52,456][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-07-06 02:18:52,488][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-07-06 02:18:52,488][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-07-06 02:18:52,602][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 60 not upgraded.
[2017-07-06 02:18:52,602][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-07-06 02:18:52,666][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 179644 files and directories currently installed.)
[2017-07-06 02:18:52,682][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-07-06 02:18:52,855][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-07-06 02:18:52,969][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-07-06 02:18:52,972][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-07-06 02:18:53,188][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-07-06 02:18:53,309][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-07-06 02:18:53,474][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-07-06 02:18:53,506][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-07-06 02:18:53,538][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-07-06 02:18:53,703][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-07-06 02:18:53,818][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-07-06 02:18:53,819][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-07-06 02:18:53,984][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-07-06 02:18:53,984][gdb3][DEBUG ] dpkg: warning: while removing ceph-base, directory '/var/lib/ceph/tmp' not empty so not removed
[2017-07-06 02:18:54,000][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-07-06 02:18:54,115][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-07-06 02:18:54,229][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-07-06 02:18:54,229][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-07-06 02:18:54,293][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu9) ...
[2017-07-06 02:18:55,109][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-07-06 02:18:55,274][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 02:18:55,274][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-07-06 02:18:55,274][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 02:18:55,274][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 02:18:55,274][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 02:18:55,274][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 02:18:55,274][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 02:18:55,274][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f40e2265710>
[2017-07-06 02:18:55,274][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 02:18:55,274][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-06 02:18:55,275][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f40e2b72230>
[2017-07-06 02:18:55,275][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 02:18:55,275][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 02:18:55,275][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-07-06 02:18:55,300][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 02:18:55,314][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 02:18:55,315][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 02:18:55,331][gdb3][DEBUG ] detect machine type
[2017-07-06 02:18:55,334][gdb3][DEBUG ] find the location of an executable
[2017-07-06 02:18:55,349][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 02:18:55,362][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 02:18:55,363][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 02:18:55,379][gdb3][DEBUG ] detect machine type
[2017-07-06 02:18:55,381][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 02:18:55,382][gdb3][INFO  ] purging data on gdb3
[2017-07-06 02:18:55,382][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-07-06 02:18:55,395][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-07-06 02:18:55,564][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 02:18:55,564][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-07-06 02:18:55,564][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 02:18:55,564][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 02:18:55,564][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 02:18:55,564][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 02:18:55,564][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 02:18:55,564][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f817c7b99e0>
[2017-07-06 02:18:55,565][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 02:18:55,565][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7f817d07c848>
[2017-07-06 02:18:55,565][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 02:18:55,565][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 02:19:17,641][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 02:19:17,642][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-07-06 02:19:17,642][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 02:19:17,642][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 02:19:17,642][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 02:19:17,642][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 02:19:17,642][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 02:19:17,642][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f5468e4d560>
[2017-07-06 02:19:17,642][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 02:19:17,642][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-07-06 02:19:17,642][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-07-06 02:19:17,642][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f54694d1758>
[2017-07-06 02:19:17,643][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-07-06 02:19:17,643][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 02:19:17,643][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-07-06 02:19:17,643][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 02:19:17,643][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-07-06 02:19:17,643][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-07-06 02:19:17,643][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-07-06 02:19:17,669][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 02:19:17,683][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 02:19:17,684][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 02:19:17,700][gdb3][DEBUG ] detect machine type
[2017-07-06 02:19:17,703][gdb3][DEBUG ] find the location of an executable
[2017-07-06 02:19:17,704][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-07-06 02:19:17,715][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-07-06 02:19:17,721][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-07-06 02:19:17,721][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-07-06 02:19:17,722][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-07-06 02:19:17,722][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-07-06 02:19:17,722][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-07-06 02:19:17,722][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-07-06 02:19:17,722][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-07-06 02:19:17,722][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-07-06 02:19:17,887][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 02:19:17,888][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-07-06 02:19:17,888][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 02:19:17,888][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 02:19:17,888][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 02:19:17,888][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 02:19:17,888][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-07-06 02:19:17,888][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 02:19:17,888][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3ff2534e60>
[2017-07-06 02:19:17,888][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 02:19:17,888][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f3ff2509b18>
[2017-07-06 02:19:17,888][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 02:19:17,888][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-07-06 02:19:17,888][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 02:19:17,889][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-07-06 02:19:17,889][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-07-06 02:19:17,915][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 02:19:17,929][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 02:19:17,930][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 02:19:17,946][gdb3][DEBUG ] detect machine type
[2017-07-06 02:19:17,948][gdb3][DEBUG ] find the location of an executable
[2017-07-06 02:19:17,948][ceph_deploy.mon][ERROR ] ceph needs to be installed in remote host: gdb3
[2017-07-06 02:19:17,949][ceph_deploy][ERROR ] GenericError: Failed to create 1 monitors

[2017-07-06 02:19:18,129][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 02:19:18,129][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-07-06 02:19:18,129][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 02:19:18,129][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 02:19:18,129][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 02:19:18,129][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 02:19:18,129][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 02:19:18,129][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f1432e96518>
[2017-07-06 02:19:18,129][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 02:19:18,129][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-07-06 02:19:18,130][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f14337ad938>
[2017-07-06 02:19:18,130][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 02:19:18,130][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 02:19:18,130][ceph_deploy][ERROR ] RuntimeError: ceph.client.admin.keyring not found

[2017-07-06 02:20:39,448][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 02:20:39,449][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-07-06 02:20:39,449][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 02:20:39,449][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 02:20:39,449][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 02:20:39,449][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 02:20:39,449][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 02:20:39,449][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ff004f09560>
[2017-07-06 02:20:39,449][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 02:20:39,449][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-07-06 02:20:39,449][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-07-06 02:20:39,449][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7ff00558d758>
[2017-07-06 02:20:39,449][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-07-06 02:20:39,450][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 02:20:39,450][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-07-06 02:20:39,450][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 02:20:39,450][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-07-06 02:20:39,450][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-07-06 02:20:39,450][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-07-06 02:20:39,475][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 02:20:39,489][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 02:20:39,490][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 02:20:39,506][gdb3][DEBUG ] detect machine type
[2017-07-06 02:20:39,508][gdb3][DEBUG ] find the location of an executable
[2017-07-06 02:20:39,509][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-07-06 02:20:39,520][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-07-06 02:20:39,527][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-07-06 02:20:39,527][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-07-06 02:20:39,527][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-07-06 02:20:39,527][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-07-06 02:20:39,527][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-07-06 02:20:39,527][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-07-06 02:20:39,527][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-07-06 02:20:39,528][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-07-06 02:20:39,692][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 02:20:39,693][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-07-06 02:20:39,693][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 02:20:39,693][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 02:20:39,693][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 02:20:39,693][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 02:20:39,693][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-07-06 02:20:39,693][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 02:20:39,693][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f036b186e60>
[2017-07-06 02:20:39,694][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 02:20:39,694][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f036b15bb18>
[2017-07-06 02:20:39,694][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 02:20:39,694][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-07-06 02:20:39,694][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 02:20:39,695][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-07-06 02:20:39,695][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-07-06 02:20:39,721][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 02:20:39,735][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 02:20:39,736][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 02:20:39,752][gdb3][DEBUG ] detect machine type
[2017-07-06 02:20:39,754][gdb3][DEBUG ] find the location of an executable
[2017-07-06 02:20:39,755][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-07-06 02:20:39,755][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-07-06 02:20:39,755][gdb3][DEBUG ] get remote short hostname
[2017-07-06 02:20:39,755][gdb3][DEBUG ] deploying mon to gdb3
[2017-07-06 02:20:39,755][gdb3][DEBUG ] get remote short hostname
[2017-07-06 02:20:39,756][gdb3][DEBUG ] remote hostname: gdb3
[2017-07-06 02:20:39,756][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 02:20:39,757][gdb3][DEBUG ] create the mon path if it does not exist
[2017-07-06 02:20:39,758][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-06 02:20:39,758][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-06 02:20:39,758][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-06 02:20:39,759][gdb3][DEBUG ] create the monitor keyring file
[2017-07-06 02:20:39,760][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-07-06 02:20:39,798][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-07-06 02:20:39,798][gdb3][DEBUG ] ceph-mon: set fsid to 27c8a69d-df07-4fbe-96ad-e5d06e6d4d49
[2017-07-06 02:20:39,805][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-07-06 02:20:39,809][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-06 02:20:39,809][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-07-06 02:20:39,810][gdb3][DEBUG ] create the init path if it does not exist
[2017-07-06 02:20:39,811][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 02:20:39,884][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-07-06 02:20:39,952][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-07-06 02:20:41,991][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 02:20:42,106][gdb3][DEBUG ] ********************************************************************************
[2017-07-06 02:20:42,107][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-07-06 02:20:42,107][gdb3][DEBUG ] {
[2017-07-06 02:20:42,107][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-07-06 02:20:42,107][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-07-06 02:20:42,107][gdb3][DEBUG ]   "features": {
[2017-07-06 02:20:42,107][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-07-06 02:20:42,107][gdb3][DEBUG ]     "quorum_mon": [
[2017-07-06 02:20:42,107][gdb3][DEBUG ]       "kraken", 
[2017-07-06 02:20:42,107][gdb3][DEBUG ]       "luminous"
[2017-07-06 02:20:42,107][gdb3][DEBUG ]     ], 
[2017-07-06 02:20:42,107][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-07-06 02:20:42,108][gdb3][DEBUG ]     "required_mon": [
[2017-07-06 02:20:42,108][gdb3][DEBUG ]       "kraken", 
[2017-07-06 02:20:42,108][gdb3][DEBUG ]       "luminous"
[2017-07-06 02:20:42,108][gdb3][DEBUG ]     ]
[2017-07-06 02:20:42,108][gdb3][DEBUG ]   }, 
[2017-07-06 02:20:42,108][gdb3][DEBUG ]   "monmap": {
[2017-07-06 02:20:42,108][gdb3][DEBUG ]     "created": "2017-07-06 02:20:39.783026", 
[2017-07-06 02:20:42,108][gdb3][DEBUG ]     "epoch": 2, 
[2017-07-06 02:20:42,108][gdb3][DEBUG ]     "features": {
[2017-07-06 02:20:42,108][gdb3][DEBUG ]       "optional": [], 
[2017-07-06 02:20:42,108][gdb3][DEBUG ]       "persistent": [
[2017-07-06 02:20:42,108][gdb3][DEBUG ]         "kraken", 
[2017-07-06 02:20:42,108][gdb3][DEBUG ]         "luminous"
[2017-07-06 02:20:42,108][gdb3][DEBUG ]       ]
[2017-07-06 02:20:42,108][gdb3][DEBUG ]     }, 
[2017-07-06 02:20:42,108][gdb3][DEBUG ]     "fsid": "27c8a69d-df07-4fbe-96ad-e5d06e6d4d49", 
[2017-07-06 02:20:42,108][gdb3][DEBUG ]     "modified": "2017-07-06 02:20:40.031021", 
[2017-07-06 02:20:42,109][gdb3][DEBUG ]     "mons": [
[2017-07-06 02:20:42,109][gdb3][DEBUG ]       {
[2017-07-06 02:20:42,109][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-07-06 02:20:42,109][gdb3][DEBUG ]         "name": "gdb3", 
[2017-07-06 02:20:42,109][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-07-06 02:20:42,109][gdb3][DEBUG ]         "rank": 0
[2017-07-06 02:20:42,109][gdb3][DEBUG ]       }
[2017-07-06 02:20:42,109][gdb3][DEBUG ]     ]
[2017-07-06 02:20:42,109][gdb3][DEBUG ]   }, 
[2017-07-06 02:20:42,109][gdb3][DEBUG ]   "name": "gdb3", 
[2017-07-06 02:20:42,109][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-07-06 02:20:42,109][gdb3][DEBUG ]   "quorum": [
[2017-07-06 02:20:42,109][gdb3][DEBUG ]     0
[2017-07-06 02:20:42,109][gdb3][DEBUG ]   ], 
[2017-07-06 02:20:42,109][gdb3][DEBUG ]   "rank": 0, 
[2017-07-06 02:20:42,109][gdb3][DEBUG ]   "state": "leader", 
[2017-07-06 02:20:42,110][gdb3][DEBUG ]   "sync_provider": []
[2017-07-06 02:20:42,110][gdb3][DEBUG ] }
[2017-07-06 02:20:42,110][gdb3][DEBUG ] ********************************************************************************
[2017-07-06 02:20:42,110][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-07-06 02:20:42,111][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 02:20:42,176][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-07-06 02:20:42,191][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 02:20:42,206][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 02:20:42,206][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 02:20:42,223][gdb3][DEBUG ] detect machine type
[2017-07-06 02:20:42,225][gdb3][DEBUG ] find the location of an executable
[2017-07-06 02:20:42,227][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 02:20:42,292][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-07-06 02:20:42,292][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-07-06 02:20:42,292][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-07-06 02:20:42,294][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpB_1G2a
[2017-07-06 02:20:42,309][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 02:20:42,322][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 02:20:42,323][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 02:20:42,339][gdb3][DEBUG ] detect machine type
[2017-07-06 02:20:42,342][gdb3][DEBUG ] get remote short hostname
[2017-07-06 02:20:42,342][gdb3][DEBUG ] fetch remote file
[2017-07-06 02:20:42,343][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 02:20:42,409][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-07-06 02:20:42,575][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-07-06 02:20:42,741][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-07-06 02:20:42,908][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-07-06 02:20:43,124][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-07-06 02:20:43,290][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-07-06 02:20:43,456][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-07-06 02:20:43,623][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-07-06 02:20:43,789][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-07-06 02:20:43,955][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-07-06 02:20:44,120][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-07-06 02:20:44,120][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-07-06 02:20:44,121][ceph_deploy.gatherkeys][INFO  ] Replacing 'ceph.bootstrap-mgr.keyring' and backing up old key as 'ceph.bootstrap-mgr.keyring-20170706022044'
[2017-07-06 02:20:44,122][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-07-06 02:20:44,122][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-07-06 02:20:44,122][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-07-06 02:20:44,122][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpB_1G2a
[2017-07-06 02:20:44,303][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 02:20:44,303][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-07-06 02:20:44,303][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 02:20:44,303][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 02:20:44,303][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 02:20:44,303][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 02:20:44,303][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 02:20:44,303][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fd8bde54518>
[2017-07-06 02:20:44,304][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 02:20:44,304][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-07-06 02:20:44,304][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fd8be76b938>
[2017-07-06 02:20:44,304][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 02:20:44,304][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 02:20:44,304][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-07-06 02:20:44,330][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 02:20:44,343][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 02:20:44,344][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 02:20:44,360][gdb3][DEBUG ] detect machine type
[2017-07-06 02:20:44,362][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 02:22:45,618][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 02:22:45,618][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-07-06 02:22:45,618][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 02:22:45,618][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 02:22:45,618][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 02:22:45,618][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 02:22:45,618][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 02:22:45,619][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe577833fc8>
[2017-07-06 02:22:45,619][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 02:22:45,619][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-06 02:22:45,619][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7fe5781461b8>
[2017-07-06 02:22:45,619][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 02:22:45,619][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 02:22:45,619][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-07-06 02:22:45,619][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-07-06 02:22:45,619][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-07-06 02:22:45,619][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-07-06 02:22:45,645][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 02:22:45,658][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 02:22:45,659][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 02:22:45,675][gdb3][DEBUG ] detect machine type
[2017-07-06 02:22:45,677][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 02:22:45,677][gdb3][INFO  ] Purging Ceph on gdb3
[2017-07-06 02:22:45,678][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-07-06 02:22:45,716][gdb3][DEBUG ] Reading package lists...
[2017-07-06 02:22:45,881][gdb3][DEBUG ] Building dependency tree...
[2017-07-06 02:22:45,881][gdb3][DEBUG ] Reading state information...
[2017-07-06 02:22:45,945][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-07-06 02:22:45,945][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-07-06 02:22:45,945][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-07-06 02:22:45,945][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-07-06 02:22:45,945][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-07-06 02:22:45,945][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-07-06 02:22:45,945][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1016 linux-aws-headers-4.4.0-1017
[2017-07-06 02:22:45,946][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1018 linux-headers-4.4.0-1013-aws
[2017-07-06 02:22:45,946][gdb3][DEBUG ]   linux-headers-4.4.0-1016-aws linux-headers-4.4.0-1017-aws
[2017-07-06 02:22:45,946][gdb3][DEBUG ]   linux-headers-4.4.0-1018-aws linux-image-4.4.0-1013-aws
[2017-07-06 02:22:45,946][gdb3][DEBUG ]   linux-image-4.4.0-1016-aws linux-image-4.4.0-1017-aws
[2017-07-06 02:22:45,946][gdb3][DEBUG ]   linux-image-4.4.0-1018-aws ntp python-blinker python-cephfs
[2017-07-06 02:22:45,946][gdb3][DEBUG ]   python-cffi-backend python-chardet python-cryptography python-enum34
[2017-07-06 02:22:45,946][gdb3][DEBUG ]   python-flask python-idna python-ipaddress python-itsdangerous python-jinja2
[2017-07-06 02:22:45,946][gdb3][DEBUG ]   python-markupsafe python-ndg-httpsclient python-openssl python-pyasn1
[2017-07-06 02:22:45,946][gdb3][DEBUG ]   python-pyinotify python-rados python-rbd python-requests python-rgw
[2017-07-06 02:22:45,946][gdb3][DEBUG ]   python-six python-urllib3 python-werkzeug
[2017-07-06 02:22:45,946][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-07-06 02:22:45,978][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-07-06 02:22:45,978][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-07-06 02:22:46,092][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 60 not upgraded.
[2017-07-06 02:22:46,093][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-07-06 02:22:46,156][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 179644 files and directories currently installed.)
[2017-07-06 02:22:46,164][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-07-06 02:22:46,329][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-07-06 02:22:46,443][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-07-06 02:22:46,475][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-07-06 02:22:46,689][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-07-06 02:22:46,804][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-07-06 02:22:46,969][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-07-06 02:22:47,001][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-07-06 02:22:47,032][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-07-06 02:22:47,198][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-07-06 02:22:47,262][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-07-06 02:22:47,277][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-07-06 02:22:47,442][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-07-06 02:22:47,473][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-07-06 02:22:47,638][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-07-06 02:22:47,670][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-07-06 02:22:47,685][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-07-06 02:22:47,799][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu9) ...
[2017-07-06 02:22:48,616][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-07-06 02:22:48,778][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 02:22:48,778][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-07-06 02:22:48,778][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 02:22:48,778][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 02:22:48,778][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 02:22:48,778][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 02:22:48,778][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 02:22:48,779][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fd6765f5710>
[2017-07-06 02:22:48,779][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 02:22:48,779][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-06 02:22:48,779][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7fd676f02230>
[2017-07-06 02:22:48,779][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 02:22:48,779][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 02:22:48,779][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-07-06 02:22:48,804][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 02:22:48,818][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 02:22:48,819][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 02:22:48,835][gdb3][DEBUG ] detect machine type
[2017-07-06 02:22:48,837][gdb3][DEBUG ] find the location of an executable
[2017-07-06 02:22:48,853][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 02:22:48,867][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 02:22:48,868][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 02:22:48,884][gdb3][DEBUG ] detect machine type
[2017-07-06 02:22:48,887][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 02:22:48,887][gdb3][INFO  ] purging data on gdb3
[2017-07-06 02:22:48,888][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-07-06 02:22:48,901][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-07-06 02:22:49,072][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 02:22:49,072][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-07-06 02:22:49,072][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 02:22:49,072][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 02:22:49,072][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 02:22:49,072][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 02:22:49,073][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 02:22:49,073][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6b7dd859e0>
[2017-07-06 02:22:49,073][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 02:22:49,073][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7f6b7e648848>
[2017-07-06 02:22:49,073][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 02:22:49,073][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 02:23:09,561][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 02:23:09,562][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-07-06 02:23:09,562][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 02:23:09,562][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 02:23:09,562][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 02:23:09,562][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 02:23:09,562][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 02:23:09,562][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7047360560>
[2017-07-06 02:23:09,562][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 02:23:09,562][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-07-06 02:23:09,562][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-07-06 02:23:09,563][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f70479e4758>
[2017-07-06 02:23:09,563][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-07-06 02:23:09,563][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 02:23:09,563][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-07-06 02:23:09,563][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 02:23:09,563][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-07-06 02:23:09,563][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-07-06 02:23:09,563][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-07-06 02:23:09,589][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 02:23:09,603][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 02:23:09,603][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 02:23:09,619][gdb3][DEBUG ] detect machine type
[2017-07-06 02:23:09,622][gdb3][DEBUG ] find the location of an executable
[2017-07-06 02:23:09,623][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-07-06 02:23:09,634][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-07-06 02:23:09,640][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-07-06 02:23:09,640][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-07-06 02:23:09,641][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-07-06 02:23:09,641][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-07-06 02:23:09,641][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-07-06 02:23:09,641][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-07-06 02:23:09,641][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-07-06 02:23:09,641][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-07-06 02:23:09,806][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 02:23:09,806][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-07-06 02:23:09,806][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 02:23:09,806][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 02:23:09,806][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 02:23:09,806][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 02:23:09,806][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-07-06 02:23:09,806][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 02:23:09,806][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9bd5800e60>
[2017-07-06 02:23:09,807][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 02:23:09,807][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f9bd57d5b18>
[2017-07-06 02:23:09,807][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 02:23:09,807][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-07-06 02:23:09,807][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 02:23:09,807][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-07-06 02:23:09,808][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-07-06 02:23:09,833][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 02:23:09,847][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 02:23:09,847][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 02:23:09,864][gdb3][DEBUG ] detect machine type
[2017-07-06 02:23:09,866][gdb3][DEBUG ] find the location of an executable
[2017-07-06 02:23:09,867][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-07-06 02:23:09,867][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-07-06 02:23:09,867][gdb3][DEBUG ] get remote short hostname
[2017-07-06 02:23:09,867][gdb3][DEBUG ] deploying mon to gdb3
[2017-07-06 02:23:09,867][gdb3][DEBUG ] get remote short hostname
[2017-07-06 02:23:09,868][gdb3][DEBUG ] remote hostname: gdb3
[2017-07-06 02:23:09,868][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 02:23:09,869][gdb3][DEBUG ] create the mon path if it does not exist
[2017-07-06 02:23:09,870][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-06 02:23:09,870][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-06 02:23:09,871][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-06 02:23:09,871][gdb3][DEBUG ] create the monitor keyring file
[2017-07-06 02:23:09,872][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-07-06 02:23:09,910][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-07-06 02:23:09,910][gdb3][DEBUG ] ceph-mon: set fsid to 5b56fef1-c89a-4db0-9bcf-6963b9199fcb
[2017-07-06 02:23:09,913][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-07-06 02:23:09,915][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-06 02:23:09,915][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-07-06 02:23:09,915][gdb3][DEBUG ] create the init path if it does not exist
[2017-07-06 02:23:09,916][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 02:23:09,987][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-07-06 02:23:10,059][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-07-06 02:23:12,097][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 02:23:12,162][gdb3][DEBUG ] ********************************************************************************
[2017-07-06 02:23:12,162][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-07-06 02:23:12,162][gdb3][DEBUG ] {
[2017-07-06 02:23:12,162][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-07-06 02:23:12,162][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-07-06 02:23:12,162][gdb3][DEBUG ]   "features": {
[2017-07-06 02:23:12,162][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-07-06 02:23:12,162][gdb3][DEBUG ]     "quorum_mon": [
[2017-07-06 02:23:12,162][gdb3][DEBUG ]       "kraken", 
[2017-07-06 02:23:12,162][gdb3][DEBUG ]       "luminous"
[2017-07-06 02:23:12,163][gdb3][DEBUG ]     ], 
[2017-07-06 02:23:12,163][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-07-06 02:23:12,163][gdb3][DEBUG ]     "required_mon": [
[2017-07-06 02:23:12,163][gdb3][DEBUG ]       "kraken", 
[2017-07-06 02:23:12,163][gdb3][DEBUG ]       "luminous"
[2017-07-06 02:23:12,163][gdb3][DEBUG ]     ]
[2017-07-06 02:23:12,163][gdb3][DEBUG ]   }, 
[2017-07-06 02:23:12,163][gdb3][DEBUG ]   "monmap": {
[2017-07-06 02:23:12,163][gdb3][DEBUG ]     "created": "2017-07-06 02:23:09.894943", 
[2017-07-06 02:23:12,163][gdb3][DEBUG ]     "epoch": 2, 
[2017-07-06 02:23:12,163][gdb3][DEBUG ]     "features": {
[2017-07-06 02:23:12,163][gdb3][DEBUG ]       "optional": [], 
[2017-07-06 02:23:12,163][gdb3][DEBUG ]       "persistent": [
[2017-07-06 02:23:12,163][gdb3][DEBUG ]         "kraken", 
[2017-07-06 02:23:12,163][gdb3][DEBUG ]         "luminous"
[2017-07-06 02:23:12,163][gdb3][DEBUG ]       ]
[2017-07-06 02:23:12,163][gdb3][DEBUG ]     }, 
[2017-07-06 02:23:12,164][gdb3][DEBUG ]     "fsid": "5b56fef1-c89a-4db0-9bcf-6963b9199fcb", 
[2017-07-06 02:23:12,164][gdb3][DEBUG ]     "modified": "2017-07-06 02:23:10.148909", 
[2017-07-06 02:23:12,164][gdb3][DEBUG ]     "mons": [
[2017-07-06 02:23:12,164][gdb3][DEBUG ]       {
[2017-07-06 02:23:12,164][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-07-06 02:23:12,164][gdb3][DEBUG ]         "name": "gdb3", 
[2017-07-06 02:23:12,164][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-07-06 02:23:12,164][gdb3][DEBUG ]         "rank": 0
[2017-07-06 02:23:12,164][gdb3][DEBUG ]       }
[2017-07-06 02:23:12,164][gdb3][DEBUG ]     ]
[2017-07-06 02:23:12,164][gdb3][DEBUG ]   }, 
[2017-07-06 02:23:12,164][gdb3][DEBUG ]   "name": "gdb3", 
[2017-07-06 02:23:12,164][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-07-06 02:23:12,164][gdb3][DEBUG ]   "quorum": [
[2017-07-06 02:23:12,164][gdb3][DEBUG ]     0
[2017-07-06 02:23:12,164][gdb3][DEBUG ]   ], 
[2017-07-06 02:23:12,165][gdb3][DEBUG ]   "rank": 0, 
[2017-07-06 02:23:12,165][gdb3][DEBUG ]   "state": "leader", 
[2017-07-06 02:23:12,165][gdb3][DEBUG ]   "sync_provider": []
[2017-07-06 02:23:12,165][gdb3][DEBUG ] }
[2017-07-06 02:23:12,165][gdb3][DEBUG ] ********************************************************************************
[2017-07-06 02:23:12,165][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-07-06 02:23:12,166][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 02:23:12,231][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-07-06 02:23:12,246][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 02:23:12,260][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 02:23:12,260][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 02:23:12,277][gdb3][DEBUG ] detect machine type
[2017-07-06 02:23:12,279][gdb3][DEBUG ] find the location of an executable
[2017-07-06 02:23:12,280][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 02:23:12,345][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-07-06 02:23:12,345][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-07-06 02:23:12,345][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-07-06 02:23:12,347][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpkM5Xxd
[2017-07-06 02:23:12,362][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 02:23:12,375][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 02:23:12,376][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 02:23:12,392][gdb3][DEBUG ] detect machine type
[2017-07-06 02:23:12,394][gdb3][DEBUG ] get remote short hostname
[2017-07-06 02:23:12,395][gdb3][DEBUG ] fetch remote file
[2017-07-06 02:23:12,396][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 02:23:12,462][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-07-06 02:23:12,628][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-07-06 02:23:12,794][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-07-06 02:23:12,960][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-07-06 02:23:13,126][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-07-06 02:23:13,292][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-07-06 02:23:13,459][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-07-06 02:23:13,625][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-07-06 02:23:13,791][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-07-06 02:23:13,957][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-07-06 02:23:14,173][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-07-06 02:23:14,173][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-07-06 02:23:14,173][ceph_deploy.gatherkeys][INFO  ] Replacing 'ceph.bootstrap-mgr.keyring' and backing up old key as 'ceph.bootstrap-mgr.keyring-20170706022314'
[2017-07-06 02:23:14,173][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-07-06 02:23:14,173][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-07-06 02:23:14,174][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-07-06 02:23:14,174][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpkM5Xxd
[2017-07-06 02:23:14,355][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 02:23:14,355][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-07-06 02:23:14,355][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 02:23:14,356][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 02:23:14,356][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 02:23:14,356][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 02:23:14,356][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 02:23:14,356][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb7aab5b518>
[2017-07-06 02:23:14,356][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 02:23:14,356][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-07-06 02:23:14,356][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fb7ab472938>
[2017-07-06 02:23:14,356][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 02:23:14,356][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 02:23:14,356][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-07-06 02:23:14,382][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 02:23:14,396][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 02:23:14,396][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 02:23:14,412][gdb3][DEBUG ] detect machine type
[2017-07-06 02:23:14,415][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 02:23:22,016][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 02:23:22,017][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb1
[2017-07-06 02:23:22,017][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 02:23:22,017][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 02:23:22,017][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 02:23:22,017][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 02:23:22,017][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 02:23:22,017][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f1f0c685518>
[2017-07-06 02:23:22,017][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 02:23:22,017][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-07-06 02:23:22,017][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f1f0cf9c938>
[2017-07-06 02:23:22,017][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 02:23:22,018][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 02:23:22,018][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-07-06 02:23:22,277][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 02:23:22,520][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 02:23:22,520][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 02:23:22,538][gdb1][DEBUG ] detect machine type
[2017-07-06 02:23:22,542][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 02:23:22,718][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 02:23:22,718][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-07-06 02:23:22,718][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 02:23:22,718][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 02:23:22,718][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 02:23:22,718][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-06 02:23:22,718][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 02:23:22,718][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 02:23:22,718][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 02:23:22,718][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 02:23:22,719][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 02:23:22,719][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 02:23:22,719][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 02:23:22,719][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 02:23:22,719][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f696742b908>
[2017-07-06 02:23:22,719][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 02:23:22,719][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 02:23:22,719][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f6967681aa0>
[2017-07-06 02:23:22,719][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 02:23:22,719][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 02:23:22,719][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 02:23:22,719][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-07-06 02:23:22,962][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 02:23:23,156][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 02:23:23,157][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 02:23:23,174][gdb1][DEBUG ] detect machine type
[2017-07-06 02:23:23,178][gdb1][DEBUG ] find the location of an executable
[2017-07-06 02:23:23,179][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 02:23:23,179][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-07-06 02:23:23,179][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 02:23:23,182][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-07-06 02:23:23,182][gdb1][DEBUG ] find the location of an executable
[2017-07-06 02:23:23,184][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 02:23:23,304][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 02:23:23,320][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 02:23:23,336][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 02:23:23,343][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 02:23:23,359][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 02:23:23,375][gdb1][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-07-06 02:23:28,381][gdb1][INFO  ] checking OSD status...
[2017-07-06 02:23:28,382][gdb1][DEBUG ] find the location of an executable
[2017-07-06 02:23:28,384][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 02:23:28,599][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-07-06 02:23:28,762][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 02:23:28,763][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-07-06 02:23:28,763][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 02:23:28,763][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 02:23:28,763][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 02:23:28,763][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 02:23:28,763][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 02:23:28,763][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 02:23:28,763][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f22ddf5a908>
[2017-07-06 02:23:28,763][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 02:23:28,763][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f22de1b0aa0>
[2017-07-06 02:23:28,763][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 02:23:28,763][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 02:23:28,763][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-06 02:23:28,764][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-07-06 02:23:29,010][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 02:23:29,236][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 02:23:29,237][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 02:23:29,253][gdb1][DEBUG ] detect machine type
[2017-07-06 02:23:29,257][gdb1][DEBUG ] find the location of an executable
[2017-07-06 02:23:29,258][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 02:23:29,258][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-07-06 02:23:29,258][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 02:23:29,259][gdb1][DEBUG ] find the location of an executable
[2017-07-06 02:23:29,261][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 02:23:29,431][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 02:23:29,431][gdb1][WARNING] activate: Cluster uuid is 382eeac0-7e10-4bdc-98d7-53d22201d56d
[2017-07-06 02:23:29,431][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 02:23:29,431][gdb1][WARNING] Traceback (most recent call last):
[2017-07-06 02:23:29,431][gdb1][WARNING]   File "/usr/local/bin/ceph-disk", line 9, in <module>
[2017-07-06 02:23:29,432][gdb1][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-07-06 02:23:29,432][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5653, in run
[2017-07-06 02:23:29,432][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5604, in main
[2017-07-06 02:23:29,432][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3713, in main_activate
[2017-07-06 02:23:29,432][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3533, in activate_dir
[2017-07-06 02:23:29,432][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3609, in activate
[2017-07-06 02:23:29,432][gdb1][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid 382eeac0-7e10-4bdc-98d7-53d22201d56d
[2017-07-06 02:23:29,433][gdb1][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-07-06 02:23:29,433][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-07-06 18:30:58,884][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:30:58,885][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-07-06 18:30:58,885][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:30:58,885][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:30:58,885][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:30:58,885][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:30:58,885][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:30:58,885][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3b174dc128>
[2017-07-06 18:30:58,886][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:30:58,886][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-06 18:30:58,886][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f3b17de91b8>
[2017-07-06 18:30:58,886][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:30:58,886][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:30:58,886][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-07-06 18:30:58,886][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-07-06 18:30:58,886][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-07-06 18:30:58,886][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-07-06 18:30:58,912][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 18:30:58,928][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 18:30:58,928][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 18:30:58,945][gdb3][DEBUG ] detect machine type
[2017-07-06 18:30:58,948][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:30:58,948][gdb3][INFO  ] Purging Ceph on gdb3
[2017-07-06 18:30:58,949][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-07-06 18:30:58,987][gdb3][DEBUG ] Reading package lists...
[2017-07-06 18:30:59,152][gdb3][DEBUG ] Building dependency tree...
[2017-07-06 18:30:59,152][gdb3][DEBUG ] Reading state information...
[2017-07-06 18:30:59,216][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-07-06 18:30:59,216][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-07-06 18:30:59,216][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-07-06 18:30:59,217][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-07-06 18:30:59,217][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-07-06 18:30:59,217][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-07-06 18:30:59,217][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1016 linux-aws-headers-4.4.0-1017
[2017-07-06 18:30:59,217][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1018 linux-headers-4.4.0-1013-aws
[2017-07-06 18:30:59,217][gdb3][DEBUG ]   linux-headers-4.4.0-1016-aws linux-headers-4.4.0-1017-aws
[2017-07-06 18:30:59,217][gdb3][DEBUG ]   linux-headers-4.4.0-1018-aws linux-image-4.4.0-1013-aws
[2017-07-06 18:30:59,217][gdb3][DEBUG ]   linux-image-4.4.0-1016-aws linux-image-4.4.0-1017-aws
[2017-07-06 18:30:59,217][gdb3][DEBUG ]   linux-image-4.4.0-1018-aws ntp python-blinker python-cephfs
[2017-07-06 18:30:59,218][gdb3][DEBUG ]   python-cffi-backend python-chardet python-cryptography python-enum34
[2017-07-06 18:30:59,218][gdb3][DEBUG ]   python-flask python-idna python-ipaddress python-itsdangerous python-jinja2
[2017-07-06 18:30:59,218][gdb3][DEBUG ]   python-markupsafe python-ndg-httpsclient python-openssl python-pyasn1
[2017-07-06 18:30:59,218][gdb3][DEBUG ]   python-pyinotify python-rados python-rbd python-requests python-rgw
[2017-07-06 18:30:59,218][gdb3][DEBUG ]   python-six python-urllib3 python-werkzeug
[2017-07-06 18:30:59,218][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-07-06 18:30:59,250][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-07-06 18:30:59,250][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-07-06 18:30:59,364][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 60 not upgraded.
[2017-07-06 18:30:59,365][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-07-06 18:30:59,479][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 179644 files and directories currently installed.)
[2017-07-06 18:30:59,479][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-07-06 18:30:59,645][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-07-06 18:30:59,759][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-07-06 18:30:59,759][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-07-06 18:30:59,973][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-07-06 18:31:00,088][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-07-06 18:31:00,252][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-07-06 18:31:00,316][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-07-06 18:31:00,332][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-07-06 18:31:00,499][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-07-06 18:31:00,568][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-07-06 18:31:00,599][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-07-06 18:31:00,769][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-07-06 18:31:00,801][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-07-06 18:31:00,965][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-07-06 18:31:01,030][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-07-06 18:31:01,030][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-07-06 18:31:01,144][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu9) ...
[2017-07-06 18:31:01,960][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-07-06 18:31:02,123][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:31:02,124][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-07-06 18:31:02,124][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:31:02,124][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:31:02,124][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:31:02,124][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:31:02,124][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:31:02,124][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f54101b17a0>
[2017-07-06 18:31:02,124][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:31:02,124][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-06 18:31:02,124][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f5410abe230>
[2017-07-06 18:31:02,124][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:31:02,124][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:31:02,125][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-07-06 18:31:02,150][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 18:31:02,164][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 18:31:02,165][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 18:31:02,181][gdb3][DEBUG ] detect machine type
[2017-07-06 18:31:02,183][gdb3][DEBUG ] find the location of an executable
[2017-07-06 18:31:02,199][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 18:31:02,214][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 18:31:02,214][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 18:31:02,231][gdb3][DEBUG ] detect machine type
[2017-07-06 18:31:02,233][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:31:02,233][gdb3][INFO  ] purging data on gdb3
[2017-07-06 18:31:02,234][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-07-06 18:31:02,247][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-07-06 18:31:02,418][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:31:02,418][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-07-06 18:31:02,418][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:31:02,418][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:31:02,419][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:31:02,419][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:31:02,419][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:31:02,419][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f2c50662a70>
[2017-07-06 18:31:02,419][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:31:02,419][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7f2c50f25848>
[2017-07-06 18:31:02,419][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:31:02,419][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:31:17,389][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:31:17,389][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-07-06 18:31:17,389][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:31:17,389][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:31:17,389][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:31:17,389][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:31:17,389][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:31:17,390][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f30bc5aa5f0>
[2017-07-06 18:31:17,390][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:31:17,390][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-07-06 18:31:17,390][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-07-06 18:31:17,390][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f30bcc2e758>
[2017-07-06 18:31:17,390][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-07-06 18:31:17,390][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:31:17,390][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-07-06 18:31:17,390][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:31:17,390][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-07-06 18:31:17,390][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-07-06 18:31:17,390][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-07-06 18:31:17,416][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 18:31:17,430][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 18:31:17,431][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 18:31:17,447][gdb3][DEBUG ] detect machine type
[2017-07-06 18:31:17,450][gdb3][DEBUG ] find the location of an executable
[2017-07-06 18:31:17,451][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-07-06 18:31:17,462][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-07-06 18:31:17,468][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-07-06 18:31:17,469][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-07-06 18:31:17,469][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-07-06 18:31:17,469][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-07-06 18:31:17,469][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-07-06 18:31:17,469][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-07-06 18:31:17,469][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-07-06 18:31:17,469][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-07-06 18:31:17,635][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:31:17,636][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-07-06 18:31:17,636][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:31:17,636][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:31:17,636][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:31:17,636][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:31:17,636][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-07-06 18:31:17,636][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:31:17,636][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7109cb8ef0>
[2017-07-06 18:31:17,636][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:31:17,636][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f7109c8cb18>
[2017-07-06 18:31:17,636][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:31:17,637][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-07-06 18:31:17,637][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:31:17,637][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-07-06 18:31:17,637][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-07-06 18:31:17,663][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 18:31:17,677][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 18:31:17,678][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 18:31:17,694][gdb3][DEBUG ] detect machine type
[2017-07-06 18:31:17,696][gdb3][DEBUG ] find the location of an executable
[2017-07-06 18:31:17,697][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-07-06 18:31:17,697][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-07-06 18:31:17,697][gdb3][DEBUG ] get remote short hostname
[2017-07-06 18:31:17,697][gdb3][DEBUG ] deploying mon to gdb3
[2017-07-06 18:31:17,697][gdb3][DEBUG ] get remote short hostname
[2017-07-06 18:31:17,698][gdb3][DEBUG ] remote hostname: gdb3
[2017-07-06 18:31:17,698][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:31:17,700][gdb3][DEBUG ] create the mon path if it does not exist
[2017-07-06 18:31:17,700][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-06 18:31:17,700][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-06 18:31:17,701][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-06 18:31:17,701][gdb3][DEBUG ] create the monitor keyring file
[2017-07-06 18:31:17,702][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-07-06 18:31:17,740][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-07-06 18:31:17,740][gdb3][DEBUG ] ceph-mon: set fsid to d9c79ed7-5e4b-47a9-846d-15203f03f5c7
[2017-07-06 18:31:17,744][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-07-06 18:31:17,744][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-06 18:31:17,744][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-07-06 18:31:17,745][gdb3][DEBUG ] create the init path if it does not exist
[2017-07-06 18:31:17,746][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 18:31:17,815][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-07-06 18:31:17,884][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-07-06 18:31:19,954][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 18:31:20,020][gdb3][DEBUG ] ********************************************************************************
[2017-07-06 18:31:20,020][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-07-06 18:31:20,020][gdb3][DEBUG ] {
[2017-07-06 18:31:20,020][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-07-06 18:31:20,020][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-07-06 18:31:20,020][gdb3][DEBUG ]   "features": {
[2017-07-06 18:31:20,020][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-07-06 18:31:20,020][gdb3][DEBUG ]     "quorum_mon": [
[2017-07-06 18:31:20,020][gdb3][DEBUG ]       "kraken", 
[2017-07-06 18:31:20,020][gdb3][DEBUG ]       "luminous"
[2017-07-06 18:31:20,020][gdb3][DEBUG ]     ], 
[2017-07-06 18:31:20,021][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-07-06 18:31:20,021][gdb3][DEBUG ]     "required_mon": [
[2017-07-06 18:31:20,021][gdb3][DEBUG ]       "kraken", 
[2017-07-06 18:31:20,021][gdb3][DEBUG ]       "luminous"
[2017-07-06 18:31:20,021][gdb3][DEBUG ]     ]
[2017-07-06 18:31:20,021][gdb3][DEBUG ]   }, 
[2017-07-06 18:31:20,021][gdb3][DEBUG ]   "monmap": {
[2017-07-06 18:31:20,021][gdb3][DEBUG ]     "created": "2017-07-06 18:31:17.725432", 
[2017-07-06 18:31:20,021][gdb3][DEBUG ]     "epoch": 2, 
[2017-07-06 18:31:20,021][gdb3][DEBUG ]     "features": {
[2017-07-06 18:31:20,021][gdb3][DEBUG ]       "optional": [], 
[2017-07-06 18:31:20,021][gdb3][DEBUG ]       "persistent": [
[2017-07-06 18:31:20,021][gdb3][DEBUG ]         "kraken", 
[2017-07-06 18:31:20,021][gdb3][DEBUG ]         "luminous"
[2017-07-06 18:31:20,021][gdb3][DEBUG ]       ]
[2017-07-06 18:31:20,021][gdb3][DEBUG ]     }, 
[2017-07-06 18:31:20,022][gdb3][DEBUG ]     "fsid": "d9c79ed7-5e4b-47a9-846d-15203f03f5c7", 
[2017-07-06 18:31:20,022][gdb3][DEBUG ]     "modified": "2017-07-06 18:31:17.980197", 
[2017-07-06 18:31:20,022][gdb3][DEBUG ]     "mons": [
[2017-07-06 18:31:20,022][gdb3][DEBUG ]       {
[2017-07-06 18:31:20,022][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-07-06 18:31:20,022][gdb3][DEBUG ]         "name": "gdb3", 
[2017-07-06 18:31:20,022][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-07-06 18:31:20,022][gdb3][DEBUG ]         "rank": 0
[2017-07-06 18:31:20,022][gdb3][DEBUG ]       }
[2017-07-06 18:31:20,022][gdb3][DEBUG ]     ]
[2017-07-06 18:31:20,022][gdb3][DEBUG ]   }, 
[2017-07-06 18:31:20,022][gdb3][DEBUG ]   "name": "gdb3", 
[2017-07-06 18:31:20,022][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-07-06 18:31:20,022][gdb3][DEBUG ]   "quorum": [
[2017-07-06 18:31:20,022][gdb3][DEBUG ]     0
[2017-07-06 18:31:20,022][gdb3][DEBUG ]   ], 
[2017-07-06 18:31:20,022][gdb3][DEBUG ]   "rank": 0, 
[2017-07-06 18:31:20,023][gdb3][DEBUG ]   "state": "leader", 
[2017-07-06 18:31:20,023][gdb3][DEBUG ]   "sync_provider": []
[2017-07-06 18:31:20,023][gdb3][DEBUG ] }
[2017-07-06 18:31:20,023][gdb3][DEBUG ] ********************************************************************************
[2017-07-06 18:31:20,023][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-07-06 18:31:20,024][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 18:31:20,089][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-07-06 18:31:20,105][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 18:31:20,120][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 18:31:20,120][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 18:31:20,137][gdb3][DEBUG ] detect machine type
[2017-07-06 18:31:20,140][gdb3][DEBUG ] find the location of an executable
[2017-07-06 18:31:20,141][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 18:31:20,206][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-07-06 18:31:20,206][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-07-06 18:31:20,206][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-07-06 18:31:20,208][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpxyBJwj
[2017-07-06 18:31:20,224][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 18:31:20,238][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 18:31:20,239][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 18:31:20,255][gdb3][DEBUG ] detect machine type
[2017-07-06 18:31:20,258][gdb3][DEBUG ] get remote short hostname
[2017-07-06 18:31:20,258][gdb3][DEBUG ] fetch remote file
[2017-07-06 18:31:20,259][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 18:31:20,325][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-07-06 18:31:20,491][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-07-06 18:31:20,658][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-07-06 18:31:20,824][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-07-06 18:31:20,990][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-07-06 18:31:21,156][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-07-06 18:31:21,322][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-07-06 18:31:21,489][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-07-06 18:31:21,655][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-07-06 18:31:21,821][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-07-06 18:31:21,986][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-07-06 18:31:21,987][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-07-06 18:31:21,987][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mgr.keyring
[2017-07-06 18:31:21,987][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-07-06 18:31:21,987][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-07-06 18:31:21,987][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-07-06 18:31:21,987][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpxyBJwj
[2017-07-06 18:31:22,167][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:31:22,167][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-07-06 18:31:22,168][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:31:22,168][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:31:22,168][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:31:22,168][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:31:22,168][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:31:22,168][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f29991635a8>
[2017-07-06 18:31:22,168][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:31:22,168][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-07-06 18:31:22,168][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f2999a7a938>
[2017-07-06 18:31:22,168][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:31:22,168][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:31:22,168][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-07-06 18:31:22,195][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 18:31:22,209][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 18:31:22,210][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 18:31:22,226][gdb3][DEBUG ] detect machine type
[2017-07-06 18:31:22,229][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:35:17,099][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:35:17,099][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-07-06 18:35:17,099][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:35:17,099][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:35:17,099][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:35:17,099][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 18:35:17,099][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:35:17,100][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f480954b5a8>
[2017-07-06 18:35:17,100][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:35:17,100][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-07-06 18:35:17,100][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f4809e62938>
[2017-07-06 18:35:17,100][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:35:17,100][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:35:17,100][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-07-06 18:35:17,343][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:35:17,542][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:35:17,543][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:35:17,559][gdb0][DEBUG ] detect machine type
[2017-07-06 18:35:17,563][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:35:17,736][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:35:17,736][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-07-06 18:35:17,736][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:35:17,736][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:35:17,736][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 18:35:17,736][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 18:35:17,736][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 18:35:17,737][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:35:17,737][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 18:35:17,737][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 18:35:17,737][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:35:17,737][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 18:35:17,737][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 18:35:17,737][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:35:17,737][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f67b6cff998>
[2017-07-06 18:35:17,737][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:35:17,737][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 18:35:17,737][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f67b6f55aa0>
[2017-07-06 18:35:17,737][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:35:17,737][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:35:17,737][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 18:35:17,738][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 18:35:17,983][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:35:18,214][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:35:18,214][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:35:18,230][gdb0][DEBUG ] detect machine type
[2017-07-06 18:35:18,234][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:35:18,235][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:35:18,236][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-07-06 18:35:18,236][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:35:18,238][gdb0][WARNING] osd keyring does not exist yet, creating one
[2017-07-06 18:35:18,239][gdb0][DEBUG ] create a keyring file
[2017-07-06 18:35:18,241][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-07-06 18:35:18,241][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:35:18,243][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 18:35:18,414][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 18:35:18,414][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:35:18,414][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:35:18,414][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:35:18,430][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 18:35:18,437][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-07-06 18:35:23,450][gdb0][INFO  ] checking OSD status...
[2017-07-06 18:35:23,450][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:35:23,454][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 18:35:23,619][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-07-06 18:35:23,788][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:35:23,788][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-07-06 18:35:23,788][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:35:23,788][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:35:23,788][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:35:23,788][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:35:23,789][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 18:35:23,789][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:35:23,789][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f706c878998>
[2017-07-06 18:35:23,789][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:35:23,789][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f706caceaa0>
[2017-07-06 18:35:23,789][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:35:23,789][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:35:23,789][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 18:35:23,789][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 18:35:24,030][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:35:24,262][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:35:24,263][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:35:24,278][gdb0][DEBUG ] detect machine type
[2017-07-06 18:35:24,283][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:35:24,284][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:35:24,284][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-07-06 18:35:24,284][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 18:35:24,284][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:35:24,287][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 18:35:24,457][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 18:35:24,457][gdb0][WARNING] activate: Cluster uuid is f4f36e31-c61f-42db-97ec-96a4b3bd98b7
[2017-07-06 18:35:24,458][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 18:35:24,458][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=radosgw-sync --show-config-value=fsid
[2017-07-06 18:35:24,458][gdb0][WARNING] Traceback (most recent call last):
[2017-07-06 18:35:24,458][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-07-06 18:35:24,458][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-07-06 18:35:24,458][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-07-06 18:35:24,458][gdb0][WARNING]     main(sys.argv[1:])
[2017-07-06 18:35:24,458][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-07-06 18:35:24,458][gdb0][WARNING]     args.func(args)
[2017-07-06 18:35:24,458][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-07-06 18:35:24,458][gdb0][WARNING]     init=args.mark_init,
[2017-07-06 18:35:24,458][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-07-06 18:35:24,459][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-07-06 18:35:24,459][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3609, in activate
[2017-07-06 18:35:24,459][gdb0][WARNING]     ' with fsid %s' % ceph_fsid)
[2017-07-06 18:35:24,459][gdb0][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid f4f36e31-c61f-42db-97ec-96a4b3bd98b7
[2017-07-06 18:35:24,460][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-07-06 18:35:24,460][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-07-06 18:35:50,696][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:35:50,696][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-07-06 18:35:50,696][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:35:50,696][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:35:50,696][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:35:50,696][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 18:35:50,696][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:35:50,696][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9eaef8b5a8>
[2017-07-06 18:35:50,696][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:35:50,697][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-07-06 18:35:50,697][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f9eaf8a2938>
[2017-07-06 18:35:50,697][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:35:50,697][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:35:50,697][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-07-06 18:35:50,934][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:35:51,166][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:35:51,167][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:35:51,183][gdb0][DEBUG ] detect machine type
[2017-07-06 18:35:51,187][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:35:51,358][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:35:51,358][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-07-06 18:35:51,358][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:35:51,358][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:35:51,358][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 18:35:51,358][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 18:35:51,358][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 18:35:51,358][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:35:51,358][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 18:35:51,358][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 18:35:51,359][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:35:51,359][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 18:35:51,359][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 18:35:51,359][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:35:51,359][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3751237998>
[2017-07-06 18:35:51,359][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:35:51,359][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 18:35:51,359][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f375148daa0>
[2017-07-06 18:35:51,359][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:35:51,359][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:35:51,359][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 18:35:51,360][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 18:35:51,607][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:35:51,837][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:35:51,838][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:35:51,854][gdb0][DEBUG ] detect machine type
[2017-07-06 18:35:51,858][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:35:51,859][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:35:51,859][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-07-06 18:35:51,859][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:35:51,862][gdb0][WARNING] osd keyring does not exist yet, creating one
[2017-07-06 18:35:51,862][gdb0][DEBUG ] create a keyring file
[2017-07-06 18:35:51,864][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-07-06 18:35:51,864][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:35:51,866][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 18:35:52,037][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 18:35:52,037][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:35:52,037][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:35:52,037][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:35:52,053][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 18:35:52,060][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-07-06 18:35:57,073][gdb0][INFO  ] checking OSD status...
[2017-07-06 18:35:57,073][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:35:57,076][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 18:35:57,241][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-07-06 18:35:57,405][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:35:57,405][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-07-06 18:35:57,405][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:35:57,405][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:35:57,405][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:35:57,405][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:35:57,405][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 18:35:57,405][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:35:57,405][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fad1c5c1998>
[2017-07-06 18:35:57,405][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:35:57,406][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fad1c817aa0>
[2017-07-06 18:35:57,406][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:35:57,406][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:35:57,406][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 18:35:57,406][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 18:35:57,647][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:35:57,842][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:35:57,842][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:35:57,858][gdb0][DEBUG ] detect machine type
[2017-07-06 18:35:57,862][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:35:57,862][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:35:57,863][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-07-06 18:35:57,863][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 18:35:57,863][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:35:57,865][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 18:35:58,035][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 18:35:58,035][gdb0][WARNING] activate: Cluster uuid is f4f36e31-c61f-42db-97ec-96a4b3bd98b7
[2017-07-06 18:35:58,036][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 18:35:58,036][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=radosgw-sync --show-config-value=fsid
[2017-07-06 18:35:58,036][gdb0][WARNING] Traceback (most recent call last):
[2017-07-06 18:35:58,036][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-07-06 18:35:58,036][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-07-06 18:35:58,036][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-07-06 18:35:58,036][gdb0][WARNING]     main(sys.argv[1:])
[2017-07-06 18:35:58,036][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-07-06 18:35:58,036][gdb0][WARNING]     args.func(args)
[2017-07-06 18:35:58,036][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-07-06 18:35:58,036][gdb0][WARNING]     init=args.mark_init,
[2017-07-06 18:35:58,036][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-07-06 18:35:58,037][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-07-06 18:35:58,037][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3609, in activate
[2017-07-06 18:35:58,037][gdb0][WARNING]     ' with fsid %s' % ceph_fsid)
[2017-07-06 18:35:58,037][gdb0][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid f4f36e31-c61f-42db-97ec-96a4b3bd98b7
[2017-07-06 18:35:58,037][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-07-06 18:35:58,037][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-07-06 18:37:30,325][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:37:30,325][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-07-06 18:37:30,325][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:37:30,325][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:37:30,325][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:37:30,325][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 18:37:30,325][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:37:30,325][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7bfa6765a8>
[2017-07-06 18:37:30,326][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:37:30,326][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-07-06 18:37:30,326][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f7bfaf8d938>
[2017-07-06 18:37:30,326][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:37:30,326][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:37:30,326][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-07-06 18:37:30,654][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:37:30,898][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:37:30,898][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:37:30,930][gdb0][DEBUG ] detect machine type
[2017-07-06 18:37:30,934][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:37:31,105][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:37:31,105][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-07-06 18:37:31,105][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:37:31,105][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:37:31,106][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 18:37:31,106][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 18:37:31,106][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 18:37:31,106][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:37:31,106][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 18:37:31,106][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 18:37:31,106][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:37:31,106][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 18:37:31,106][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 18:37:31,106][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:37:31,106][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f5038bc5998>
[2017-07-06 18:37:31,106][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:37:31,106][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 18:37:31,106][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f5038e1baa0>
[2017-07-06 18:37:31,107][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:37:31,107][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:37:31,107][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 18:37:31,107][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 18:37:31,342][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:37:31,569][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:37:31,570][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:37:31,586][gdb0][DEBUG ] detect machine type
[2017-07-06 18:37:31,589][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:37:31,590][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:37:31,590][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-07-06 18:37:31,590][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:37:31,593][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-07-06 18:37:31,593][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:37:31,595][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 18:37:31,916][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 18:37:32,181][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:37:32,181][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:37:32,181][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:37:32,197][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 18:37:32,213][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-07-06 18:37:37,219][gdb0][INFO  ] checking OSD status...
[2017-07-06 18:37:37,219][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:37:37,222][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 18:37:37,488][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-07-06 18:37:37,653][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:37:37,653][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-07-06 18:37:37,653][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:37:37,653][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:37:37,653][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:37:37,653][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:37:37,653][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 18:37:37,653][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:37:37,654][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6b83048998>
[2017-07-06 18:37:37,654][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:37:37,654][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f6b8329eaa0>
[2017-07-06 18:37:37,654][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:37:37,654][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:37:37,654][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 18:37:37,654][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 18:37:37,891][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:37:38,118][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:37:38,119][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:37:38,135][gdb0][DEBUG ] detect machine type
[2017-07-06 18:37:38,139][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:37:38,140][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:37:38,140][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-07-06 18:37:38,140][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 18:37:38,140][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:37:38,142][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 18:37:38,313][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 18:37:38,313][gdb0][WARNING] activate: Cluster uuid is f4f36e31-c61f-42db-97ec-96a4b3bd98b7
[2017-07-06 18:37:38,313][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 18:37:38,313][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=radosgw-sync --show-config-value=fsid
[2017-07-06 18:37:38,313][gdb0][WARNING] Traceback (most recent call last):
[2017-07-06 18:37:38,313][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-07-06 18:37:38,313][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-07-06 18:37:38,313][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-07-06 18:37:38,313][gdb0][WARNING]     main(sys.argv[1:])
[2017-07-06 18:37:38,313][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-07-06 18:37:38,314][gdb0][WARNING]     args.func(args)
[2017-07-06 18:37:38,314][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-07-06 18:37:38,314][gdb0][WARNING]     init=args.mark_init,
[2017-07-06 18:37:38,314][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-07-06 18:37:38,314][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-07-06 18:37:38,314][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3609, in activate
[2017-07-06 18:37:38,314][gdb0][WARNING]     ' with fsid %s' % ceph_fsid)
[2017-07-06 18:37:38,314][gdb0][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid f4f36e31-c61f-42db-97ec-96a4b3bd98b7
[2017-07-06 18:37:38,314][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-07-06 18:37:38,314][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-07-06 18:38:12,296][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:38:12,296][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-07-06 18:38:12,297][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:38:12,297][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:38:12,297][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:38:12,297][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 18:38:12,297][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:38:12,297][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fac7e0825a8>
[2017-07-06 18:38:12,297][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:38:12,297][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-07-06 18:38:12,297][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fac7e999938>
[2017-07-06 18:38:12,297][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:38:12,297][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:38:12,297][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-07-06 18:38:12,538][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:38:12,770][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:38:12,770][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:38:12,786][gdb0][DEBUG ] detect machine type
[2017-07-06 18:38:12,790][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:38:12,963][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:38:12,963][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-07-06 18:38:12,963][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:38:12,963][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:38:12,963][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 18:38:12,963][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 18:38:12,963][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 18:38:12,964][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:38:12,964][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 18:38:12,964][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 18:38:12,964][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:38:12,964][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 18:38:12,964][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 18:38:12,964][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:38:12,964][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9f889c2998>
[2017-07-06 18:38:12,964][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:38:12,964][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 18:38:12,964][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f9f88c18aa0>
[2017-07-06 18:38:12,964][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:38:12,964][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:38:12,965][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 18:38:12,965][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 18:38:13,207][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:38:13,437][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:38:13,438][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:38:13,454][gdb0][DEBUG ] detect machine type
[2017-07-06 18:38:13,458][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:38:13,459][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:38:13,460][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-07-06 18:38:13,460][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:38:13,462][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-07-06 18:38:13,462][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:38:13,465][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 18:38:13,635][gdb0][WARNING] Traceback (most recent call last):
[2017-07-06 18:38:13,636][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-07-06 18:38:13,636][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-07-06 18:38:13,636][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-07-06 18:38:13,636][gdb0][WARNING]     main(sys.argv[1:])
[2017-07-06 18:38:13,636][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-07-06 18:38:13,636][gdb0][WARNING]     args.func(args)
[2017-07-06 18:38:13,636][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2029, in main
[2017-07-06 18:38:13,636][gdb0][WARNING]     Prepare.factory(args).prepare()
[2017-07-06 18:38:13,636][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2025, in factory
[2017-07-06 18:38:13,636][gdb0][WARNING]     return PrepareFilestore(args)
[2017-07-06 18:38:13,636][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2037, in __init__
[2017-07-06 18:38:13,637][gdb0][WARNING]     self.data = PrepareFilestoreData(args)
[2017-07-06 18:38:13,637][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2739, in __init__
[2017-07-06 18:38:13,637][gdb0][WARNING]     self.set_type()
[2017-07-06 18:38:13,637][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2747, in set_type
[2017-07-06 18:38:13,637][gdb0][WARNING]     dmode = os.stat(self.args.data).st_mode
[2017-07-06 18:38:13,637][gdb0][WARNING] OSError: [Errno 2] No such file or directory: '/mnt/memstore'
[2017-07-06 18:38:13,637][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-07-06 18:38:13,637][ceph_deploy.osd][ERROR ] Failed to execute command: /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 18:38:13,637][ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs

[2017-07-06 18:38:13,810][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:38:13,811][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-07-06 18:38:13,811][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:38:13,811][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:38:13,811][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:38:13,811][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:38:13,811][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 18:38:13,811][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:38:13,811][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fdb59dad998>
[2017-07-06 18:38:13,811][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:38:13,811][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fdb5a003aa0>
[2017-07-06 18:38:13,812][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:38:13,812][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:38:13,812][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 18:38:13,812][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 18:38:14,054][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:38:14,290][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:38:14,290][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:38:14,306][gdb0][DEBUG ] detect machine type
[2017-07-06 18:38:14,310][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:38:14,311][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:38:14,311][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-07-06 18:38:14,311][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 18:38:14,311][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:38:14,313][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 18:38:14,484][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 18:38:14,484][gdb0][WARNING] Traceback (most recent call last):
[2017-07-06 18:38:14,484][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-07-06 18:38:14,484][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-07-06 18:38:14,484][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-07-06 18:38:14,484][gdb0][WARNING]     main(sys.argv[1:])
[2017-07-06 18:38:14,484][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-07-06 18:38:14,484][gdb0][WARNING]     args.func(args)
[2017-07-06 18:38:14,484][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3684, in main_activate
[2017-07-06 18:38:14,485][gdb0][WARNING]     raise Error('%s does not exist' % args.path)
[2017-07-06 18:38:14,485][gdb0][WARNING] ceph_disk.main.Error: Error: /mnt/memstore does not exist
[2017-07-06 18:38:14,485][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-07-06 18:38:14,485][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-07-06 18:38:24,125][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:38:24,125][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-07-06 18:38:24,125][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:38:24,125][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:38:24,125][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:38:24,126][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 18:38:24,126][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:38:24,126][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe8baaf45a8>
[2017-07-06 18:38:24,126][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:38:24,126][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-07-06 18:38:24,126][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fe8bb40b938>
[2017-07-06 18:38:24,126][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:38:24,126][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:38:24,126][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-07-06 18:38:24,370][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:38:24,598][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:38:24,599][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:38:24,615][gdb0][DEBUG ] detect machine type
[2017-07-06 18:38:24,619][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:38:24,790][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:38:24,790][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-07-06 18:38:24,790][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:38:24,790][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:38:24,790][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 18:38:24,790][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 18:38:24,790][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 18:38:24,790][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:38:24,791][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 18:38:24,791][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 18:38:24,791][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:38:24,791][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 18:38:24,791][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 18:38:24,791][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:38:24,791][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9e6cfc2998>
[2017-07-06 18:38:24,791][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:38:24,791][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 18:38:24,791][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f9e6d218aa0>
[2017-07-06 18:38:24,791][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:38:24,791][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:38:24,791][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 18:38:24,792][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 18:38:25,026][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:38:25,257][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:38:25,258][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:38:25,274][gdb0][DEBUG ] detect machine type
[2017-07-06 18:38:25,278][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:38:25,279][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:38:25,279][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-07-06 18:38:25,279][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:38:25,282][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-07-06 18:38:25,282][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:38:25,284][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 18:38:25,454][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 18:38:25,454][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:38:25,454][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:38:25,455][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:38:25,462][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 18:38:25,478][gdb0][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-07-06 18:38:25,478][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.2762.tmp
[2017-07-06 18:38:25,481][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.2762.tmp
[2017-07-06 18:38:25,485][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.2762.tmp
[2017-07-06 18:38:30,506][gdb0][INFO  ] checking OSD status...
[2017-07-06 18:38:30,506][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:38:30,509][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 18:38:30,674][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-07-06 18:38:30,841][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:38:30,841][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-07-06 18:38:30,842][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:38:30,842][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:38:30,842][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:38:30,842][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:38:30,842][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 18:38:30,842][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:38:30,842][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe58ddae998>
[2017-07-06 18:38:30,842][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:38:30,842][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fe58e004aa0>
[2017-07-06 18:38:30,842][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:38:30,842][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:38:30,842][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 18:38:30,843][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 18:38:31,078][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:38:31,302][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:38:31,302][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:38:31,318][gdb0][DEBUG ] detect machine type
[2017-07-06 18:38:31,322][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:38:31,323][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:38:31,323][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-07-06 18:38:31,323][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 18:38:31,323][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:38:31,325][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 18:38:31,496][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 18:38:31,496][gdb0][WARNING] activate: Cluster uuid is d9c79ed7-5e4b-47a9-846d-15203f03f5c7
[2017-07-06 18:38:31,496][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 18:38:31,496][gdb0][WARNING] activate: Cluster name is ceph
[2017-07-06 18:38:31,496][gdb0][WARNING] activate: OSD uuid is 5024f09f-19bb-476f-bab1-0f7a0fcf9002
[2017-07-06 18:38:31,496][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-07-06 18:38:31,497][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 5024f09f-19bb-476f-bab1-0f7a0fcf9002
[2017-07-06 18:38:31,611][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.2904.tmp
[2017-07-06 18:38:31,612][gdb0][WARNING] activate: OSD id is 0
[2017-07-06 18:38:31,612][gdb0][WARNING] activate: Initializing OSD...
[2017-07-06 18:38:31,612][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-07-06 18:38:31,777][gdb0][WARNING] got monmap epoch 2
[2017-07-06 18:38:31,777][gdb0][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 0 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid 5024f09f-19bb-476f-bab1-0f7a0fcf9002 --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-07-06 18:38:34,500][gdb0][WARNING] Traceback (most recent call last):
[2017-07-06 18:38:34,500][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-07-06 18:38:34,500][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-07-06 18:38:34,500][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-07-06 18:38:34,500][gdb0][WARNING]     main(sys.argv[1:])
[2017-07-06 18:38:34,500][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-07-06 18:38:34,501][gdb0][WARNING]     args.func(args)
[2017-07-06 18:38:34,501][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-07-06 18:38:34,501][gdb0][WARNING]     init=args.mark_init,
[2017-07-06 18:38:34,501][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-07-06 18:38:34,501][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-07-06 18:38:34,501][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3638, in activate
[2017-07-06 18:38:34,501][gdb0][WARNING]     keyring=keyring,
[2017-07-06 18:38:34,501][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3076, in mkfs
[2017-07-06 18:38:34,501][gdb0][WARNING]     '--setgroup', get_ceph_group(),
[2017-07-06 18:38:34,501][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3023, in ceph_osd_mkfs
[2017-07-06 18:38:34,501][gdb0][WARNING]     raise Error('%s failed : %s' % (str(arguments), error))
[2017-07-06 18:38:34,501][gdb0][WARNING] ceph_disk.main.Error: Error: ['ceph-osd', '--cluster', 'ceph', '--mkfs', '--mkkey', '-i', u'0', '--monmap', '/mnt/memstore/activate.monmap', '--osd-data', '/mnt/memstore', '--osd-journal', '/mnt/memstore/journal', '--osd-uuid', u'5024f09f-19bb-476f-bab1-0f7a0fcf9002', '--keyring', '/mnt/memstore/keyring', '--setuser', 'ceph', '--setgroup', 'ceph'] failed : /home/ubuntu/ceph/src/os/memstore/MemStore.cc: In function 'virtual void MemStore::set_fsid(uuid_d)' thread 7f6d5dd52c80 time 2017-07-06 18:38:31.773009
[2017-07-06 18:38:34,501][gdb0][WARNING] /home/ubuntu/ceph/src/os/memstore/MemStore.cc: 176: FAILED assert(r >= 0)
[2017-07-06 18:38:34,501][gdb0][WARNING]  ceph version 12.0.1-1208-gab9e841 (ab9e8419ec962af158b94a85533509edce622db0)
[2017-07-06 18:38:34,502][gdb0][WARNING]  1: (ceph::__ceph_assert_fail(char const*, char const*, int, char const*)+0x102) [0x56270143a072]
[2017-07-06 18:38:34,502][gdb0][WARNING]  2: (MemStore::set_fsid(uuid_d)+0xc8) [0x56270120c128]
[2017-07-06 18:38:34,502][gdb0][WARNING]  3: (OSD::mkfs(CephContext*, ObjectStore*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, uuid_d, int)+0x13f) [0x562700e5ae5f]
[2017-07-06 18:38:34,502][gdb0][WARNING]  4: (main()+0x1043) [0x562700e257c3]
[2017-07-06 18:38:34,502][gdb0][WARNING]  5: (__libc_start_main()+0xf0) [0x7f6d5b1bc830]
[2017-07-06 18:38:34,502][gdb0][WARNING]  6: (_start()+0x29) [0x562700e33cc9]
[2017-07-06 18:38:34,502][gdb0][WARNING]  NOTE: a copy of the executable, or `objdump -rdS <executable>` is needed to interpret this.
[2017-07-06 18:38:34,502][gdb0][WARNING] 2017-07-06 18:38:31.786310 7f6d5dd52c80 -1 /home/ubuntu/ceph/src/os/memstore/MemStore.cc: In function 'virtual void MemStore::set_fsid(uuid_d)' thread 7f6d5dd52c80 time 2017-07-06 18:38:31.773009
[2017-07-06 18:38:34,502][gdb0][WARNING] /home/ubuntu/ceph/src/os/memstore/MemStore.cc: 176: FAILED assert(r >= 0)
[2017-07-06 18:38:34,502][gdb0][WARNING] 
[2017-07-06 18:38:34,502][gdb0][WARNING]  ceph version 12.0.1-1208-gab9e841 (ab9e8419ec962af158b94a85533509edce622db0)
[2017-07-06 18:38:34,502][gdb0][WARNING]  1: (ceph::__ceph_assert_fail(char const*, char const*, int, char const*)+0x102) [0x56270143a072]
[2017-07-06 18:38:34,502][gdb0][WARNING]  2: (MemStore::set_fsid(uuid_d)+0xc8) [0x56270120c128]
[2017-07-06 18:38:34,502][gdb0][WARNING]  3: (OSD::mkfs(CephContext*, ObjectStore*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, uuid_d, int)+0x13f) [0x562700e5ae5f]
[2017-07-06 18:38:34,503][gdb0][WARNING]  4: (main()+0x1043) [0x562700e257c3]
[2017-07-06 18:38:34,503][gdb0][WARNING]  5: (__libc_start_main()+0xf0) [0x7f6d5b1bc830]
[2017-07-06 18:38:34,503][gdb0][WARNING]  6: (_start()+0x29) [0x562700e33cc9]
[2017-07-06 18:38:34,503][gdb0][WARNING]  NOTE: a copy of the executable, or `objdump -rdS <executable>` is needed to interpret this.
[2017-07-06 18:38:34,503][gdb0][WARNING] 
[2017-07-06 18:38:34,503][gdb0][WARNING]      0> 2017-07-06 18:38:31.786310 7f6d5dd52c80 -1 /home/ubuntu/ceph/src/os/memstore/MemStore.cc: In function 'virtual void MemStore::set_fsid(uuid_d)' thread 7f6d5dd52c80 time 2017-07-06 18:38:31.773009
[2017-07-06 18:38:34,503][gdb0][WARNING] /home/ubuntu/ceph/src/os/memstore/MemStore.cc: 176: FAILED assert(r >= 0)
[2017-07-06 18:38:34,503][gdb0][WARNING] 
[2017-07-06 18:38:34,503][gdb0][WARNING]  ceph version 12.0.1-1208-gab9e841 (ab9e8419ec962af158b94a85533509edce622db0)
[2017-07-06 18:38:34,503][gdb0][WARNING]  1: (ceph::__ceph_assert_fail(char const*, char const*, int, char const*)+0x102) [0x56270143a072]
[2017-07-06 18:38:34,503][gdb0][WARNING]  2: (MemStore::set_fsid(uuid_d)+0xc8) [0x56270120c128]
[2017-07-06 18:38:34,503][gdb0][WARNING]  3: (OSD::mkfs(CephContext*, ObjectStore*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, uuid_d, int)+0x13f) [0x562700e5ae5f]
[2017-07-06 18:38:34,503][gdb0][WARNING]  4: (main()+0x1043) [0x562700e257c3]
[2017-07-06 18:38:34,503][gdb0][WARNING]  5: (__libc_start_main()+0xf0) [0x7f6d5b1bc830]
[2017-07-06 18:38:34,504][gdb0][WARNING]  6: (_start()+0x29) [0x562700e33cc9]
[2017-07-06 18:38:34,504][gdb0][WARNING]  NOTE: a copy of the executable, or `objdump -rdS <executable>` is needed to interpret this.
[2017-07-06 18:38:34,504][gdb0][WARNING] 
[2017-07-06 18:38:34,504][gdb0][WARNING] *** Caught signal (Aborted) **
[2017-07-06 18:38:34,504][gdb0][WARNING]  in thread 7f6d5dd52c80 thread_name:ceph-osd
[2017-07-06 18:38:34,504][gdb0][WARNING]  ceph version 12.0.1-1208-gab9e841 (ab9e8419ec962af158b94a85533509edce622db0)
[2017-07-06 18:38:34,504][gdb0][WARNING]  1: (()+0xcab9b2) [0x5627013d69b2]
[2017-07-06 18:38:34,504][gdb0][WARNING]  2: (()+0x11390) [0x7f6d5c236390]
[2017-07-06 18:38:34,504][gdb0][WARNING]  3: (gsignal()+0x38) [0x7f6d5b1d1428]
[2017-07-06 18:38:34,504][gdb0][WARNING]  4: (abort()+0x16a) [0x7f6d5b1d302a]
[2017-07-06 18:38:34,504][gdb0][WARNING]  5: (ceph::__ceph_assert_fail(char const*, char const*, int, char const*)+0x28e) [0x56270143a1fe]
[2017-07-06 18:38:34,504][gdb0][WARNING]  6: (MemStore::set_fsid(uuid_d)+0xc8) [0x56270120c128]
[2017-07-06 18:38:34,504][gdb0][WARNING]  7: (OSD::mkfs(CephContext*, ObjectStore*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, uuid_d, int)+0x13f) [0x562700e5ae5f]
[2017-07-06 18:38:34,504][gdb0][WARNING]  8: (main()+0x1043) [0x562700e257c3]
[2017-07-06 18:38:34,505][gdb0][WARNING]  9: (__libc_start_main()+0xf0) [0x7f6d5b1bc830]
[2017-07-06 18:38:34,505][gdb0][WARNING]  10: (_start()+0x29) [0x562700e33cc9]
[2017-07-06 18:38:34,505][gdb0][WARNING] 2017-07-06 18:38:31.789348 7f6d5dd52c80 -1 *** Caught signal (Aborted) **
[2017-07-06 18:38:34,505][gdb0][WARNING]  in thread 7f6d5dd52c80 thread_name:ceph-osd
[2017-07-06 18:38:34,505][gdb0][WARNING] 
[2017-07-06 18:38:34,505][gdb0][WARNING]  ceph version 12.0.1-1208-gab9e841 (ab9e8419ec962af158b94a85533509edce622db0)
[2017-07-06 18:38:34,505][gdb0][WARNING]  1: (()+0xcab9b2) [0x5627013d69b2]
[2017-07-06 18:38:34,505][gdb0][WARNING]  2: (()+0x11390) [0x7f6d5c236390]
[2017-07-06 18:38:34,505][gdb0][WARNING]  3: (gsignal()+0x38) [0x7f6d5b1d1428]
[2017-07-06 18:38:34,505][gdb0][WARNING]  4: (abort()+0x16a) [0x7f6d5b1d302a]
[2017-07-06 18:38:34,505][gdb0][WARNING]  5: (ceph::__ceph_assert_fail(char const*, char const*, int, char const*)+0x28e) [0x56270143a1fe]
[2017-07-06 18:38:34,505][gdb0][WARNING]  6: (MemStore::set_fsid(uuid_d)+0xc8) [0x56270120c128]
[2017-07-06 18:38:34,505][gdb0][WARNING]  7: (OSD::mkfs(CephContext*, ObjectStore*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, uuid_d, int)+0x13f) [0x562700e5ae5f]
[2017-07-06 18:38:34,505][gdb0][WARNING]  8: (main()+0x1043) [0x562700e257c3]
[2017-07-06 18:38:34,505][gdb0][WARNING]  9: (__libc_start_main()+0xf0) [0x7f6d5b1bc830]
[2017-07-06 18:38:34,506][gdb0][WARNING]  10: (_start()+0x29) [0x562700e33cc9]
[2017-07-06 18:38:34,506][gdb0][WARNING]  NOTE: a copy of the executable, or `objdump -rdS <executable>` is needed to interpret this.
[2017-07-06 18:38:34,506][gdb0][WARNING] 
[2017-07-06 18:38:34,506][gdb0][WARNING]      0> 2017-07-06 18:38:31.789348 7f6d5dd52c80 -1 *** Caught signal (Aborted) **
[2017-07-06 18:38:34,506][gdb0][WARNING]  in thread 7f6d5dd52c80 thread_name:ceph-osd
[2017-07-06 18:38:34,506][gdb0][WARNING] 
[2017-07-06 18:38:34,506][gdb0][WARNING]  ceph version 12.0.1-1208-gab9e841 (ab9e8419ec962af158b94a85533509edce622db0)
[2017-07-06 18:38:34,506][gdb0][WARNING]  1: (()+0xcab9b2) [0x5627013d69b2]
[2017-07-06 18:38:34,506][gdb0][WARNING]  2: (()+0x11390) [0x7f6d5c236390]
[2017-07-06 18:38:34,506][gdb0][WARNING]  3: (gsignal()+0x38) [0x7f6d5b1d1428]
[2017-07-06 18:38:34,506][gdb0][WARNING]  4: (abort()+0x16a) [0x7f6d5b1d302a]
[2017-07-06 18:38:34,506][gdb0][WARNING]  5: (ceph::__ceph_assert_fail(char const*, char const*, int, char const*)+0x28e) [0x56270143a1fe]
[2017-07-06 18:38:34,506][gdb0][WARNING]  6: (MemStore::set_fsid(uuid_d)+0xc8) [0x56270120c128]
[2017-07-06 18:38:34,506][gdb0][WARNING]  7: (OSD::mkfs(CephContext*, ObjectStore*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, uuid_d, int)+0x13f) [0x562700e5ae5f]
[2017-07-06 18:38:34,507][gdb0][WARNING]  8: (main()+0x1043) [0x562700e257c3]
[2017-07-06 18:38:34,507][gdb0][WARNING]  9: (__libc_start_main()+0xf0) [0x7f6d5b1bc830]
[2017-07-06 18:38:34,507][gdb0][WARNING]  10: (_start()+0x29) [0x562700e33cc9]
[2017-07-06 18:38:34,507][gdb0][WARNING]  NOTE: a copy of the executable, or `objdump -rdS <executable>` is needed to interpret this.
[2017-07-06 18:38:34,507][gdb0][WARNING] 
[2017-07-06 18:38:34,507][gdb0][WARNING] /usr/bin/timeout: the monitored command dumped core
[2017-07-06 18:38:34,507][gdb0][WARNING] 
[2017-07-06 18:38:34,507][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-07-06 18:38:34,507][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-07-06 18:39:22,387][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:39:22,387][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-07-06 18:39:22,387][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:39:22,387][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:39:22,388][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:39:22,388][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:39:22,388][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:39:22,388][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa40079a128>
[2017-07-06 18:39:22,388][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:39:22,388][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-06 18:39:22,388][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7fa4010a71b8>
[2017-07-06 18:39:22,388][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:39:22,388][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:39:22,388][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-07-06 18:39:22,388][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-07-06 18:39:22,388][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-07-06 18:39:22,388][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-07-06 18:39:22,414][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 18:39:22,429][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 18:39:22,430][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 18:39:22,446][gdb3][DEBUG ] detect machine type
[2017-07-06 18:39:22,449][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:39:22,449][gdb3][INFO  ] Purging Ceph on gdb3
[2017-07-06 18:39:22,450][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-07-06 18:39:22,487][gdb3][DEBUG ] Reading package lists...
[2017-07-06 18:39:22,652][gdb3][DEBUG ] Building dependency tree...
[2017-07-06 18:39:22,652][gdb3][DEBUG ] Reading state information...
[2017-07-06 18:39:22,716][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-07-06 18:39:22,716][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-07-06 18:39:22,716][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-07-06 18:39:22,716][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-07-06 18:39:22,716][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-07-06 18:39:22,716][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-07-06 18:39:22,717][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1016 linux-aws-headers-4.4.0-1017
[2017-07-06 18:39:22,717][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1018 linux-headers-4.4.0-1013-aws
[2017-07-06 18:39:22,717][gdb3][DEBUG ]   linux-headers-4.4.0-1016-aws linux-headers-4.4.0-1017-aws
[2017-07-06 18:39:22,717][gdb3][DEBUG ]   linux-headers-4.4.0-1018-aws linux-image-4.4.0-1013-aws
[2017-07-06 18:39:22,717][gdb3][DEBUG ]   linux-image-4.4.0-1016-aws linux-image-4.4.0-1017-aws
[2017-07-06 18:39:22,717][gdb3][DEBUG ]   linux-image-4.4.0-1018-aws ntp python-blinker python-cephfs
[2017-07-06 18:39:22,717][gdb3][DEBUG ]   python-cffi-backend python-chardet python-cryptography python-enum34
[2017-07-06 18:39:22,717][gdb3][DEBUG ]   python-flask python-idna python-ipaddress python-itsdangerous python-jinja2
[2017-07-06 18:39:22,717][gdb3][DEBUG ]   python-markupsafe python-ndg-httpsclient python-openssl python-pyasn1
[2017-07-06 18:39:22,717][gdb3][DEBUG ]   python-pyinotify python-rados python-rbd python-requests python-rgw
[2017-07-06 18:39:22,717][gdb3][DEBUG ]   python-six python-urllib3 python-werkzeug
[2017-07-06 18:39:22,717][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-07-06 18:39:22,749][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-07-06 18:39:22,749][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-07-06 18:39:22,863][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 60 not upgraded.
[2017-07-06 18:39:22,864][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-07-06 18:39:22,978][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 179644 files and directories currently installed.)
[2017-07-06 18:39:22,978][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-07-06 18:39:23,142][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-07-06 18:39:23,207][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-07-06 18:39:23,239][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-07-06 18:39:23,453][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-07-06 18:39:23,568][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-07-06 18:39:23,732][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-07-06 18:39:23,796][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-07-06 18:39:23,860][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-07-06 18:39:24,025][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-07-06 18:39:24,057][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-07-06 18:39:24,089][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-07-06 18:39:24,254][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-07-06 18:39:24,318][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-07-06 18:39:24,433][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-07-06 18:39:24,547][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-07-06 18:39:24,547][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-07-06 18:39:24,611][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu9) ...
[2017-07-06 18:39:25,427][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-07-06 18:39:25,592][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:39:25,592][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-07-06 18:39:25,592][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:39:25,592][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:39:25,593][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:39:25,593][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:39:25,593][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:39:25,593][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f1da83fa7a0>
[2017-07-06 18:39:25,593][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:39:25,593][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-06 18:39:25,593][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f1da8d07230>
[2017-07-06 18:39:25,593][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:39:25,593][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:39:25,593][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-07-06 18:39:25,620][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 18:39:25,633][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 18:39:25,634][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 18:39:25,650][gdb3][DEBUG ] detect machine type
[2017-07-06 18:39:25,653][gdb3][DEBUG ] find the location of an executable
[2017-07-06 18:39:25,668][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 18:39:25,681][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 18:39:25,682][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 18:39:25,698][gdb3][DEBUG ] detect machine type
[2017-07-06 18:39:25,700][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:39:25,700][gdb3][INFO  ] purging data on gdb3
[2017-07-06 18:39:25,701][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-07-06 18:39:25,714][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-07-06 18:39:25,884][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:39:25,884][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-07-06 18:39:25,884][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:39:25,885][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:39:25,885][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:39:25,885][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:39:25,885][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:39:25,885][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3a28432a70>
[2017-07-06 18:39:25,885][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:39:25,885][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7f3a28cf5848>
[2017-07-06 18:39:25,885][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:39:25,885][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:39:42,187][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:39:42,188][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-07-06 18:39:42,188][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:39:42,188][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:39:42,188][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:39:42,188][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:39:42,188][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:39:42,188][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f10d40bb5f0>
[2017-07-06 18:39:42,188][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:39:42,188][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-07-06 18:39:42,188][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-07-06 18:39:42,188][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f10d473f758>
[2017-07-06 18:39:42,188][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-07-06 18:39:42,189][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:39:42,189][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-07-06 18:39:42,189][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:39:42,189][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-07-06 18:39:42,189][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-07-06 18:39:42,189][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-07-06 18:39:42,215][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 18:39:42,229][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 18:39:42,230][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 18:39:42,246][gdb3][DEBUG ] detect machine type
[2017-07-06 18:39:42,248][gdb3][DEBUG ] find the location of an executable
[2017-07-06 18:39:42,249][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-07-06 18:39:42,261][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-07-06 18:39:42,267][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-07-06 18:39:42,267][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-07-06 18:39:42,267][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-07-06 18:39:42,267][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-07-06 18:39:42,267][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-07-06 18:39:42,267][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-07-06 18:39:42,267][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-07-06 18:39:42,268][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-07-06 18:39:42,433][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:39:42,433][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-07-06 18:39:42,434][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:39:42,434][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:39:42,434][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:39:42,434][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:39:42,434][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-07-06 18:39:42,434][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:39:42,434][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3cda9b6ef0>
[2017-07-06 18:39:42,434][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:39:42,434][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f3cda98ab18>
[2017-07-06 18:39:42,434][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:39:42,434][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-07-06 18:39:42,434][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:39:42,435][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-07-06 18:39:42,435][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-07-06 18:39:42,462][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 18:39:42,476][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 18:39:42,476][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 18:39:42,493][gdb3][DEBUG ] detect machine type
[2017-07-06 18:39:42,495][gdb3][DEBUG ] find the location of an executable
[2017-07-06 18:39:42,496][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-07-06 18:39:42,496][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-07-06 18:39:42,496][gdb3][DEBUG ] get remote short hostname
[2017-07-06 18:39:42,496][gdb3][DEBUG ] deploying mon to gdb3
[2017-07-06 18:39:42,496][gdb3][DEBUG ] get remote short hostname
[2017-07-06 18:39:42,497][gdb3][DEBUG ] remote hostname: gdb3
[2017-07-06 18:39:42,497][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:39:42,499][gdb3][DEBUG ] create the mon path if it does not exist
[2017-07-06 18:39:42,499][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-06 18:39:42,499][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-06 18:39:42,500][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-06 18:39:42,500][gdb3][DEBUG ] create the monitor keyring file
[2017-07-06 18:39:42,501][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-07-06 18:39:42,539][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-07-06 18:39:42,539][gdb3][DEBUG ] ceph-mon: set fsid to 6a195b40-ec45-48cb-bc3d-fd87024626be
[2017-07-06 18:39:42,543][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-07-06 18:39:42,544][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-06 18:39:42,544][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-07-06 18:39:42,545][gdb3][DEBUG ] create the init path if it does not exist
[2017-07-06 18:39:42,546][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 18:39:42,618][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-07-06 18:39:42,692][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-07-06 18:39:44,730][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 18:39:44,795][gdb3][DEBUG ] ********************************************************************************
[2017-07-06 18:39:44,796][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-07-06 18:39:44,796][gdb3][DEBUG ] {
[2017-07-06 18:39:44,796][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-07-06 18:39:44,796][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-07-06 18:39:44,796][gdb3][DEBUG ]   "features": {
[2017-07-06 18:39:44,796][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-07-06 18:39:44,796][gdb3][DEBUG ]     "quorum_mon": [
[2017-07-06 18:39:44,796][gdb3][DEBUG ]       "kraken", 
[2017-07-06 18:39:44,796][gdb3][DEBUG ]       "luminous"
[2017-07-06 18:39:44,796][gdb3][DEBUG ]     ], 
[2017-07-06 18:39:44,796][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-07-06 18:39:44,796][gdb3][DEBUG ]     "required_mon": [
[2017-07-06 18:39:44,797][gdb3][DEBUG ]       "kraken", 
[2017-07-06 18:39:44,797][gdb3][DEBUG ]       "luminous"
[2017-07-06 18:39:44,797][gdb3][DEBUG ]     ]
[2017-07-06 18:39:44,797][gdb3][DEBUG ]   }, 
[2017-07-06 18:39:44,797][gdb3][DEBUG ]   "monmap": {
[2017-07-06 18:39:44,797][gdb3][DEBUG ]     "created": "2017-07-06 18:39:42.524956", 
[2017-07-06 18:39:44,797][gdb3][DEBUG ]     "epoch": 2, 
[2017-07-06 18:39:44,797][gdb3][DEBUG ]     "features": {
[2017-07-06 18:39:44,797][gdb3][DEBUG ]       "optional": [], 
[2017-07-06 18:39:44,797][gdb3][DEBUG ]       "persistent": [
[2017-07-06 18:39:44,797][gdb3][DEBUG ]         "kraken", 
[2017-07-06 18:39:44,797][gdb3][DEBUG ]         "luminous"
[2017-07-06 18:39:44,797][gdb3][DEBUG ]       ]
[2017-07-06 18:39:44,797][gdb3][DEBUG ]     }, 
[2017-07-06 18:39:44,797][gdb3][DEBUG ]     "fsid": "6a195b40-ec45-48cb-bc3d-fd87024626be", 
[2017-07-06 18:39:44,797][gdb3][DEBUG ]     "modified": "2017-07-06 18:39:42.802587", 
[2017-07-06 18:39:44,798][gdb3][DEBUG ]     "mons": [
[2017-07-06 18:39:44,798][gdb3][DEBUG ]       {
[2017-07-06 18:39:44,798][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-07-06 18:39:44,798][gdb3][DEBUG ]         "name": "gdb3", 
[2017-07-06 18:39:44,798][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-07-06 18:39:44,798][gdb3][DEBUG ]         "rank": 0
[2017-07-06 18:39:44,798][gdb3][DEBUG ]       }
[2017-07-06 18:39:44,798][gdb3][DEBUG ]     ]
[2017-07-06 18:39:44,798][gdb3][DEBUG ]   }, 
[2017-07-06 18:39:44,798][gdb3][DEBUG ]   "name": "gdb3", 
[2017-07-06 18:39:44,798][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-07-06 18:39:44,798][gdb3][DEBUG ]   "quorum": [
[2017-07-06 18:39:44,798][gdb3][DEBUG ]     0
[2017-07-06 18:39:44,798][gdb3][DEBUG ]   ], 
[2017-07-06 18:39:44,798][gdb3][DEBUG ]   "rank": 0, 
[2017-07-06 18:39:44,798][gdb3][DEBUG ]   "state": "leader", 
[2017-07-06 18:39:44,799][gdb3][DEBUG ]   "sync_provider": []
[2017-07-06 18:39:44,799][gdb3][DEBUG ] }
[2017-07-06 18:39:44,799][gdb3][DEBUG ] ********************************************************************************
[2017-07-06 18:39:44,799][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-07-06 18:39:44,800][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 18:39:44,865][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-07-06 18:39:44,880][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 18:39:44,894][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 18:39:44,894][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 18:39:44,910][gdb3][DEBUG ] detect machine type
[2017-07-06 18:39:44,913][gdb3][DEBUG ] find the location of an executable
[2017-07-06 18:39:44,914][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 18:39:44,979][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-07-06 18:39:44,979][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-07-06 18:39:44,979][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-07-06 18:39:44,981][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmp5BI6G7
[2017-07-06 18:39:44,996][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 18:39:45,010][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 18:39:45,011][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 18:39:45,027][gdb3][DEBUG ] detect machine type
[2017-07-06 18:39:45,029][gdb3][DEBUG ] get remote short hostname
[2017-07-06 18:39:45,030][gdb3][DEBUG ] fetch remote file
[2017-07-06 18:39:45,031][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 18:39:45,097][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-07-06 18:39:45,263][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-07-06 18:39:45,429][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-07-06 18:39:45,595][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-07-06 18:39:45,761][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-07-06 18:39:45,927][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-07-06 18:39:46,094][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-07-06 18:39:46,260][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-07-06 18:39:46,426][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-07-06 18:39:46,592][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-07-06 18:39:46,757][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-07-06 18:39:46,758][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-07-06 18:39:46,758][ceph_deploy.gatherkeys][INFO  ] Replacing 'ceph.bootstrap-mgr.keyring' and backing up old key as 'ceph.bootstrap-mgr.keyring-20170706183946'
[2017-07-06 18:39:46,758][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-07-06 18:39:46,758][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-07-06 18:39:46,758][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-07-06 18:39:46,758][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmp5BI6G7
[2017-07-06 18:39:46,938][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:39:46,938][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-07-06 18:39:46,938][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:39:46,938][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:39:46,938][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:39:46,938][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:39:46,938][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:39:46,938][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f5d0f20d5a8>
[2017-07-06 18:39:46,938][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:39:46,939][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-07-06 18:39:46,939][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f5d0fb24938>
[2017-07-06 18:39:46,939][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:39:46,939][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:39:46,939][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-07-06 18:39:46,965][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 18:39:46,979][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 18:39:46,979][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 18:39:46,996][gdb3][DEBUG ] detect machine type
[2017-07-06 18:39:46,998][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:40:00,418][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:40:00,419][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-07-06 18:40:00,419][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:40:00,419][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:40:00,419][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:40:00,419][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 18:40:00,419][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:40:00,419][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9c59e935a8>
[2017-07-06 18:40:00,419][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:40:00,419][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-07-06 18:40:00,419][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f9c5a7aa938>
[2017-07-06 18:40:00,419][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:40:00,420][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:40:00,420][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-07-06 18:40:00,662][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:40:00,890][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:40:00,890][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:40:00,906][gdb0][DEBUG ] detect machine type
[2017-07-06 18:40:00,910][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:40:01,079][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:40:01,079][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-07-06 18:40:01,079][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:40:01,079][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:40:01,079][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 18:40:01,079][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 18:40:01,079][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 18:40:01,079][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:40:01,079][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 18:40:01,080][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 18:40:01,080][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:40:01,080][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 18:40:01,080][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 18:40:01,080][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:40:01,080][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa0edab0998>
[2017-07-06 18:40:01,080][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:40:01,080][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 18:40:01,080][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fa0edd06aa0>
[2017-07-06 18:40:01,080][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:40:01,080][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:40:01,080][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 18:40:01,081][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 18:40:01,319][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:40:01,550][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:40:01,550][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:40:01,567][gdb0][DEBUG ] detect machine type
[2017-07-06 18:40:01,570][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:40:01,571][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:40:01,571][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-07-06 18:40:01,571][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:40:01,574][gdb0][WARNING] osd keyring does not exist yet, creating one
[2017-07-06 18:40:01,574][gdb0][DEBUG ] create a keyring file
[2017-07-06 18:40:01,576][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-07-06 18:40:01,576][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:40:01,578][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 18:40:01,748][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 18:40:01,748][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:40:01,748][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:40:01,748][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:40:01,764][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 18:40:01,772][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-07-06 18:40:06,785][gdb0][INFO  ] checking OSD status...
[2017-07-06 18:40:06,785][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:40:06,787][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 18:40:06,953][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-07-06 18:40:07,117][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:40:07,117][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-07-06 18:40:07,117][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:40:07,117][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:40:07,117][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:40:07,118][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:40:07,118][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 18:40:07,118][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:40:07,118][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f5240165998>
[2017-07-06 18:40:07,118][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:40:07,118][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f52403bbaa0>
[2017-07-06 18:40:07,118][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:40:07,118][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:40:07,118][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 18:40:07,118][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 18:40:07,358][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:40:07,586][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:40:07,586][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:40:07,602][gdb0][DEBUG ] detect machine type
[2017-07-06 18:40:07,606][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:40:07,607][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:40:07,607][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-07-06 18:40:07,608][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 18:40:07,608][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:40:07,610][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 18:40:07,780][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 18:40:07,780][gdb0][WARNING] activate: Cluster uuid is d9c79ed7-5e4b-47a9-846d-15203f03f5c7
[2017-07-06 18:40:07,781][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 18:40:07,781][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=radosgw-sync --show-config-value=fsid
[2017-07-06 18:40:07,781][gdb0][WARNING] Traceback (most recent call last):
[2017-07-06 18:40:07,781][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-07-06 18:40:07,781][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-07-06 18:40:07,781][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-07-06 18:40:07,781][gdb0][WARNING]     main(sys.argv[1:])
[2017-07-06 18:40:07,781][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-07-06 18:40:07,781][gdb0][WARNING]     args.func(args)
[2017-07-06 18:40:07,781][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-07-06 18:40:07,781][gdb0][WARNING]     init=args.mark_init,
[2017-07-06 18:40:07,781][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-07-06 18:40:07,781][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-07-06 18:40:07,782][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3609, in activate
[2017-07-06 18:40:07,782][gdb0][WARNING]     ' with fsid %s' % ceph_fsid)
[2017-07-06 18:40:07,782][gdb0][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid d9c79ed7-5e4b-47a9-846d-15203f03f5c7
[2017-07-06 18:40:07,782][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-07-06 18:40:07,782][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-07-06 18:40:22,212][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:40:22,213][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb0
[2017-07-06 18:40:22,213][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:40:22,213][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:40:22,213][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:40:22,213][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:40:22,213][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:40:22,213][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe20b2ce5a8>
[2017-07-06 18:40:22,213][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:40:22,213][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-07-06 18:40:22,213][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fe20bbe5938>
[2017-07-06 18:40:22,213][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:40:22,213][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:40:22,214][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-07-06 18:40:22,451][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:40:22,678][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:40:22,679][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:40:22,695][gdb0][DEBUG ] detect machine type
[2017-07-06 18:40:22,699][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:40:26,353][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:40:26,353][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-07-06 18:40:26,353][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:40:26,353][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:40:26,353][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:40:26,353][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 18:40:26,353][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:40:26,353][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f8d50de55a8>
[2017-07-06 18:40:26,353][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:40:26,353][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-07-06 18:40:26,354][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f8d516fc938>
[2017-07-06 18:40:26,354][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:40:26,354][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:40:26,354][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-07-06 18:40:26,590][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:40:26,818][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:40:26,818][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:40:26,834][gdb0][DEBUG ] detect machine type
[2017-07-06 18:40:26,838][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:40:27,011][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:40:27,011][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-07-06 18:40:27,011][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:40:27,011][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:40:27,011][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 18:40:27,011][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 18:40:27,012][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 18:40:27,012][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:40:27,012][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 18:40:27,012][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 18:40:27,012][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:40:27,012][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 18:40:27,012][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 18:40:27,012][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:40:27,012][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f649244f998>
[2017-07-06 18:40:27,012][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:40:27,012][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 18:40:27,012][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f64926a5aa0>
[2017-07-06 18:40:27,012][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:40:27,012][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:40:27,012][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 18:40:27,013][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 18:40:27,250][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:40:27,478][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:40:27,478][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:40:27,495][gdb0][DEBUG ] detect machine type
[2017-07-06 18:40:27,499][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:40:27,500][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:40:27,500][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-07-06 18:40:27,500][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:40:27,503][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-07-06 18:40:27,503][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:40:27,505][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 18:40:27,675][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 18:40:27,676][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:40:27,676][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:40:27,676][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:40:27,683][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 18:40:27,691][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-07-06 18:40:32,712][gdb0][INFO  ] checking OSD status...
[2017-07-06 18:40:32,712][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:40:32,715][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 18:40:32,880][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-07-06 18:40:33,045][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:40:33,045][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-07-06 18:40:33,046][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:40:33,046][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:40:33,046][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:40:33,046][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:40:33,046][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 18:40:33,046][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:40:33,046][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ff3319f8998>
[2017-07-06 18:40:33,046][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:40:33,046][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7ff331c4eaa0>
[2017-07-06 18:40:33,046][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:40:33,046][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:40:33,046][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 18:40:33,047][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 18:40:33,286][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:40:33,510][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:40:33,511][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:40:33,526][gdb0][DEBUG ] detect machine type
[2017-07-06 18:40:33,530][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:40:33,531][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:40:33,531][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-07-06 18:40:33,531][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 18:40:33,531][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:40:33,533][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 18:40:33,704][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 18:40:33,704][gdb0][WARNING] activate: Cluster uuid is d9c79ed7-5e4b-47a9-846d-15203f03f5c7
[2017-07-06 18:40:33,704][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 18:40:33,704][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=radosgw-sync --show-config-value=fsid
[2017-07-06 18:40:33,704][gdb0][WARNING] Traceback (most recent call last):
[2017-07-06 18:40:33,704][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-07-06 18:40:33,704][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-07-06 18:40:33,704][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-07-06 18:40:33,704][gdb0][WARNING]     main(sys.argv[1:])
[2017-07-06 18:40:33,705][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-07-06 18:40:33,705][gdb0][WARNING]     args.func(args)
[2017-07-06 18:40:33,705][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-07-06 18:40:33,705][gdb0][WARNING]     init=args.mark_init,
[2017-07-06 18:40:33,705][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-07-06 18:40:33,705][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-07-06 18:40:33,705][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3609, in activate
[2017-07-06 18:40:33,705][gdb0][WARNING]     ' with fsid %s' % ceph_fsid)
[2017-07-06 18:40:33,705][gdb0][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid d9c79ed7-5e4b-47a9-846d-15203f03f5c7
[2017-07-06 18:40:33,705][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-07-06 18:40:33,706][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-07-06 18:40:54,849][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:40:54,850][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-07-06 18:40:54,850][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:40:54,850][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:40:54,850][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:40:54,850][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 18:40:54,850][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:40:54,850][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f18e0aa45a8>
[2017-07-06 18:40:54,850][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:40:54,850][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-07-06 18:40:54,850][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f18e13bb938>
[2017-07-06 18:40:54,850][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:40:54,850][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:40:54,851][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-07-06 18:40:55,086][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:40:55,274][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:40:55,275][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:40:55,291][gdb0][DEBUG ] detect machine type
[2017-07-06 18:40:55,295][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:40:55,466][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:40:55,466][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-07-06 18:40:55,466][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:40:55,467][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:40:55,467][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 18:40:55,467][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 18:40:55,467][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 18:40:55,467][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:40:55,467][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 18:40:55,467][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 18:40:55,467][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:40:55,467][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 18:40:55,467][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 18:40:55,467][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:40:55,467][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7911401998>
[2017-07-06 18:40:55,467][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:40:55,467][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 18:40:55,467][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f7911657aa0>
[2017-07-06 18:40:55,468][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:40:55,468][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:40:55,468][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 18:40:55,468][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 18:40:55,710][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:40:55,933][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:40:55,934][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:40:55,950][gdb0][DEBUG ] detect machine type
[2017-07-06 18:40:55,954][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:40:55,955][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:40:55,955][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-07-06 18:40:55,955][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:40:55,957][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-07-06 18:40:55,957][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:40:55,959][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 18:40:56,130][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 18:40:56,130][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:40:56,130][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:40:56,130][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:40:56,138][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 18:40:56,154][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-07-06 18:41:01,162][gdb0][INFO  ] checking OSD status...
[2017-07-06 18:41:01,163][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:41:01,165][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 18:41:01,330][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-07-06 18:41:01,496][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:41:01,496][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-07-06 18:41:01,497][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:41:01,497][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:41:01,497][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:41:01,497][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:41:01,497][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 18:41:01,497][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:41:01,497][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fcd715cb998>
[2017-07-06 18:41:01,497][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:41:01,497][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fcd71821aa0>
[2017-07-06 18:41:01,497][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:41:01,497][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:41:01,497][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 18:41:01,498][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 18:41:01,734][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:41:01,962][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:41:01,963][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:41:01,978][gdb0][DEBUG ] detect machine type
[2017-07-06 18:41:01,982][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:41:01,983][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:41:01,983][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-07-06 18:41:01,983][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 18:41:01,983][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:41:01,985][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 18:41:02,156][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 18:41:02,156][gdb0][WARNING] activate: Cluster uuid is d9c79ed7-5e4b-47a9-846d-15203f03f5c7
[2017-07-06 18:41:02,156][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 18:41:02,156][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=radosgw-sync --show-config-value=fsid
[2017-07-06 18:41:02,156][gdb0][WARNING] Traceback (most recent call last):
[2017-07-06 18:41:02,156][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-07-06 18:41:02,156][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-07-06 18:41:02,156][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-07-06 18:41:02,156][gdb0][WARNING]     main(sys.argv[1:])
[2017-07-06 18:41:02,156][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-07-06 18:41:02,157][gdb0][WARNING]     args.func(args)
[2017-07-06 18:41:02,157][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-07-06 18:41:02,157][gdb0][WARNING]     init=args.mark_init,
[2017-07-06 18:41:02,157][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-07-06 18:41:02,157][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-07-06 18:41:02,157][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3609, in activate
[2017-07-06 18:41:02,157][gdb0][WARNING]     ' with fsid %s' % ceph_fsid)
[2017-07-06 18:41:02,157][gdb0][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid d9c79ed7-5e4b-47a9-846d-15203f03f5c7
[2017-07-06 18:41:02,157][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-07-06 18:41:02,157][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-07-06 18:41:40,662][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:41:40,662][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-07-06 18:41:40,663][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:41:40,663][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:41:40,663][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:41:40,663][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 18:41:40,663][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:41:40,663][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fba9524d5a8>
[2017-07-06 18:41:40,663][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:41:40,663][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-07-06 18:41:40,663][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fba95b64938>
[2017-07-06 18:41:40,663][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:41:40,663][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:41:40,663][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-07-06 18:41:40,910][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:41:41,151][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:41:41,152][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:41:41,168][gdb0][DEBUG ] detect machine type
[2017-07-06 18:41:41,172][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:41:41,344][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:41:41,345][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-07-06 18:41:41,345][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:41:41,345][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:41:41,345][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 18:41:41,345][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 18:41:41,345][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 18:41:41,345][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:41:41,345][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 18:41:41,345][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 18:41:41,345][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:41:41,345][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 18:41:41,346][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 18:41:41,346][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:41:41,346][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f5ee97d3998>
[2017-07-06 18:41:41,346][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:41:41,346][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 18:41:41,346][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f5ee9a29aa0>
[2017-07-06 18:41:41,346][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:41:41,346][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:41:41,346][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 18:41:41,346][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 18:41:41,587][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:41:41,810][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:41:41,811][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:41:41,826][gdb0][DEBUG ] detect machine type
[2017-07-06 18:41:41,831][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:41:41,832][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:41:41,832][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-07-06 18:41:41,832][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:41:41,835][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-07-06 18:41:41,835][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:41:41,837][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 18:41:42,008][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 18:41:42,008][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:41:42,008][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:41:42,008][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 18:41:42,024][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 18:41:42,031][gdb0][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-07-06 18:41:42,033][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.4400.tmp
[2017-07-06 18:41:42,036][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.4400.tmp
[2017-07-06 18:41:42,044][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.4400.tmp
[2017-07-06 18:41:47,056][gdb0][INFO  ] checking OSD status...
[2017-07-06 18:41:47,057][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:41:47,059][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 18:41:47,224][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-07-06 18:41:47,392][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:41:47,392][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-07-06 18:41:47,392][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:41:47,392][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:41:47,392][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:41:47,393][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:41:47,393][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 18:41:47,393][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:41:47,393][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f07421b5998>
[2017-07-06 18:41:47,393][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:41:47,393][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f074240baa0>
[2017-07-06 18:41:47,393][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:41:47,393][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:41:47,393][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 18:41:47,393][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 18:41:47,634][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:41:47,866][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:41:47,866][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:41:47,882][gdb0][DEBUG ] detect machine type
[2017-07-06 18:41:47,886][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:41:47,887][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:41:47,887][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-07-06 18:41:47,887][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 18:41:47,887][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:41:47,889][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 18:41:48,060][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 18:41:48,060][gdb0][WARNING] activate: Cluster uuid is 6a195b40-ec45-48cb-bc3d-fd87024626be
[2017-07-06 18:41:48,060][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 18:41:48,060][gdb0][WARNING] activate: Cluster name is ceph
[2017-07-06 18:41:48,060][gdb0][WARNING] activate: OSD uuid is 6a8e4b37-08e3-4944-8c5e-ef8953af6211
[2017-07-06 18:41:48,060][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-07-06 18:41:48,060][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 6a8e4b37-08e3-4944-8c5e-ef8953af6211
[2017-07-06 18:41:48,225][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.4584.tmp
[2017-07-06 18:41:48,225][gdb0][WARNING] activate: OSD id is 0
[2017-07-06 18:41:48,225][gdb0][WARNING] activate: Initializing OSD...
[2017-07-06 18:41:48,225][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-07-06 18:41:48,389][gdb0][WARNING] got monmap epoch 2
[2017-07-06 18:41:48,389][gdb0][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 0 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid 6a8e4b37-08e3-4944-8c5e-ef8953af6211 --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-07-06 18:41:48,393][gdb0][WARNING] activate: Marking with init system systemd
[2017-07-06 18:41:48,393][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-07-06 18:41:48,393][gdb0][WARNING] activate: Authorizing OSD key...
[2017-07-06 18:41:48,393][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.0 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-07-06 18:41:48,558][gdb0][WARNING] added key for osd.0
[2017-07-06 18:41:48,558][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.4584.tmp
[2017-07-06 18:41:48,558][gdb0][WARNING] activate: ceph osd.0 data dir is ready at /mnt/memstore
[2017-07-06 18:41:48,558][gdb0][WARNING] activate_dir: Creating symlink /var/lib/ceph/osd/ceph-0 -> /mnt/memstore
[2017-07-06 18:41:48,558][gdb0][WARNING] start_daemon: Starting ceph osd.0...
[2017-07-06 18:41:48,558][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0
[2017-07-06 18:41:48,558][gdb0][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service.
[2017-07-06 18:41:48,622][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0 --runtime
[2017-07-06 18:41:48,736][gdb0][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@0
[2017-07-06 18:41:48,736][gdb0][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service to /lib/systemd/system/ceph-osd@.service.
[2017-07-06 18:41:48,752][gdb0][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@0
[2017-07-06 18:41:53,872][gdb0][INFO  ] checking OSD status...
[2017-07-06 18:41:53,872][gdb0][DEBUG ] find the location of an executable
[2017-07-06 18:41:53,874][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 18:41:54,042][gdb0][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 18:44:07,086][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:44:07,087][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy rgw create gdb0
[2017-07-06 18:44:07,087][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:44:07,087][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:44:07,087][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:44:07,087][ceph_deploy.cli][INFO  ]  rgw                           : [('gdb0', 'rgw.gdb0')]
[2017-07-06 18:44:07,087][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:44:07,087][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-06 18:44:07,087][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:44:07,087][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0f81647830>
[2017-07-06 18:44:07,087][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:44:07,087][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7f0f81d08758>
[2017-07-06 18:44:07,088][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:44:07,088][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:44:07,088][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts gdb0:rgw.gdb0
[2017-07-06 18:44:07,330][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:44:07,562][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:44:07,562][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:44:07,579][gdb0][DEBUG ] detect machine type
[2017-07-06 18:44:07,583][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:44:07,583][ceph_deploy.rgw][DEBUG ] remote host will use systemd
[2017-07-06 18:44:07,583][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to gdb0
[2017-07-06 18:44:07,583][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:44:07,586][gdb0][DEBUG ] create path recursively if it doesn't exist
[2017-07-06 18:44:07,588][gdb0][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.gdb0 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.gdb0/keyring
[2017-07-06 18:44:07,705][gdb0][ERROR ] 2017-07-06 18:44:07.656025 7f777b3c4700  0 librados: client.bootstrap-rgw authentication error (1) Operation not permitted
[2017-07-06 18:44:07,706][gdb0][ERROR ] error connecting to the cluster
[2017-07-06 18:44:07,706][gdb0][ERROR ] exit code from command was: 1
[2017-07-06 18:44:07,706][ceph_deploy.rgw][ERROR ] could not create rgw
[2017-07-06 18:44:07,706][ceph_deploy][ERROR ] GenericError: Failed to create 1 RGWs

[2017-07-06 18:44:28,774][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:44:28,774][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy rgw create gdb0
[2017-07-06 18:44:28,774][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:44:28,774][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:44:28,775][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:44:28,775][ceph_deploy.cli][INFO  ]  rgw                           : [('gdb0', 'rgw.gdb0')]
[2017-07-06 18:44:28,775][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:44:28,775][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-06 18:44:28,775][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:44:28,775][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa514f16830>
[2017-07-06 18:44:28,775][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:44:28,775][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7fa5155d7758>
[2017-07-06 18:44:28,775][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:44:28,775][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:44:28,775][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts gdb0:rgw.gdb0
[2017-07-06 18:44:29,014][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:44:29,241][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:44:29,242][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:44:29,258][gdb0][DEBUG ] detect machine type
[2017-07-06 18:44:29,262][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:44:29,262][ceph_deploy.rgw][DEBUG ] remote host will use systemd
[2017-07-06 18:44:29,263][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to gdb0
[2017-07-06 18:44:29,263][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:44:29,266][gdb0][DEBUG ] create path recursively if it doesn't exist
[2017-07-06 18:44:29,268][gdb0][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.gdb0 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.gdb0/keyring
[2017-07-06 18:44:29,385][gdb0][ERROR ] 2017-07-06 18:44:29.335963 7f15a7998700  0 librados: client.bootstrap-rgw authentication error (1) Operation not permitted
[2017-07-06 18:44:29,385][gdb0][ERROR ] error connecting to the cluster
[2017-07-06 18:44:29,385][gdb0][ERROR ] exit code from command was: 1
[2017-07-06 18:44:29,386][ceph_deploy.rgw][ERROR ] could not create rgw
[2017-07-06 18:44:29,386][ceph_deploy][ERROR ] GenericError: Failed to create 1 RGWs

[2017-07-06 18:45:51,733][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:45:51,734][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb0
[2017-07-06 18:45:51,734][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:45:51,734][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:45:51,734][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:45:51,734][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:45:51,734][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:45:51,734][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f8a61a035a8>
[2017-07-06 18:45:51,734][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:45:51,734][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-07-06 18:45:51,734][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f8a6231a938>
[2017-07-06 18:45:51,735][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:45:51,735][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:45:51,735][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-07-06 18:45:51,975][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:45:52,166][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:45:52,166][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:45:52,182][gdb0][DEBUG ] detect machine type
[2017-07-06 18:45:52,186][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:45:55,096][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:45:55,097][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy rgw create gdb0
[2017-07-06 18:45:55,097][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:45:55,097][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:45:55,097][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:45:55,097][ceph_deploy.cli][INFO  ]  rgw                           : [('gdb0', 'rgw.gdb0')]
[2017-07-06 18:45:55,097][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:45:55,097][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-06 18:45:55,097][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:45:55,097][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fbb66e14830>
[2017-07-06 18:45:55,097][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:45:55,097][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7fbb674d5758>
[2017-07-06 18:45:55,097][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:45:55,097][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:45:55,098][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts gdb0:rgw.gdb0
[2017-07-06 18:45:55,334][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:45:55,570][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:45:55,570][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:45:55,586][gdb0][DEBUG ] detect machine type
[2017-07-06 18:45:55,590][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:45:55,591][ceph_deploy.rgw][DEBUG ] remote host will use systemd
[2017-07-06 18:45:55,591][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to gdb0
[2017-07-06 18:45:55,591][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:45:55,594][gdb0][DEBUG ] create path recursively if it doesn't exist
[2017-07-06 18:45:55,596][gdb0][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.gdb0 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.gdb0/keyring
[2017-07-06 18:45:55,713][gdb0][ERROR ] 2017-07-06 18:45:55.663719 7ff7abbae700  0 librados: client.bootstrap-rgw authentication error (1) Operation not permitted
[2017-07-06 18:45:55,713][gdb0][ERROR ] error connecting to the cluster
[2017-07-06 18:45:55,713][gdb0][ERROR ] exit code from command was: 1
[2017-07-06 18:45:55,713][ceph_deploy.rgw][ERROR ] could not create rgw
[2017-07-06 18:45:55,713][ceph_deploy][ERROR ] GenericError: Failed to create 1 RGWs

[2017-07-06 18:45:58,613][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:45:58,613][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy rgw create gdb0
[2017-07-06 18:45:58,613][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:45:58,613][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:45:58,614][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:45:58,614][ceph_deploy.cli][INFO  ]  rgw                           : [('gdb0', 'rgw.gdb0')]
[2017-07-06 18:45:58,614][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:45:58,614][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-06 18:45:58,614][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:45:58,614][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fc56d8c7830>
[2017-07-06 18:45:58,614][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:45:58,614][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7fc56df88758>
[2017-07-06 18:45:58,614][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:45:58,614][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:45:58,614][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts gdb0:rgw.gdb0
[2017-07-06 18:45:58,858][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:45:59,086][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:45:59,086][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:45:59,102][gdb0][DEBUG ] detect machine type
[2017-07-06 18:45:59,106][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:45:59,106][ceph_deploy.rgw][DEBUG ] remote host will use systemd
[2017-07-06 18:45:59,106][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to gdb0
[2017-07-06 18:45:59,106][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:45:59,109][gdb0][DEBUG ] create path recursively if it doesn't exist
[2017-07-06 18:45:59,111][gdb0][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.gdb0 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.gdb0/keyring
[2017-07-06 18:45:59,229][gdb0][ERROR ] 2017-07-06 18:45:59.178107 7f03e3d9c700  0 librados: client.bootstrap-rgw authentication error (1) Operation not permitted
[2017-07-06 18:45:59,229][gdb0][ERROR ] error connecting to the cluster
[2017-07-06 18:45:59,229][gdb0][ERROR ] exit code from command was: 1
[2017-07-06 18:45:59,229][ceph_deploy.rgw][ERROR ] could not create rgw
[2017-07-06 18:45:59,229][ceph_deploy][ERROR ] GenericError: Failed to create 1 RGWs

[2017-07-06 18:48:38,874][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:48:38,874][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy rgw create gdb0
[2017-07-06 18:48:38,874][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:48:38,874][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:48:38,874][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:48:38,874][ceph_deploy.cli][INFO  ]  rgw                           : [('gdb0', 'rgw.gdb0')]
[2017-07-06 18:48:38,875][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:48:38,875][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-06 18:48:38,875][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:48:38,875][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fd426d61878>
[2017-07-06 18:48:38,875][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:48:38,875][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7fd427422758>
[2017-07-06 18:48:38,875][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:48:38,875][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:48:38,875][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts gdb0:rgw.gdb0
[2017-07-06 18:48:39,114][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:48:39,310][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:48:39,310][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:48:39,326][gdb0][DEBUG ] detect machine type
[2017-07-06 18:48:39,330][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:48:39,330][ceph_deploy.rgw][DEBUG ] remote host will use systemd
[2017-07-06 18:48:39,330][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to gdb0
[2017-07-06 18:48:39,331][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:48:39,333][gdb0][DEBUG ] create path recursively if it doesn't exist
[2017-07-06 18:48:39,336][gdb0][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.gdb0 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.gdb0/keyring
[2017-07-06 18:48:39,454][gdb0][ERROR ] 2017-07-06 18:48:39.409773 7f5d54954700  0 librados: client.bootstrap-rgw authentication error (1) Operation not permitted
[2017-07-06 18:48:39,454][gdb0][ERROR ] error connecting to the cluster
[2017-07-06 18:48:39,454][gdb0][ERROR ] exit code from command was: 1
[2017-07-06 18:48:39,454][ceph_deploy.rgw][ERROR ] could not create rgw
[2017-07-06 18:48:39,454][ceph_deploy][ERROR ] GenericError: Failed to create 1 RGWs

[2017-07-06 18:49:17,971][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:49:17,971][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy rgw create gdb0
[2017-07-06 18:49:17,972][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:49:17,972][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:49:17,972][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:49:17,972][ceph_deploy.cli][INFO  ]  rgw                           : [('gdb0', 'rgw.gdb0')]
[2017-07-06 18:49:17,972][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:49:17,972][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-06 18:49:17,972][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:49:17,972][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3e9c333878>
[2017-07-06 18:49:17,972][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:49:17,972][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7f3e9c9f4758>
[2017-07-06 18:49:17,972][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:49:17,972][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:49:17,972][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts gdb0:rgw.gdb0
[2017-07-06 18:49:18,214][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:49:18,415][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:49:18,415][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:49:18,431][gdb0][DEBUG ] detect machine type
[2017-07-06 18:49:18,436][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:49:18,436][ceph_deploy.rgw][DEBUG ] remote host will use systemd
[2017-07-06 18:49:18,436][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to gdb0
[2017-07-06 18:49:18,436][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:49:18,439][gdb0][DEBUG ] create path recursively if it doesn't exist
[2017-07-06 18:49:18,441][gdb0][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.gdb0 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.gdb0/keyring
[2017-07-06 18:49:18,558][gdb0][ERROR ] 2017-07-06 18:49:18.510168 7f2b65b2a700  0 librados: client.bootstrap-rgw authentication error (1) Operation not permitted
[2017-07-06 18:49:18,558][gdb0][ERROR ] error connecting to the cluster
[2017-07-06 18:49:18,558][gdb0][ERROR ] exit code from command was: 1
[2017-07-06 18:49:18,558][ceph_deploy.rgw][ERROR ] could not create rgw
[2017-07-06 18:49:18,558][ceph_deploy][ERROR ] GenericError: Failed to create 1 RGWs

[2017-07-06 18:50:42,735][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 18:50:42,736][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy rgw create gdb0
[2017-07-06 18:50:42,736][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 18:50:42,736][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 18:50:42,736][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 18:50:42,736][ceph_deploy.cli][INFO  ]  rgw                           : [('gdb0', 'rgw.gdb0')]
[2017-07-06 18:50:42,736][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 18:50:42,736][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-06 18:50:42,736][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 18:50:42,736][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f132aebc878>
[2017-07-06 18:50:42,736][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 18:50:42,736][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7f132b57d758>
[2017-07-06 18:50:42,736][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 18:50:42,736][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 18:50:42,736][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts gdb0:rgw.gdb0
[2017-07-06 18:50:42,978][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 18:50:43,165][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 18:50:43,166][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 18:50:43,183][gdb0][DEBUG ] detect machine type
[2017-07-06 18:50:43,187][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 18:50:43,187][ceph_deploy.rgw][DEBUG ] remote host will use systemd
[2017-07-06 18:50:43,187][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to gdb0
[2017-07-06 18:50:43,187][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 18:50:43,189][gdb0][WARNING] rgw keyring does not exist yet, creating one
[2017-07-06 18:50:43,190][gdb0][DEBUG ] create a keyring file
[2017-07-06 18:50:43,191][gdb0][DEBUG ] create path recursively if it doesn't exist
[2017-07-06 18:50:43,194][gdb0][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.gdb0 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.gdb0/keyring
[2017-07-06 18:50:43,365][gdb0][INFO  ] Running command: sudo systemctl enable ceph-radosgw@rgw.gdb0
[2017-07-06 18:50:43,434][gdb0][INFO  ] Running command: sudo systemctl start ceph-radosgw@rgw.gdb0
[2017-07-06 18:50:43,503][gdb0][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 18:50:43,570][ceph_deploy.rgw][INFO  ] The Ceph Object Gateway (RGW) is now running on host gdb0 and default port 7480
[2017-07-06 20:53:26,732][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 20:53:26,732][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-07-06 20:53:26,732][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 20:53:26,732][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 20:53:26,732][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 20:53:26,732][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 20:53:26,732][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 20:53:26,732][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f648ab11128>
[2017-07-06 20:53:26,733][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 20:53:26,733][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-06 20:53:26,733][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f648b41e1b8>
[2017-07-06 20:53:26,733][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 20:53:26,733][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 20:53:26,733][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-07-06 20:53:26,733][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-07-06 20:53:26,733][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-07-06 20:53:26,733][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-07-06 20:53:26,760][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 20:53:26,774][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 20:53:26,774][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 20:53:26,791][gdb3][DEBUG ] detect machine type
[2017-07-06 20:53:26,793][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 20:53:26,793][gdb3][INFO  ] Purging Ceph on gdb3
[2017-07-06 20:53:26,794][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-07-06 20:53:26,832][gdb3][DEBUG ] Reading package lists...
[2017-07-06 20:53:26,997][gdb3][DEBUG ] Building dependency tree...
[2017-07-06 20:53:26,997][gdb3][DEBUG ] Reading state information...
[2017-07-06 20:53:27,061][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-07-06 20:53:27,061][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-07-06 20:53:27,061][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-07-06 20:53:27,062][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-07-06 20:53:27,062][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-07-06 20:53:27,062][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-07-06 20:53:27,062][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1016 linux-aws-headers-4.4.0-1017
[2017-07-06 20:53:27,062][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1018 linux-headers-4.4.0-1013-aws
[2017-07-06 20:53:27,062][gdb3][DEBUG ]   linux-headers-4.4.0-1016-aws linux-headers-4.4.0-1017-aws
[2017-07-06 20:53:27,062][gdb3][DEBUG ]   linux-headers-4.4.0-1018-aws linux-image-4.4.0-1013-aws
[2017-07-06 20:53:27,062][gdb3][DEBUG ]   linux-image-4.4.0-1016-aws linux-image-4.4.0-1017-aws
[2017-07-06 20:53:27,063][gdb3][DEBUG ]   linux-image-4.4.0-1018-aws ntp python-blinker python-cephfs
[2017-07-06 20:53:27,063][gdb3][DEBUG ]   python-cffi-backend python-chardet python-cryptography python-enum34
[2017-07-06 20:53:27,063][gdb3][DEBUG ]   python-flask python-idna python-ipaddress python-itsdangerous python-jinja2
[2017-07-06 20:53:27,063][gdb3][DEBUG ]   python-markupsafe python-ndg-httpsclient python-openssl python-pyasn1
[2017-07-06 20:53:27,063][gdb3][DEBUG ]   python-pyinotify python-rados python-rbd python-requests python-rgw
[2017-07-06 20:53:27,063][gdb3][DEBUG ]   python-six python-urllib3 python-werkzeug
[2017-07-06 20:53:27,063][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-07-06 20:53:27,127][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-07-06 20:53:27,127][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-07-06 20:53:27,241][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 60 not upgraded.
[2017-07-06 20:53:27,242][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-07-06 20:53:27,306][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 179644 files and directories currently installed.)
[2017-07-06 20:53:27,306][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-07-06 20:53:27,470][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-07-06 20:53:27,584][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-07-06 20:53:27,616][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-07-06 20:53:27,831][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-07-06 20:53:27,947][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-07-06 20:53:28,112][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-07-06 20:53:28,182][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-07-06 20:53:28,214][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-07-06 20:53:28,379][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-07-06 20:53:28,443][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-07-06 20:53:28,475][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-07-06 20:53:28,640][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-07-06 20:53:28,672][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-07-06 20:53:28,836][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-07-06 20:53:28,900][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-07-06 20:53:28,900][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-07-06 20:53:29,014][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu9) ...
[2017-07-06 20:53:29,831][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-07-06 20:53:29,997][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 20:53:29,998][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-07-06 20:53:29,998][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 20:53:29,998][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 20:53:29,998][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 20:53:29,998][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 20:53:29,998][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 20:53:29,998][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f43a1ad17a0>
[2017-07-06 20:53:29,998][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 20:53:29,998][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-06 20:53:29,998][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f43a23de230>
[2017-07-06 20:53:29,998][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 20:53:29,998][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 20:53:29,999][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-07-06 20:53:30,025][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 20:53:30,039][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 20:53:30,039][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 20:53:30,056][gdb3][DEBUG ] detect machine type
[2017-07-06 20:53:30,058][gdb3][DEBUG ] find the location of an executable
[2017-07-06 20:53:30,074][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 20:53:30,088][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 20:53:30,088][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 20:53:30,105][gdb3][DEBUG ] detect machine type
[2017-07-06 20:53:30,107][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 20:53:30,107][gdb3][INFO  ] purging data on gdb3
[2017-07-06 20:53:30,109][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-07-06 20:53:30,121][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-07-06 20:53:30,292][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 20:53:30,293][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-07-06 20:53:30,293][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 20:53:30,293][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 20:53:30,293][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 20:53:30,293][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 20:53:30,293][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 20:53:30,293][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f53d0782a70>
[2017-07-06 20:53:30,293][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 20:53:30,293][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7f53d1045848>
[2017-07-06 20:53:30,293][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 20:53:30,293][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 20:55:08,126][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 20:55:08,127][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-07-06 20:55:08,127][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 20:55:08,127][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 20:55:08,127][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 20:55:08,127][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 20:55:08,127][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 20:55:08,128][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f497cfd35f0>
[2017-07-06 20:55:08,128][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 20:55:08,128][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-07-06 20:55:08,128][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-07-06 20:55:08,128][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f497d657758>
[2017-07-06 20:55:08,128][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-07-06 20:55:08,128][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 20:55:08,128][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-07-06 20:55:08,128][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 20:55:08,129][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-07-06 20:55:08,129][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-07-06 20:55:08,129][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-07-06 20:55:08,155][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 20:55:08,170][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 20:55:08,170][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 20:55:08,187][gdb3][DEBUG ] detect machine type
[2017-07-06 20:55:08,189][gdb3][DEBUG ] find the location of an executable
[2017-07-06 20:55:08,190][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-07-06 20:55:08,202][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-07-06 20:55:08,208][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-07-06 20:55:08,208][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-07-06 20:55:08,208][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-07-06 20:55:08,208][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-07-06 20:55:08,209][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-07-06 20:55:08,209][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-07-06 20:55:08,209][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-07-06 20:55:08,209][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-07-06 20:55:08,377][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 20:55:08,377][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-07-06 20:55:08,377][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 20:55:08,377][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 20:55:08,377][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 20:55:08,378][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 20:55:08,378][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-07-06 20:55:08,378][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 20:55:08,378][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f902272fef0>
[2017-07-06 20:55:08,378][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 20:55:08,378][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f9022703b18>
[2017-07-06 20:55:08,378][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 20:55:08,378][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-07-06 20:55:08,378][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 20:55:08,379][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-07-06 20:55:08,379][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-07-06 20:55:08,405][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 20:55:08,419][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 20:55:08,420][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 20:55:08,436][gdb3][DEBUG ] detect machine type
[2017-07-06 20:55:08,438][gdb3][DEBUG ] find the location of an executable
[2017-07-06 20:55:08,439][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-07-06 20:55:08,439][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-07-06 20:55:08,439][gdb3][DEBUG ] get remote short hostname
[2017-07-06 20:55:08,439][gdb3][DEBUG ] deploying mon to gdb3
[2017-07-06 20:55:08,440][gdb3][DEBUG ] get remote short hostname
[2017-07-06 20:55:08,440][gdb3][DEBUG ] remote hostname: gdb3
[2017-07-06 20:55:08,440][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 20:55:08,442][gdb3][DEBUG ] create the mon path if it does not exist
[2017-07-06 20:55:08,442][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-06 20:55:08,442][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-06 20:55:08,443][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-06 20:55:08,443][gdb3][DEBUG ] create the monitor keyring file
[2017-07-06 20:55:08,444][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-07-06 20:55:08,482][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-07-06 20:55:08,482][gdb3][DEBUG ] ceph-mon: set fsid to c7c4b229-2c40-4998-9bc9-874b2ad2903a
[2017-07-06 20:55:08,484][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-07-06 20:55:08,488][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-06 20:55:08,488][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-07-06 20:55:08,489][gdb3][DEBUG ] create the init path if it does not exist
[2017-07-06 20:55:08,490][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 20:55:08,561][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-07-06 20:55:08,635][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-07-06 20:55:10,705][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 20:55:10,770][gdb3][DEBUG ] ********************************************************************************
[2017-07-06 20:55:10,770][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-07-06 20:55:10,771][gdb3][DEBUG ] {
[2017-07-06 20:55:10,771][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-07-06 20:55:10,771][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-07-06 20:55:10,771][gdb3][DEBUG ]   "features": {
[2017-07-06 20:55:10,771][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-07-06 20:55:10,771][gdb3][DEBUG ]     "quorum_mon": [
[2017-07-06 20:55:10,771][gdb3][DEBUG ]       "kraken", 
[2017-07-06 20:55:10,771][gdb3][DEBUG ]       "luminous"
[2017-07-06 20:55:10,771][gdb3][DEBUG ]     ], 
[2017-07-06 20:55:10,771][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-07-06 20:55:10,771][gdb3][DEBUG ]     "required_mon": [
[2017-07-06 20:55:10,771][gdb3][DEBUG ]       "kraken", 
[2017-07-06 20:55:10,771][gdb3][DEBUG ]       "luminous"
[2017-07-06 20:55:10,771][gdb3][DEBUG ]     ]
[2017-07-06 20:55:10,771][gdb3][DEBUG ]   }, 
[2017-07-06 20:55:10,772][gdb3][DEBUG ]   "monmap": {
[2017-07-06 20:55:10,772][gdb3][DEBUG ]     "created": "2017-07-06 20:55:08.467271", 
[2017-07-06 20:55:10,772][gdb3][DEBUG ]     "epoch": 2, 
[2017-07-06 20:55:10,772][gdb3][DEBUG ]     "features": {
[2017-07-06 20:55:10,772][gdb3][DEBUG ]       "optional": [], 
[2017-07-06 20:55:10,772][gdb3][DEBUG ]       "persistent": [
[2017-07-06 20:55:10,772][gdb3][DEBUG ]         "kraken", 
[2017-07-06 20:55:10,772][gdb3][DEBUG ]         "luminous"
[2017-07-06 20:55:10,772][gdb3][DEBUG ]       ]
[2017-07-06 20:55:10,772][gdb3][DEBUG ]     }, 
[2017-07-06 20:55:10,772][gdb3][DEBUG ]     "fsid": "c7c4b229-2c40-4998-9bc9-874b2ad2903a", 
[2017-07-06 20:55:10,772][gdb3][DEBUG ]     "modified": "2017-07-06 20:55:08.720394", 
[2017-07-06 20:55:10,772][gdb3][DEBUG ]     "mons": [
[2017-07-06 20:55:10,772][gdb3][DEBUG ]       {
[2017-07-06 20:55:10,772][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-07-06 20:55:10,772][gdb3][DEBUG ]         "name": "gdb3", 
[2017-07-06 20:55:10,773][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-07-06 20:55:10,773][gdb3][DEBUG ]         "rank": 0
[2017-07-06 20:55:10,773][gdb3][DEBUG ]       }
[2017-07-06 20:55:10,773][gdb3][DEBUG ]     ]
[2017-07-06 20:55:10,773][gdb3][DEBUG ]   }, 
[2017-07-06 20:55:10,773][gdb3][DEBUG ]   "name": "gdb3", 
[2017-07-06 20:55:10,773][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-07-06 20:55:10,773][gdb3][DEBUG ]   "quorum": [
[2017-07-06 20:55:10,773][gdb3][DEBUG ]     0
[2017-07-06 20:55:10,773][gdb3][DEBUG ]   ], 
[2017-07-06 20:55:10,773][gdb3][DEBUG ]   "rank": 0, 
[2017-07-06 20:55:10,773][gdb3][DEBUG ]   "state": "leader", 
[2017-07-06 20:55:10,773][gdb3][DEBUG ]   "sync_provider": []
[2017-07-06 20:55:10,773][gdb3][DEBUG ] }
[2017-07-06 20:55:10,773][gdb3][DEBUG ] ********************************************************************************
[2017-07-06 20:55:10,773][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-07-06 20:55:10,774][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 20:55:10,840][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-07-06 20:55:10,855][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 20:55:10,871][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 20:55:10,871][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 20:55:10,888][gdb3][DEBUG ] detect machine type
[2017-07-06 20:55:10,890][gdb3][DEBUG ] find the location of an executable
[2017-07-06 20:55:10,891][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 20:55:10,956][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-07-06 20:55:10,956][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-07-06 20:55:10,957][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-07-06 20:55:10,958][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpdkcsEN
[2017-07-06 20:55:10,974][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 20:55:10,987][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 20:55:10,988][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 20:55:11,005][gdb3][DEBUG ] detect machine type
[2017-07-06 20:55:11,007][gdb3][DEBUG ] get remote short hostname
[2017-07-06 20:55:11,007][gdb3][DEBUG ] fetch remote file
[2017-07-06 20:55:11,009][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 20:55:11,075][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-07-06 20:55:11,241][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-07-06 20:55:11,407][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-07-06 20:55:11,573][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-07-06 20:55:11,740][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-07-06 20:55:11,906][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-07-06 20:55:12,072][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-07-06 20:55:12,238][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-07-06 20:55:12,404][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-07-06 20:55:12,571][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-07-06 20:55:12,786][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-07-06 20:55:12,786][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-07-06 20:55:12,787][ceph_deploy.gatherkeys][INFO  ] Replacing 'ceph.bootstrap-mgr.keyring' and backing up old key as 'ceph.bootstrap-mgr.keyring-20170706205512'
[2017-07-06 20:55:12,787][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-07-06 20:55:12,787][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-07-06 20:55:12,787][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-07-06 20:55:12,787][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpdkcsEN
[2017-07-06 20:55:12,968][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 20:55:12,968][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-07-06 20:55:12,968][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 20:55:12,968][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 20:55:12,968][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 20:55:12,969][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 20:55:12,969][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 20:55:12,969][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f54b349b5a8>
[2017-07-06 20:55:12,969][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 20:55:12,969][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-07-06 20:55:12,969][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f54b3db2938>
[2017-07-06 20:55:12,969][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 20:55:12,969][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 20:55:12,969][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-07-06 20:55:12,995][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 20:55:13,010][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 20:55:13,010][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 20:55:13,027][gdb3][DEBUG ] detect machine type
[2017-07-06 20:55:13,029][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 20:55:39,608][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 20:55:39,608][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-07-06 20:55:39,608][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 20:55:39,608][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 20:55:39,608][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 20:55:39,608][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 20:55:39,608][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 20:55:39,608][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7feb9cd6b5a8>
[2017-07-06 20:55:39,609][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 20:55:39,609][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-07-06 20:55:39,609][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7feb9d682938>
[2017-07-06 20:55:39,609][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 20:55:39,609][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 20:55:39,609][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-07-06 20:55:39,927][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 20:55:40,157][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 20:55:40,158][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 20:55:40,190][gdb0][DEBUG ] detect machine type
[2017-07-06 20:55:40,194][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 20:55:40,367][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 20:55:40,367][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-07-06 20:55:40,367][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 20:55:40,367][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 20:55:40,367][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 20:55:40,367][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 20:55:40,367][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 20:55:40,368][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 20:55:40,368][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 20:55:40,368][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 20:55:40,368][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 20:55:40,368][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 20:55:40,368][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 20:55:40,368][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 20:55:40,368][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f2eb2138998>
[2017-07-06 20:55:40,368][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 20:55:40,368][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 20:55:40,368][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f2eb238eaa0>
[2017-07-06 20:55:40,368][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 20:55:40,368][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 20:55:40,368][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 20:55:40,369][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 20:55:40,610][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 20:55:40,841][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 20:55:40,842][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 20:55:40,857][gdb0][DEBUG ] detect machine type
[2017-07-06 20:55:40,862][gdb0][DEBUG ] find the location of an executable
[2017-07-06 20:55:40,863][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 20:55:40,863][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-07-06 20:55:40,863][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 20:55:40,865][gdb0][WARNING] osd keyring does not exist yet, creating one
[2017-07-06 20:55:40,866][gdb0][DEBUG ] create a keyring file
[2017-07-06 20:55:40,867][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-07-06 20:55:40,867][gdb0][DEBUG ] find the location of an executable
[2017-07-06 20:55:40,869][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 20:55:41,191][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 20:55:41,191][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 20:55:41,191][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 20:55:41,194][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 20:55:41,210][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 20:55:41,226][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-07-06 20:55:46,232][gdb0][INFO  ] checking OSD status...
[2017-07-06 20:55:46,233][gdb0][DEBUG ] find the location of an executable
[2017-07-06 20:55:46,235][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 20:55:46,451][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-07-06 20:55:46,614][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 20:55:46,614][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-07-06 20:55:46,614][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 20:55:46,614][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 20:55:46,615][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 20:55:46,615][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 20:55:46,615][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 20:55:46,615][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 20:55:46,615][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fc56d0f4998>
[2017-07-06 20:55:46,615][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 20:55:46,615][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fc56d34aaa0>
[2017-07-06 20:55:46,615][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 20:55:46,615][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 20:55:46,615][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 20:55:46,615][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 20:55:46,862][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 20:55:47,094][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 20:55:47,094][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 20:55:47,110][gdb0][DEBUG ] detect machine type
[2017-07-06 20:55:47,114][gdb0][DEBUG ] find the location of an executable
[2017-07-06 20:55:47,115][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 20:55:47,115][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-07-06 20:55:47,115][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 20:55:47,116][gdb0][DEBUG ] find the location of an executable
[2017-07-06 20:55:47,118][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 20:55:47,288][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 20:55:47,288][gdb0][WARNING] activate: Cluster uuid is 6a195b40-ec45-48cb-bc3d-fd87024626be
[2017-07-06 20:55:47,288][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 20:55:47,288][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=radosgw-sync --show-config-value=fsid
[2017-07-06 20:55:47,288][gdb0][WARNING] Traceback (most recent call last):
[2017-07-06 20:55:47,288][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-07-06 20:55:47,289][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-07-06 20:55:47,289][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-07-06 20:55:47,289][gdb0][WARNING]     main(sys.argv[1:])
[2017-07-06 20:55:47,289][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-07-06 20:55:47,289][gdb0][WARNING]     args.func(args)
[2017-07-06 20:55:47,289][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-07-06 20:55:47,289][gdb0][WARNING]     init=args.mark_init,
[2017-07-06 20:55:47,289][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-07-06 20:55:47,289][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-07-06 20:55:47,289][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3609, in activate
[2017-07-06 20:55:47,289][gdb0][WARNING]     ' with fsid %s' % ceph_fsid)
[2017-07-06 20:55:47,289][gdb0][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid 6a195b40-ec45-48cb-bc3d-fd87024626be
[2017-07-06 20:55:47,290][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-07-06 20:55:47,290][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-07-06 20:56:13,489][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 20:56:13,489][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-07-06 20:56:13,489][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 20:56:13,490][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 20:56:13,490][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 20:56:13,490][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 20:56:13,490][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 20:56:13,490][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f08ce0bb5a8>
[2017-07-06 20:56:13,490][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 20:56:13,490][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-07-06 20:56:13,490][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f08ce9d2938>
[2017-07-06 20:56:13,490][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 20:56:13,490][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 20:56:13,490][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-07-06 20:56:13,734][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 20:56:13,970][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 20:56:13,970][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 20:56:13,986][gdb0][DEBUG ] detect machine type
[2017-07-06 20:56:13,990][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 20:56:14,162][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 20:56:14,163][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-07-06 20:56:14,163][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 20:56:14,163][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 20:56:14,163][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 20:56:14,163][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 20:56:14,163][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 20:56:14,163][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 20:56:14,163][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 20:56:14,163][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 20:56:14,163][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 20:56:14,163][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 20:56:14,164][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 20:56:14,164][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 20:56:14,164][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f4ce97b6998>
[2017-07-06 20:56:14,164][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 20:56:14,164][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 20:56:14,164][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f4ce9a0caa0>
[2017-07-06 20:56:14,164][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 20:56:14,164][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 20:56:14,164][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 20:56:14,164][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 20:56:14,410][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 20:56:14,642][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 20:56:14,642][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 20:56:14,658][gdb0][DEBUG ] detect machine type
[2017-07-06 20:56:14,662][gdb0][DEBUG ] find the location of an executable
[2017-07-06 20:56:14,663][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 20:56:14,663][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-07-06 20:56:14,663][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 20:56:14,665][gdb0][WARNING] osd keyring does not exist yet, creating one
[2017-07-06 20:56:14,666][gdb0][DEBUG ] create a keyring file
[2017-07-06 20:56:14,667][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-07-06 20:56:14,667][gdb0][DEBUG ] find the location of an executable
[2017-07-06 20:56:14,669][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 20:56:14,840][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 20:56:14,840][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 20:56:14,840][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 20:56:14,840][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 20:56:14,856][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 20:56:14,863][gdb0][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-07-06 20:56:14,864][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.2542.tmp
[2017-07-06 20:56:14,867][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.2542.tmp
[2017-07-06 20:56:14,870][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.2542.tmp
[2017-07-06 20:56:19,891][gdb0][INFO  ] checking OSD status...
[2017-07-06 20:56:19,891][gdb0][DEBUG ] find the location of an executable
[2017-07-06 20:56:19,894][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 20:56:20,060][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-07-06 20:56:20,223][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 20:56:20,223][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-07-06 20:56:20,224][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 20:56:20,224][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 20:56:20,224][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 20:56:20,224][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 20:56:20,224][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 20:56:20,224][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 20:56:20,224][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa0dcd3e998>
[2017-07-06 20:56:20,224][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 20:56:20,224][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fa0dcf94aa0>
[2017-07-06 20:56:20,224][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 20:56:20,224][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 20:56:20,224][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 20:56:20,225][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 20:56:20,462][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 20:56:20,698][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 20:56:20,698][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 20:56:20,714][gdb0][DEBUG ] detect machine type
[2017-07-06 20:56:20,718][gdb0][DEBUG ] find the location of an executable
[2017-07-06 20:56:20,719][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 20:56:20,719][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-07-06 20:56:20,719][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 20:56:20,719][gdb0][DEBUG ] find the location of an executable
[2017-07-06 20:56:20,721][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 20:56:20,892][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 20:56:20,892][gdb0][WARNING] activate: Cluster uuid is c7c4b229-2c40-4998-9bc9-874b2ad2903a
[2017-07-06 20:56:20,892][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 20:56:20,892][gdb0][WARNING] activate: Cluster name is ceph
[2017-07-06 20:56:20,892][gdb0][WARNING] activate: OSD uuid is 2c94c1de-f843-479e-a777-1af2ed66d2c6
[2017-07-06 20:56:20,892][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-07-06 20:56:20,892][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 2c94c1de-f843-479e-a777-1af2ed66d2c6
[2017-07-06 20:56:21,057][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.2660.tmp
[2017-07-06 20:56:21,057][gdb0][WARNING] activate: OSD id is 0
[2017-07-06 20:56:21,057][gdb0][WARNING] activate: Initializing OSD...
[2017-07-06 20:56:21,057][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-07-06 20:56:21,171][gdb0][WARNING] got monmap epoch 2
[2017-07-06 20:56:21,171][gdb0][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 0 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid 2c94c1de-f843-479e-a777-1af2ed66d2c6 --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-07-06 20:56:21,386][gdb0][WARNING] Traceback (most recent call last):
[2017-07-06 20:56:21,386][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-07-06 20:56:21,386][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-07-06 20:56:21,386][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-07-06 20:56:21,386][gdb0][WARNING]     main(sys.argv[1:])
[2017-07-06 20:56:21,386][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-07-06 20:56:21,386][gdb0][WARNING]     args.func(args)
[2017-07-06 20:56:21,387][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-07-06 20:56:21,387][gdb0][WARNING]     init=args.mark_init,
[2017-07-06 20:56:21,387][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-07-06 20:56:21,387][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-07-06 20:56:21,387][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3638, in activate
[2017-07-06 20:56:21,387][gdb0][WARNING]     keyring=keyring,
[2017-07-06 20:56:21,387][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3076, in mkfs
[2017-07-06 20:56:21,387][gdb0][WARNING]     '--setgroup', get_ceph_group(),
[2017-07-06 20:56:21,387][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3023, in ceph_osd_mkfs
[2017-07-06 20:56:21,387][gdb0][WARNING]     raise Error('%s failed : %s' % (str(arguments), error))
[2017-07-06 20:56:21,387][gdb0][WARNING] ceph_disk.main.Error: Error: ['ceph-osd', '--cluster', 'ceph', '--mkfs', '--mkkey', '-i', u'0', '--monmap', '/mnt/memstore/activate.monmap', '--osd-data', '/mnt/memstore', '--osd-journal', '/mnt/memstore/journal', '--osd-uuid', u'2c94c1de-f843-479e-a777-1af2ed66d2c6', '--keyring', '/mnt/memstore/keyring', '--setuser', 'ceph', '--setgroup', 'ceph'] failed : 2017-07-06 20:56:21.174961 7f88377ecc80 -1 asok(0x562d46204d20) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-osd.0.asok': (17) File exists
[2017-07-06 20:56:21,387][gdb0][WARNING] /home/ubuntu/ceph/src/os/memstore/MemStore.cc: In function 'virtual void MemStore::set_fsid(uuid_d)' thread 7f88377ecc80 time 2017-07-06 20:56:21.175703
[2017-07-06 20:56:21,387][gdb0][WARNING] /home/ubuntu/ceph/src/os/memstore/MemStore.cc: 176: FAILED assert(r >= 0)
[2017-07-06 20:56:21,388][gdb0][WARNING]  ceph version 12.0.1-1208-gab9e841 (ab9e8419ec962af158b94a85533509edce622db0)
[2017-07-06 20:56:21,388][gdb0][WARNING]  1: (ceph::__ceph_assert_fail(char const*, char const*, int, char const*)+0x102) [0x562d3c061072]
[2017-07-06 20:56:21,388][gdb0][WARNING]  2: (MemStore::set_fsid(uuid_d)+0xc8) [0x562d3be33128]
[2017-07-06 20:56:21,388][gdb0][WARNING]  3: (OSD::mkfs(CephContext*, ObjectStore*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, uuid_d, int)+0x13f) [0x562d3ba81e5f]
[2017-07-06 20:56:21,388][gdb0][WARNING]  4: (main()+0x1043) [0x562d3ba4c7c3]
[2017-07-06 20:56:21,388][gdb0][WARNING]  5: (__libc_start_main()+0xf0) [0x7f8834c56830]
[2017-07-06 20:56:21,388][gdb0][WARNING]  6: (_start()+0x29) [0x562d3ba5acc9]
[2017-07-06 20:56:21,388][gdb0][WARNING]  NOTE: a copy of the executable, or `objdump -rdS <executable>` is needed to interpret this.
[2017-07-06 20:56:21,388][gdb0][WARNING] 2017-07-06 20:56:21.178591 7f88377ecc80 -1 /home/ubuntu/ceph/src/os/memstore/MemStore.cc: In function 'virtual void MemStore::set_fsid(uuid_d)' thread 7f88377ecc80 time 2017-07-06 20:56:21.175703
[2017-07-06 20:56:21,388][gdb0][WARNING] /home/ubuntu/ceph/src/os/memstore/MemStore.cc: 176: FAILED assert(r >= 0)
[2017-07-06 20:56:21,388][gdb0][WARNING] 
[2017-07-06 20:56:21,388][gdb0][WARNING]  ceph version 12.0.1-1208-gab9e841 (ab9e8419ec962af158b94a85533509edce622db0)
[2017-07-06 20:56:21,388][gdb0][WARNING]  1: (ceph::__ceph_assert_fail(char const*, char const*, int, char const*)+0x102) [0x562d3c061072]
[2017-07-06 20:56:21,388][gdb0][WARNING]  2: (MemStore::set_fsid(uuid_d)+0xc8) [0x562d3be33128]
[2017-07-06 20:56:21,389][gdb0][WARNING]  3: (OSD::mkfs(CephContext*, ObjectStore*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, uuid_d, int)+0x13f) [0x562d3ba81e5f]
[2017-07-06 20:56:21,389][gdb0][WARNING]  4: (main()+0x1043) [0x562d3ba4c7c3]
[2017-07-06 20:56:21,389][gdb0][WARNING]  5: (__libc_start_main()+0xf0) [0x7f8834c56830]
[2017-07-06 20:56:21,389][gdb0][WARNING]  6: (_start()+0x29) [0x562d3ba5acc9]
[2017-07-06 20:56:21,389][gdb0][WARNING]  NOTE: a copy of the executable, or `objdump -rdS <executable>` is needed to interpret this.
[2017-07-06 20:56:21,389][gdb0][WARNING] 
[2017-07-06 20:56:21,389][gdb0][WARNING]    -21> 2017-07-06 20:56:21.174961 7f88377ecc80 -1 asok(0x562d46204d20) AdminSocketConfigObs::init: failed: AdminSocket::bind_and_listen: failed to bind the UNIX domain socket to '/var/run/ceph/ceph-osd.0.asok': (17) File exists
[2017-07-06 20:56:21,389][gdb0][WARNING]      0> 2017-07-06 20:56:21.178591 7f88377ecc80 -1 /home/ubuntu/ceph/src/os/memstore/MemStore.cc: In function 'virtual void MemStore::set_fsid(uuid_d)' thread 7f88377ecc80 time 2017-07-06 20:56:21.175703
[2017-07-06 20:56:21,389][gdb0][WARNING] /home/ubuntu/ceph/src/os/memstore/MemStore.cc: 176: FAILED assert(r >= 0)
[2017-07-06 20:56:21,389][gdb0][WARNING] 
[2017-07-06 20:56:21,389][gdb0][WARNING]  ceph version 12.0.1-1208-gab9e841 (ab9e8419ec962af158b94a85533509edce622db0)
[2017-07-06 20:56:21,389][gdb0][WARNING]  1: (ceph::__ceph_assert_fail(char const*, char const*, int, char const*)+0x102) [0x562d3c061072]
[2017-07-06 20:56:21,389][gdb0][WARNING]  2: (MemStore::set_fsid(uuid_d)+0xc8) [0x562d3be33128]
[2017-07-06 20:56:21,389][gdb0][WARNING]  3: (OSD::mkfs(CephContext*, ObjectStore*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, uuid_d, int)+0x13f) [0x562d3ba81e5f]
[2017-07-06 20:56:21,390][gdb0][WARNING]  4: (main()+0x1043) [0x562d3ba4c7c3]
[2017-07-06 20:56:21,390][gdb0][WARNING]  5: (__libc_start_main()+0xf0) [0x7f8834c56830]
[2017-07-06 20:56:21,390][gdb0][WARNING]  6: (_start()+0x29) [0x562d3ba5acc9]
[2017-07-06 20:56:21,390][gdb0][WARNING]  NOTE: a copy of the executable, or `objdump -rdS <executable>` is needed to interpret this.
[2017-07-06 20:56:21,390][gdb0][WARNING] 
[2017-07-06 20:56:21,390][gdb0][WARNING] *** Caught signal (Aborted) **
[2017-07-06 20:56:21,390][gdb0][WARNING]  in thread 7f88377ecc80 thread_name:ceph-osd
[2017-07-06 20:56:21,390][gdb0][WARNING]  ceph version 12.0.1-1208-gab9e841 (ab9e8419ec962af158b94a85533509edce622db0)
[2017-07-06 20:56:21,390][gdb0][WARNING]  1: (()+0xcab9b2) [0x562d3bffd9b2]
[2017-07-06 20:56:21,390][gdb0][WARNING]  2: (()+0x11390) [0x7f8835cd0390]
[2017-07-06 20:56:21,390][gdb0][WARNING]  3: (gsignal()+0x38) [0x7f8834c6b428]
[2017-07-06 20:56:21,390][gdb0][WARNING]  4: (abort()+0x16a) [0x7f8834c6d02a]
[2017-07-06 20:56:21,390][gdb0][WARNING]  5: (ceph::__ceph_assert_fail(char const*, char const*, int, char const*)+0x28e) [0x562d3c0611fe]
[2017-07-06 20:56:21,390][gdb0][WARNING]  6: (MemStore::set_fsid(uuid_d)+0xc8) [0x562d3be33128]
[2017-07-06 20:56:21,390][gdb0][WARNING]  7: (OSD::mkfs(CephContext*, ObjectStore*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, uuid_d, int)+0x13f) [0x562d3ba81e5f]
[2017-07-06 20:56:21,391][gdb0][WARNING]  8: (main()+0x1043) [0x562d3ba4c7c3]
[2017-07-06 20:56:21,391][gdb0][WARNING]  9: (__libc_start_main()+0xf0) [0x7f8834c56830]
[2017-07-06 20:56:21,391][gdb0][WARNING]  10: (_start()+0x29) [0x562d3ba5acc9]
[2017-07-06 20:56:21,391][gdb0][WARNING] 2017-07-06 20:56:21.181620 7f88377ecc80 -1 *** Caught signal (Aborted) **
[2017-07-06 20:56:21,391][gdb0][WARNING]  in thread 7f88377ecc80 thread_name:ceph-osd
[2017-07-06 20:56:21,391][gdb0][WARNING] 
[2017-07-06 20:56:21,391][gdb0][WARNING]  ceph version 12.0.1-1208-gab9e841 (ab9e8419ec962af158b94a85533509edce622db0)
[2017-07-06 20:56:21,391][gdb0][WARNING]  1: (()+0xcab9b2) [0x562d3bffd9b2]
[2017-07-06 20:56:21,391][gdb0][WARNING]  2: (()+0x11390) [0x7f8835cd0390]
[2017-07-06 20:56:21,391][gdb0][WARNING]  3: (gsignal()+0x38) [0x7f8834c6b428]
[2017-07-06 20:56:21,391][gdb0][WARNING]  4: (abort()+0x16a) [0x7f8834c6d02a]
[2017-07-06 20:56:21,391][gdb0][WARNING]  5: (ceph::__ceph_assert_fail(char const*, char const*, int, char const*)+0x28e) [0x562d3c0611fe]
[2017-07-06 20:56:21,391][gdb0][WARNING]  6: (MemStore::set_fsid(uuid_d)+0xc8) [0x562d3be33128]
[2017-07-06 20:56:21,391][gdb0][WARNING]  7: (OSD::mkfs(CephContext*, ObjectStore*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, uuid_d, int)+0x13f) [0x562d3ba81e5f]
[2017-07-06 20:56:21,391][gdb0][WARNING]  8: (main()+0x1043) [0x562d3ba4c7c3]
[2017-07-06 20:56:21,392][gdb0][WARNING]  9: (__libc_start_main()+0xf0) [0x7f8834c56830]
[2017-07-06 20:56:21,392][gdb0][WARNING]  10: (_start()+0x29) [0x562d3ba5acc9]
[2017-07-06 20:56:21,392][gdb0][WARNING]  NOTE: a copy of the executable, or `objdump -rdS <executable>` is needed to interpret this.
[2017-07-06 20:56:21,392][gdb0][WARNING] 
[2017-07-06 20:56:21,392][gdb0][WARNING]      0> 2017-07-06 20:56:21.181620 7f88377ecc80 -1 *** Caught signal (Aborted) **
[2017-07-06 20:56:21,392][gdb0][WARNING]  in thread 7f88377ecc80 thread_name:ceph-osd
[2017-07-06 20:56:21,392][gdb0][WARNING] 
[2017-07-06 20:56:21,392][gdb0][WARNING]  ceph version 12.0.1-1208-gab9e841 (ab9e8419ec962af158b94a85533509edce622db0)
[2017-07-06 20:56:21,392][gdb0][WARNING]  1: (()+0xcab9b2) [0x562d3bffd9b2]
[2017-07-06 20:56:21,392][gdb0][WARNING]  2: (()+0x11390) [0x7f8835cd0390]
[2017-07-06 20:56:21,392][gdb0][WARNING]  3: (gsignal()+0x38) [0x7f8834c6b428]
[2017-07-06 20:56:21,392][gdb0][WARNING]  4: (abort()+0x16a) [0x7f8834c6d02a]
[2017-07-06 20:56:21,392][gdb0][WARNING]  5: (ceph::__ceph_assert_fail(char const*, char const*, int, char const*)+0x28e) [0x562d3c0611fe]
[2017-07-06 20:56:21,392][gdb0][WARNING]  6: (MemStore::set_fsid(uuid_d)+0xc8) [0x562d3be33128]
[2017-07-06 20:56:21,393][gdb0][WARNING]  7: (OSD::mkfs(CephContext*, ObjectStore*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, uuid_d, int)+0x13f) [0x562d3ba81e5f]
[2017-07-06 20:56:21,393][gdb0][WARNING]  8: (main()+0x1043) [0x562d3ba4c7c3]
[2017-07-06 20:56:21,393][gdb0][WARNING]  9: (__libc_start_main()+0xf0) [0x7f8834c56830]
[2017-07-06 20:56:21,393][gdb0][WARNING]  10: (_start()+0x29) [0x562d3ba5acc9]
[2017-07-06 20:56:21,393][gdb0][WARNING]  NOTE: a copy of the executable, or `objdump -rdS <executable>` is needed to interpret this.
[2017-07-06 20:56:21,393][gdb0][WARNING] 
[2017-07-06 20:56:21,393][gdb0][WARNING] /usr/bin/timeout: the monitored command dumped core
[2017-07-06 20:56:21,393][gdb0][WARNING] 
[2017-07-06 20:56:21,393][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-07-06 20:56:21,393][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-07-06 20:56:50,878][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 20:56:50,879][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-07-06 20:56:50,879][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 20:56:50,879][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 20:56:50,879][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 20:56:50,879][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 20:56:50,879][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 20:56:50,879][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9d44abd5a8>
[2017-07-06 20:56:50,879][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 20:56:50,879][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-07-06 20:56:50,879][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f9d453d4938>
[2017-07-06 20:56:50,879][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 20:56:50,880][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 20:56:50,880][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-07-06 20:56:51,130][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 20:56:51,366][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 20:56:51,367][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 20:56:51,382][gdb0][DEBUG ] detect machine type
[2017-07-06 20:56:51,386][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 20:56:51,558][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 20:56:51,559][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-07-06 20:56:51,559][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 20:56:51,559][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 20:56:51,559][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 20:56:51,559][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 20:56:51,559][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 20:56:51,559][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 20:56:51,559][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 20:56:51,559][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 20:56:51,559][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 20:56:51,559][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 20:56:51,559][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 20:56:51,560][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 20:56:51,560][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb1bb31d998>
[2017-07-06 20:56:51,560][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 20:56:51,560][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 20:56:51,560][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fb1bb573aa0>
[2017-07-06 20:56:51,560][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 20:56:51,560][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 20:56:51,560][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 20:56:51,560][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 20:56:51,802][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 20:56:52,030][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 20:56:52,030][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 20:56:52,046][gdb0][DEBUG ] detect machine type
[2017-07-06 20:56:52,050][gdb0][DEBUG ] find the location of an executable
[2017-07-06 20:56:52,051][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 20:56:52,051][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-07-06 20:56:52,052][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 20:56:52,054][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-07-06 20:56:52,054][gdb0][DEBUG ] find the location of an executable
[2017-07-06 20:56:52,057][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 20:56:52,227][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 20:56:52,228][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 20:56:52,228][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 20:56:52,228][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 20:56:52,235][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 20:56:52,251][gdb0][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-07-06 20:56:52,251][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.2887.tmp
[2017-07-06 20:56:52,251][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.2887.tmp
[2017-07-06 20:56:52,255][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.2887.tmp
[2017-07-06 20:56:57,276][gdb0][INFO  ] checking OSD status...
[2017-07-06 20:56:57,276][gdb0][DEBUG ] find the location of an executable
[2017-07-06 20:56:57,279][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 20:56:57,444][gdb0][WARNING] there is 1 OSD down
[2017-07-06 20:56:57,444][gdb0][WARNING] there is 1 OSD out
[2017-07-06 20:56:57,444][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-07-06 20:56:57,607][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 20:56:57,608][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-07-06 20:56:57,608][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 20:56:57,608][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 20:56:57,608][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 20:56:57,608][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 20:56:57,608][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 20:56:57,608][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 20:56:57,608][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f019949e998>
[2017-07-06 20:56:57,608][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 20:56:57,608][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f01996f4aa0>
[2017-07-06 20:56:57,608][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 20:56:57,608][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 20:56:57,609][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 20:56:57,609][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 20:56:57,858][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 20:56:58,089][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 20:56:58,090][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 20:56:58,106][gdb0][DEBUG ] detect machine type
[2017-07-06 20:56:58,110][gdb0][DEBUG ] find the location of an executable
[2017-07-06 20:56:58,110][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 20:56:58,110][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-07-06 20:56:58,111][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 20:56:58,111][gdb0][DEBUG ] find the location of an executable
[2017-07-06 20:56:58,113][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 20:56:58,283][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 20:56:58,284][gdb0][WARNING] activate: Cluster uuid is c7c4b229-2c40-4998-9bc9-874b2ad2903a
[2017-07-06 20:56:58,284][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 20:56:58,284][gdb0][WARNING] activate: Cluster name is ceph
[2017-07-06 20:56:58,284][gdb0][WARNING] activate: OSD uuid is 0f2c53dd-45e4-47c6-9ce5-df7d62cdcca8
[2017-07-06 20:56:58,284][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-07-06 20:56:58,284][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 0f2c53dd-45e4-47c6-9ce5-df7d62cdcca8
[2017-07-06 20:56:58,549][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.3009.tmp
[2017-07-06 20:56:58,549][gdb0][WARNING] activate: OSD id is 1
[2017-07-06 20:56:58,549][gdb0][WARNING] activate: Initializing OSD...
[2017-07-06 20:56:58,549][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-07-06 20:56:58,663][gdb0][WARNING] got monmap epoch 2
[2017-07-06 20:56:58,663][gdb0][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 1 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid 0f2c53dd-45e4-47c6-9ce5-df7d62cdcca8 --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-07-06 20:56:58,679][gdb0][WARNING] activate: Marking with init system systemd
[2017-07-06 20:56:58,679][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-07-06 20:56:58,679][gdb0][WARNING] activate: Authorizing OSD key...
[2017-07-06 20:56:58,679][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.1 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-07-06 20:56:58,844][gdb0][WARNING] added key for osd.1
[2017-07-06 20:56:58,844][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.3009.tmp
[2017-07-06 20:56:58,844][gdb0][WARNING] activate: ceph osd.1 data dir is ready at /mnt/memstore
[2017-07-06 20:56:58,844][gdb0][WARNING] activate_dir: Creating symlink /var/lib/ceph/osd/ceph-1 -> /mnt/memstore
[2017-07-06 20:56:58,844][gdb0][WARNING] start_daemon: Starting ceph osd.1...
[2017-07-06 20:56:58,844][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@1
[2017-07-06 20:56:58,844][gdb0][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@1.service.
[2017-07-06 20:56:58,876][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@1 --runtime
[2017-07-06 20:56:58,940][gdb0][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@1
[2017-07-06 20:56:58,940][gdb0][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@1.service to /lib/systemd/system/ceph-osd@.service.
[2017-07-06 20:56:58,956][gdb0][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@1
[2017-07-06 20:57:04,076][gdb0][INFO  ] checking OSD status...
[2017-07-06 20:57:04,076][gdb0][DEBUG ] find the location of an executable
[2017-07-06 20:57:04,078][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 20:57:04,243][gdb0][WARNING] there is 1 OSD down
[2017-07-06 20:57:04,244][gdb0][WARNING] there is 1 OSD out
[2017-07-06 20:57:04,246][gdb0][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 21:26:36,092][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:26:36,092][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-07-06 21:26:36,092][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:26:36,092][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:26:36,092][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:26:36,093][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:26:36,093][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:26:36,093][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ff5ef217128>
[2017-07-06 21:26:36,093][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:26:36,093][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-06 21:26:36,093][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7ff5efb241b8>
[2017-07-06 21:26:36,093][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:26:36,093][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:26:36,093][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-07-06 21:26:36,093][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-07-06 21:26:36,093][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-07-06 21:26:36,093][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-07-06 21:26:36,119][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:26:36,133][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:26:36,134][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:26:36,151][gdb3][DEBUG ] detect machine type
[2017-07-06 21:26:36,153][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:26:36,154][gdb3][INFO  ] Purging Ceph on gdb3
[2017-07-06 21:26:36,154][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-07-06 21:26:36,192][gdb3][DEBUG ] Reading package lists...
[2017-07-06 21:26:36,357][gdb3][DEBUG ] Building dependency tree...
[2017-07-06 21:26:36,357][gdb3][DEBUG ] Reading state information...
[2017-07-06 21:26:36,421][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-07-06 21:26:36,421][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-07-06 21:26:36,422][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-07-06 21:26:36,422][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-07-06 21:26:36,422][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-07-06 21:26:36,422][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-07-06 21:26:36,422][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1016 linux-aws-headers-4.4.0-1017
[2017-07-06 21:26:36,422][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1018 linux-headers-4.4.0-1013-aws
[2017-07-06 21:26:36,422][gdb3][DEBUG ]   linux-headers-4.4.0-1016-aws linux-headers-4.4.0-1017-aws
[2017-07-06 21:26:36,422][gdb3][DEBUG ]   linux-headers-4.4.0-1018-aws linux-image-4.4.0-1013-aws
[2017-07-06 21:26:36,422][gdb3][DEBUG ]   linux-image-4.4.0-1016-aws linux-image-4.4.0-1017-aws
[2017-07-06 21:26:36,423][gdb3][DEBUG ]   linux-image-4.4.0-1018-aws ntp python-blinker python-cephfs
[2017-07-06 21:26:36,423][gdb3][DEBUG ]   python-cffi-backend python-chardet python-cryptography python-enum34
[2017-07-06 21:26:36,423][gdb3][DEBUG ]   python-flask python-idna python-ipaddress python-itsdangerous python-jinja2
[2017-07-06 21:26:36,423][gdb3][DEBUG ]   python-markupsafe python-ndg-httpsclient python-openssl python-pyasn1
[2017-07-06 21:26:36,423][gdb3][DEBUG ]   python-pyinotify python-rados python-rbd python-requests python-rgw
[2017-07-06 21:26:36,423][gdb3][DEBUG ]   python-six python-urllib3 python-werkzeug
[2017-07-06 21:26:36,423][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-07-06 21:26:36,455][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-07-06 21:26:36,455][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-07-06 21:26:36,569][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 60 not upgraded.
[2017-07-06 21:26:36,570][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-07-06 21:26:36,634][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 179644 files and directories currently installed.)
[2017-07-06 21:26:36,641][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-07-06 21:26:36,857][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-07-06 21:26:36,921][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-07-06 21:26:36,953][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-07-06 21:26:37,167][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-07-06 21:26:37,286][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-07-06 21:26:37,454][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-07-06 21:26:37,520][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-07-06 21:26:37,551][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-07-06 21:26:37,718][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-07-06 21:26:37,782][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-07-06 21:26:37,798][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-07-06 21:26:37,963][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-07-06 21:26:38,027][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-07-06 21:26:38,141][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-07-06 21:26:38,255][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-07-06 21:26:38,255][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-07-06 21:26:38,369][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu9) ...
[2017-07-06 21:26:39,186][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-07-06 21:26:39,350][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:26:39,350][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-07-06 21:26:39,351][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:26:39,351][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:26:39,351][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:26:39,351][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:26:39,351][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:26:39,351][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f37d14927a0>
[2017-07-06 21:26:39,351][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:26:39,351][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-06 21:26:39,351][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f37d1d9f230>
[2017-07-06 21:26:39,351][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:26:39,351][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:26:39,351][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-07-06 21:26:39,378][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:26:39,392][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:26:39,392][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:26:39,409][gdb3][DEBUG ] detect machine type
[2017-07-06 21:26:39,411][gdb3][DEBUG ] find the location of an executable
[2017-07-06 21:26:39,427][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:26:39,440][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:26:39,441][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:26:39,457][gdb3][DEBUG ] detect machine type
[2017-07-06 21:26:39,459][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:26:39,459][gdb3][INFO  ] purging data on gdb3
[2017-07-06 21:26:39,460][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-07-06 21:26:39,473][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-07-06 21:26:39,642][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:26:39,643][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-07-06 21:26:39,643][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:26:39,643][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:26:39,643][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:26:39,643][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:26:39,643][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:26:39,643][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa48befaa70>
[2017-07-06 21:26:39,643][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:26:39,643][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7fa48c7bd848>
[2017-07-06 21:26:39,643][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:26:39,643][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:26:55,332][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:26:55,332][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-07-06 21:26:55,332][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:26:55,333][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:26:55,333][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:26:55,333][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:26:55,333][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:26:55,333][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f8759da15f0>
[2017-07-06 21:26:55,333][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:26:55,333][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-07-06 21:26:55,333][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-07-06 21:26:55,333][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f875a425758>
[2017-07-06 21:26:55,333][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-07-06 21:26:55,333][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:26:55,333][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-07-06 21:26:55,333][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:26:55,333][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-07-06 21:26:55,334][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-07-06 21:26:55,334][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-07-06 21:26:55,359][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:26:55,374][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:26:55,374][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:26:55,391][gdb3][DEBUG ] detect machine type
[2017-07-06 21:26:55,393][gdb3][DEBUG ] find the location of an executable
[2017-07-06 21:26:55,394][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-07-06 21:26:55,405][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-07-06 21:26:55,411][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-07-06 21:26:55,412][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-07-06 21:26:55,412][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-07-06 21:26:55,412][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-07-06 21:26:55,412][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-07-06 21:26:55,412][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-07-06 21:26:55,412][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-07-06 21:26:55,412][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-07-06 21:26:55,578][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:26:55,578][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-07-06 21:26:55,579][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:26:55,579][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:26:55,579][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:26:55,579][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:26:55,579][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-07-06 21:26:55,579][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:26:55,579][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f4550140ef0>
[2017-07-06 21:26:55,579][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:26:55,580][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f4550114b18>
[2017-07-06 21:26:55,580][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:26:55,580][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-07-06 21:26:55,580][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:26:55,581][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-07-06 21:26:55,581][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-07-06 21:26:55,607][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:26:55,621][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:26:55,622][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:26:55,639][gdb3][DEBUG ] detect machine type
[2017-07-06 21:26:55,641][gdb3][DEBUG ] find the location of an executable
[2017-07-06 21:26:55,642][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-07-06 21:26:55,642][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-07-06 21:26:55,642][gdb3][DEBUG ] get remote short hostname
[2017-07-06 21:26:55,642][gdb3][DEBUG ] deploying mon to gdb3
[2017-07-06 21:26:55,642][gdb3][DEBUG ] get remote short hostname
[2017-07-06 21:26:55,642][gdb3][DEBUG ] remote hostname: gdb3
[2017-07-06 21:26:55,643][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:26:55,644][gdb3][DEBUG ] create the mon path if it does not exist
[2017-07-06 21:26:55,645][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-06 21:26:55,645][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-06 21:26:55,645][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-06 21:26:55,645][gdb3][DEBUG ] create the monitor keyring file
[2017-07-06 21:26:55,647][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-07-06 21:26:55,684][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-07-06 21:26:55,685][gdb3][DEBUG ] ceph-mon: set fsid to 28192ce3-1952-4ea7-b4eb-4f65e3d697cd
[2017-07-06 21:26:55,688][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-07-06 21:26:55,692][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-06 21:26:55,692][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-07-06 21:26:55,692][gdb3][DEBUG ] create the init path if it does not exist
[2017-07-06 21:26:55,694][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 21:26:55,765][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-07-06 21:26:55,836][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-07-06 21:26:57,874][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 21:26:57,939][gdb3][DEBUG ] ********************************************************************************
[2017-07-06 21:26:57,939][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-07-06 21:26:57,940][gdb3][DEBUG ] {
[2017-07-06 21:26:57,940][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-07-06 21:26:57,940][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-07-06 21:26:57,940][gdb3][DEBUG ]   "features": {
[2017-07-06 21:26:57,940][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-07-06 21:26:57,940][gdb3][DEBUG ]     "quorum_mon": [
[2017-07-06 21:26:57,940][gdb3][DEBUG ]       "kraken", 
[2017-07-06 21:26:57,940][gdb3][DEBUG ]       "luminous"
[2017-07-06 21:26:57,940][gdb3][DEBUG ]     ], 
[2017-07-06 21:26:57,940][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-07-06 21:26:57,940][gdb3][DEBUG ]     "required_mon": [
[2017-07-06 21:26:57,940][gdb3][DEBUG ]       "kraken", 
[2017-07-06 21:26:57,940][gdb3][DEBUG ]       "luminous"
[2017-07-06 21:26:57,940][gdb3][DEBUG ]     ]
[2017-07-06 21:26:57,940][gdb3][DEBUG ]   }, 
[2017-07-06 21:26:57,941][gdb3][DEBUG ]   "monmap": {
[2017-07-06 21:26:57,941][gdb3][DEBUG ]     "created": "2017-07-06 21:26:55.670140", 
[2017-07-06 21:26:57,941][gdb3][DEBUG ]     "epoch": 2, 
[2017-07-06 21:26:57,941][gdb3][DEBUG ]     "features": {
[2017-07-06 21:26:57,941][gdb3][DEBUG ]       "optional": [], 
[2017-07-06 21:26:57,941][gdb3][DEBUG ]       "persistent": [
[2017-07-06 21:26:57,941][gdb3][DEBUG ]         "kraken", 
[2017-07-06 21:26:57,941][gdb3][DEBUG ]         "luminous"
[2017-07-06 21:26:57,941][gdb3][DEBUG ]       ]
[2017-07-06 21:26:57,941][gdb3][DEBUG ]     }, 
[2017-07-06 21:26:57,941][gdb3][DEBUG ]     "fsid": "28192ce3-1952-4ea7-b4eb-4f65e3d697cd", 
[2017-07-06 21:26:57,941][gdb3][DEBUG ]     "modified": "2017-07-06 21:26:55.916291", 
[2017-07-06 21:26:57,941][gdb3][DEBUG ]     "mons": [
[2017-07-06 21:26:57,941][gdb3][DEBUG ]       {
[2017-07-06 21:26:57,941][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-07-06 21:26:57,941][gdb3][DEBUG ]         "name": "gdb3", 
[2017-07-06 21:26:57,941][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-07-06 21:26:57,941][gdb3][DEBUG ]         "rank": 0
[2017-07-06 21:26:57,942][gdb3][DEBUG ]       }
[2017-07-06 21:26:57,942][gdb3][DEBUG ]     ]
[2017-07-06 21:26:57,942][gdb3][DEBUG ]   }, 
[2017-07-06 21:26:57,942][gdb3][DEBUG ]   "name": "gdb3", 
[2017-07-06 21:26:57,942][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-07-06 21:26:57,942][gdb3][DEBUG ]   "quorum": [
[2017-07-06 21:26:57,942][gdb3][DEBUG ]     0
[2017-07-06 21:26:57,942][gdb3][DEBUG ]   ], 
[2017-07-06 21:26:57,942][gdb3][DEBUG ]   "rank": 0, 
[2017-07-06 21:26:57,942][gdb3][DEBUG ]   "state": "leader", 
[2017-07-06 21:26:57,942][gdb3][DEBUG ]   "sync_provider": []
[2017-07-06 21:26:57,942][gdb3][DEBUG ] }
[2017-07-06 21:26:57,942][gdb3][DEBUG ] ********************************************************************************
[2017-07-06 21:26:57,942][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-07-06 21:26:57,943][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 21:26:58,008][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-07-06 21:26:58,027][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:26:58,042][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:26:58,043][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:26:58,060][gdb3][DEBUG ] detect machine type
[2017-07-06 21:26:58,062][gdb3][DEBUG ] find the location of an executable
[2017-07-06 21:26:58,063][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 21:26:58,128][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-07-06 21:26:58,128][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-07-06 21:26:58,128][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-07-06 21:26:58,130][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpJzmWDM
[2017-07-06 21:26:58,147][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:26:58,162][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:26:58,163][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:26:58,180][gdb3][DEBUG ] detect machine type
[2017-07-06 21:26:58,182][gdb3][DEBUG ] get remote short hostname
[2017-07-06 21:26:58,182][gdb3][DEBUG ] fetch remote file
[2017-07-06 21:26:58,183][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 21:26:58,249][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-07-06 21:26:58,416][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-07-06 21:26:58,582][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-07-06 21:26:58,748][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-07-06 21:26:58,914][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-07-06 21:26:59,080][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-07-06 21:26:59,246][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-07-06 21:26:59,412][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-07-06 21:26:59,579][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-07-06 21:26:59,745][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-07-06 21:26:59,910][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-07-06 21:26:59,910][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-07-06 21:26:59,910][ceph_deploy.gatherkeys][INFO  ] Replacing 'ceph.bootstrap-mgr.keyring' and backing up old key as 'ceph.bootstrap-mgr.keyring-20170706212659'
[2017-07-06 21:26:59,911][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-07-06 21:26:59,911][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-07-06 21:26:59,911][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-07-06 21:26:59,911][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpJzmWDM
[2017-07-06 21:27:00,090][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:27:00,091][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-07-06 21:27:00,091][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:27:00,091][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:27:00,091][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:27:00,091][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:27:00,091][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:27:00,091][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fbb7556d5a8>
[2017-07-06 21:27:00,091][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:27:00,091][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-07-06 21:27:00,091][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fbb75e84938>
[2017-07-06 21:27:00,092][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:27:00,092][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:27:00,092][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-07-06 21:27:00,118][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:27:00,132][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:27:00,133][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:27:00,150][gdb3][DEBUG ] detect machine type
[2017-07-06 21:27:00,152][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:27:14,995][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:27:14,995][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb3
[2017-07-06 21:27:14,995][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:27:14,995][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:27:14,995][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:27:14,995][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 21:27:14,995][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:27:14,996][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f87645875a8>
[2017-07-06 21:27:14,996][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:27:14,996][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-07-06 21:27:14,996][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f8764e9e938>
[2017-07-06 21:27:14,996][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:27:14,996][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:27:14,996][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-07-06 21:27:15,023][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:27:15,036][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:27:15,037][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:27:15,054][gdb3][DEBUG ] detect machine type
[2017-07-06 21:27:15,056][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:27:15,228][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:27:15,228][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb3:/mnt/memstore
[2017-07-06 21:27:15,228][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:27:15,228][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:27:15,228][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 21:27:15,228][ceph_deploy.cli][INFO  ]  disk                          : [('gdb3', '/mnt/memstore', None)]
[2017-07-06 21:27:15,228][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 21:27:15,228][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:27:15,228][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 21:27:15,229][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 21:27:15,229][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:27:15,229][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 21:27:15,229][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 21:27:15,229][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:27:15,229][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fcc1801b998>
[2017-07-06 21:27:15,229][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:27:15,229][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 21:27:15,229][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fcc18271aa0>
[2017-07-06 21:27:15,229][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:27:15,229][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:27:15,229][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 21:27:15,229][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb3:/mnt/memstore:
[2017-07-06 21:27:15,256][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:27:15,270][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:27:15,270][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:27:15,287][gdb3][DEBUG ] detect machine type
[2017-07-06 21:27:15,289][gdb3][DEBUG ] find the location of an executable
[2017-07-06 21:27:15,290][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:27:15,290][ceph_deploy.osd][DEBUG ] Deploying osd to gdb3
[2017-07-06 21:27:15,290][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:27:15,291][gdb3][WARNING] osd keyring does not exist yet, creating one
[2017-07-06 21:27:15,292][gdb3][DEBUG ] create a keyring file
[2017-07-06 21:27:15,293][ceph_deploy.osd][DEBUG ] Preparing host gdb3 disk /mnt/memstore journal None activate False
[2017-07-06 21:27:15,293][gdb3][DEBUG ] find the location of an executable
[2017-07-06 21:27:15,294][gdb3][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 21:27:15,414][gdb3][WARNING] Traceback (most recent call last):
[2017-07-06 21:27:15,414][gdb3][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-07-06 21:27:15,414][gdb3][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-07-06 21:27:15,415][gdb3][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-07-06 21:27:15,415][gdb3][WARNING]     main(sys.argv[1:])
[2017-07-06 21:27:15,415][gdb3][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-07-06 21:27:15,415][gdb3][WARNING]     args.func(args)
[2017-07-06 21:27:15,415][gdb3][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2029, in main
[2017-07-06 21:27:15,415][gdb3][WARNING]     Prepare.factory(args).prepare()
[2017-07-06 21:27:15,415][gdb3][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2025, in factory
[2017-07-06 21:27:15,415][gdb3][WARNING]     return PrepareFilestore(args)
[2017-07-06 21:27:15,415][gdb3][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2037, in __init__
[2017-07-06 21:27:15,415][gdb3][WARNING]     self.data = PrepareFilestoreData(args)
[2017-07-06 21:27:15,415][gdb3][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2739, in __init__
[2017-07-06 21:27:15,415][gdb3][WARNING]     self.set_type()
[2017-07-06 21:27:15,415][gdb3][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2747, in set_type
[2017-07-06 21:27:15,416][gdb3][WARNING]     dmode = os.stat(self.args.data).st_mode
[2017-07-06 21:27:15,416][gdb3][WARNING] OSError: [Errno 2] No such file or directory: '/mnt/memstore'
[2017-07-06 21:27:15,424][gdb3][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-07-06 21:27:15,424][ceph_deploy.osd][ERROR ] Failed to execute command: /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 21:27:15,424][ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs

[2017-07-06 21:27:15,596][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:27:15,596][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb3:/mnt/memstore
[2017-07-06 21:27:15,596][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:27:15,596][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:27:15,596][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:27:15,596][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:27:15,596][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 21:27:15,597][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:27:15,597][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fab87003998>
[2017-07-06 21:27:15,597][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:27:15,597][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fab87259aa0>
[2017-07-06 21:27:15,597][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:27:15,597][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:27:15,597][ceph_deploy.cli][INFO  ]  disk                          : [('gdb3', '/mnt/memstore', None)]
[2017-07-06 21:27:15,597][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb3:/mnt/memstore:
[2017-07-06 21:27:15,623][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:27:15,637][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:27:15,638][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:27:15,654][gdb3][DEBUG ] detect machine type
[2017-07-06 21:27:15,657][gdb3][DEBUG ] find the location of an executable
[2017-07-06 21:27:15,657][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:27:15,657][ceph_deploy.osd][DEBUG ] activating host gdb3 disk /mnt/memstore
[2017-07-06 21:27:15,657][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 21:27:15,657][gdb3][DEBUG ] find the location of an executable
[2017-07-06 21:27:15,658][gdb3][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 21:27:15,779][gdb3][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 21:27:15,779][gdb3][WARNING] Traceback (most recent call last):
[2017-07-06 21:27:15,779][gdb3][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-07-06 21:27:15,779][gdb3][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-07-06 21:27:15,779][gdb3][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-07-06 21:27:15,779][gdb3][WARNING]     main(sys.argv[1:])
[2017-07-06 21:27:15,779][gdb3][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-07-06 21:27:15,779][gdb3][WARNING]     args.func(args)
[2017-07-06 21:27:15,779][gdb3][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3684, in main_activate
[2017-07-06 21:27:15,780][gdb3][WARNING]     raise Error('%s does not exist' % args.path)
[2017-07-06 21:27:15,780][gdb3][WARNING] ceph_disk.main.Error: Error: /mnt/memstore does not exist
[2017-07-06 21:27:15,780][gdb3][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-07-06 21:27:15,780][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-07-06 21:28:23,240][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:28:23,241][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb3
[2017-07-06 21:28:23,241][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:28:23,241][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:28:23,241][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:28:23,241][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 21:28:23,241][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:28:23,241][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f53a72485a8>
[2017-07-06 21:28:23,241][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:28:23,241][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-07-06 21:28:23,241][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f53a7b5f938>
[2017-07-06 21:28:23,241][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:28:23,241][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:28:23,241][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-07-06 21:28:23,267][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:28:23,281][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:28:23,281][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:28:23,298][gdb3][DEBUG ] detect machine type
[2017-07-06 21:28:23,300][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:28:23,469][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:28:23,470][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb3:/mnt/memstore
[2017-07-06 21:28:23,470][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:28:23,470][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:28:23,470][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 21:28:23,470][ceph_deploy.cli][INFO  ]  disk                          : [('gdb3', '/mnt/memstore', None)]
[2017-07-06 21:28:23,470][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 21:28:23,470][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:28:23,470][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 21:28:23,470][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 21:28:23,470][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:28:23,470][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 21:28:23,470][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 21:28:23,471][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:28:23,471][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9ea590b998>
[2017-07-06 21:28:23,471][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:28:23,471][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 21:28:23,471][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f9ea5b61aa0>
[2017-07-06 21:28:23,471][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:28:23,471][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:28:23,471][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 21:28:23,471][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb3:/mnt/memstore:
[2017-07-06 21:28:23,497][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:28:23,512][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:28:23,512][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:28:23,528][gdb3][DEBUG ] detect machine type
[2017-07-06 21:28:23,531][gdb3][DEBUG ] find the location of an executable
[2017-07-06 21:28:23,531][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:28:23,531][ceph_deploy.osd][DEBUG ] Deploying osd to gdb3
[2017-07-06 21:28:23,531][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:28:23,533][ceph_deploy.osd][DEBUG ] Preparing host gdb3 disk /mnt/memstore journal None activate False
[2017-07-06 21:28:23,533][gdb3][DEBUG ] find the location of an executable
[2017-07-06 21:28:23,534][gdb3][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 21:28:23,654][gdb3][WARNING] Traceback (most recent call last):
[2017-07-06 21:28:23,655][gdb3][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-07-06 21:28:23,655][gdb3][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-07-06 21:28:23,655][gdb3][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-07-06 21:28:23,655][gdb3][WARNING]     main(sys.argv[1:])
[2017-07-06 21:28:23,655][gdb3][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-07-06 21:28:23,655][gdb3][WARNING]     args.func(args)
[2017-07-06 21:28:23,655][gdb3][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2029, in main
[2017-07-06 21:28:23,655][gdb3][WARNING]     Prepare.factory(args).prepare()
[2017-07-06 21:28:23,655][gdb3][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2025, in factory
[2017-07-06 21:28:23,655][gdb3][WARNING]     return PrepareFilestore(args)
[2017-07-06 21:28:23,655][gdb3][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2037, in __init__
[2017-07-06 21:28:23,655][gdb3][WARNING]     self.data = PrepareFilestoreData(args)
[2017-07-06 21:28:23,656][gdb3][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2739, in __init__
[2017-07-06 21:28:23,656][gdb3][WARNING]     self.set_type()
[2017-07-06 21:28:23,656][gdb3][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 2747, in set_type
[2017-07-06 21:28:23,656][gdb3][WARNING]     dmode = os.stat(self.args.data).st_mode
[2017-07-06 21:28:23,656][gdb3][WARNING] OSError: [Errno 2] No such file or directory: '/mnt/memstore'
[2017-07-06 21:28:23,656][gdb3][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-07-06 21:28:23,656][ceph_deploy.osd][ERROR ] Failed to execute command: /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 21:28:23,656][ceph_deploy][ERROR ] GenericError: Failed to create 1 OSDs

[2017-07-06 21:28:23,829][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:28:23,829][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb3:/mnt/memstore
[2017-07-06 21:28:23,829][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:28:23,829][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:28:23,829][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:28:23,829][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:28:23,829][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 21:28:23,829][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:28:23,829][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fc3d230e998>
[2017-07-06 21:28:23,829][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:28:23,829][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fc3d2564aa0>
[2017-07-06 21:28:23,830][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:28:23,830][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:28:23,830][ceph_deploy.cli][INFO  ]  disk                          : [('gdb3', '/mnt/memstore', None)]
[2017-07-06 21:28:23,830][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb3:/mnt/memstore:
[2017-07-06 21:28:23,856][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:28:23,869][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:28:23,870][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:28:23,887][gdb3][DEBUG ] detect machine type
[2017-07-06 21:28:23,889][gdb3][DEBUG ] find the location of an executable
[2017-07-06 21:28:23,889][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:28:23,889][ceph_deploy.osd][DEBUG ] activating host gdb3 disk /mnt/memstore
[2017-07-06 21:28:23,890][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 21:28:23,890][gdb3][DEBUG ] find the location of an executable
[2017-07-06 21:28:23,891][gdb3][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 21:28:24,011][gdb3][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 21:28:24,011][gdb3][WARNING] Traceback (most recent call last):
[2017-07-06 21:28:24,011][gdb3][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-07-06 21:28:24,011][gdb3][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-07-06 21:28:24,012][gdb3][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-07-06 21:28:24,012][gdb3][WARNING]     main(sys.argv[1:])
[2017-07-06 21:28:24,012][gdb3][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-07-06 21:28:24,012][gdb3][WARNING]     args.func(args)
[2017-07-06 21:28:24,012][gdb3][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3684, in main_activate
[2017-07-06 21:28:24,012][gdb3][WARNING]     raise Error('%s does not exist' % args.path)
[2017-07-06 21:28:24,012][gdb3][WARNING] ceph_disk.main.Error: Error: /mnt/memstore does not exist
[2017-07-06 21:28:24,012][gdb3][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-07-06 21:28:24,013][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-07-06 21:28:49,408][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:28:49,408][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-07-06 21:28:49,408][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:28:49,408][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:28:49,408][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:28:49,408][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 21:28:49,408][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:28:49,409][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f450f55c5a8>
[2017-07-06 21:28:49,409][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:28:49,409][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-07-06 21:28:49,409][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f450fe73938>
[2017-07-06 21:28:49,409][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:28:49,409][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:28:49,409][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-07-06 21:28:49,646][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 21:28:49,878][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 21:28:49,878][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 21:28:49,894][gdb0][DEBUG ] detect machine type
[2017-07-06 21:28:49,898][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:28:50,068][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:28:50,068][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-07-06 21:28:50,068][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:28:50,068][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:28:50,068][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 21:28:50,068][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 21:28:50,068][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 21:28:50,068][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:28:50,068][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 21:28:50,068][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 21:28:50,069][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:28:50,069][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 21:28:50,069][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 21:28:50,069][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:28:50,069][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f4916d99998>
[2017-07-06 21:28:50,069][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:28:50,069][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 21:28:50,069][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f4916fefaa0>
[2017-07-06 21:28:50,069][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:28:50,069][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:28:50,069][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 21:28:50,069][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 21:28:50,310][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 21:28:50,541][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 21:28:50,542][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 21:28:50,558][gdb0][DEBUG ] detect machine type
[2017-07-06 21:28:50,561][gdb0][DEBUG ] find the location of an executable
[2017-07-06 21:28:50,562][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:28:50,562][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-07-06 21:28:50,563][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:28:50,565][gdb0][WARNING] osd keyring does not exist yet, creating one
[2017-07-06 21:28:50,565][gdb0][DEBUG ] create a keyring file
[2017-07-06 21:28:50,567][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-07-06 21:28:50,567][gdb0][DEBUG ] find the location of an executable
[2017-07-06 21:28:50,569][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 21:28:50,740][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 21:28:50,740][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 21:28:50,740][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 21:28:50,740][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 21:28:50,748][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 21:28:50,764][gdb0][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-07-06 21:28:50,764][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.3908.tmp
[2017-07-06 21:28:50,779][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.3908.tmp
[2017-07-06 21:28:50,783][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.3908.tmp
[2017-07-06 21:28:55,804][gdb0][INFO  ] checking OSD status...
[2017-07-06 21:28:55,804][gdb0][DEBUG ] find the location of an executable
[2017-07-06 21:28:55,807][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 21:28:55,972][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-07-06 21:28:56,137][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:28:56,137][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-07-06 21:28:56,137][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:28:56,137][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:28:56,137][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:28:56,137][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:28:56,137][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 21:28:56,137][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:28:56,137][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3176680998>
[2017-07-06 21:28:56,138][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:28:56,138][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f31768d6aa0>
[2017-07-06 21:28:56,138][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:28:56,138][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:28:56,138][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 21:28:56,138][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 21:28:56,378][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 21:28:56,609][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 21:28:56,610][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 21:28:56,626][gdb0][DEBUG ] detect machine type
[2017-07-06 21:28:56,630][gdb0][DEBUG ] find the location of an executable
[2017-07-06 21:28:56,630][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:28:56,630][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-07-06 21:28:56,630][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 21:28:56,631][gdb0][DEBUG ] find the location of an executable
[2017-07-06 21:28:56,632][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 21:28:56,803][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 21:28:56,803][gdb0][WARNING] activate: Cluster uuid is 28192ce3-1952-4ea7-b4eb-4f65e3d697cd
[2017-07-06 21:28:56,803][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 21:28:56,803][gdb0][WARNING] activate: Cluster name is ceph
[2017-07-06 21:28:56,803][gdb0][WARNING] activate: OSD uuid is a6a57a6e-6acb-43b3-becb-14b8827d5d81
[2017-07-06 21:28:56,803][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-07-06 21:28:56,804][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise a6a57a6e-6acb-43b3-becb-14b8827d5d81
[2017-07-06 21:28:56,968][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.4025.tmp
[2017-07-06 21:28:56,968][gdb0][WARNING] activate: OSD id is 0
[2017-07-06 21:28:56,968][gdb0][WARNING] activate: Initializing OSD...
[2017-07-06 21:28:56,968][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-07-06 21:28:57,082][gdb0][WARNING] got monmap epoch 2
[2017-07-06 21:28:57,083][gdb0][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 0 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid a6a57a6e-6acb-43b3-becb-14b8827d5d81 --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-07-06 21:28:57,114][gdb0][WARNING] activate: Marking with init system systemd
[2017-07-06 21:28:57,115][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-07-06 21:28:57,115][gdb0][WARNING] activate: Authorizing OSD key...
[2017-07-06 21:28:57,115][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.0 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-07-06 21:28:57,279][gdb0][WARNING] added key for osd.0
[2017-07-06 21:28:57,279][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.4025.tmp
[2017-07-06 21:28:57,279][gdb0][WARNING] activate: ceph osd.0 data dir is ready at /mnt/memstore
[2017-07-06 21:28:57,279][gdb0][WARNING] activate_dir: Creating symlink /var/lib/ceph/osd/ceph-0 -> /mnt/memstore
[2017-07-06 21:28:57,280][gdb0][WARNING] start_daemon: Starting ceph osd.0...
[2017-07-06 21:28:57,280][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0
[2017-07-06 21:28:57,280][gdb0][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service.
[2017-07-06 21:28:57,312][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0 --runtime
[2017-07-06 21:28:57,376][gdb0][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@0
[2017-07-06 21:28:57,376][gdb0][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service to /lib/systemd/system/ceph-osd@.service.
[2017-07-06 21:28:57,408][gdb0][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@0
[2017-07-06 21:29:02,527][gdb0][INFO  ] checking OSD status...
[2017-07-06 21:29:02,527][gdb0][DEBUG ] find the location of an executable
[2017-07-06 21:29:02,530][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 21:29:02,698][gdb0][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 21:31:26,457][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:31:26,458][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-07-06 21:31:26,458][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:31:26,458][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:31:26,458][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:31:26,458][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:31:26,458][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:31:26,458][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f4249692128>
[2017-07-06 21:31:26,458][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:31:26,458][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-06 21:31:26,458][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f4249f9f1b8>
[2017-07-06 21:31:26,458][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:31:26,458][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:31:26,458][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-07-06 21:31:26,458][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-07-06 21:31:26,459][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-07-06 21:31:26,459][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-07-06 21:31:26,485][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:31:26,499][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:31:26,500][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:31:26,517][gdb3][DEBUG ] detect machine type
[2017-07-06 21:31:26,519][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:31:26,519][gdb3][INFO  ] Purging Ceph on gdb3
[2017-07-06 21:31:26,520][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-07-06 21:31:26,558][gdb3][DEBUG ] Reading package lists...
[2017-07-06 21:31:26,723][gdb3][DEBUG ] Building dependency tree...
[2017-07-06 21:31:26,723][gdb3][DEBUG ] Reading state information...
[2017-07-06 21:31:26,787][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-07-06 21:31:26,787][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-07-06 21:31:26,787][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-07-06 21:31:26,788][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-07-06 21:31:26,788][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-07-06 21:31:26,788][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-07-06 21:31:26,788][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1016 linux-aws-headers-4.4.0-1017
[2017-07-06 21:31:26,788][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1018 linux-headers-4.4.0-1013-aws
[2017-07-06 21:31:26,788][gdb3][DEBUG ]   linux-headers-4.4.0-1016-aws linux-headers-4.4.0-1017-aws
[2017-07-06 21:31:26,788][gdb3][DEBUG ]   linux-headers-4.4.0-1018-aws linux-image-4.4.0-1013-aws
[2017-07-06 21:31:26,788][gdb3][DEBUG ]   linux-image-4.4.0-1016-aws linux-image-4.4.0-1017-aws
[2017-07-06 21:31:26,789][gdb3][DEBUG ]   linux-image-4.4.0-1018-aws ntp python-blinker python-cephfs
[2017-07-06 21:31:26,789][gdb3][DEBUG ]   python-cffi-backend python-chardet python-cryptography python-enum34
[2017-07-06 21:31:26,789][gdb3][DEBUG ]   python-flask python-idna python-ipaddress python-itsdangerous python-jinja2
[2017-07-06 21:31:26,789][gdb3][DEBUG ]   python-markupsafe python-ndg-httpsclient python-openssl python-pyasn1
[2017-07-06 21:31:26,789][gdb3][DEBUG ]   python-pyinotify python-rados python-rbd python-requests python-rgw
[2017-07-06 21:31:26,789][gdb3][DEBUG ]   python-six python-urllib3 python-werkzeug
[2017-07-06 21:31:26,789][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-07-06 21:31:26,821][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-07-06 21:31:26,821][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-07-06 21:31:26,935][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 60 not upgraded.
[2017-07-06 21:31:26,936][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-07-06 21:31:27,000][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 179644 files and directories currently installed.)
[2017-07-06 21:31:27,015][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-07-06 21:31:27,184][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-07-06 21:31:27,298][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-07-06 21:31:27,314][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-07-06 21:31:27,528][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-07-06 21:31:27,643][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-07-06 21:31:27,812][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-07-06 21:31:27,878][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-07-06 21:31:27,910][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-07-06 21:31:28,075][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-07-06 21:31:28,139][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-07-06 21:31:28,155][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-07-06 21:31:28,320][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-07-06 21:31:28,336][gdb3][DEBUG ] dpkg: warning: while removing ceph-base, directory '/var/lib/ceph/bootstrap-osd' not empty so not removed
[2017-07-06 21:31:28,368][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-07-06 21:31:28,532][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-07-06 21:31:28,564][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-07-06 21:31:28,580][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-07-06 21:31:28,694][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu9) ...
[2017-07-06 21:31:29,510][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-07-06 21:31:29,676][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:31:29,676][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-07-06 21:31:29,676][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:31:29,676][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:31:29,676][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:31:29,676][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:31:29,676][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:31:29,677][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fce2d2007a0>
[2017-07-06 21:31:29,677][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:31:29,677][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-06 21:31:29,677][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7fce2db0d230>
[2017-07-06 21:31:29,677][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:31:29,677][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:31:29,677][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-07-06 21:31:29,703][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:31:29,717][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:31:29,718][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:31:29,734][gdb3][DEBUG ] detect machine type
[2017-07-06 21:31:29,736][gdb3][DEBUG ] find the location of an executable
[2017-07-06 21:31:29,752][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:31:29,765][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:31:29,766][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:31:29,782][gdb3][DEBUG ] detect machine type
[2017-07-06 21:31:29,784][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:31:29,784][gdb3][INFO  ] purging data on gdb3
[2017-07-06 21:31:29,785][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-07-06 21:31:29,798][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-07-06 21:31:29,968][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:31:29,969][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-07-06 21:31:29,969][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:31:29,969][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:31:29,969][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:31:29,969][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:31:29,969][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:31:29,969][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fd981e96a70>
[2017-07-06 21:31:29,969][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:31:29,969][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7fd982759848>
[2017-07-06 21:31:29,969][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:31:29,969][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:31:48,804][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:31:48,805][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-07-06 21:31:48,805][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:31:48,805][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:31:48,805][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:31:48,805][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:31:48,805][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:31:48,805][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f057cec55f0>
[2017-07-06 21:31:48,805][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:31:48,805][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-07-06 21:31:48,805][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-07-06 21:31:48,806][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f057d549758>
[2017-07-06 21:31:48,806][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-07-06 21:31:48,806][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:31:48,806][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-07-06 21:31:48,806][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:31:48,806][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-07-06 21:31:48,806][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-07-06 21:31:48,806][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-07-06 21:31:48,833][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:31:48,847][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:31:48,848][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:31:48,865][gdb3][DEBUG ] detect machine type
[2017-07-06 21:31:48,867][gdb3][DEBUG ] find the location of an executable
[2017-07-06 21:31:48,868][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-07-06 21:31:48,880][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-07-06 21:31:48,886][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-07-06 21:31:48,886][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-07-06 21:31:48,886][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-07-06 21:31:48,886][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-07-06 21:31:48,887][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-07-06 21:31:48,887][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-07-06 21:31:48,887][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-07-06 21:31:48,887][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-07-06 21:31:49,053][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:31:49,054][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-07-06 21:31:49,054][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:31:49,054][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:31:49,054][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:31:49,054][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:31:49,054][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-07-06 21:31:49,054][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:31:49,054][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f01be1daef0>
[2017-07-06 21:31:49,054][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:31:49,055][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f01be1aeb18>
[2017-07-06 21:31:49,055][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:31:49,055][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-07-06 21:31:49,055][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:31:49,056][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-07-06 21:31:49,056][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-07-06 21:31:49,082][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:31:49,096][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:31:49,097][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:31:49,113][gdb3][DEBUG ] detect machine type
[2017-07-06 21:31:49,116][gdb3][DEBUG ] find the location of an executable
[2017-07-06 21:31:49,116][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-07-06 21:31:49,116][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-07-06 21:31:49,116][gdb3][DEBUG ] get remote short hostname
[2017-07-06 21:31:49,117][gdb3][DEBUG ] deploying mon to gdb3
[2017-07-06 21:31:49,117][gdb3][DEBUG ] get remote short hostname
[2017-07-06 21:31:49,117][gdb3][DEBUG ] remote hostname: gdb3
[2017-07-06 21:31:49,118][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:31:49,119][gdb3][DEBUG ] create the mon path if it does not exist
[2017-07-06 21:31:49,119][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-06 21:31:49,120][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-06 21:31:49,120][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-06 21:31:49,120][gdb3][DEBUG ] create the monitor keyring file
[2017-07-06 21:31:49,121][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-07-06 21:31:49,159][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-07-06 21:31:49,160][gdb3][DEBUG ] ceph-mon: set fsid to 6899be12-89ec-48ae-b5e0-ea15dc89fdb3
[2017-07-06 21:31:49,167][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-07-06 21:31:49,170][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-06 21:31:49,171][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-07-06 21:31:49,171][gdb3][DEBUG ] create the init path if it does not exist
[2017-07-06 21:31:49,172][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 21:31:49,240][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-07-06 21:31:49,312][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-07-06 21:31:51,382][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 21:31:51,447][gdb3][DEBUG ] ********************************************************************************
[2017-07-06 21:31:51,448][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-07-06 21:31:51,448][gdb3][DEBUG ] {
[2017-07-06 21:31:51,448][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-07-06 21:31:51,448][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-07-06 21:31:51,448][gdb3][DEBUG ]   "features": {
[2017-07-06 21:31:51,448][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-07-06 21:31:51,448][gdb3][DEBUG ]     "quorum_mon": [
[2017-07-06 21:31:51,448][gdb3][DEBUG ]       "kraken", 
[2017-07-06 21:31:51,448][gdb3][DEBUG ]       "luminous"
[2017-07-06 21:31:51,448][gdb3][DEBUG ]     ], 
[2017-07-06 21:31:51,448][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-07-06 21:31:51,448][gdb3][DEBUG ]     "required_mon": [
[2017-07-06 21:31:51,449][gdb3][DEBUG ]       "kraken", 
[2017-07-06 21:31:51,449][gdb3][DEBUG ]       "luminous"
[2017-07-06 21:31:51,449][gdb3][DEBUG ]     ]
[2017-07-06 21:31:51,449][gdb3][DEBUG ]   }, 
[2017-07-06 21:31:51,449][gdb3][DEBUG ]   "monmap": {
[2017-07-06 21:31:51,449][gdb3][DEBUG ]     "created": "2017-07-06 21:31:49.144961", 
[2017-07-06 21:31:51,449][gdb3][DEBUG ]     "epoch": 2, 
[2017-07-06 21:31:51,449][gdb3][DEBUG ]     "features": {
[2017-07-06 21:31:51,449][gdb3][DEBUG ]       "optional": [], 
[2017-07-06 21:31:51,449][gdb3][DEBUG ]       "persistent": [
[2017-07-06 21:31:51,449][gdb3][DEBUG ]         "kraken", 
[2017-07-06 21:31:51,449][gdb3][DEBUG ]         "luminous"
[2017-07-06 21:31:51,449][gdb3][DEBUG ]       ]
[2017-07-06 21:31:51,449][gdb3][DEBUG ]     }, 
[2017-07-06 21:31:51,449][gdb3][DEBUG ]     "fsid": "6899be12-89ec-48ae-b5e0-ea15dc89fdb3", 
[2017-07-06 21:31:51,449][gdb3][DEBUG ]     "modified": "2017-07-06 21:31:49.396011", 
[2017-07-06 21:31:51,450][gdb3][DEBUG ]     "mons": [
[2017-07-06 21:31:51,450][gdb3][DEBUG ]       {
[2017-07-06 21:31:51,450][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-07-06 21:31:51,450][gdb3][DEBUG ]         "name": "gdb3", 
[2017-07-06 21:31:51,450][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-07-06 21:31:51,450][gdb3][DEBUG ]         "rank": 0
[2017-07-06 21:31:51,450][gdb3][DEBUG ]       }
[2017-07-06 21:31:51,450][gdb3][DEBUG ]     ]
[2017-07-06 21:31:51,450][gdb3][DEBUG ]   }, 
[2017-07-06 21:31:51,450][gdb3][DEBUG ]   "name": "gdb3", 
[2017-07-06 21:31:51,450][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-07-06 21:31:51,450][gdb3][DEBUG ]   "quorum": [
[2017-07-06 21:31:51,450][gdb3][DEBUG ]     0
[2017-07-06 21:31:51,450][gdb3][DEBUG ]   ], 
[2017-07-06 21:31:51,450][gdb3][DEBUG ]   "rank": 0, 
[2017-07-06 21:31:51,450][gdb3][DEBUG ]   "state": "leader", 
[2017-07-06 21:31:51,451][gdb3][DEBUG ]   "sync_provider": []
[2017-07-06 21:31:51,451][gdb3][DEBUG ] }
[2017-07-06 21:31:51,451][gdb3][DEBUG ] ********************************************************************************
[2017-07-06 21:31:51,451][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-07-06 21:31:51,452][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 21:31:51,517][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-07-06 21:31:51,532][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:31:51,547][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:31:51,547][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:31:51,563][gdb3][DEBUG ] detect machine type
[2017-07-06 21:31:51,566][gdb3][DEBUG ] find the location of an executable
[2017-07-06 21:31:51,567][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 21:31:51,632][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-07-06 21:31:51,632][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-07-06 21:31:51,632][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-07-06 21:31:51,634][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpVncIew
[2017-07-06 21:31:51,649][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:31:51,663][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:31:51,664][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:31:51,680][gdb3][DEBUG ] detect machine type
[2017-07-06 21:31:51,683][gdb3][DEBUG ] get remote short hostname
[2017-07-06 21:31:51,683][gdb3][DEBUG ] fetch remote file
[2017-07-06 21:31:51,685][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 21:31:51,751][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-07-06 21:31:51,917][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-07-06 21:31:52,083][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-07-06 21:31:52,249][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-07-06 21:31:52,415][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-07-06 21:31:52,581][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-07-06 21:31:52,748][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-07-06 21:31:52,914][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-07-06 21:31:53,080][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-07-06 21:31:53,246][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-07-06 21:31:53,411][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-07-06 21:31:53,412][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-07-06 21:31:53,412][ceph_deploy.gatherkeys][INFO  ] Replacing 'ceph.bootstrap-mgr.keyring' and backing up old key as 'ceph.bootstrap-mgr.keyring-20170706213153'
[2017-07-06 21:31:53,412][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-07-06 21:31:53,412][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-07-06 21:31:53,412][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-07-06 21:31:53,412][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpVncIew
[2017-07-06 21:31:53,592][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:31:53,593][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-07-06 21:31:53,593][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:31:53,593][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:31:53,593][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:31:53,593][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:31:53,593][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:31:53,593][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f00252df5a8>
[2017-07-06 21:31:53,593][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:31:53,593][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-07-06 21:31:53,593][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f0025bf6938>
[2017-07-06 21:31:53,593][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:31:53,593][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:31:53,594][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-07-06 21:31:53,619][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:31:53,633][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:31:53,634][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:31:53,651][gdb3][DEBUG ] detect machine type
[2017-07-06 21:31:53,653][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:32:32,201][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:32:32,202][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb1
[2017-07-06 21:32:32,202][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:32:32,202][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:32:32,202][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:32:32,202][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 21:32:32,202][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:32:32,202][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fbd374c25a8>
[2017-07-06 21:32:32,202][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:32:32,202][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-07-06 21:32:32,202][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fbd37dd9938>
[2017-07-06 21:32:32,202][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:32:32,202][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:32:32,203][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-07-06 21:32:32,596][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 21:32:32,842][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 21:32:32,843][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 21:32:32,860][gdb1][DEBUG ] detect machine type
[2017-07-06 21:32:32,864][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:32:33,037][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:32:33,037][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-07-06 21:32:33,037][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:32:33,037][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:32:33,037][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 21:32:33,038][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-06 21:32:33,038][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 21:32:33,038][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:32:33,038][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 21:32:33,038][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 21:32:33,038][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:32:33,038][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 21:32:33,038][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 21:32:33,038][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:32:33,038][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f8b0a5ed998>
[2017-07-06 21:32:33,038][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:32:33,038][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 21:32:33,038][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f8b0a843aa0>
[2017-07-06 21:32:33,038][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:32:33,038][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:32:33,038][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 21:32:33,039][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-07-06 21:32:33,283][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 21:32:33,511][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 21:32:33,511][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 21:32:33,528][gdb1][DEBUG ] detect machine type
[2017-07-06 21:32:33,532][gdb1][DEBUG ] find the location of an executable
[2017-07-06 21:32:33,533][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:32:33,533][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-07-06 21:32:33,533][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:32:33,536][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-07-06 21:32:33,536][gdb1][DEBUG ] find the location of an executable
[2017-07-06 21:32:33,538][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 21:32:33,709][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 21:32:33,873][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 21:32:33,889][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 21:32:33,905][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 21:32:33,913][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 21:32:33,920][gdb1][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-07-06 21:32:38,941][gdb1][INFO  ] checking OSD status...
[2017-07-06 21:32:38,942][gdb1][DEBUG ] find the location of an executable
[2017-07-06 21:32:38,944][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 21:32:39,160][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-07-06 21:32:39,325][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:32:39,326][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-07-06 21:32:39,326][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:32:39,326][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:32:39,326][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:32:39,326][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:32:39,326][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 21:32:39,326][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:32:39,326][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f8abc960998>
[2017-07-06 21:32:39,326][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:32:39,326][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f8abcbb6aa0>
[2017-07-06 21:32:39,326][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:32:39,326][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:32:39,327][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-06 21:32:39,327][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-07-06 21:32:39,563][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 21:32:39,790][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 21:32:39,790][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 21:32:39,806][gdb1][DEBUG ] detect machine type
[2017-07-06 21:32:39,810][gdb1][DEBUG ] find the location of an executable
[2017-07-06 21:32:39,811][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:32:39,811][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-07-06 21:32:39,811][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 21:32:39,811][gdb1][DEBUG ] find the location of an executable
[2017-07-06 21:32:39,814][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 21:32:39,934][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 21:32:39,936][gdb1][WARNING] activate: Cluster uuid is 382eeac0-7e10-4bdc-98d7-53d22201d56d
[2017-07-06 21:32:39,936][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 21:32:39,952][gdb1][WARNING] Traceback (most recent call last):
[2017-07-06 21:32:39,952][gdb1][WARNING]   File "/usr/local/bin/ceph-disk", line 9, in <module>
[2017-07-06 21:32:39,952][gdb1][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-07-06 21:32:39,952][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5653, in run
[2017-07-06 21:32:39,952][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5604, in main
[2017-07-06 21:32:39,952][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3713, in main_activate
[2017-07-06 21:32:39,952][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3533, in activate_dir
[2017-07-06 21:32:39,952][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3609, in activate
[2017-07-06 21:32:39,952][gdb1][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid 382eeac0-7e10-4bdc-98d7-53d22201d56d
[2017-07-06 21:32:39,956][gdb1][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-07-06 21:32:39,956][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-07-06 21:34:39,106][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:34:39,106][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb1
[2017-07-06 21:34:39,106][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:34:39,106][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:34:39,107][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:34:39,107][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 21:34:39,107][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:34:39,107][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0d1ea4b5a8>
[2017-07-06 21:34:39,107][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:34:39,107][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-07-06 21:34:39,107][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f0d1f362938>
[2017-07-06 21:34:39,107][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:34:39,107][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:34:39,107][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-07-06 21:34:39,347][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 21:34:39,538][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 21:34:39,538][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 21:34:39,555][gdb1][DEBUG ] detect machine type
[2017-07-06 21:34:39,559][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:34:39,731][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:34:39,732][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-07-06 21:34:39,732][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:34:39,732][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:34:39,732][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 21:34:39,732][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-06 21:34:39,732][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 21:34:39,732][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:34:39,732][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 21:34:39,732][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 21:34:39,732][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:34:39,732][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 21:34:39,732][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 21:34:39,732][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:34:39,733][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f68bf04d998>
[2017-07-06 21:34:39,733][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:34:39,733][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 21:34:39,733][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f68bf2a3aa0>
[2017-07-06 21:34:39,733][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:34:39,733][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:34:39,733][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 21:34:39,733][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-07-06 21:34:39,971][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 21:34:40,203][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 21:34:40,203][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 21:34:40,220][gdb1][DEBUG ] detect machine type
[2017-07-06 21:34:40,224][gdb1][DEBUG ] find the location of an executable
[2017-07-06 21:34:40,225][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:34:40,225][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-07-06 21:34:40,225][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:34:40,228][gdb1][WARNING] osd keyring does not exist yet, creating one
[2017-07-06 21:34:40,228][gdb1][DEBUG ] create a keyring file
[2017-07-06 21:34:40,230][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-07-06 21:34:40,230][gdb1][DEBUG ] find the location of an executable
[2017-07-06 21:34:40,232][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 21:34:40,402][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 21:34:40,402][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 21:34:40,403][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 21:34:40,403][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 21:34:40,406][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 21:34:40,422][gdb1][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-07-06 21:34:40,422][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.19917.tmp
[2017-07-06 21:34:40,425][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.19917.tmp
[2017-07-06 21:34:40,429][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.19917.tmp
[2017-07-06 21:34:45,450][gdb1][INFO  ] checking OSD status...
[2017-07-06 21:34:45,450][gdb1][DEBUG ] find the location of an executable
[2017-07-06 21:34:45,452][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 21:34:45,618][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-07-06 21:34:45,784][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:34:45,784][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-07-06 21:34:45,784][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:34:45,784][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:34:45,784][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:34:45,784][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:34:45,784][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 21:34:45,784][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:34:45,784][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6d70679998>
[2017-07-06 21:34:45,784][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:34:45,785][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f6d708cfaa0>
[2017-07-06 21:34:45,785][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:34:45,785][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:34:45,785][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-06 21:34:45,785][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-07-06 21:34:46,031][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 21:34:46,222][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 21:34:46,223][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 21:34:46,240][gdb1][DEBUG ] detect machine type
[2017-07-06 21:34:46,243][gdb1][DEBUG ] find the location of an executable
[2017-07-06 21:34:46,244][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:34:46,244][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-07-06 21:34:46,244][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 21:34:46,245][gdb1][DEBUG ] find the location of an executable
[2017-07-06 21:34:46,247][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 21:34:46,367][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 21:34:46,367][gdb1][WARNING] activate: Cluster uuid is 6899be12-89ec-48ae-b5e0-ea15dc89fdb3
[2017-07-06 21:34:46,368][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 21:34:46,383][gdb1][WARNING] activate: Cluster name is ceph
[2017-07-06 21:34:46,383][gdb1][WARNING] activate: OSD uuid is ba6f0d3b-fad6-443a-aed7-52c821cea60c
[2017-07-06 21:34:46,384][gdb1][WARNING] allocate_osd_id: Allocating OSD id...
[2017-07-06 21:34:46,384][gdb1][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise ba6f0d3b-fad6-443a-aed7-52c821cea60c
[2017-07-06 21:34:46,548][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.20037.tmp
[2017-07-06 21:34:46,548][gdb1][WARNING] activate: OSD id is 0
[2017-07-06 21:34:46,548][gdb1][WARNING] activate: Initializing OSD...
[2017-07-06 21:34:46,548][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-07-06 21:34:46,713][gdb1][WARNING] got monmap epoch 2
[2017-07-06 21:34:46,713][gdb1][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 0 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid ba6f0d3b-fad6-443a-aed7-52c821cea60c --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-07-06 21:34:46,729][gdb1][WARNING] activate: Marking with init system systemd
[2017-07-06 21:34:46,729][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-07-06 21:34:46,729][gdb1][WARNING] activate: Authorizing OSD key...
[2017-07-06 21:34:46,729][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.0 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-07-06 21:34:46,893][gdb1][WARNING] added key for osd.0
[2017-07-06 21:34:46,893][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.20037.tmp
[2017-07-06 21:34:46,893][gdb1][WARNING] activate: ceph osd.0 data dir is ready at /mnt/memstore
[2017-07-06 21:34:46,893][gdb1][WARNING] Traceback (most recent call last):
[2017-07-06 21:34:46,894][gdb1][WARNING]   File "/usr/local/bin/ceph-disk", line 9, in <module>
[2017-07-06 21:34:46,894][gdb1][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-07-06 21:34:46,894][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5653, in run
[2017-07-06 21:34:46,894][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5604, in main
[2017-07-06 21:34:46,894][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3713, in main_activate
[2017-07-06 21:34:46,894][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3543, in activate_dir
[2017-07-06 21:34:46,894][gdb1][WARNING] OSError: [Errno 22] Invalid argument: '/var/lib/ceph/osd/ceph-0'
[2017-07-06 21:34:46,894][gdb1][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-07-06 21:34:46,894][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-07-06 21:35:39,287][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:35:39,287][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb1
[2017-07-06 21:35:39,287][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:35:39,287][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:35:39,287][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:35:39,287][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 21:35:39,288][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:35:39,288][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f4c04b8d5a8>
[2017-07-06 21:35:39,288][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:35:39,288][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-07-06 21:35:39,288][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f4c054a4938>
[2017-07-06 21:35:39,288][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:35:39,288][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:35:39,288][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-07-06 21:35:39,527][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 21:35:39,759][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 21:35:39,759][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 21:35:39,776][gdb1][DEBUG ] detect machine type
[2017-07-06 21:35:39,779][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:35:39,951][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:35:39,951][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-07-06 21:35:39,951][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:35:39,952][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:35:39,952][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 21:35:39,952][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-06 21:35:39,952][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 21:35:39,952][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:35:39,952][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 21:35:39,952][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 21:35:39,952][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:35:39,952][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 21:35:39,952][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 21:35:39,952][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:35:39,952][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f753b726998>
[2017-07-06 21:35:39,952][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:35:39,952][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 21:35:39,952][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f753b97caa0>
[2017-07-06 21:35:39,953][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:35:39,953][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:35:39,953][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 21:35:39,953][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-07-06 21:35:40,187][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 21:35:40,378][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 21:35:40,379][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 21:35:40,395][gdb1][DEBUG ] detect machine type
[2017-07-06 21:35:40,399][gdb1][DEBUG ] find the location of an executable
[2017-07-06 21:35:40,400][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:35:40,400][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-07-06 21:35:40,400][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:35:40,403][gdb1][WARNING] osd keyring does not exist yet, creating one
[2017-07-06 21:35:40,403][gdb1][DEBUG ] create a keyring file
[2017-07-06 21:35:40,405][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-07-06 21:35:40,405][gdb1][DEBUG ] find the location of an executable
[2017-07-06 21:35:40,407][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 21:35:40,578][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 21:35:40,578][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 21:35:40,578][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 21:35:40,578][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 21:35:40,578][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 21:35:40,594][gdb1][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-07-06 21:35:40,602][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.20336.tmp
[2017-07-06 21:35:40,602][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.20336.tmp
[2017-07-06 21:35:40,609][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.20336.tmp
[2017-07-06 21:35:45,622][gdb1][INFO  ] checking OSD status...
[2017-07-06 21:35:45,622][gdb1][DEBUG ] find the location of an executable
[2017-07-06 21:35:45,625][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 21:35:45,790][gdb1][WARNING] there is 1 OSD down
[2017-07-06 21:35:45,790][gdb1][WARNING] there is 1 OSD out
[2017-07-06 21:35:45,791][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-07-06 21:35:45,956][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:35:45,957][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-07-06 21:35:45,957][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:35:45,957][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:35:45,957][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:35:45,957][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:35:45,957][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 21:35:45,957][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:35:45,957][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe067a93998>
[2017-07-06 21:35:45,957][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:35:45,957][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fe067ce9aa0>
[2017-07-06 21:35:45,957][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:35:45,958][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:35:45,958][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-06 21:35:45,958][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-07-06 21:35:46,195][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 21:35:46,426][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 21:35:46,427][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 21:35:46,443][gdb1][DEBUG ] detect machine type
[2017-07-06 21:35:46,447][gdb1][DEBUG ] find the location of an executable
[2017-07-06 21:35:46,448][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:35:46,448][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-07-06 21:35:46,448][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 21:35:46,449][gdb1][DEBUG ] find the location of an executable
[2017-07-06 21:35:46,450][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 21:35:46,621][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 21:35:46,621][gdb1][WARNING] activate: Cluster uuid is 6899be12-89ec-48ae-b5e0-ea15dc89fdb3
[2017-07-06 21:35:46,621][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 21:35:46,621][gdb1][WARNING] activate: Cluster name is ceph
[2017-07-06 21:35:46,621][gdb1][WARNING] activate: OSD uuid is 0b527c71-0011-40c4-a63f-4b266e8ce1f4
[2017-07-06 21:35:46,621][gdb1][WARNING] allocate_osd_id: Allocating OSD id...
[2017-07-06 21:35:46,622][gdb1][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 0b527c71-0011-40c4-a63f-4b266e8ce1f4
[2017-07-06 21:35:47,739][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.20453.tmp
[2017-07-06 21:35:47,739][gdb1][WARNING] activate: OSD id is 1
[2017-07-06 21:35:47,739][gdb1][WARNING] activate: Initializing OSD...
[2017-07-06 21:35:47,739][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-07-06 21:35:47,853][gdb1][WARNING] got monmap epoch 2
[2017-07-06 21:35:47,854][gdb1][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 1 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid 0b527c71-0011-40c4-a63f-4b266e8ce1f4 --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-07-06 21:35:47,869][gdb1][WARNING] activate: Marking with init system systemd
[2017-07-06 21:35:47,869][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-07-06 21:35:47,871][gdb1][WARNING] activate: Authorizing OSD key...
[2017-07-06 21:35:47,871][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.1 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-07-06 21:35:48,035][gdb1][WARNING] added key for osd.1
[2017-07-06 21:35:48,035][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.20453.tmp
[2017-07-06 21:35:48,035][gdb1][WARNING] activate: ceph osd.1 data dir is ready at /mnt/memstore
[2017-07-06 21:35:48,035][gdb1][WARNING] activate_dir: Creating symlink /var/lib/ceph/osd/ceph-1 -> /mnt/memstore
[2017-07-06 21:35:48,035][gdb1][WARNING] start_daemon: Starting ceph osd.1...
[2017-07-06 21:35:48,035][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@1
[2017-07-06 21:35:48,051][gdb1][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@1.service.
[2017-07-06 21:35:48,215][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@1 --runtime
[2017-07-06 21:35:48,280][gdb1][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@1
[2017-07-06 21:35:48,280][gdb1][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@1.service to /lib/systemd/system/ceph-osd@.service.
[2017-07-06 21:35:48,312][gdb1][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@1
[2017-07-06 21:35:53,431][gdb1][INFO  ] checking OSD status...
[2017-07-06 21:35:53,431][gdb1][DEBUG ] find the location of an executable
[2017-07-06 21:35:53,434][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 21:35:53,599][gdb1][WARNING] there is 1 OSD down
[2017-07-06 21:35:53,599][gdb1][WARNING] there is 1 OSD out
[2017-07-06 21:35:53,601][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 21:37:51,328][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:37:51,329][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-07-06 21:37:51,329][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:37:51,329][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:37:51,329][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:37:51,329][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:37:51,329][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:37:51,329][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa52913b128>
[2017-07-06 21:37:51,329][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:37:51,329][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-06 21:37:51,329][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7fa529a481b8>
[2017-07-06 21:37:51,329][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:37:51,330][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:37:51,330][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-07-06 21:37:51,330][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-07-06 21:37:51,330][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-07-06 21:37:51,330][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-07-06 21:37:51,356][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:37:51,370][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:37:51,370][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:37:51,387][gdb3][DEBUG ] detect machine type
[2017-07-06 21:37:51,389][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:37:51,389][gdb3][INFO  ] Purging Ceph on gdb3
[2017-07-06 21:37:51,390][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-07-06 21:37:51,428][gdb3][DEBUG ] Reading package lists...
[2017-07-06 21:37:51,592][gdb3][DEBUG ] Building dependency tree...
[2017-07-06 21:37:51,593][gdb3][DEBUG ] Reading state information...
[2017-07-06 21:37:51,657][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-07-06 21:37:51,657][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-07-06 21:37:51,657][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-07-06 21:37:51,657][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-07-06 21:37:51,657][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-07-06 21:37:51,657][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-07-06 21:37:51,657][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1016 linux-aws-headers-4.4.0-1017
[2017-07-06 21:37:51,658][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1018 linux-headers-4.4.0-1013-aws
[2017-07-06 21:37:51,658][gdb3][DEBUG ]   linux-headers-4.4.0-1016-aws linux-headers-4.4.0-1017-aws
[2017-07-06 21:37:51,658][gdb3][DEBUG ]   linux-headers-4.4.0-1018-aws linux-image-4.4.0-1013-aws
[2017-07-06 21:37:51,658][gdb3][DEBUG ]   linux-image-4.4.0-1016-aws linux-image-4.4.0-1017-aws
[2017-07-06 21:37:51,658][gdb3][DEBUG ]   linux-image-4.4.0-1018-aws ntp python-blinker python-cephfs
[2017-07-06 21:37:51,658][gdb3][DEBUG ]   python-cffi-backend python-chardet python-cryptography python-enum34
[2017-07-06 21:37:51,658][gdb3][DEBUG ]   python-flask python-idna python-ipaddress python-itsdangerous python-jinja2
[2017-07-06 21:37:51,658][gdb3][DEBUG ]   python-markupsafe python-ndg-httpsclient python-openssl python-pyasn1
[2017-07-06 21:37:51,658][gdb3][DEBUG ]   python-pyinotify python-rados python-rbd python-requests python-rgw
[2017-07-06 21:37:51,659][gdb3][DEBUG ]   python-six python-urllib3 python-werkzeug
[2017-07-06 21:37:51,659][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-07-06 21:37:51,691][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-07-06 21:37:51,691][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-07-06 21:37:51,805][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 60 not upgraded.
[2017-07-06 21:37:51,805][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-07-06 21:37:51,919][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 179644 files and directories currently installed.)
[2017-07-06 21:37:51,919][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-07-06 21:37:52,084][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-07-06 21:37:52,148][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-07-06 21:37:52,219][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-07-06 21:37:52,385][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-07-06 21:37:52,500][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-07-06 21:37:52,667][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-07-06 21:37:52,731][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-07-06 21:37:52,747][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-07-06 21:37:52,911][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-07-06 21:37:53,029][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-07-06 21:37:53,029][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-07-06 21:37:53,195][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-07-06 21:37:53,211][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-07-06 21:37:53,375][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-07-06 21:37:53,407][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-07-06 21:37:53,423][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-07-06 21:37:53,537][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu9) ...
[2017-07-06 21:37:54,354][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-07-06 21:37:54,518][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:37:54,519][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-07-06 21:37:54,519][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:37:54,519][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:37:54,519][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:37:54,519][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:37:54,519][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:37:54,519][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f5fb9dc87a0>
[2017-07-06 21:37:54,519][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:37:54,519][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-06 21:37:54,519][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f5fba6d5230>
[2017-07-06 21:37:54,520][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:37:54,520][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:37:54,520][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-07-06 21:37:54,546][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:37:54,561][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:37:54,561][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:37:54,578][gdb3][DEBUG ] detect machine type
[2017-07-06 21:37:54,581][gdb3][DEBUG ] find the location of an executable
[2017-07-06 21:37:54,597][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:37:54,612][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:37:54,613][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:37:54,630][gdb3][DEBUG ] detect machine type
[2017-07-06 21:37:54,632][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:37:54,632][gdb3][INFO  ] purging data on gdb3
[2017-07-06 21:37:54,633][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-07-06 21:37:54,646][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-07-06 21:37:54,816][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:37:54,816][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-07-06 21:37:54,816][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:37:54,816][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:37:54,816][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:37:54,816][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:37:54,816][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:37:54,816][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f94af465a70>
[2017-07-06 21:37:54,817][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:37:54,817][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7f94afd28848>
[2017-07-06 21:37:54,817][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:37:54,817][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:38:12,861][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:38:12,861][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-07-06 21:38:12,861][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:38:12,861][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:38:12,862][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:38:12,862][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:38:12,862][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:38:12,862][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe1ea9895f0>
[2017-07-06 21:38:12,862][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:38:12,862][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-07-06 21:38:12,862][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-07-06 21:38:12,862][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7fe1eb00d758>
[2017-07-06 21:38:12,862][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-07-06 21:38:12,862][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:38:12,862][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-07-06 21:38:12,862][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:38:12,862][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-07-06 21:38:12,862][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-07-06 21:38:12,863][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-07-06 21:38:12,889][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:38:12,903][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:38:12,903][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:38:12,920][gdb3][DEBUG ] detect machine type
[2017-07-06 21:38:12,923][gdb3][DEBUG ] find the location of an executable
[2017-07-06 21:38:12,924][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-07-06 21:38:12,935][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-07-06 21:38:12,942][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-07-06 21:38:12,942][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-07-06 21:38:12,942][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-07-06 21:38:12,942][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-07-06 21:38:12,942][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-07-06 21:38:12,942][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-07-06 21:38:12,942][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-07-06 21:38:12,942][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-07-06 21:38:13,109][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:38:13,109][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-07-06 21:38:13,109][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:38:13,109][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:38:13,109][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:38:13,109][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:38:13,109][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-07-06 21:38:13,110][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:38:13,110][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9349c57ef0>
[2017-07-06 21:38:13,110][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:38:13,110][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f9349c2bb18>
[2017-07-06 21:38:13,110][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:38:13,110][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-07-06 21:38:13,110][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:38:13,111][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-07-06 21:38:13,111][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-07-06 21:38:13,137][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:38:13,151][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:38:13,152][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:38:13,168][gdb3][DEBUG ] detect machine type
[2017-07-06 21:38:13,171][gdb3][DEBUG ] find the location of an executable
[2017-07-06 21:38:13,171][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-07-06 21:38:13,171][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-07-06 21:38:13,171][gdb3][DEBUG ] get remote short hostname
[2017-07-06 21:38:13,172][gdb3][DEBUG ] deploying mon to gdb3
[2017-07-06 21:38:13,172][gdb3][DEBUG ] get remote short hostname
[2017-07-06 21:38:13,172][gdb3][DEBUG ] remote hostname: gdb3
[2017-07-06 21:38:13,173][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:38:13,174][gdb3][DEBUG ] create the mon path if it does not exist
[2017-07-06 21:38:13,174][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-06 21:38:13,175][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-06 21:38:13,175][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-06 21:38:13,175][gdb3][DEBUG ] create the monitor keyring file
[2017-07-06 21:38:13,176][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-07-06 21:38:13,214][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-07-06 21:38:13,215][gdb3][DEBUG ] ceph-mon: set fsid to 7236ff6b-c970-4b9a-b9c8-98f42ac8519f
[2017-07-06 21:38:13,218][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-07-06 21:38:13,225][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-06 21:38:13,226][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-07-06 21:38:13,226][gdb3][DEBUG ] create the init path if it does not exist
[2017-07-06 21:38:13,227][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 21:38:13,295][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-07-06 21:38:13,368][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-07-06 21:38:15,438][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 21:38:15,503][gdb3][DEBUG ] ********************************************************************************
[2017-07-06 21:38:15,503][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-07-06 21:38:15,504][gdb3][DEBUG ] {
[2017-07-06 21:38:15,504][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-07-06 21:38:15,504][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-07-06 21:38:15,504][gdb3][DEBUG ]   "features": {
[2017-07-06 21:38:15,504][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-07-06 21:38:15,504][gdb3][DEBUG ]     "quorum_mon": [
[2017-07-06 21:38:15,504][gdb3][DEBUG ]       "kraken", 
[2017-07-06 21:38:15,504][gdb3][DEBUG ]       "luminous"
[2017-07-06 21:38:15,504][gdb3][DEBUG ]     ], 
[2017-07-06 21:38:15,504][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-07-06 21:38:15,504][gdb3][DEBUG ]     "required_mon": [
[2017-07-06 21:38:15,504][gdb3][DEBUG ]       "kraken", 
[2017-07-06 21:38:15,504][gdb3][DEBUG ]       "luminous"
[2017-07-06 21:38:15,505][gdb3][DEBUG ]     ]
[2017-07-06 21:38:15,505][gdb3][DEBUG ]   }, 
[2017-07-06 21:38:15,505][gdb3][DEBUG ]   "monmap": {
[2017-07-06 21:38:15,505][gdb3][DEBUG ]     "created": "2017-07-06 21:38:13.199946", 
[2017-07-06 21:38:15,505][gdb3][DEBUG ]     "epoch": 2, 
[2017-07-06 21:38:15,506][gdb3][DEBUG ]     "features": {
[2017-07-06 21:38:15,506][gdb3][DEBUG ]       "optional": [], 
[2017-07-06 21:38:15,506][gdb3][DEBUG ]       "persistent": [
[2017-07-06 21:38:15,506][gdb3][DEBUG ]         "kraken", 
[2017-07-06 21:38:15,506][gdb3][DEBUG ]         "luminous"
[2017-07-06 21:38:15,506][gdb3][DEBUG ]       ]
[2017-07-06 21:38:15,506][gdb3][DEBUG ]     }, 
[2017-07-06 21:38:15,506][gdb3][DEBUG ]     "fsid": "7236ff6b-c970-4b9a-b9c8-98f42ac8519f", 
[2017-07-06 21:38:15,506][gdb3][DEBUG ]     "modified": "2017-07-06 21:38:13.464585", 
[2017-07-06 21:38:15,506][gdb3][DEBUG ]     "mons": [
[2017-07-06 21:38:15,506][gdb3][DEBUG ]       {
[2017-07-06 21:38:15,506][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-07-06 21:38:15,506][gdb3][DEBUG ]         "name": "gdb3", 
[2017-07-06 21:38:15,506][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-07-06 21:38:15,507][gdb3][DEBUG ]         "rank": 0
[2017-07-06 21:38:15,507][gdb3][DEBUG ]       }
[2017-07-06 21:38:15,507][gdb3][DEBUG ]     ]
[2017-07-06 21:38:15,507][gdb3][DEBUG ]   }, 
[2017-07-06 21:38:15,507][gdb3][DEBUG ]   "name": "gdb3", 
[2017-07-06 21:38:15,507][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-07-06 21:38:15,507][gdb3][DEBUG ]   "quorum": [
[2017-07-06 21:38:15,508][gdb3][DEBUG ]     0
[2017-07-06 21:38:15,508][gdb3][DEBUG ]   ], 
[2017-07-06 21:38:15,508][gdb3][DEBUG ]   "rank": 0, 
[2017-07-06 21:38:15,508][gdb3][DEBUG ]   "state": "leader", 
[2017-07-06 21:38:15,508][gdb3][DEBUG ]   "sync_provider": []
[2017-07-06 21:38:15,508][gdb3][DEBUG ] }
[2017-07-06 21:38:15,508][gdb3][DEBUG ] ********************************************************************************
[2017-07-06 21:38:15,508][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-07-06 21:38:15,509][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 21:38:15,574][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-07-06 21:38:15,589][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:38:15,603][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:38:15,604][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:38:15,620][gdb3][DEBUG ] detect machine type
[2017-07-06 21:38:15,622][gdb3][DEBUG ] find the location of an executable
[2017-07-06 21:38:15,623][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 21:38:15,688][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-07-06 21:38:15,689][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-07-06 21:38:15,689][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-07-06 21:38:15,691][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpZhMHBs
[2017-07-06 21:38:15,706][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:38:15,720][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:38:15,720][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:38:15,737][gdb3][DEBUG ] detect machine type
[2017-07-06 21:38:15,739][gdb3][DEBUG ] get remote short hostname
[2017-07-06 21:38:15,740][gdb3][DEBUG ] fetch remote file
[2017-07-06 21:38:15,741][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 21:38:15,807][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-07-06 21:38:15,973][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-07-06 21:38:16,139][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-07-06 21:38:16,305][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-07-06 21:38:16,471][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-07-06 21:38:16,637][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-07-06 21:38:16,803][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-07-06 21:38:16,970][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-07-06 21:38:17,136][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-07-06 21:38:17,302][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-07-06 21:38:17,467][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-07-06 21:38:17,467][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-07-06 21:38:17,468][ceph_deploy.gatherkeys][INFO  ] Replacing 'ceph.bootstrap-mgr.keyring' and backing up old key as 'ceph.bootstrap-mgr.keyring-20170706213817'
[2017-07-06 21:38:17,468][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-07-06 21:38:17,468][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-07-06 21:38:17,468][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-07-06 21:38:17,468][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpZhMHBs
[2017-07-06 21:38:17,650][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:38:17,650][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-07-06 21:38:17,650][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:38:17,650][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:38:17,650][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:38:17,650][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:38:17,650][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:38:17,650][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f09d07345a8>
[2017-07-06 21:38:17,650][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:38:17,651][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-07-06 21:38:17,651][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f09d104b938>
[2017-07-06 21:38:17,651][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:38:17,651][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:38:17,651][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-07-06 21:38:17,677][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 21:38:17,691][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 21:38:17,692][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 21:38:17,708][gdb3][DEBUG ] detect machine type
[2017-07-06 21:38:17,711][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:38:23,009][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:38:23,009][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb1
[2017-07-06 21:38:23,009][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:38:23,009][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:38:23,009][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:38:23,009][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 21:38:23,009][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:38:23,009][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f66026015a8>
[2017-07-06 21:38:23,010][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:38:23,010][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-07-06 21:38:23,010][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f6602f18938>
[2017-07-06 21:38:23,010][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:38:23,010][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:38:23,010][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-07-06 21:38:23,247][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 21:38:23,458][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 21:38:23,459][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 21:38:23,475][gdb1][DEBUG ] detect machine type
[2017-07-06 21:38:23,479][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:38:23,651][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:38:23,651][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-07-06 21:38:23,651][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:38:23,651][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:38:23,652][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 21:38:23,652][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-06 21:38:23,652][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 21:38:23,652][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:38:23,652][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 21:38:23,652][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 21:38:23,652][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:38:23,652][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 21:38:23,652][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 21:38:23,652][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:38:23,652][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f4b392a5998>
[2017-07-06 21:38:23,652][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:38:23,652][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 21:38:23,652][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f4b394fbaa0>
[2017-07-06 21:38:23,652][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:38:23,653][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:38:23,653][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 21:38:23,653][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-07-06 21:38:23,891][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 21:38:24,119][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 21:38:24,120][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 21:38:24,136][gdb1][DEBUG ] detect machine type
[2017-07-06 21:38:24,140][gdb1][DEBUG ] find the location of an executable
[2017-07-06 21:38:24,140][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:38:24,140][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-07-06 21:38:24,141][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:38:24,143][gdb1][WARNING] osd keyring does not exist yet, creating one
[2017-07-06 21:38:24,143][gdb1][DEBUG ] create a keyring file
[2017-07-06 21:38:24,145][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-07-06 21:38:24,146][gdb1][DEBUG ] find the location of an executable
[2017-07-06 21:38:24,148][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 21:38:24,268][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 21:38:24,284][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 21:38:24,291][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 21:38:24,307][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 21:38:24,323][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 21:38:24,326][gdb1][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-07-06 21:38:24,330][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.21008.tmp
[2017-07-06 21:38:24,333][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.21008.tmp
[2017-07-06 21:38:24,336][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.21008.tmp
[2017-07-06 21:38:29,357][gdb1][INFO  ] checking OSD status...
[2017-07-06 21:38:29,358][gdb1][DEBUG ] find the location of an executable
[2017-07-06 21:38:29,360][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 21:38:29,526][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-07-06 21:38:29,689][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:38:29,690][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-07-06 21:38:29,690][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:38:29,690][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:38:29,690][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:38:29,690][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:38:29,690][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 21:38:29,690][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:38:29,690][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f8b19d9e998>
[2017-07-06 21:38:29,690][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:38:29,690][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f8b19ff4aa0>
[2017-07-06 21:38:29,690][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:38:29,690][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:38:29,690][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-06 21:38:29,691][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-07-06 21:38:29,935][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 21:38:30,166][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 21:38:30,167][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 21:38:30,183][gdb1][DEBUG ] detect machine type
[2017-07-06 21:38:30,187][gdb1][DEBUG ] find the location of an executable
[2017-07-06 21:38:30,188][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:38:30,188][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-07-06 21:38:30,188][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 21:38:30,188][gdb1][DEBUG ] find the location of an executable
[2017-07-06 21:38:30,190][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 21:38:30,361][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 21:38:30,361][gdb1][WARNING] activate: Cluster uuid is 7236ff6b-c970-4b9a-b9c8-98f42ac8519f
[2017-07-06 21:38:30,361][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 21:38:30,361][gdb1][WARNING] activate: Cluster name is ceph
[2017-07-06 21:38:30,361][gdb1][WARNING] activate: OSD uuid is d8eba919-e896-4106-a623-89378bf7505e
[2017-07-06 21:38:30,361][gdb1][WARNING] allocate_osd_id: Allocating OSD id...
[2017-07-06 21:38:30,361][gdb1][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise d8eba919-e896-4106-a623-89378bf7505e
[2017-07-06 21:38:30,475][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.21125.tmp
[2017-07-06 21:38:30,476][gdb1][WARNING] activate: OSD id is 0
[2017-07-06 21:38:30,476][gdb1][WARNING] activate: Initializing OSD...
[2017-07-06 21:38:30,476][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-07-06 21:38:30,640][gdb1][WARNING] got monmap epoch 2
[2017-07-06 21:38:30,640][gdb1][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 0 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid d8eba919-e896-4106-a623-89378bf7505e --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-07-06 21:38:30,672][gdb1][WARNING] activate: Marking with init system systemd
[2017-07-06 21:38:30,672][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-07-06 21:38:30,672][gdb1][WARNING] activate: Authorizing OSD key...
[2017-07-06 21:38:30,673][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.0 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-07-06 21:38:30,837][gdb1][WARNING] added key for osd.0
[2017-07-06 21:38:30,837][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.21125.tmp
[2017-07-06 21:38:30,837][gdb1][WARNING] activate: ceph osd.0 data dir is ready at /mnt/memstore
[2017-07-06 21:38:30,837][gdb1][WARNING] activate_dir: Creating symlink /var/lib/ceph/osd/ceph-0 -> /mnt/memstore
[2017-07-06 21:38:30,837][gdb1][WARNING] start_daemon: Starting ceph osd.0...
[2017-07-06 21:38:30,837][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0
[2017-07-06 21:38:30,838][gdb1][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service.
[2017-07-06 21:38:30,902][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0 --runtime
[2017-07-06 21:38:30,933][gdb1][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@0
[2017-07-06 21:38:30,934][gdb1][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service to /lib/systemd/system/ceph-osd@.service.
[2017-07-06 21:38:30,998][gdb1][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@0
[2017-07-06 21:38:41,936][gdb1][INFO  ] checking OSD status...
[2017-07-06 21:38:41,936][gdb1][DEBUG ] find the location of an executable
[2017-07-06 21:38:41,939][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 21:38:42,107][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 21:40:00,874][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:40:00,874][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy rgw create gdb1
[2017-07-06 21:40:00,874][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:40:00,874][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:40:00,874][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:40:00,874][ceph_deploy.cli][INFO  ]  rgw                           : [('gdb1', 'rgw.gdb1')]
[2017-07-06 21:40:00,874][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:40:00,874][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-06 21:40:00,874][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:40:00,874][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe712cb7830>
[2017-07-06 21:40:00,875][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:40:00,875][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7fe713378758>
[2017-07-06 21:40:00,875][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:40:00,875][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:40:00,875][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts gdb1:rgw.gdb1
[2017-07-06 21:40:01,115][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 21:40:01,319][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 21:40:01,320][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 21:40:01,336][gdb1][DEBUG ] detect machine type
[2017-07-06 21:40:01,341][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:40:01,341][ceph_deploy.rgw][DEBUG ] remote host will use systemd
[2017-07-06 21:40:01,341][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to gdb1
[2017-07-06 21:40:01,341][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:40:01,344][gdb1][DEBUG ] create path recursively if it doesn't exist
[2017-07-06 21:40:01,346][gdb1][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.gdb1 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.gdb1/keyring
[2017-07-06 21:40:01,463][gdb1][ERROR ] 2017-07-06 21:40:01.421915 7efc74daa700  0 librados: client.bootstrap-rgw authentication error (1) Operation not permitted
[2017-07-06 21:40:01,464][gdb1][ERROR ] error connecting to the cluster
[2017-07-06 21:40:01,464][gdb1][ERROR ] exit code from command was: 1
[2017-07-06 21:40:01,464][ceph_deploy.rgw][ERROR ] could not create rgw
[2017-07-06 21:40:01,464][ceph_deploy][ERROR ] GenericError: Failed to create 1 RGWs

[2017-07-06 21:40:37,159][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:40:37,160][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy rgw create gdb1
[2017-07-06 21:40:37,160][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:40:37,160][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:40:37,160][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:40:37,160][ceph_deploy.cli][INFO  ]  rgw                           : [('gdb1', 'rgw.gdb1')]
[2017-07-06 21:40:37,160][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:40:37,160][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-06 21:40:37,160][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:40:37,160][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fbc57139830>
[2017-07-06 21:40:37,160][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:40:37,160][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7fbc577fa758>
[2017-07-06 21:40:37,160][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:40:37,161][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:40:37,161][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts gdb1:rgw.gdb1
[2017-07-06 21:40:37,403][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 21:40:37,635][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 21:40:37,636][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 21:40:37,652][gdb1][DEBUG ] detect machine type
[2017-07-06 21:40:37,656][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:40:37,656][ceph_deploy.rgw][DEBUG ] remote host will use systemd
[2017-07-06 21:40:37,656][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to gdb1
[2017-07-06 21:40:37,656][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:40:37,659][gdb1][WARNING] rgw keyring does not exist yet, creating one
[2017-07-06 21:40:37,659][gdb1][DEBUG ] create a keyring file
[2017-07-06 21:40:37,661][gdb1][DEBUG ] create path recursively if it doesn't exist
[2017-07-06 21:40:37,663][gdb1][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.gdb1 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.gdb1/keyring
[2017-07-06 21:40:37,833][gdb1][INFO  ] Running command: sudo systemctl enable ceph-radosgw@rgw.gdb1
[2017-07-06 21:40:37,845][gdb1][WARNING] Failed to execute operation: No such file or directory
[2017-07-06 21:40:37,845][gdb1][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-07-06 21:40:37,845][ceph_deploy.rgw][ERROR ] Failed to execute command: systemctl enable ceph-radosgw@rgw.gdb1
[2017-07-06 21:40:37,845][ceph_deploy][ERROR ] GenericError: Failed to create 1 RGWs

[2017-07-06 21:41:13,842][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:41:13,842][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy rgw create gdb1
[2017-07-06 21:41:13,842][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:41:13,842][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:41:13,842][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:41:13,842][ceph_deploy.cli][INFO  ]  rgw                           : [('gdb1', 'rgw.gdb1')]
[2017-07-06 21:41:13,843][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:41:13,843][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-06 21:41:13,843][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:41:13,843][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f8aad1fb830>
[2017-07-06 21:41:13,843][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:41:13,843][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7f8aad8bc758>
[2017-07-06 21:41:13,843][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:41:13,843][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:41:13,843][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts gdb1:rgw.gdb1
[2017-07-06 21:41:14,086][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 21:41:14,314][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 21:41:14,315][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 21:41:14,331][gdb1][DEBUG ] detect machine type
[2017-07-06 21:41:14,335][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:41:14,336][ceph_deploy.rgw][DEBUG ] remote host will use systemd
[2017-07-06 21:41:14,336][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to gdb1
[2017-07-06 21:41:14,336][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:41:14,338][gdb1][DEBUG ] create path recursively if it doesn't exist
[2017-07-06 21:41:14,341][gdb1][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.gdb1 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.gdb1/keyring
[2017-07-06 21:41:14,511][gdb1][INFO  ] Running command: sudo systemctl enable ceph-radosgw@rgw.gdb1
[2017-07-06 21:41:14,531][gdb1][WARNING] Created symlink from /etc/systemd/system/ceph-radosgw.target.wants/ceph-radosgw@rgw.gdb1.service to /lib/systemd/system/ceph-radosgw@.service.
[2017-07-06 21:41:14,597][gdb1][INFO  ] Running command: sudo systemctl start ceph-radosgw@rgw.gdb1
[2017-07-06 21:41:14,665][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 21:41:14,732][ceph_deploy.rgw][INFO  ] The Ceph Object Gateway (RGW) is now running on host gdb1 and default port 7480
[2017-07-06 21:42:50,473][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 21:42:50,473][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy rgw create gdb1
[2017-07-06 21:42:50,473][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 21:42:50,473][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 21:42:50,473][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 21:42:50,473][ceph_deploy.cli][INFO  ]  rgw                           : [('gdb1', 'rgw.gdb1')]
[2017-07-06 21:42:50,474][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 21:42:50,474][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-06 21:42:50,474][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 21:42:50,474][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f1f71f22830>
[2017-07-06 21:42:50,474][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 21:42:50,474][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7f1f725e3758>
[2017-07-06 21:42:50,474][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 21:42:50,474][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 21:42:50,474][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts gdb1:rgw.gdb1
[2017-07-06 21:42:50,763][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 21:42:51,025][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 21:42:51,026][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 21:42:51,050][gdb1][DEBUG ] detect machine type
[2017-07-06 21:42:51,055][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 21:42:51,055][ceph_deploy.rgw][DEBUG ] remote host will use systemd
[2017-07-06 21:42:51,055][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to gdb1
[2017-07-06 21:42:51,055][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 21:42:51,058][gdb1][DEBUG ] create path recursively if it doesn't exist
[2017-07-06 21:42:51,061][gdb1][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.gdb1 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.gdb1/keyring
[2017-07-06 21:42:51,331][gdb1][INFO  ] Running command: sudo systemctl enable ceph-radosgw@rgw.gdb1
[2017-07-06 21:42:51,451][gdb1][INFO  ] Running command: sudo systemctl start ceph-radosgw@rgw.gdb1
[2017-07-06 21:42:51,463][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 21:42:51,580][ceph_deploy.rgw][INFO  ] The Ceph Object Gateway (RGW) is now running on host gdb1 and default port 7480
[2017-07-06 22:36:18,865][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:36:18,866][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy rgw create gdb1
[2017-07-06 22:36:18,866][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:36:18,866][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:36:18,866][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:36:18,866][ceph_deploy.cli][INFO  ]  rgw                           : [('gdb1', 'rgw.gdb1')]
[2017-07-06 22:36:18,866][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 22:36:18,866][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-06 22:36:18,866][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:36:18,866][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f12b3275830>
[2017-07-06 22:36:18,866][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:36:18,866][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7f12b3936758>
[2017-07-06 22:36:18,866][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:36:18,866][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:36:18,867][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts gdb1:rgw.gdb1
[2017-07-06 22:36:19,143][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 22:36:19,374][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 22:36:19,375][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 22:36:19,395][gdb1][DEBUG ] detect machine type
[2017-07-06 22:36:19,400][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 22:36:19,400][ceph_deploy.rgw][DEBUG ] remote host will use systemd
[2017-07-06 22:36:19,400][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to gdb1
[2017-07-06 22:36:19,400][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 22:36:19,403][gdb1][DEBUG ] create path recursively if it doesn't exist
[2017-07-06 22:36:19,405][gdb1][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.gdb1 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.gdb1/keyring
[2017-07-06 22:36:19,576][gdb1][INFO  ] Running command: sudo systemctl enable ceph-radosgw@rgw.gdb1
[2017-07-06 22:36:19,797][gdb1][INFO  ] Running command: sudo systemctl start ceph-radosgw@rgw.gdb1
[2017-07-06 22:36:19,809][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 22:36:19,875][ceph_deploy.rgw][INFO  ] The Ceph Object Gateway (RGW) is now running on host gdb1 and default port 7480
[2017-07-06 22:46:32,662][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:46:32,662][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb1
[2017-07-06 22:46:32,662][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:46:32,662][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:46:32,662][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:46:32,662][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 22:46:32,662][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:46:32,662][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb829eb15a8>
[2017-07-06 22:46:32,662][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:46:32,663][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-07-06 22:46:32,663][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fb82a7c8938>
[2017-07-06 22:46:32,663][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:46:32,663][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:46:32,663][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-07-06 22:46:32,904][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 22:46:33,135][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 22:46:33,136][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 22:46:33,152][gdb1][DEBUG ] detect machine type
[2017-07-06 22:46:33,156][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 22:52:26,694][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:52:26,695][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-07-06 22:52:26,695][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:52:26,695][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:52:26,695][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:52:26,695][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 22:52:26,695][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:52:26,695][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fc380ce85a8>
[2017-07-06 22:52:26,695][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:52:26,695][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-07-06 22:52:26,695][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fc3815ff938>
[2017-07-06 22:52:26,695][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:52:26,696][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:52:26,696][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-07-06 22:52:27,027][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 22:52:27,257][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 22:52:27,258][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 22:52:27,290][gdb0][DEBUG ] detect machine type
[2017-07-06 22:52:27,294][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 22:52:27,465][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:52:27,465][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-07-06 22:52:27,465][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:52:27,465][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:52:27,465][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 22:52:27,465][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 22:52:27,466][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 22:52:27,466][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:52:27,466][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 22:52:27,466][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 22:52:27,466][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 22:52:27,466][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 22:52:27,466][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 22:52:27,466][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:52:27,466][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f4a7720f998>
[2017-07-06 22:52:27,466][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:52:27,466][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 22:52:27,466][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f4a77465aa0>
[2017-07-06 22:52:27,466][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:52:27,466][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:52:27,466][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 22:52:27,467][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 22:52:27,707][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 22:52:27,930][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 22:52:27,930][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 22:52:27,946][gdb0][DEBUG ] detect machine type
[2017-07-06 22:52:27,950][gdb0][DEBUG ] find the location of an executable
[2017-07-06 22:52:27,951][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 22:52:27,951][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-07-06 22:52:27,951][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 22:52:27,955][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-07-06 22:52:27,956][gdb0][DEBUG ] find the location of an executable
[2017-07-06 22:52:27,958][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 22:52:28,329][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 22:52:28,544][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 22:52:28,544][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 22:52:28,551][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 22:52:28,567][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 22:52:28,575][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-07-06 22:52:33,587][gdb0][INFO  ] checking OSD status...
[2017-07-06 22:52:33,588][gdb0][DEBUG ] find the location of an executable
[2017-07-06 22:52:33,591][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 22:52:33,806][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-07-06 22:52:33,972][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:52:33,972][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-07-06 22:52:33,972][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:52:33,972][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:52:33,972][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:52:33,973][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 22:52:33,973][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 22:52:33,973][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:52:33,973][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fda312a0998>
[2017-07-06 22:52:33,973][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:52:33,973][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fda314f6aa0>
[2017-07-06 22:52:33,973][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:52:33,973][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:52:33,973][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 22:52:33,973][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 22:52:34,214][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 22:52:34,441][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 22:52:34,442][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 22:52:34,457][gdb0][DEBUG ] detect machine type
[2017-07-06 22:52:34,461][gdb0][DEBUG ] find the location of an executable
[2017-07-06 22:52:34,462][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 22:52:34,462][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-07-06 22:52:34,462][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 22:52:34,462][gdb0][DEBUG ] find the location of an executable
[2017-07-06 22:52:34,465][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 22:52:34,635][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 22:52:34,636][gdb0][WARNING] activate: Cluster uuid is 28192ce3-1952-4ea7-b4eb-4f65e3d697cd
[2017-07-06 22:52:34,636][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 22:52:34,636][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=radosgw-sync --show-config-value=fsid
[2017-07-06 22:52:34,636][gdb0][WARNING] Traceback (most recent call last):
[2017-07-06 22:52:34,636][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-07-06 22:52:34,636][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-07-06 22:52:34,636][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-07-06 22:52:34,636][gdb0][WARNING]     main(sys.argv[1:])
[2017-07-06 22:52:34,636][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-07-06 22:52:34,637][gdb0][WARNING]     args.func(args)
[2017-07-06 22:52:34,637][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-07-06 22:52:34,637][gdb0][WARNING]     init=args.mark_init,
[2017-07-06 22:52:34,637][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-07-06 22:52:34,637][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-07-06 22:52:34,637][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3609, in activate
[2017-07-06 22:52:34,637][gdb0][WARNING]     ' with fsid %s' % ceph_fsid)
[2017-07-06 22:52:34,637][gdb0][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid 28192ce3-1952-4ea7-b4eb-4f65e3d697cd
[2017-07-06 22:52:34,637][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-07-06 22:52:34,637][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-07-06 22:53:01,378][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:53:01,379][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-07-06 22:53:01,379][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:53:01,379][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:53:01,379][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:53:01,379][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 22:53:01,379][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:53:01,379][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f66b0ca45a8>
[2017-07-06 22:53:01,379][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:53:01,379][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-07-06 22:53:01,379][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f66b15bb938>
[2017-07-06 22:53:01,379][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:53:01,380][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:53:01,380][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-07-06 22:53:01,622][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 22:53:01,849][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 22:53:01,850][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 22:53:01,866][gdb0][DEBUG ] detect machine type
[2017-07-06 22:53:01,869][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 22:53:02,042][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:53:02,042][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-07-06 22:53:02,042][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:53:02,042][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:53:02,042][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 22:53:02,042][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 22:53:02,042][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 22:53:02,043][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:53:02,043][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 22:53:02,043][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 22:53:02,043][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 22:53:02,043][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 22:53:02,043][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 22:53:02,043][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:53:02,043][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fc398886998>
[2017-07-06 22:53:02,043][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:53:02,043][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 22:53:02,043][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fc398adcaa0>
[2017-07-06 22:53:02,043][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:53:02,043][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:53:02,043][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 22:53:02,044][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 22:53:02,290][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 22:53:02,521][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 22:53:02,522][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 22:53:02,538][gdb0][DEBUG ] detect machine type
[2017-07-06 22:53:02,542][gdb0][DEBUG ] find the location of an executable
[2017-07-06 22:53:02,543][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 22:53:02,543][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-07-06 22:53:02,543][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 22:53:02,546][gdb0][WARNING] osd keyring does not exist yet, creating one
[2017-07-06 22:53:02,546][gdb0][DEBUG ] create a keyring file
[2017-07-06 22:53:02,547][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-07-06 22:53:02,548][gdb0][DEBUG ] find the location of an executable
[2017-07-06 22:53:02,550][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 22:53:02,720][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 22:53:02,721][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 22:53:02,721][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 22:53:02,721][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 22:53:02,728][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 22:53:02,744][gdb0][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-07-06 22:53:02,744][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.2991.tmp
[2017-07-06 22:53:02,748][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.2991.tmp
[2017-07-06 22:53:02,751][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.2991.tmp
[2017-07-06 22:53:07,772][gdb0][INFO  ] checking OSD status...
[2017-07-06 22:53:07,772][gdb0][DEBUG ] find the location of an executable
[2017-07-06 22:53:07,775][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 22:53:07,940][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-07-06 22:53:08,108][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:53:08,109][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-07-06 22:53:08,109][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:53:08,109][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:53:08,109][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:53:08,109][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 22:53:08,109][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 22:53:08,109][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:53:08,109][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f896d4e6998>
[2017-07-06 22:53:08,109][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:53:08,109][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f896d73caa0>
[2017-07-06 22:53:08,109][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:53:08,109][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:53:08,109][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 22:53:08,110][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 22:53:08,350][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 22:53:08,582][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 22:53:08,582][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 22:53:08,598][gdb0][DEBUG ] detect machine type
[2017-07-06 22:53:08,602][gdb0][DEBUG ] find the location of an executable
[2017-07-06 22:53:08,603][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 22:53:08,603][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-07-06 22:53:08,603][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 22:53:08,603][gdb0][DEBUG ] find the location of an executable
[2017-07-06 22:53:08,605][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 22:53:08,775][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 22:53:08,776][gdb0][WARNING] activate: Cluster uuid is 7236ff6b-c970-4b9a-b9c8-98f42ac8519f
[2017-07-06 22:53:08,776][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 22:53:08,776][gdb0][WARNING] activate: Cluster name is ceph
[2017-07-06 22:53:08,776][gdb0][WARNING] activate: OSD uuid is 409d8b55-6aa2-4d9f-8d31-17e6903b5243
[2017-07-06 22:53:08,776][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-07-06 22:53:08,776][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 409d8b55-6aa2-4d9f-8d31-17e6903b5243
[2017-07-06 22:53:09,041][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.3113.tmp
[2017-07-06 22:53:09,041][gdb0][WARNING] activate: OSD id is 1
[2017-07-06 22:53:09,041][gdb0][WARNING] activate: Initializing OSD...
[2017-07-06 22:53:09,041][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-07-06 22:53:09,155][gdb0][WARNING] got monmap epoch 2
[2017-07-06 22:53:09,155][gdb0][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 1 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid 409d8b55-6aa2-4d9f-8d31-17e6903b5243 --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-07-06 22:53:09,187][gdb0][WARNING] activate: Marking with init system systemd
[2017-07-06 22:53:09,187][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-07-06 22:53:09,187][gdb0][WARNING] activate: Authorizing OSD key...
[2017-07-06 22:53:09,188][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.1 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-07-06 22:53:09,352][gdb0][WARNING] added key for osd.1
[2017-07-06 22:53:09,352][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.3113.tmp
[2017-07-06 22:53:09,352][gdb0][WARNING] activate: ceph osd.1 data dir is ready at /mnt/memstore
[2017-07-06 22:53:09,352][gdb0][WARNING] activate_dir: Creating symlink /var/lib/ceph/osd/ceph-1 -> /mnt/memstore
[2017-07-06 22:53:09,352][gdb0][WARNING] start_daemon: Starting ceph osd.1...
[2017-07-06 22:53:09,352][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@1
[2017-07-06 22:53:09,352][gdb0][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@1.service.
[2017-07-06 22:53:09,416][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@1 --runtime
[2017-07-06 22:53:09,448][gdb0][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@1
[2017-07-06 22:53:09,448][gdb0][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@1.service to /lib/systemd/system/ceph-osd@.service.
[2017-07-06 22:53:09,512][gdb0][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@1
[2017-07-06 22:53:14,632][gdb0][INFO  ] checking OSD status...
[2017-07-06 22:53:14,632][gdb0][DEBUG ] find the location of an executable
[2017-07-06 22:53:14,635][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 22:53:14,803][gdb0][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 22:53:22,447][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:53:22,447][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-07-06 22:53:22,447][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:53:22,447][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:53:22,447][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:53:22,447][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 22:53:22,447][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:53:22,447][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa7d0ede5a8>
[2017-07-06 22:53:22,447][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:53:22,447][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-07-06 22:53:22,448][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fa7d17f5938>
[2017-07-06 22:53:22,448][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:53:22,448][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:53:22,448][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-07-06 22:53:22,686][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 22:53:22,913][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 22:53:22,914][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 22:53:22,929][gdb0][DEBUG ] detect machine type
[2017-07-06 22:53:22,934][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 22:53:23,105][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:53:23,105][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-07-06 22:53:23,105][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:53:23,105][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:53:23,105][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 22:53:23,106][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 22:53:23,106][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 22:53:23,106][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:53:23,106][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 22:53:23,106][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 22:53:23,106][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 22:53:23,106][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 22:53:23,106][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 22:53:23,106][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:53:23,106][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f436b696998>
[2017-07-06 22:53:23,106][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:53:23,106][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 22:53:23,106][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f436b8ecaa0>
[2017-07-06 22:53:23,106][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:53:23,106][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:53:23,107][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 22:53:23,107][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 22:53:23,346][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 22:53:23,577][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 22:53:23,578][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 22:53:23,593][gdb0][DEBUG ] detect machine type
[2017-07-06 22:53:23,597][gdb0][DEBUG ] find the location of an executable
[2017-07-06 22:53:23,598][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 22:53:23,598][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-07-06 22:53:23,598][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 22:53:23,601][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-07-06 22:53:23,601][gdb0][DEBUG ] find the location of an executable
[2017-07-06 22:53:23,603][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 22:53:23,774][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 22:53:23,774][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 22:53:23,774][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 22:53:23,774][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 22:53:23,790][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 22:53:23,797][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-07-06 22:53:28,810][gdb0][INFO  ] checking OSD status...
[2017-07-06 22:53:28,810][gdb0][DEBUG ] find the location of an executable
[2017-07-06 22:53:28,813][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 22:53:28,978][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-07-06 22:53:29,151][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:53:29,151][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-07-06 22:53:29,151][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:53:29,151][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:53:29,151][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:53:29,151][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 22:53:29,151][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 22:53:29,151][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:53:29,152][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0fdb711998>
[2017-07-06 22:53:29,152][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:53:29,152][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f0fdb967aa0>
[2017-07-06 22:53:29,152][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:53:29,152][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:53:29,152][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 22:53:29,152][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 22:53:29,398][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 22:53:29,625][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 22:53:29,626][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 22:53:29,642][gdb0][DEBUG ] detect machine type
[2017-07-06 22:53:29,646][gdb0][DEBUG ] find the location of an executable
[2017-07-06 22:53:29,647][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 22:53:29,647][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-07-06 22:53:29,647][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 22:53:29,647][gdb0][DEBUG ] find the location of an executable
[2017-07-06 22:53:29,649][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 22:53:29,820][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 22:53:29,820][gdb0][WARNING] activate: Cluster uuid is 7236ff6b-c970-4b9a-b9c8-98f42ac8519f
[2017-07-06 22:53:29,820][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 22:53:29,820][gdb0][WARNING] activate: Cluster name is ceph
[2017-07-06 22:53:29,820][gdb0][WARNING] activate: OSD uuid is 409d8b55-6aa2-4d9f-8d31-17e6903b5243
[2017-07-06 22:53:29,820][gdb0][WARNING] activate: OSD id is 1
[2017-07-06 22:53:29,821][gdb0][WARNING] activate: Marking with init system systemd
[2017-07-06 22:53:29,821][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-07-06 22:53:29,821][gdb0][WARNING] activate: ceph osd.1 data dir is ready at /mnt/memstore
[2017-07-06 22:53:29,821][gdb0][WARNING] start_daemon: Starting ceph osd.1...
[2017-07-06 22:53:29,821][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@1
[2017-07-06 22:53:29,821][gdb0][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@1.service.
[2017-07-06 22:53:29,853][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@1 --runtime
[2017-07-06 22:53:29,885][gdb0][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@1
[2017-07-06 22:53:29,886][gdb0][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@1.service to /lib/systemd/system/ceph-osd@.service.
[2017-07-06 22:53:29,950][gdb0][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@1
[2017-07-06 22:53:34,955][gdb0][INFO  ] checking OSD status...
[2017-07-06 22:53:34,956][gdb0][DEBUG ] find the location of an executable
[2017-07-06 22:53:34,958][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 22:53:35,126][gdb0][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 22:53:51,610][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:53:51,611][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy rgw create gdb0
[2017-07-06 22:53:51,611][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:53:51,611][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:53:51,611][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:53:51,611][ceph_deploy.cli][INFO  ]  rgw                           : [('gdb0', 'rgw.gdb0')]
[2017-07-06 22:53:51,611][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 22:53:51,611][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-06 22:53:51,611][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:53:51,611][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7f8ff94830>
[2017-07-06 22:53:51,611][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:53:51,611][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7f7f90655758>
[2017-07-06 22:53:51,611][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:53:51,612][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:53:51,612][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts gdb0:rgw.gdb0
[2017-07-06 22:53:51,850][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 22:53:52,082][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 22:53:52,082][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 22:53:52,098][gdb0][DEBUG ] detect machine type
[2017-07-06 22:53:52,102][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 22:53:52,102][ceph_deploy.rgw][DEBUG ] remote host will use systemd
[2017-07-06 22:53:52,102][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to gdb0
[2017-07-06 22:53:52,102][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 22:53:52,106][gdb0][DEBUG ] create path recursively if it doesn't exist
[2017-07-06 22:53:52,108][gdb0][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.gdb0 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.gdb0/keyring
[2017-07-06 22:53:52,225][gdb0][ERROR ] 2017-07-06 22:53:52.159750 7f23f2901700  0 librados: client.bootstrap-rgw authentication error (1) Operation not permitted
[2017-07-06 22:53:52,225][gdb0][ERROR ] error connecting to the cluster
[2017-07-06 22:53:52,225][gdb0][ERROR ] exit code from command was: 1
[2017-07-06 22:53:52,226][ceph_deploy.rgw][ERROR ] could not create rgw
[2017-07-06 22:53:52,226][ceph_deploy][ERROR ] GenericError: Failed to create 1 RGWs

[2017-07-06 22:54:47,073][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:54:47,074][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy rgw create gdb0
[2017-07-06 22:54:47,074][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:54:47,074][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:54:47,074][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:54:47,074][ceph_deploy.cli][INFO  ]  rgw                           : [('gdb0', 'rgw.gdb0')]
[2017-07-06 22:54:47,074][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 22:54:47,074][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-06 22:54:47,074][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:54:47,074][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f706767a830>
[2017-07-06 22:54:47,074][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:54:47,074][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7f7067d3b758>
[2017-07-06 22:54:47,074][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:54:47,074][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:54:47,075][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts gdb0:rgw.gdb0
[2017-07-06 22:54:47,326][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 22:54:47,554][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 22:54:47,555][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 22:54:47,571][gdb0][DEBUG ] detect machine type
[2017-07-06 22:54:47,574][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 22:54:47,575][ceph_deploy.rgw][DEBUG ] remote host will use systemd
[2017-07-06 22:54:47,575][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to gdb0
[2017-07-06 22:54:47,575][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 22:54:47,577][gdb0][WARNING] rgw keyring does not exist yet, creating one
[2017-07-06 22:54:47,577][gdb0][DEBUG ] create a keyring file
[2017-07-06 22:54:47,579][gdb0][DEBUG ] create path recursively if it doesn't exist
[2017-07-06 22:54:47,581][gdb0][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.gdb0 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.gdb0/keyring
[2017-07-06 22:54:47,752][gdb0][INFO  ] Running command: sudo systemctl enable ceph-radosgw@rgw.gdb0
[2017-07-06 22:54:47,822][gdb0][INFO  ] Running command: sudo systemctl start ceph-radosgw@rgw.gdb0
[2017-07-06 22:54:47,891][gdb0][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 22:54:47,958][ceph_deploy.rgw][INFO  ] The Ceph Object Gateway (RGW) is now running on host gdb0 and default port 7480
[2017-07-06 22:56:18,690][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:56:18,691][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-07-06 22:56:18,691][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:56:18,691][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:56:18,691][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:56:18,691][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 22:56:18,692][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:56:18,692][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fced1304128>
[2017-07-06 22:56:18,692][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:56:18,692][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-06 22:56:18,692][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7fced1c111b8>
[2017-07-06 22:56:18,692][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:56:18,692][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:56:18,692][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-07-06 22:56:18,692][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-07-06 22:56:18,692][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-07-06 22:56:18,693][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-07-06 22:56:18,719][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 22:56:18,734][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 22:56:18,735][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 22:56:18,755][gdb3][DEBUG ] detect machine type
[2017-07-06 22:56:18,758][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 22:56:18,758][gdb3][INFO  ] Purging Ceph on gdb3
[2017-07-06 22:56:18,759][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-07-06 22:56:18,798][gdb3][DEBUG ] Reading package lists...
[2017-07-06 22:56:18,962][gdb3][DEBUG ] Building dependency tree...
[2017-07-06 22:56:18,963][gdb3][DEBUG ] Reading state information...
[2017-07-06 22:56:19,027][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-07-06 22:56:19,027][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-07-06 22:56:19,027][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-07-06 22:56:19,027][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-07-06 22:56:19,027][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-07-06 22:56:19,028][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-07-06 22:56:19,028][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1016 linux-aws-headers-4.4.0-1017
[2017-07-06 22:56:19,028][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1018 linux-headers-4.4.0-1013-aws
[2017-07-06 22:56:19,028][gdb3][DEBUG ]   linux-headers-4.4.0-1016-aws linux-headers-4.4.0-1017-aws
[2017-07-06 22:56:19,028][gdb3][DEBUG ]   linux-headers-4.4.0-1018-aws linux-image-4.4.0-1013-aws
[2017-07-06 22:56:19,028][gdb3][DEBUG ]   linux-image-4.4.0-1016-aws linux-image-4.4.0-1017-aws
[2017-07-06 22:56:19,028][gdb3][DEBUG ]   linux-image-4.4.0-1018-aws ntp python-blinker python-cephfs
[2017-07-06 22:56:19,028][gdb3][DEBUG ]   python-cffi-backend python-chardet python-cryptography python-enum34
[2017-07-06 22:56:19,029][gdb3][DEBUG ]   python-flask python-idna python-ipaddress python-itsdangerous python-jinja2
[2017-07-06 22:56:19,029][gdb3][DEBUG ]   python-markupsafe python-ndg-httpsclient python-openssl python-pyasn1
[2017-07-06 22:56:19,029][gdb3][DEBUG ]   python-pyinotify python-rados python-rbd python-requests python-rgw
[2017-07-06 22:56:19,029][gdb3][DEBUG ]   python-six python-urllib3 python-werkzeug
[2017-07-06 22:56:19,029][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-07-06 22:56:19,061][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-07-06 22:56:19,061][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-07-06 22:56:19,175][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 60 not upgraded.
[2017-07-06 22:56:19,175][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-07-06 22:56:19,290][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 179644 files and directories currently installed.)
[2017-07-06 22:56:19,290][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-07-06 22:56:19,454][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-07-06 22:56:19,518][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-07-06 22:56:19,582][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-07-06 22:56:19,798][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-07-06 22:56:19,912][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-07-06 22:56:20,076][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-07-06 22:56:20,110][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-07-06 22:56:20,142][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-07-06 22:56:20,308][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-07-06 22:56:20,372][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-07-06 22:56:20,404][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-07-06 22:56:20,568][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-07-06 22:56:20,632][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-07-06 22:56:20,746][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-07-06 22:56:20,860][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-07-06 22:56:20,860][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-07-06 22:56:20,924][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu9) ...
[2017-07-06 22:56:21,791][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-07-06 22:56:21,958][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:56:21,958][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-07-06 22:56:21,958][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:56:21,958][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:56:21,958][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:56:21,958][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 22:56:21,958][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:56:21,959][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f53230877a0>
[2017-07-06 22:56:21,959][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:56:21,959][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-06 22:56:21,959][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f5323994230>
[2017-07-06 22:56:21,959][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:56:21,959][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:56:21,959][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-07-06 22:56:21,985][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 22:56:21,999][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 22:56:22,000][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 22:56:22,017][gdb3][DEBUG ] detect machine type
[2017-07-06 22:56:22,019][gdb3][DEBUG ] find the location of an executable
[2017-07-06 22:56:22,035][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 22:56:22,050][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 22:56:22,051][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 22:56:22,067][gdb3][DEBUG ] detect machine type
[2017-07-06 22:56:22,070][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 22:56:22,070][gdb3][INFO  ] purging data on gdb3
[2017-07-06 22:56:22,071][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-07-06 22:56:22,084][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-07-06 22:56:22,256][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:56:22,256][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-07-06 22:56:22,256][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:56:22,257][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:56:22,257][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:56:22,257][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 22:56:22,257][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:56:22,257][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb0f0e36a70>
[2017-07-06 22:56:22,257][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:56:22,257][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7fb0f16f9848>
[2017-07-06 22:56:22,257][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:56:22,257][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:56:37,542][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:56:37,542][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-07-06 22:56:37,542][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:56:37,542][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:56:37,543][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:56:37,543][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 22:56:37,543][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:56:37,543][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0bf6c975f0>
[2017-07-06 22:56:37,543][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:56:37,543][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-07-06 22:56:37,543][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-07-06 22:56:37,543][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f0bf731b758>
[2017-07-06 22:56:37,543][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-07-06 22:56:37,544][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:56:37,544][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-07-06 22:56:37,544][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:56:37,544][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-07-06 22:56:37,544][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-07-06 22:56:37,544][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-07-06 22:56:37,570][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 22:56:37,584][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 22:56:37,584][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 22:56:37,601][gdb3][DEBUG ] detect machine type
[2017-07-06 22:56:37,603][gdb3][DEBUG ] find the location of an executable
[2017-07-06 22:56:37,604][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-07-06 22:56:37,615][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-07-06 22:56:37,621][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-07-06 22:56:37,622][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-07-06 22:56:37,622][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-07-06 22:56:37,622][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-07-06 22:56:37,622][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-07-06 22:56:37,622][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-07-06 22:56:37,622][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-07-06 22:56:37,622][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-07-06 22:56:37,786][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:56:37,786][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-07-06 22:56:37,787][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:56:37,787][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:56:37,787][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:56:37,787][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 22:56:37,787][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-07-06 22:56:37,787][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:56:37,787][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f32e1430ef0>
[2017-07-06 22:56:37,787][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:56:37,787][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f32e1404b18>
[2017-07-06 22:56:37,787][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:56:37,787][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-07-06 22:56:37,787][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:56:37,788][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-07-06 22:56:37,788][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-07-06 22:56:37,814][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 22:56:37,828][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 22:56:37,828][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 22:56:37,845][gdb3][DEBUG ] detect machine type
[2017-07-06 22:56:37,847][gdb3][DEBUG ] find the location of an executable
[2017-07-06 22:56:37,848][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-07-06 22:56:37,848][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-07-06 22:56:37,848][gdb3][DEBUG ] get remote short hostname
[2017-07-06 22:56:37,848][gdb3][DEBUG ] deploying mon to gdb3
[2017-07-06 22:56:37,848][gdb3][DEBUG ] get remote short hostname
[2017-07-06 22:56:37,849][gdb3][DEBUG ] remote hostname: gdb3
[2017-07-06 22:56:37,849][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 22:56:37,851][gdb3][DEBUG ] create the mon path if it does not exist
[2017-07-06 22:56:37,851][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-06 22:56:37,851][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-06 22:56:37,852][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-06 22:56:37,852][gdb3][DEBUG ] create the monitor keyring file
[2017-07-06 22:56:37,853][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-07-06 22:56:37,891][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-07-06 22:56:37,891][gdb3][DEBUG ] ceph-mon: set fsid to 0f468cb7-1ae1-4a7b-8bb0-7f3c1a4e7a30
[2017-07-06 22:56:37,923][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-07-06 22:56:37,923][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-06 22:56:37,924][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-07-06 22:56:37,924][gdb3][DEBUG ] create the init path if it does not exist
[2017-07-06 22:56:37,925][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 22:56:37,995][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-07-06 22:56:38,063][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-07-06 22:56:40,133][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 22:56:40,198][gdb3][DEBUG ] ********************************************************************************
[2017-07-06 22:56:40,199][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-07-06 22:56:40,199][gdb3][DEBUG ] {
[2017-07-06 22:56:40,199][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-07-06 22:56:40,199][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-07-06 22:56:40,199][gdb3][DEBUG ]   "features": {
[2017-07-06 22:56:40,199][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-07-06 22:56:40,199][gdb3][DEBUG ]     "quorum_mon": [
[2017-07-06 22:56:40,199][gdb3][DEBUG ]       "kraken", 
[2017-07-06 22:56:40,199][gdb3][DEBUG ]       "luminous"
[2017-07-06 22:56:40,199][gdb3][DEBUG ]     ], 
[2017-07-06 22:56:40,199][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-07-06 22:56:40,199][gdb3][DEBUG ]     "required_mon": [
[2017-07-06 22:56:40,199][gdb3][DEBUG ]       "kraken", 
[2017-07-06 22:56:40,200][gdb3][DEBUG ]       "luminous"
[2017-07-06 22:56:40,200][gdb3][DEBUG ]     ]
[2017-07-06 22:56:40,200][gdb3][DEBUG ]   }, 
[2017-07-06 22:56:40,200][gdb3][DEBUG ]   "monmap": {
[2017-07-06 22:56:40,200][gdb3][DEBUG ]     "created": "2017-07-06 22:56:37.876700", 
[2017-07-06 22:56:40,201][gdb3][DEBUG ]     "epoch": 2, 
[2017-07-06 22:56:40,201][gdb3][DEBUG ]     "features": {
[2017-07-06 22:56:40,201][gdb3][DEBUG ]       "optional": [], 
[2017-07-06 22:56:40,201][gdb3][DEBUG ]       "persistent": [
[2017-07-06 22:56:40,201][gdb3][DEBUG ]         "kraken", 
[2017-07-06 22:56:40,201][gdb3][DEBUG ]         "luminous"
[2017-07-06 22:56:40,201][gdb3][DEBUG ]       ]
[2017-07-06 22:56:40,201][gdb3][DEBUG ]     }, 
[2017-07-06 22:56:40,201][gdb3][DEBUG ]     "fsid": "0f468cb7-1ae1-4a7b-8bb0-7f3c1a4e7a30", 
[2017-07-06 22:56:40,201][gdb3][DEBUG ]     "modified": "2017-07-06 22:56:38.160098", 
[2017-07-06 22:56:40,201][gdb3][DEBUG ]     "mons": [
[2017-07-06 22:56:40,201][gdb3][DEBUG ]       {
[2017-07-06 22:56:40,201][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-07-06 22:56:40,201][gdb3][DEBUG ]         "name": "gdb3", 
[2017-07-06 22:56:40,201][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-07-06 22:56:40,201][gdb3][DEBUG ]         "rank": 0
[2017-07-06 22:56:40,201][gdb3][DEBUG ]       }
[2017-07-06 22:56:40,201][gdb3][DEBUG ]     ]
[2017-07-06 22:56:40,202][gdb3][DEBUG ]   }, 
[2017-07-06 22:56:40,202][gdb3][DEBUG ]   "name": "gdb3", 
[2017-07-06 22:56:40,202][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-07-06 22:56:40,202][gdb3][DEBUG ]   "quorum": [
[2017-07-06 22:56:40,202][gdb3][DEBUG ]     0
[2017-07-06 22:56:40,202][gdb3][DEBUG ]   ], 
[2017-07-06 22:56:40,202][gdb3][DEBUG ]   "rank": 0, 
[2017-07-06 22:56:40,202][gdb3][DEBUG ]   "state": "leader", 
[2017-07-06 22:56:40,202][gdb3][DEBUG ]   "sync_provider": []
[2017-07-06 22:56:40,202][gdb3][DEBUG ] }
[2017-07-06 22:56:40,202][gdb3][DEBUG ] ********************************************************************************
[2017-07-06 22:56:40,202][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-07-06 22:56:40,203][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 22:56:40,268][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-07-06 22:56:40,287][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 22:56:40,300][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 22:56:40,301][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 22:56:40,317][gdb3][DEBUG ] detect machine type
[2017-07-06 22:56:40,320][gdb3][DEBUG ] find the location of an executable
[2017-07-06 22:56:40,321][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 22:56:40,386][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-07-06 22:56:40,386][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-07-06 22:56:40,386][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-07-06 22:56:40,388][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmp4JxnfG
[2017-07-06 22:56:40,403][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 22:56:40,417][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 22:56:40,417][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 22:56:40,434][gdb3][DEBUG ] detect machine type
[2017-07-06 22:56:40,436][gdb3][DEBUG ] get remote short hostname
[2017-07-06 22:56:40,436][gdb3][DEBUG ] fetch remote file
[2017-07-06 22:56:40,437][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 22:56:40,503][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-07-06 22:56:40,669][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-07-06 22:56:40,836][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-07-06 22:56:41,002][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-07-06 22:56:41,168][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-07-06 22:56:41,334][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-07-06 22:56:41,500][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-07-06 22:56:41,666][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-07-06 22:56:41,832][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-07-06 22:56:41,999][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-07-06 22:56:42,164][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-07-06 22:56:42,164][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-07-06 22:56:42,164][ceph_deploy.gatherkeys][INFO  ] Replacing 'ceph.bootstrap-mgr.keyring' and backing up old key as 'ceph.bootstrap-mgr.keyring-20170706225642'
[2017-07-06 22:56:42,165][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-07-06 22:56:42,165][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-07-06 22:56:42,165][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-07-06 22:56:42,165][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmp4JxnfG
[2017-07-06 22:56:42,345][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:56:42,346][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-07-06 22:56:42,346][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:56:42,346][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:56:42,346][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:56:42,346][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 22:56:42,346][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:56:42,346][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fbf1f1985a8>
[2017-07-06 22:56:42,346][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:56:42,346][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-07-06 22:56:42,346][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fbf1faaf938>
[2017-07-06 22:56:42,346][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:56:42,346][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:56:42,346][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-07-06 22:56:42,373][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 22:56:42,387][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 22:56:42,387][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 22:56:42,404][gdb3][DEBUG ] detect machine type
[2017-07-06 22:56:42,406][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 22:57:13,092][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:57:13,092][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-07-06 22:57:13,092][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:57:13,092][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:57:13,092][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:57:13,092][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 22:57:13,092][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:57:13,092][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6e9e52d5a8>
[2017-07-06 22:57:13,092][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:57:13,092][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-07-06 22:57:13,093][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f6e9ee44938>
[2017-07-06 22:57:13,093][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:57:13,093][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:57:13,093][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-07-06 22:57:13,346][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 22:57:13,573][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 22:57:13,573][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 22:57:13,589][gdb0][DEBUG ] detect machine type
[2017-07-06 22:57:13,593][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 22:57:13,767][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:57:13,768][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-07-06 22:57:13,768][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:57:13,768][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:57:13,768][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 22:57:13,768][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 22:57:13,768][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 22:57:13,768][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:57:13,768][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 22:57:13,768][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 22:57:13,768][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 22:57:13,768][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 22:57:13,768][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 22:57:13,768][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:57:13,769][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0f23459998>
[2017-07-06 22:57:13,769][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:57:13,769][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 22:57:13,769][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f0f236afaa0>
[2017-07-06 22:57:13,769][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:57:13,769][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:57:13,769][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 22:57:13,769][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 22:57:14,011][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 22:57:14,242][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 22:57:14,242][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 22:57:14,258][gdb0][DEBUG ] detect machine type
[2017-07-06 22:57:14,262][gdb0][DEBUG ] find the location of an executable
[2017-07-06 22:57:14,263][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 22:57:14,263][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-07-06 22:57:14,263][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 22:57:14,266][gdb0][WARNING] osd keyring does not exist yet, creating one
[2017-07-06 22:57:14,266][gdb0][DEBUG ] create a keyring file
[2017-07-06 22:57:14,268][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-07-06 22:57:14,268][gdb0][DEBUG ] find the location of an executable
[2017-07-06 22:57:14,270][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 22:57:14,440][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 22:57:14,441][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 22:57:14,441][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 22:57:14,441][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 22:57:14,456][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 22:57:14,464][gdb0][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-07-06 22:57:14,472][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.4255.tmp
[2017-07-06 22:57:14,479][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.4255.tmp
[2017-07-06 22:57:14,479][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.4255.tmp
[2017-07-06 22:57:19,500][gdb0][INFO  ] checking OSD status...
[2017-07-06 22:57:19,500][gdb0][DEBUG ] find the location of an executable
[2017-07-06 22:57:19,503][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 22:57:19,668][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-07-06 22:57:19,834][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:57:19,834][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-07-06 22:57:19,835][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:57:19,835][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:57:19,835][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:57:19,835][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 22:57:19,835][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 22:57:19,835][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:57:19,835][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f100f256998>
[2017-07-06 22:57:19,835][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:57:19,835][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f100f4acaa0>
[2017-07-06 22:57:19,835][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:57:19,835][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:57:19,835][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 22:57:19,836][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 22:57:20,074][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 22:57:20,297][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 22:57:20,297][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 22:57:20,313][gdb0][DEBUG ] detect machine type
[2017-07-06 22:57:20,317][gdb0][DEBUG ] find the location of an executable
[2017-07-06 22:57:20,318][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 22:57:20,319][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-07-06 22:57:20,319][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 22:57:20,319][gdb0][DEBUG ] find the location of an executable
[2017-07-06 22:57:20,321][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 22:57:20,492][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 22:57:20,492][gdb0][WARNING] activate: Cluster uuid is 0f468cb7-1ae1-4a7b-8bb0-7f3c1a4e7a30
[2017-07-06 22:57:20,492][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 22:57:20,492][gdb0][WARNING] activate: Cluster name is ceph
[2017-07-06 22:57:20,492][gdb0][WARNING] activate: OSD uuid is 6c16d95d-6254-43a4-b50a-f500d66a6849
[2017-07-06 22:57:20,493][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-07-06 22:57:20,493][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 6c16d95d-6254-43a4-b50a-f500d66a6849
[2017-07-06 22:57:20,657][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.4378.tmp
[2017-07-06 22:57:20,657][gdb0][WARNING] activate: OSD id is 0
[2017-07-06 22:57:20,657][gdb0][WARNING] activate: Initializing OSD...
[2017-07-06 22:57:20,657][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-07-06 22:57:20,771][gdb0][WARNING] got monmap epoch 2
[2017-07-06 22:57:20,772][gdb0][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 0 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid 6c16d95d-6254-43a4-b50a-f500d66a6849 --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-07-06 22:57:20,803][gdb0][WARNING] activate: Marking with init system systemd
[2017-07-06 22:57:20,804][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-07-06 22:57:20,804][gdb0][WARNING] activate: Authorizing OSD key...
[2017-07-06 22:57:20,804][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.0 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-07-06 22:57:20,968][gdb0][WARNING] added key for osd.0
[2017-07-06 22:57:20,972][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.4378.tmp
[2017-07-06 22:57:20,973][gdb0][WARNING] activate: ceph osd.0 data dir is ready at /mnt/memstore
[2017-07-06 22:57:20,973][gdb0][WARNING] activate_dir: Creating symlink /var/lib/ceph/osd/ceph-0 -> /mnt/memstore
[2017-07-06 22:57:20,973][gdb0][WARNING] start_daemon: Starting ceph osd.0...
[2017-07-06 22:57:20,973][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0
[2017-07-06 22:57:20,977][gdb0][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service.
[2017-07-06 22:57:21,041][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0 --runtime
[2017-07-06 22:57:21,073][gdb0][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@0
[2017-07-06 22:57:21,073][gdb0][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service to /lib/systemd/system/ceph-osd@.service.
[2017-07-06 22:57:21,137][gdb0][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@0
[2017-07-06 22:57:26,206][gdb0][INFO  ] checking OSD status...
[2017-07-06 22:57:26,206][gdb0][DEBUG ] find the location of an executable
[2017-07-06 22:57:26,209][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 22:57:26,378][gdb0][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 22:57:47,247][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:57:47,247][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy rgw create gdb0
[2017-07-06 22:57:47,247][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:57:47,247][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:57:47,247][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:57:47,248][ceph_deploy.cli][INFO  ]  rgw                           : [('gdb0', 'rgw.gdb0')]
[2017-07-06 22:57:47,248][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 22:57:47,248][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-06 22:57:47,248][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:57:47,248][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3be80dd830>
[2017-07-06 22:57:47,248][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:57:47,248][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7f3be879e758>
[2017-07-06 22:57:47,248][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:57:47,248][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:57:47,248][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts gdb0:rgw.gdb0
[2017-07-06 22:57:47,486][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 22:57:47,717][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 22:57:47,718][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 22:57:47,733][gdb0][DEBUG ] detect machine type
[2017-07-06 22:57:47,737][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 22:57:47,737][ceph_deploy.rgw][DEBUG ] remote host will use systemd
[2017-07-06 22:57:47,737][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to gdb0
[2017-07-06 22:57:47,737][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 22:57:47,740][gdb0][DEBUG ] create path recursively if it doesn't exist
[2017-07-06 22:57:47,742][gdb0][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.gdb0 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.gdb0/keyring
[2017-07-06 22:57:47,859][gdb0][ERROR ] 2017-07-06 22:57:47.786852 7f1663909700  0 librados: client.bootstrap-rgw authentication error (1) Operation not permitted
[2017-07-06 22:57:47,859][gdb0][ERROR ] error connecting to the cluster
[2017-07-06 22:57:47,859][gdb0][ERROR ] exit code from command was: 1
[2017-07-06 22:57:47,859][ceph_deploy.rgw][ERROR ] could not create rgw
[2017-07-06 22:57:47,859][ceph_deploy][ERROR ] GenericError: Failed to create 1 RGWs

[2017-07-06 22:58:03,421][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 22:58:03,422][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy rgw create gdb0
[2017-07-06 22:58:03,422][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 22:58:03,422][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 22:58:03,422][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 22:58:03,422][ceph_deploy.cli][INFO  ]  rgw                           : [('gdb0', 'rgw.gdb0')]
[2017-07-06 22:58:03,422][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 22:58:03,422][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-06 22:58:03,422][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 22:58:03,422][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0bbaad6830>
[2017-07-06 22:58:03,422][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 22:58:03,422][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7f0bbb197758>
[2017-07-06 22:58:03,422][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 22:58:03,422][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 22:58:03,422][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts gdb0:rgw.gdb0
[2017-07-06 22:58:03,663][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 22:58:03,886][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 22:58:03,886][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 22:58:03,902][gdb0][DEBUG ] detect machine type
[2017-07-06 22:58:03,906][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 22:58:03,906][ceph_deploy.rgw][DEBUG ] remote host will use systemd
[2017-07-06 22:58:03,906][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to gdb0
[2017-07-06 22:58:03,906][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 22:58:03,909][gdb0][WARNING] rgw keyring does not exist yet, creating one
[2017-07-06 22:58:03,909][gdb0][DEBUG ] create a keyring file
[2017-07-06 22:58:03,911][gdb0][DEBUG ] create path recursively if it doesn't exist
[2017-07-06 22:58:03,913][gdb0][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.gdb0 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.gdb0/keyring
[2017-07-06 22:58:04,083][gdb0][INFO  ] Running command: sudo systemctl enable ceph-radosgw@rgw.gdb0
[2017-07-06 22:58:04,153][gdb0][INFO  ] Running command: sudo systemctl start ceph-radosgw@rgw.gdb0
[2017-07-06 22:58:04,165][gdb0][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 22:58:04,232][ceph_deploy.rgw][INFO  ] The Ceph Object Gateway (RGW) is now running on host gdb0 and default port 7480
[2017-07-06 23:22:27,536][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 23:22:27,536][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-07-06 23:22:27,536][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 23:22:27,536][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 23:22:27,537][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 23:22:27,537][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 23:22:27,537][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 23:22:27,537][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe25e92e128>
[2017-07-06 23:22:27,537][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 23:22:27,537][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-06 23:22:27,537][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7fe25f23b1b8>
[2017-07-06 23:22:27,537][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 23:22:27,537][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 23:22:27,537][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-07-06 23:22:27,537][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-07-06 23:22:27,537][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-07-06 23:22:27,537][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-07-06 23:22:27,564][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 23:22:27,577][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 23:22:27,578][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 23:22:27,594][gdb3][DEBUG ] detect machine type
[2017-07-06 23:22:27,597][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 23:22:27,597][gdb3][INFO  ] Purging Ceph on gdb3
[2017-07-06 23:22:27,598][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-07-06 23:22:27,636][gdb3][DEBUG ] Reading package lists...
[2017-07-06 23:22:27,800][gdb3][DEBUG ] Building dependency tree...
[2017-07-06 23:22:27,801][gdb3][DEBUG ] Reading state information...
[2017-07-06 23:22:27,865][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-07-06 23:22:27,865][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-07-06 23:22:27,865][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-07-06 23:22:27,865][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-07-06 23:22:27,866][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-07-06 23:22:27,866][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-07-06 23:22:27,866][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1016 linux-aws-headers-4.4.0-1017
[2017-07-06 23:22:27,866][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1018 linux-headers-4.4.0-1013-aws
[2017-07-06 23:22:27,866][gdb3][DEBUG ]   linux-headers-4.4.0-1016-aws linux-headers-4.4.0-1017-aws
[2017-07-06 23:22:27,866][gdb3][DEBUG ]   linux-headers-4.4.0-1018-aws linux-image-4.4.0-1013-aws
[2017-07-06 23:22:27,866][gdb3][DEBUG ]   linux-image-4.4.0-1016-aws linux-image-4.4.0-1017-aws
[2017-07-06 23:22:27,867][gdb3][DEBUG ]   linux-image-4.4.0-1018-aws ntp python-blinker python-cephfs
[2017-07-06 23:22:27,867][gdb3][DEBUG ]   python-cffi-backend python-chardet python-cryptography python-enum34
[2017-07-06 23:22:27,867][gdb3][DEBUG ]   python-flask python-idna python-ipaddress python-itsdangerous python-jinja2
[2017-07-06 23:22:27,867][gdb3][DEBUG ]   python-markupsafe python-ndg-httpsclient python-openssl python-pyasn1
[2017-07-06 23:22:27,867][gdb3][DEBUG ]   python-pyinotify python-rados python-rbd python-requests python-rgw
[2017-07-06 23:22:27,867][gdb3][DEBUG ]   python-six python-urllib3 python-werkzeug
[2017-07-06 23:22:27,867][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-07-06 23:22:27,899][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-07-06 23:22:27,899][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-07-06 23:22:28,013][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 60 not upgraded.
[2017-07-06 23:22:28,014][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-07-06 23:22:28,078][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 179644 files and directories currently installed.)
[2017-07-06 23:22:28,085][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-07-06 23:22:28,300][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-07-06 23:22:28,414][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-07-06 23:22:28,414][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-07-06 23:22:28,678][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-07-06 23:22:28,793][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-07-06 23:22:28,958][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-07-06 23:22:29,022][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-07-06 23:22:29,037][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-07-06 23:22:29,203][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-07-06 23:22:29,321][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-07-06 23:22:29,321][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-07-06 23:22:29,487][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-07-06 23:22:29,519][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-07-06 23:22:29,683][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-07-06 23:22:29,747][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-07-06 23:22:29,748][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-07-06 23:22:29,862][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu9) ...
[2017-07-06 23:22:30,678][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-07-06 23:22:30,841][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 23:22:30,842][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-07-06 23:22:30,842][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 23:22:30,842][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 23:22:30,842][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 23:22:30,842][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 23:22:30,842][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 23:22:30,842][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fd93fa5d7a0>
[2017-07-06 23:22:30,842][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 23:22:30,842][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-06 23:22:30,842][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7fd94036a230>
[2017-07-06 23:22:30,842][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 23:22:30,843][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 23:22:30,843][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-07-06 23:22:30,869][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 23:22:30,882][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 23:22:30,883][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 23:22:30,900][gdb3][DEBUG ] detect machine type
[2017-07-06 23:22:30,902][gdb3][DEBUG ] find the location of an executable
[2017-07-06 23:22:30,917][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 23:22:30,930][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 23:22:30,930][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 23:22:30,947][gdb3][DEBUG ] detect machine type
[2017-07-06 23:22:30,949][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 23:22:30,949][gdb3][INFO  ] purging data on gdb3
[2017-07-06 23:22:30,950][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-07-06 23:22:30,963][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-07-06 23:22:31,132][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 23:22:31,132][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-07-06 23:22:31,132][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 23:22:31,132][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 23:22:31,132][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 23:22:31,132][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 23:22:31,132][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 23:22:31,133][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f2259d74a70>
[2017-07-06 23:22:31,133][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 23:22:31,133][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7f225a637848>
[2017-07-06 23:22:31,133][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 23:22:31,133][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 23:22:50,617][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 23:22:50,618][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-07-06 23:22:50,618][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 23:22:50,618][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 23:22:50,618][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 23:22:50,618][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 23:22:50,618][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 23:22:50,618][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fd9f5e365f0>
[2017-07-06 23:22:50,618][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 23:22:50,618][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-07-06 23:22:50,618][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-07-06 23:22:50,619][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7fd9f64ba758>
[2017-07-06 23:22:50,619][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-07-06 23:22:50,619][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 23:22:50,619][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-07-06 23:22:50,619][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 23:22:50,619][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-07-06 23:22:50,619][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-07-06 23:22:50,619][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-07-06 23:22:50,645][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 23:22:50,660][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 23:22:50,660][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 23:22:50,677][gdb3][DEBUG ] detect machine type
[2017-07-06 23:22:50,679][gdb3][DEBUG ] find the location of an executable
[2017-07-06 23:22:50,680][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-07-06 23:22:50,692][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-07-06 23:22:50,698][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-07-06 23:22:50,698][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-07-06 23:22:50,698][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-07-06 23:22:50,698][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-07-06 23:22:50,698][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-07-06 23:22:50,698][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-07-06 23:22:50,699][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-07-06 23:22:50,699][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-07-06 23:22:50,865][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 23:22:50,866][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-07-06 23:22:50,866][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 23:22:50,866][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 23:22:50,866][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 23:22:50,866][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 23:22:50,866][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-07-06 23:22:50,866][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 23:22:50,866][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fe4ab91aef0>
[2017-07-06 23:22:50,866][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 23:22:50,866][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7fe4ab8eeb18>
[2017-07-06 23:22:50,866][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 23:22:50,866][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-07-06 23:22:50,867][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 23:22:50,867][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-07-06 23:22:50,867][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-07-06 23:22:50,893][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 23:22:50,907][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 23:22:50,908][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 23:22:50,924][gdb3][DEBUG ] detect machine type
[2017-07-06 23:22:50,926][gdb3][DEBUG ] find the location of an executable
[2017-07-06 23:22:50,927][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-07-06 23:22:50,927][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-07-06 23:22:50,927][gdb3][DEBUG ] get remote short hostname
[2017-07-06 23:22:50,927][gdb3][DEBUG ] deploying mon to gdb3
[2017-07-06 23:22:50,927][gdb3][DEBUG ] get remote short hostname
[2017-07-06 23:22:50,928][gdb3][DEBUG ] remote hostname: gdb3
[2017-07-06 23:22:50,928][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 23:22:50,930][gdb3][DEBUG ] create the mon path if it does not exist
[2017-07-06 23:22:50,930][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-06 23:22:50,930][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-06 23:22:50,931][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-06 23:22:50,931][gdb3][DEBUG ] create the monitor keyring file
[2017-07-06 23:22:50,932][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-07-06 23:22:50,970][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-07-06 23:22:50,970][gdb3][DEBUG ] ceph-mon: set fsid to 7273016e-b03e-4d95-b0ee-5ed43c689535
[2017-07-06 23:22:50,975][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-07-06 23:22:50,978][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-06 23:22:50,979][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-07-06 23:22:50,979][gdb3][DEBUG ] create the init path if it does not exist
[2017-07-06 23:22:50,980][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 23:22:51,050][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-07-06 23:22:51,124][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-07-06 23:22:53,194][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 23:22:53,259][gdb3][DEBUG ] ********************************************************************************
[2017-07-06 23:22:53,259][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-07-06 23:22:53,259][gdb3][DEBUG ] {
[2017-07-06 23:22:53,259][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-07-06 23:22:53,259][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-07-06 23:22:53,259][gdb3][DEBUG ]   "features": {
[2017-07-06 23:22:53,259][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-07-06 23:22:53,259][gdb3][DEBUG ]     "quorum_mon": [
[2017-07-06 23:22:53,260][gdb3][DEBUG ]       "kraken", 
[2017-07-06 23:22:53,260][gdb3][DEBUG ]       "luminous"
[2017-07-06 23:22:53,260][gdb3][DEBUG ]     ], 
[2017-07-06 23:22:53,260][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-07-06 23:22:53,260][gdb3][DEBUG ]     "required_mon": [
[2017-07-06 23:22:53,260][gdb3][DEBUG ]       "kraken", 
[2017-07-06 23:22:53,260][gdb3][DEBUG ]       "luminous"
[2017-07-06 23:22:53,260][gdb3][DEBUG ]     ]
[2017-07-06 23:22:53,260][gdb3][DEBUG ]   }, 
[2017-07-06 23:22:53,260][gdb3][DEBUG ]   "monmap": {
[2017-07-06 23:22:53,260][gdb3][DEBUG ]     "created": "2017-07-06 23:22:50.955260", 
[2017-07-06 23:22:53,260][gdb3][DEBUG ]     "epoch": 2, 
[2017-07-06 23:22:53,260][gdb3][DEBUG ]     "features": {
[2017-07-06 23:22:53,260][gdb3][DEBUG ]       "optional": [], 
[2017-07-06 23:22:53,260][gdb3][DEBUG ]       "persistent": [
[2017-07-06 23:22:53,261][gdb3][DEBUG ]         "kraken", 
[2017-07-06 23:22:53,261][gdb3][DEBUG ]         "luminous"
[2017-07-06 23:22:53,261][gdb3][DEBUG ]       ]
[2017-07-06 23:22:53,261][gdb3][DEBUG ]     }, 
[2017-07-06 23:22:53,261][gdb3][DEBUG ]     "fsid": "7273016e-b03e-4d95-b0ee-5ed43c689535", 
[2017-07-06 23:22:53,261][gdb3][DEBUG ]     "modified": "2017-07-06 23:22:51.202057", 
[2017-07-06 23:22:53,261][gdb3][DEBUG ]     "mons": [
[2017-07-06 23:22:53,261][gdb3][DEBUG ]       {
[2017-07-06 23:22:53,261][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-07-06 23:22:53,261][gdb3][DEBUG ]         "name": "gdb3", 
[2017-07-06 23:22:53,261][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-07-06 23:22:53,261][gdb3][DEBUG ]         "rank": 0
[2017-07-06 23:22:53,261][gdb3][DEBUG ]       }
[2017-07-06 23:22:53,261][gdb3][DEBUG ]     ]
[2017-07-06 23:22:53,261][gdb3][DEBUG ]   }, 
[2017-07-06 23:22:53,261][gdb3][DEBUG ]   "name": "gdb3", 
[2017-07-06 23:22:53,262][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-07-06 23:22:53,262][gdb3][DEBUG ]   "quorum": [
[2017-07-06 23:22:53,262][gdb3][DEBUG ]     0
[2017-07-06 23:22:53,262][gdb3][DEBUG ]   ], 
[2017-07-06 23:22:53,262][gdb3][DEBUG ]   "rank": 0, 
[2017-07-06 23:22:53,262][gdb3][DEBUG ]   "state": "leader", 
[2017-07-06 23:22:53,262][gdb3][DEBUG ]   "sync_provider": []
[2017-07-06 23:22:53,262][gdb3][DEBUG ] }
[2017-07-06 23:22:53,262][gdb3][DEBUG ] ********************************************************************************
[2017-07-06 23:22:53,262][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-07-06 23:22:53,263][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 23:22:53,328][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-07-06 23:22:53,345][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 23:22:53,358][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 23:22:53,359][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 23:22:53,375][gdb3][DEBUG ] detect machine type
[2017-07-06 23:22:53,378][gdb3][DEBUG ] find the location of an executable
[2017-07-06 23:22:53,379][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 23:22:53,444][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-07-06 23:22:53,445][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-07-06 23:22:53,445][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-07-06 23:22:53,447][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpWbgu_3
[2017-07-06 23:22:53,462][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 23:22:53,476][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 23:22:53,476][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 23:22:53,493][gdb3][DEBUG ] detect machine type
[2017-07-06 23:22:53,495][gdb3][DEBUG ] get remote short hostname
[2017-07-06 23:22:53,496][gdb3][DEBUG ] fetch remote file
[2017-07-06 23:22:53,497][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-06 23:22:53,563][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-07-06 23:22:53,729][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-07-06 23:22:53,896][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-07-06 23:22:54,062][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-07-06 23:22:54,228][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-07-06 23:22:54,394][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-07-06 23:22:54,560][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-07-06 23:22:54,726][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-07-06 23:22:54,892][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-07-06 23:22:55,058][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-07-06 23:22:55,224][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-07-06 23:22:55,224][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-07-06 23:22:55,224][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mgr.keyring
[2017-07-06 23:22:55,224][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-07-06 23:22:55,225][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-07-06 23:22:55,225][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-07-06 23:22:55,225][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpWbgu_3
[2017-07-06 23:22:55,405][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 23:22:55,406][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-07-06 23:22:55,406][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 23:22:55,406][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 23:22:55,406][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 23:22:55,406][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 23:22:55,406][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 23:22:55,406][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f012a0115a8>
[2017-07-06 23:22:55,406][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 23:22:55,406][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-07-06 23:22:55,406][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f012a928938>
[2017-07-06 23:22:55,406][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 23:22:55,406][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 23:22:55,406][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-07-06 23:22:55,433][gdb3][DEBUG ] connection detected need for sudo
[2017-07-06 23:22:55,447][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-06 23:22:55,447][gdb3][DEBUG ] detect platform information from remote host
[2017-07-06 23:22:55,464][gdb3][DEBUG ] detect machine type
[2017-07-06 23:22:55,466][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 23:23:01,312][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 23:23:01,312][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-07-06 23:23:01,313][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 23:23:01,313][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 23:23:01,313][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 23:23:01,313][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 23:23:01,313][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 23:23:01,313][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fc9b25c75a8>
[2017-07-06 23:23:01,313][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 23:23:01,313][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-07-06 23:23:01,313][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fc9b2ede938>
[2017-07-06 23:23:01,313][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 23:23:01,313][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 23:23:01,313][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-07-06 23:23:01,636][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 23:23:01,866][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 23:23:01,867][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 23:23:01,898][gdb0][DEBUG ] detect machine type
[2017-07-06 23:23:01,901][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 23:23:02,076][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 23:23:02,076][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-07-06 23:23:02,076][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 23:23:02,076][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 23:23:02,077][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 23:23:02,077][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 23:23:02,077][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 23:23:02,077][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 23:23:02,077][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 23:23:02,077][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 23:23:02,077][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 23:23:02,077][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 23:23:02,077][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 23:23:02,077][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 23:23:02,077][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9e47b19998>
[2017-07-06 23:23:02,077][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 23:23:02,077][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 23:23:02,077][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f9e47d6faa0>
[2017-07-06 23:23:02,077][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 23:23:02,078][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 23:23:02,078][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 23:23:02,078][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 23:23:02,319][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 23:23:02,546][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 23:23:02,547][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 23:23:02,563][gdb0][DEBUG ] detect machine type
[2017-07-06 23:23:02,568][gdb0][DEBUG ] find the location of an executable
[2017-07-06 23:23:02,569][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 23:23:02,569][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-07-06 23:23:02,569][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 23:23:02,571][gdb0][WARNING] osd keyring does not exist yet, creating one
[2017-07-06 23:23:02,571][gdb0][DEBUG ] create a keyring file
[2017-07-06 23:23:02,573][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-07-06 23:23:02,574][gdb0][DEBUG ] find the location of an executable
[2017-07-06 23:23:02,576][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 23:23:02,897][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 23:23:03,111][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 23:23:03,112][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 23:23:03,119][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 23:23:03,135][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 23:23:03,151][gdb0][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-07-06 23:23:03,151][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.2253.tmp
[2017-07-06 23:23:03,151][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.2253.tmp
[2017-07-06 23:23:03,159][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.2253.tmp
[2017-07-06 23:23:08,172][gdb0][INFO  ] checking OSD status...
[2017-07-06 23:23:08,172][gdb0][DEBUG ] find the location of an executable
[2017-07-06 23:23:08,174][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 23:23:08,440][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-07-06 23:23:08,606][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 23:23:08,606][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-07-06 23:23:08,607][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 23:23:08,607][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 23:23:08,607][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 23:23:08,607][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 23:23:08,607][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 23:23:08,607][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 23:23:08,607][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f906ac51998>
[2017-07-06 23:23:08,607][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 23:23:08,607][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f906aea7aa0>
[2017-07-06 23:23:08,607][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 23:23:08,607][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 23:23:08,607][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-06 23:23:08,608][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-07-06 23:23:08,851][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 23:23:09,082][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 23:23:09,083][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 23:23:09,100][gdb0][DEBUG ] detect machine type
[2017-07-06 23:23:09,104][gdb0][DEBUG ] find the location of an executable
[2017-07-06 23:23:09,104][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 23:23:09,104][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-07-06 23:23:09,104][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 23:23:09,105][gdb0][DEBUG ] find the location of an executable
[2017-07-06 23:23:09,106][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 23:23:09,277][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 23:23:09,277][gdb0][WARNING] activate: Cluster uuid is 7273016e-b03e-4d95-b0ee-5ed43c689535
[2017-07-06 23:23:09,277][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 23:23:09,277][gdb0][WARNING] activate: Cluster name is ceph
[2017-07-06 23:23:09,277][gdb0][WARNING] activate: OSD uuid is b43f1926-06b2-4ee0-b08c-6bd685786e63
[2017-07-06 23:23:09,277][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-07-06 23:23:09,278][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise b43f1926-06b2-4ee0-b08c-6bd685786e63
[2017-07-06 23:23:09,442][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.2370.tmp
[2017-07-06 23:23:09,442][gdb0][WARNING] activate: OSD id is 0
[2017-07-06 23:23:09,442][gdb0][WARNING] activate: Initializing OSD...
[2017-07-06 23:23:09,442][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-07-06 23:23:09,556][gdb0][WARNING] got monmap epoch 2
[2017-07-06 23:23:09,557][gdb0][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 0 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid b43f1926-06b2-4ee0-b08c-6bd685786e63 --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-07-06 23:23:09,621][gdb0][WARNING] activate: Marking with init system systemd
[2017-07-06 23:23:09,621][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-07-06 23:23:09,621][gdb0][WARNING] activate: Authorizing OSD key...
[2017-07-06 23:23:09,621][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.0 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-07-06 23:23:09,735][gdb0][WARNING] added key for osd.0
[2017-07-06 23:23:09,751][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.2370.tmp
[2017-07-06 23:23:09,751][gdb0][WARNING] activate: ceph osd.0 data dir is ready at /mnt/memstore
[2017-07-06 23:23:09,751][gdb0][WARNING] activate_dir: Creating symlink /var/lib/ceph/osd/ceph-0 -> /mnt/memstore
[2017-07-06 23:23:09,751][gdb0][WARNING] start_daemon: Starting ceph osd.0...
[2017-07-06 23:23:09,751][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0
[2017-07-06 23:23:09,754][gdb0][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service.
[2017-07-06 23:23:09,819][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0 --runtime
[2017-07-06 23:23:09,883][gdb0][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@0
[2017-07-06 23:23:09,883][gdb0][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service to /lib/systemd/system/ceph-osd@.service.
[2017-07-06 23:23:09,947][gdb0][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@0
[2017-07-06 23:23:15,016][gdb0][INFO  ] checking OSD status...
[2017-07-06 23:23:15,016][gdb0][DEBUG ] find the location of an executable
[2017-07-06 23:23:15,019][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 23:23:15,187][gdb0][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 23:24:19,636][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 23:24:19,636][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy rgw create gdb0
[2017-07-06 23:24:19,637][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 23:24:19,637][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 23:24:19,637][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 23:24:19,637][ceph_deploy.cli][INFO  ]  rgw                           : [('gdb0', 'rgw.gdb0')]
[2017-07-06 23:24:19,637][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 23:24:19,637][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-06 23:24:19,637][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 23:24:19,637][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3bc7249830>
[2017-07-06 23:24:19,637][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 23:24:19,637][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7f3bc790a758>
[2017-07-06 23:24:19,637][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 23:24:19,637][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 23:24:19,637][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts gdb0:rgw.gdb0
[2017-07-06 23:24:19,879][gdb0][DEBUG ] connection detected need for sudo
[2017-07-06 23:24:20,106][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-06 23:24:20,107][gdb0][DEBUG ] detect platform information from remote host
[2017-07-06 23:24:20,123][gdb0][DEBUG ] detect machine type
[2017-07-06 23:24:20,127][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 23:24:20,127][ceph_deploy.rgw][DEBUG ] remote host will use systemd
[2017-07-06 23:24:20,128][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to gdb0
[2017-07-06 23:24:20,128][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 23:24:20,130][gdb0][WARNING] rgw keyring does not exist yet, creating one
[2017-07-06 23:24:20,131][gdb0][DEBUG ] create a keyring file
[2017-07-06 23:24:20,132][gdb0][DEBUG ] create path recursively if it doesn't exist
[2017-07-06 23:24:20,135][gdb0][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.gdb0 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.gdb0/keyring
[2017-07-06 23:24:20,306][gdb0][INFO  ] Running command: sudo systemctl enable ceph-radosgw@rgw.gdb0
[2017-07-06 23:24:20,376][gdb0][INFO  ] Running command: sudo systemctl start ceph-radosgw@rgw.gdb0
[2017-07-06 23:24:20,444][gdb0][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 23:24:20,511][ceph_deploy.rgw][INFO  ] The Ceph Object Gateway (RGW) is now running on host gdb0 and default port 7480
[2017-07-06 23:24:58,770][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 23:24:58,770][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb1
[2017-07-06 23:24:58,770][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 23:24:58,770][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 23:24:58,770][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 23:24:58,770][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 23:24:58,770][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 23:24:58,770][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ffa285b95a8>
[2017-07-06 23:24:58,770][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 23:24:58,771][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-07-06 23:24:58,771][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7ffa28ed0938>
[2017-07-06 23:24:58,771][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 23:24:58,771][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 23:24:58,771][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-07-06 23:24:59,019][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 23:24:59,250][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 23:24:59,251][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 23:24:59,268][gdb1][DEBUG ] detect machine type
[2017-07-06 23:24:59,272][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 23:24:59,443][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 23:24:59,444][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-07-06 23:24:59,444][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 23:24:59,444][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 23:24:59,444][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 23:24:59,444][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-06 23:24:59,444][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 23:24:59,444][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 23:24:59,444][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 23:24:59,444][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 23:24:59,444][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 23:24:59,445][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 23:24:59,445][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 23:24:59,445][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 23:24:59,445][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fd289c2d998>
[2017-07-06 23:24:59,445][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 23:24:59,445][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 23:24:59,445][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fd289e83aa0>
[2017-07-06 23:24:59,445][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 23:24:59,445][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 23:24:59,445][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 23:24:59,445][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-07-06 23:24:59,683][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 23:24:59,914][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 23:24:59,914][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 23:24:59,931][gdb1][DEBUG ] detect machine type
[2017-07-06 23:24:59,934][gdb1][DEBUG ] find the location of an executable
[2017-07-06 23:24:59,935][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 23:24:59,935][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-07-06 23:24:59,936][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 23:24:59,938][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-07-06 23:24:59,938][gdb1][DEBUG ] find the location of an executable
[2017-07-06 23:24:59,940][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 23:25:00,261][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 23:25:00,263][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 23:25:00,278][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 23:25:00,294][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 23:25:00,302][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 23:25:00,317][gdb1][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-07-06 23:25:05,326][gdb1][INFO  ] checking OSD status...
[2017-07-06 23:25:05,326][gdb1][DEBUG ] find the location of an executable
[2017-07-06 23:25:05,330][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 23:25:05,495][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-07-06 23:25:05,660][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 23:25:05,660][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-07-06 23:25:05,660][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 23:25:05,660][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 23:25:05,660][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 23:25:05,661][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 23:25:05,661][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 23:25:05,661][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 23:25:05,661][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f2771acd998>
[2017-07-06 23:25:05,661][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 23:25:05,661][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f2771d23aa0>
[2017-07-06 23:25:05,661][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 23:25:05,661][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 23:25:05,661][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-06 23:25:05,661][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-07-06 23:25:05,899][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 23:25:06,127][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 23:25:06,128][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 23:25:06,144][gdb1][DEBUG ] detect machine type
[2017-07-06 23:25:06,148][gdb1][DEBUG ] find the location of an executable
[2017-07-06 23:25:06,149][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 23:25:06,150][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-07-06 23:25:06,150][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 23:25:06,150][gdb1][DEBUG ] find the location of an executable
[2017-07-06 23:25:06,152][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 23:25:06,323][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 23:25:06,323][gdb1][WARNING] activate: Cluster uuid is 7236ff6b-c970-4b9a-b9c8-98f42ac8519f
[2017-07-06 23:25:06,323][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 23:25:06,323][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=radosgw-sync --show-config-value=fsid
[2017-07-06 23:25:06,323][gdb1][WARNING] Traceback (most recent call last):
[2017-07-06 23:25:06,323][gdb1][WARNING]   File "/usr/local/bin/ceph-disk", line 9, in <module>
[2017-07-06 23:25:06,323][gdb1][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-07-06 23:25:06,323][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5653, in run
[2017-07-06 23:25:06,323][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5604, in main
[2017-07-06 23:25:06,324][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3713, in main_activate
[2017-07-06 23:25:06,324][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3533, in activate_dir
[2017-07-06 23:25:06,324][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3609, in activate
[2017-07-06 23:25:06,324][gdb1][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid 7236ff6b-c970-4b9a-b9c8-98f42ac8519f
[2017-07-06 23:25:06,324][gdb1][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-07-06 23:25:06,324][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-07-06 23:26:11,286][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 23:26:11,286][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb1
[2017-07-06 23:26:11,286][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 23:26:11,286][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 23:26:11,286][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 23:26:11,286][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-06 23:26:11,286][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 23:26:11,286][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb9923485a8>
[2017-07-06 23:26:11,286][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 23:26:11,286][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-07-06 23:26:11,286][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fb992c5f938>
[2017-07-06 23:26:11,287][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 23:26:11,287][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 23:26:11,287][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-07-06 23:26:11,527][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 23:26:11,783][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 23:26:11,783][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 23:26:11,800][gdb1][DEBUG ] detect machine type
[2017-07-06 23:26:11,805][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 23:26:11,977][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 23:26:11,978][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-07-06 23:26:11,978][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 23:26:11,978][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 23:26:11,978][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-06 23:26:11,978][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-06 23:26:11,978][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-06 23:26:11,978][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 23:26:11,978][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-06 23:26:11,978][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-06 23:26:11,978][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 23:26:11,978][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-06 23:26:11,978][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-06 23:26:11,979][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 23:26:11,979][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7fc56f0998>
[2017-07-06 23:26:11,979][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 23:26:11,979][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-06 23:26:11,979][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f7fc5946aa0>
[2017-07-06 23:26:11,979][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 23:26:11,979][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 23:26:11,979][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-06 23:26:11,979][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-07-06 23:26:12,215][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 23:26:12,443][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 23:26:12,444][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 23:26:12,461][gdb1][DEBUG ] detect machine type
[2017-07-06 23:26:12,464][gdb1][DEBUG ] find the location of an executable
[2017-07-06 23:26:12,465][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 23:26:12,465][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-07-06 23:26:12,466][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 23:26:12,468][gdb1][WARNING] osd keyring does not exist yet, creating one
[2017-07-06 23:26:12,468][gdb1][DEBUG ] create a keyring file
[2017-07-06 23:26:12,470][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-07-06 23:26:12,470][gdb1][DEBUG ] find the location of an executable
[2017-07-06 23:26:12,472][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-06 23:26:12,643][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 23:26:12,643][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 23:26:12,643][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 23:26:12,647][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-06 23:26:12,662][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-06 23:26:12,670][gdb1][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-07-06 23:26:12,673][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.31027.tmp
[2017-07-06 23:26:12,677][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.31027.tmp
[2017-07-06 23:26:12,680][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.31027.tmp
[2017-07-06 23:26:17,701][gdb1][INFO  ] checking OSD status...
[2017-07-06 23:26:17,701][gdb1][DEBUG ] find the location of an executable
[2017-07-06 23:26:17,704][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 23:26:17,869][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-07-06 23:26:18,035][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 23:26:18,035][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-07-06 23:26:18,035][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 23:26:18,035][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 23:26:18,036][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 23:26:18,036][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 23:26:18,036][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-06 23:26:18,036][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 23:26:18,036][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fc3b9d22998>
[2017-07-06 23:26:18,036][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 23:26:18,036][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fc3b9f78aa0>
[2017-07-06 23:26:18,036][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 23:26:18,036][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 23:26:18,036][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-06 23:26:18,036][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-07-06 23:26:18,275][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 23:26:18,507][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 23:26:18,508][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 23:26:18,524][gdb1][DEBUG ] detect machine type
[2017-07-06 23:26:18,528][gdb1][DEBUG ] find the location of an executable
[2017-07-06 23:26:18,529][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 23:26:18,529][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-07-06 23:26:18,529][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-06 23:26:18,530][gdb1][DEBUG ] find the location of an executable
[2017-07-06 23:26:18,532][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-06 23:26:18,702][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-07-06 23:26:18,702][gdb1][WARNING] activate: Cluster uuid is 7273016e-b03e-4d95-b0ee-5ed43c689535
[2017-07-06 23:26:18,702][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-06 23:26:18,702][gdb1][WARNING] activate: Cluster name is ceph
[2017-07-06 23:26:18,703][gdb1][WARNING] activate: OSD uuid is 713064ab-422f-4203-89fc-371e6ad47ac0
[2017-07-06 23:26:18,703][gdb1][WARNING] allocate_osd_id: Allocating OSD id...
[2017-07-06 23:26:18,703][gdb1][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 713064ab-422f-4203-89fc-371e6ad47ac0
[2017-07-06 23:26:19,369][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.31144.tmp
[2017-07-06 23:26:19,369][gdb1][WARNING] activate: OSD id is 1
[2017-07-06 23:26:19,369][gdb1][WARNING] activate: Initializing OSD...
[2017-07-06 23:26:19,369][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-07-06 23:26:19,483][gdb1][WARNING] got monmap epoch 2
[2017-07-06 23:26:19,483][gdb1][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 1 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid 713064ab-422f-4203-89fc-371e6ad47ac0 --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-07-06 23:26:19,515][gdb1][WARNING] activate: Marking with init system systemd
[2017-07-06 23:26:19,515][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-07-06 23:26:19,516][gdb1][WARNING] activate: Authorizing OSD key...
[2017-07-06 23:26:19,516][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.1 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-07-06 23:26:19,680][gdb1][WARNING] added key for osd.1
[2017-07-06 23:26:19,680][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.31144.tmp
[2017-07-06 23:26:19,680][gdb1][WARNING] activate: ceph osd.1 data dir is ready at /mnt/memstore
[2017-07-06 23:26:19,680][gdb1][WARNING] activate_dir: Creating symlink /var/lib/ceph/osd/ceph-1 -> /mnt/memstore
[2017-07-06 23:26:19,680][gdb1][WARNING] start_daemon: Starting ceph osd.1...
[2017-07-06 23:26:19,680][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@1
[2017-07-06 23:26:19,681][gdb1][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@1.service.
[2017-07-06 23:26:19,745][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@1 --runtime
[2017-07-06 23:26:19,776][gdb1][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@1
[2017-07-06 23:26:19,778][gdb1][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@1.service to /lib/systemd/system/ceph-osd@.service.
[2017-07-06 23:26:19,842][gdb1][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@1
[2017-07-06 23:26:24,911][gdb1][INFO  ] checking OSD status...
[2017-07-06 23:26:24,912][gdb1][DEBUG ] find the location of an executable
[2017-07-06 23:26:24,914][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-06 23:26:25,082][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 23:26:56,665][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-06 23:26:56,665][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy rgw create gdb1
[2017-07-06 23:26:56,665][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-06 23:26:56,666][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-06 23:26:56,666][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-06 23:26:56,666][ceph_deploy.cli][INFO  ]  rgw                           : [('gdb1', 'rgw.gdb1')]
[2017-07-06 23:26:56,666][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-06 23:26:56,666][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-06 23:26:56,666][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-06 23:26:56,666][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f8c9fdcc830>
[2017-07-06 23:26:56,666][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-06 23:26:56,666][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7f8ca048d758>
[2017-07-06 23:26:56,666][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-06 23:26:56,666][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-06 23:26:56,666][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts gdb1:rgw.gdb1
[2017-07-06 23:26:56,903][gdb1][DEBUG ] connection detected need for sudo
[2017-07-06 23:26:57,138][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-06 23:26:57,139][gdb1][DEBUG ] detect platform information from remote host
[2017-07-06 23:26:57,155][gdb1][DEBUG ] detect machine type
[2017-07-06 23:26:57,159][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-06 23:26:57,159][ceph_deploy.rgw][DEBUG ] remote host will use systemd
[2017-07-06 23:26:57,159][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to gdb1
[2017-07-06 23:26:57,159][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-06 23:26:57,162][gdb1][WARNING] rgw keyring does not exist yet, creating one
[2017-07-06 23:26:57,162][gdb1][DEBUG ] create a keyring file
[2017-07-06 23:26:57,165][gdb1][DEBUG ] create path recursively if it doesn't exist
[2017-07-06 23:26:57,167][gdb1][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.gdb1 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.gdb1/keyring
[2017-07-06 23:26:57,337][gdb1][INFO  ] Running command: sudo systemctl enable ceph-radosgw@rgw.gdb1
[2017-07-06 23:26:57,407][gdb1][INFO  ] Running command: sudo systemctl start ceph-radosgw@rgw.gdb1
[2017-07-06 23:26:57,443][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-06 23:26:57,560][ceph_deploy.rgw][INFO  ] The Ceph Object Gateway (RGW) is now running on host gdb1 and default port 7480
[2017-07-07 01:47:07,691][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 01:47:07,692][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-07-07 01:47:07,692][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 01:47:07,692][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 01:47:07,692][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 01:47:07,692][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 01:47:07,692][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 01:47:07,693][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0fe04640e0>
[2017-07-07 01:47:07,693][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 01:47:07,693][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-07 01:47:07,693][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f0fe0d711b8>
[2017-07-07 01:47:07,693][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 01:47:07,693][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 01:47:07,693][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-07-07 01:47:07,693][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-07-07 01:47:07,693][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-07-07 01:47:07,693][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-07-07 01:47:07,729][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 01:47:07,743][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 01:47:07,745][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 01:47:07,760][gdb3][DEBUG ] detect machine type
[2017-07-07 01:47:07,762][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 01:47:07,763][gdb3][INFO  ] Purging Ceph on gdb3
[2017-07-07 01:47:07,763][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-07-07 01:47:08,036][gdb3][DEBUG ] Reading package lists...
[2017-07-07 01:47:08,200][gdb3][DEBUG ] Building dependency tree...
[2017-07-07 01:47:08,201][gdb3][DEBUG ] Reading state information...
[2017-07-07 01:47:08,265][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-07-07 01:47:08,265][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-07-07 01:47:08,265][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-07-07 01:47:08,265][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-07-07 01:47:08,265][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-07-07 01:47:08,265][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-07-07 01:47:08,266][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1016 linux-aws-headers-4.4.0-1017
[2017-07-07 01:47:08,266][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1018 linux-headers-4.4.0-1013-aws
[2017-07-07 01:47:08,266][gdb3][DEBUG ]   linux-headers-4.4.0-1016-aws linux-headers-4.4.0-1017-aws
[2017-07-07 01:47:08,266][gdb3][DEBUG ]   linux-headers-4.4.0-1018-aws linux-image-4.4.0-1013-aws
[2017-07-07 01:47:08,266][gdb3][DEBUG ]   linux-image-4.4.0-1016-aws linux-image-4.4.0-1017-aws
[2017-07-07 01:47:08,266][gdb3][DEBUG ]   linux-image-4.4.0-1018-aws ntp python-blinker python-cephfs
[2017-07-07 01:47:08,266][gdb3][DEBUG ]   python-cffi-backend python-chardet python-cryptography python-enum34
[2017-07-07 01:47:08,266][gdb3][DEBUG ]   python-flask python-idna python-ipaddress python-itsdangerous python-jinja2
[2017-07-07 01:47:08,267][gdb3][DEBUG ]   python-markupsafe python-ndg-httpsclient python-openssl python-pyasn1
[2017-07-07 01:47:08,267][gdb3][DEBUG ]   python-pyinotify python-rados python-rbd python-requests python-rgw
[2017-07-07 01:47:08,267][gdb3][DEBUG ]   python-six python-urllib3 python-werkzeug
[2017-07-07 01:47:08,267][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-07-07 01:47:08,299][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-07-07 01:47:08,299][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-07-07 01:47:08,614][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 60 not upgraded.
[2017-07-07 01:47:08,614][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-07-07 01:47:09,079][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 179644 files and directories currently installed.)
[2017-07-07 01:47:09,079][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-07-07 01:47:09,294][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-07-07 01:47:09,358][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-07-07 01:47:09,390][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-07-07 01:47:09,606][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-07-07 01:47:09,721][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-07-07 01:47:09,887][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-07-07 01:47:09,951][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-07-07 01:47:09,959][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-07-07 01:47:10,126][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-07-07 01:47:10,242][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-07-07 01:47:10,243][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-07-07 01:47:10,408][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-07-07 01:47:10,408][gdb3][DEBUG ] dpkg: warning: while removing ceph-base, directory '/var/lib/ceph/tmp' not empty so not removed
[2017-07-07 01:47:10,423][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-07-07 01:47:10,588][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-07-07 01:47:10,620][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-07-07 01:47:10,627][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-07-07 01:47:10,842][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu9) ...
[2017-07-07 01:47:11,909][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-07-07 01:47:12,073][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 01:47:12,073][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-07-07 01:47:12,074][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 01:47:12,074][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 01:47:12,074][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 01:47:12,074][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 01:47:12,074][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 01:47:12,074][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f016ebdf758>
[2017-07-07 01:47:12,074][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 01:47:12,074][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-07 01:47:12,074][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f016f4ec230>
[2017-07-07 01:47:12,074][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 01:47:12,074][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 01:47:12,074][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-07-07 01:47:12,100][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 01:47:12,114][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 01:47:12,115][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 01:47:12,131][gdb3][DEBUG ] detect machine type
[2017-07-07 01:47:12,133][gdb3][DEBUG ] find the location of an executable
[2017-07-07 01:47:12,149][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 01:47:12,164][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 01:47:12,164][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 01:47:12,181][gdb3][DEBUG ] detect machine type
[2017-07-07 01:47:12,183][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 01:47:12,183][gdb3][INFO  ] purging data on gdb3
[2017-07-07 01:47:12,184][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-07-07 01:47:12,197][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-07-07 01:47:12,366][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 01:47:12,366][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-07-07 01:47:12,366][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 01:47:12,366][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 01:47:12,367][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 01:47:12,367][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 01:47:12,367][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 01:47:12,367][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fbd3d870a28>
[2017-07-07 01:47:12,367][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 01:47:12,367][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7fbd3e133848>
[2017-07-07 01:47:12,367][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 01:47:12,367][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 01:47:29,450][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 01:47:29,451][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-07-07 01:47:29,451][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 01:47:29,451][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 01:47:29,451][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 01:47:29,451][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 01:47:29,451][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 01:47:29,451][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fbacae875a8>
[2017-07-07 01:47:29,451][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 01:47:29,451][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-07-07 01:47:29,451][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-07-07 01:47:29,451][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7fbacb50b758>
[2017-07-07 01:47:29,452][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-07-07 01:47:29,452][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 01:47:29,452][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-07-07 01:47:29,452][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 01:47:29,452][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-07-07 01:47:29,452][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-07-07 01:47:29,452][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-07-07 01:47:29,478][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 01:47:29,491][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 01:47:29,492][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 01:47:29,508][gdb3][DEBUG ] detect machine type
[2017-07-07 01:47:29,510][gdb3][DEBUG ] find the location of an executable
[2017-07-07 01:47:29,511][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-07-07 01:47:29,523][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-07-07 01:47:29,529][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-07-07 01:47:29,529][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-07-07 01:47:29,529][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-07-07 01:47:29,529][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-07-07 01:47:29,529][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-07-07 01:47:29,529][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-07-07 01:47:29,529][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-07-07 01:47:29,530][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-07-07 01:47:29,693][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 01:47:29,694][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-07-07 01:47:29,694][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 01:47:29,694][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 01:47:29,694][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 01:47:29,694][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 01:47:29,694][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-07-07 01:47:29,694][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 01:47:29,694][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f928322bea8>
[2017-07-07 01:47:29,694][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 01:47:29,694][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f9283200b18>
[2017-07-07 01:47:29,694][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 01:47:29,694][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-07-07 01:47:29,695][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 01:47:29,695][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-07-07 01:47:29,695][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-07-07 01:47:29,721][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 01:47:29,734][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 01:47:29,735][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 01:47:29,752][gdb3][DEBUG ] detect machine type
[2017-07-07 01:47:29,754][gdb3][DEBUG ] find the location of an executable
[2017-07-07 01:47:29,754][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-07-07 01:47:29,754][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-07-07 01:47:29,755][gdb3][DEBUG ] get remote short hostname
[2017-07-07 01:47:29,755][gdb3][DEBUG ] deploying mon to gdb3
[2017-07-07 01:47:29,755][gdb3][DEBUG ] get remote short hostname
[2017-07-07 01:47:29,755][gdb3][DEBUG ] remote hostname: gdb3
[2017-07-07 01:47:29,756][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 01:47:29,757][gdb3][DEBUG ] create the mon path if it does not exist
[2017-07-07 01:47:29,757][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-07 01:47:29,758][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-07 01:47:29,758][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-07 01:47:29,758][gdb3][DEBUG ] create the monitor keyring file
[2017-07-07 01:47:29,759][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-07-07 01:47:29,797][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-07-07 01:47:29,797][gdb3][DEBUG ] ceph-mon: set fsid to b0dfcf9e-b3ee-4f73-9bf2-0bf2f0984930
[2017-07-07 01:47:29,798][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-07-07 01:47:29,802][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-07 01:47:29,802][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-07-07 01:47:29,803][gdb3][DEBUG ] create the init path if it does not exist
[2017-07-07 01:47:29,804][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-07 01:47:29,872][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-07-07 01:47:29,940][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-07-07 01:47:31,978][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 01:47:32,043][gdb3][DEBUG ] ********************************************************************************
[2017-07-07 01:47:32,043][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-07-07 01:47:32,043][gdb3][DEBUG ] {
[2017-07-07 01:47:32,043][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-07-07 01:47:32,044][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-07-07 01:47:32,044][gdb3][DEBUG ]   "features": {
[2017-07-07 01:47:32,044][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-07-07 01:47:32,044][gdb3][DEBUG ]     "quorum_mon": [
[2017-07-07 01:47:32,044][gdb3][DEBUG ]       "kraken", 
[2017-07-07 01:47:32,044][gdb3][DEBUG ]       "luminous"
[2017-07-07 01:47:32,044][gdb3][DEBUG ]     ], 
[2017-07-07 01:47:32,044][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-07-07 01:47:32,044][gdb3][DEBUG ]     "required_mon": [
[2017-07-07 01:47:32,044][gdb3][DEBUG ]       "kraken", 
[2017-07-07 01:47:32,044][gdb3][DEBUG ]       "luminous"
[2017-07-07 01:47:32,044][gdb3][DEBUG ]     ]
[2017-07-07 01:47:32,044][gdb3][DEBUG ]   }, 
[2017-07-07 01:47:32,044][gdb3][DEBUG ]   "monmap": {
[2017-07-07 01:47:32,044][gdb3][DEBUG ]     "created": "2017-07-07 01:47:29.782195", 
[2017-07-07 01:47:32,044][gdb3][DEBUG ]     "epoch": 2, 
[2017-07-07 01:47:32,045][gdb3][DEBUG ]     "features": {
[2017-07-07 01:47:32,045][gdb3][DEBUG ]       "optional": [], 
[2017-07-07 01:47:32,045][gdb3][DEBUG ]       "persistent": [
[2017-07-07 01:47:32,045][gdb3][DEBUG ]         "kraken", 
[2017-07-07 01:47:32,045][gdb3][DEBUG ]         "luminous"
[2017-07-07 01:47:32,045][gdb3][DEBUG ]       ]
[2017-07-07 01:47:32,045][gdb3][DEBUG ]     }, 
[2017-07-07 01:47:32,045][gdb3][DEBUG ]     "fsid": "b0dfcf9e-b3ee-4f73-9bf2-0bf2f0984930", 
[2017-07-07 01:47:32,045][gdb3][DEBUG ]     "modified": "2017-07-07 01:47:30.027302", 
[2017-07-07 01:47:32,045][gdb3][DEBUG ]     "mons": [
[2017-07-07 01:47:32,045][gdb3][DEBUG ]       {
[2017-07-07 01:47:32,045][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-07-07 01:47:32,045][gdb3][DEBUG ]         "name": "gdb3", 
[2017-07-07 01:47:32,045][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-07-07 01:47:32,045][gdb3][DEBUG ]         "rank": 0
[2017-07-07 01:47:32,046][gdb3][DEBUG ]       }
[2017-07-07 01:47:32,046][gdb3][DEBUG ]     ]
[2017-07-07 01:47:32,046][gdb3][DEBUG ]   }, 
[2017-07-07 01:47:32,046][gdb3][DEBUG ]   "name": "gdb3", 
[2017-07-07 01:47:32,046][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-07-07 01:47:32,046][gdb3][DEBUG ]   "quorum": [
[2017-07-07 01:47:32,046][gdb3][DEBUG ]     0
[2017-07-07 01:47:32,046][gdb3][DEBUG ]   ], 
[2017-07-07 01:47:32,046][gdb3][DEBUG ]   "rank": 0, 
[2017-07-07 01:47:32,046][gdb3][DEBUG ]   "state": "leader", 
[2017-07-07 01:47:32,046][gdb3][DEBUG ]   "sync_provider": []
[2017-07-07 01:47:32,046][gdb3][DEBUG ] }
[2017-07-07 01:47:32,046][gdb3][DEBUG ] ********************************************************************************
[2017-07-07 01:47:32,046][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-07-07 01:47:32,047][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 01:47:32,112][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-07-07 01:47:32,127][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 01:47:32,141][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 01:47:32,142][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 01:47:32,158][gdb3][DEBUG ] detect machine type
[2017-07-07 01:47:32,160][gdb3][DEBUG ] find the location of an executable
[2017-07-07 01:47:32,161][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 01:47:32,226][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-07-07 01:47:32,227][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-07-07 01:47:32,227][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-07-07 01:47:32,228][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpzWTuTX
[2017-07-07 01:47:32,244][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 01:47:32,257][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 01:47:32,258][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 01:47:32,274][gdb3][DEBUG ] detect machine type
[2017-07-07 01:47:32,276][gdb3][DEBUG ] get remote short hostname
[2017-07-07 01:47:32,276][gdb3][DEBUG ] fetch remote file
[2017-07-07 01:47:32,278][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 01:47:32,344][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-07-07 01:47:32,510][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-07-07 01:47:32,726][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-07-07 01:47:32,892][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-07-07 01:47:33,058][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-07-07 01:47:33,225][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-07-07 01:47:33,391][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-07-07 01:47:33,557][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-07-07 01:47:33,723][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-07-07 01:47:33,889][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-07-07 01:47:34,054][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-07-07 01:47:34,054][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-07-07 01:47:34,054][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mgr.keyring
[2017-07-07 01:47:34,055][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-07-07 01:47:34,055][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-07-07 01:47:34,055][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-07-07 01:47:34,055][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpzWTuTX
[2017-07-07 01:47:34,234][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 01:47:34,235][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-07-07 01:47:34,235][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 01:47:34,235][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 01:47:34,235][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 01:47:34,235][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 01:47:34,235][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 01:47:34,235][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f8ace822560>
[2017-07-07 01:47:34,235][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 01:47:34,235][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-07-07 01:47:34,235][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f8acf139938>
[2017-07-07 01:47:34,235][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 01:47:34,235][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 01:47:34,235][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-07-07 01:47:34,261][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 01:47:34,275][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 01:47:34,275][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 01:47:34,291][gdb3][DEBUG ] detect machine type
[2017-07-07 01:47:34,294][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 01:47:38,880][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 01:47:38,880][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb1
[2017-07-07 01:47:38,880][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 01:47:38,880][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 01:47:38,880][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 01:47:38,880][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-07 01:47:38,880][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 01:47:38,880][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f385c708560>
[2017-07-07 01:47:38,880][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 01:47:38,881][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-07-07 01:47:38,881][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f385d01f938>
[2017-07-07 01:47:38,881][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 01:47:38,881][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 01:47:38,881][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-07-07 01:47:39,203][gdb1][DEBUG ] connection detected need for sudo
[2017-07-07 01:47:39,432][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-07 01:47:39,432][gdb1][DEBUG ] detect platform information from remote host
[2017-07-07 01:47:39,463][gdb1][DEBUG ] detect machine type
[2017-07-07 01:47:39,466][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 01:47:39,637][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 01:47:39,637][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-07-07 01:47:39,637][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 01:47:39,637][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 01:47:39,637][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-07 01:47:39,637][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-07 01:47:39,637][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-07 01:47:39,637][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 01:47:39,637][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-07 01:47:39,638][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-07 01:47:39,638][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 01:47:39,638][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-07 01:47:39,638][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-07 01:47:39,638][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 01:47:39,638][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fde3346e950>
[2017-07-07 01:47:39,638][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 01:47:39,638][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-07 01:47:39,638][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fde336c4aa0>
[2017-07-07 01:47:39,638][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 01:47:39,638][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 01:47:39,638][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-07 01:47:39,639][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-07-07 01:47:39,881][gdb1][DEBUG ] connection detected need for sudo
[2017-07-07 01:47:40,108][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-07 01:47:40,108][gdb1][DEBUG ] detect platform information from remote host
[2017-07-07 01:47:40,124][gdb1][DEBUG ] detect machine type
[2017-07-07 01:47:40,128][gdb1][DEBUG ] find the location of an executable
[2017-07-07 01:47:40,129][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 01:47:40,129][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-07-07 01:47:40,129][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 01:47:40,132][gdb1][WARNING] osd keyring does not exist yet, creating one
[2017-07-07 01:47:40,132][gdb1][DEBUG ] create a keyring file
[2017-07-07 01:47:40,134][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-07-07 01:47:40,134][gdb1][DEBUG ] find the location of an executable
[2017-07-07 01:47:40,136][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-07 01:47:40,456][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-07 01:47:40,621][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-07 01:47:40,621][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-07 01:47:40,621][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-07 01:47:40,629][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-07 01:47:40,636][gdb1][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-07-07 01:47:40,652][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.2205.tmp
[2017-07-07 01:47:40,652][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.2205.tmp
[2017-07-07 01:47:40,653][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.2205.tmp
[2017-07-07 01:47:45,674][gdb1][INFO  ] checking OSD status...
[2017-07-07 01:47:45,674][gdb1][DEBUG ] find the location of an executable
[2017-07-07 01:47:45,677][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-07 01:47:45,943][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-07-07 01:47:46,106][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 01:47:46,106][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-07-07 01:47:46,106][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 01:47:46,106][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 01:47:46,107][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 01:47:46,107][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 01:47:46,107][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-07 01:47:46,107][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 01:47:46,107][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f8f701aa950>
[2017-07-07 01:47:46,107][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 01:47:46,107][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f8f70400aa0>
[2017-07-07 01:47:46,107][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 01:47:46,107][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 01:47:46,107][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-07 01:47:46,107][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-07-07 01:47:46,348][gdb1][DEBUG ] connection detected need for sudo
[2017-07-07 01:47:46,580][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-07 01:47:46,580][gdb1][DEBUG ] detect platform information from remote host
[2017-07-07 01:47:46,596][gdb1][DEBUG ] detect machine type
[2017-07-07 01:47:46,600][gdb1][DEBUG ] find the location of an executable
[2017-07-07 01:47:46,601][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 01:47:46,601][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-07-07 01:47:46,601][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-07 01:47:46,601][gdb1][DEBUG ] find the location of an executable
[2017-07-07 01:47:46,603][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-07 01:47:46,774][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-07-07 01:47:46,774][gdb1][WARNING] activate: Cluster uuid is b0dfcf9e-b3ee-4f73-9bf2-0bf2f0984930
[2017-07-07 01:47:46,774][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-07 01:47:46,774][gdb1][WARNING] activate: Cluster name is ceph
[2017-07-07 01:47:46,774][gdb1][WARNING] activate: OSD uuid is b9fe9e45-6433-412f-8480-c335c5eb5a8d
[2017-07-07 01:47:46,774][gdb1][WARNING] allocate_osd_id: Allocating OSD id...
[2017-07-07 01:47:46,774][gdb1][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise b9fe9e45-6433-412f-8480-c335c5eb5a8d
[2017-07-07 01:47:46,938][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.2322.tmp
[2017-07-07 01:47:46,939][gdb1][WARNING] activate: OSD id is 0
[2017-07-07 01:47:46,939][gdb1][WARNING] activate: Initializing OSD...
[2017-07-07 01:47:46,939][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-07-07 01:47:47,053][gdb1][WARNING] got monmap epoch 2
[2017-07-07 01:47:47,060][gdb1][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 0 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid b9fe9e45-6433-412f-8480-c335c5eb5a8d --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-07-07 01:47:47,124][gdb1][WARNING] activate: Marking with init system systemd
[2017-07-07 01:47:47,124][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-07-07 01:47:47,125][gdb1][WARNING] activate: Authorizing OSD key...
[2017-07-07 01:47:47,125][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.0 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-07-07 01:47:47,289][gdb1][WARNING] added key for osd.0
[2017-07-07 01:47:47,289][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.2322.tmp
[2017-07-07 01:47:47,289][gdb1][WARNING] activate: ceph osd.0 data dir is ready at /mnt/memstore
[2017-07-07 01:47:47,289][gdb1][WARNING] activate_dir: Creating symlink /var/lib/ceph/osd/ceph-0 -> /mnt/memstore
[2017-07-07 01:47:47,289][gdb1][WARNING] start_daemon: Starting ceph osd.0...
[2017-07-07 01:47:47,289][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0
[2017-07-07 01:47:47,290][gdb1][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service.
[2017-07-07 01:47:47,321][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0 --runtime
[2017-07-07 01:47:47,385][gdb1][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@0
[2017-07-07 01:47:47,385][gdb1][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service to /lib/systemd/system/ceph-osd@.service.
[2017-07-07 01:47:47,417][gdb1][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@0
[2017-07-07 01:47:52,537][gdb1][INFO  ] checking OSD status...
[2017-07-07 01:47:52,537][gdb1][DEBUG ] find the location of an executable
[2017-07-07 01:47:52,540][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-07 01:47:52,707][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-07 01:48:26,993][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 01:48:26,994][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy rgw create gdb1
[2017-07-07 01:48:26,994][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 01:48:26,994][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 01:48:26,994][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 01:48:26,994][ceph_deploy.cli][INFO  ]  rgw                           : [('gdb1', 'rgw.gdb1')]
[2017-07-07 01:48:26,994][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 01:48:26,994][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-07 01:48:26,994][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 01:48:26,994][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f8532c697e8>
[2017-07-07 01:48:26,994][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 01:48:26,994][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7f853332a758>
[2017-07-07 01:48:26,994][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 01:48:26,995][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 01:48:26,995][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts gdb1:rgw.gdb1
[2017-07-07 01:48:27,237][gdb1][DEBUG ] connection detected need for sudo
[2017-07-07 01:48:27,432][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-07 01:48:27,433][gdb1][DEBUG ] detect platform information from remote host
[2017-07-07 01:48:27,449][gdb1][DEBUG ] detect machine type
[2017-07-07 01:48:27,453][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 01:48:27,453][ceph_deploy.rgw][DEBUG ] remote host will use systemd
[2017-07-07 01:48:27,453][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to gdb1
[2017-07-07 01:48:27,453][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 01:48:27,456][gdb1][DEBUG ] create path recursively if it doesn't exist
[2017-07-07 01:48:27,459][gdb1][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.gdb1 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.gdb1/keyring
[2017-07-07 01:48:27,576][gdb1][ERROR ] 2017-07-07 01:48:27.518852 7efe4dbf2700  0 librados: client.bootstrap-rgw authentication error (1) Operation not permitted
[2017-07-07 01:48:27,576][gdb1][ERROR ] error connecting to the cluster
[2017-07-07 01:48:27,576][gdb1][ERROR ] exit code from command was: 1
[2017-07-07 01:48:27,576][ceph_deploy.rgw][ERROR ] could not create rgw
[2017-07-07 01:48:27,576][ceph_deploy][ERROR ] GenericError: Failed to create 1 RGWs

[2017-07-07 01:49:20,761][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 01:49:20,762][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy rgw create gdb1
[2017-07-07 01:49:20,762][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 01:49:20,762][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 01:49:20,762][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 01:49:20,762][ceph_deploy.cli][INFO  ]  rgw                           : [('gdb1', 'rgw.gdb1')]
[2017-07-07 01:49:20,762][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 01:49:20,762][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-07 01:49:20,762][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 01:49:20,762][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3b87bed7e8>
[2017-07-07 01:49:20,762][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 01:49:20,762][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7f3b882ae758>
[2017-07-07 01:49:20,762][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 01:49:20,762][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 01:49:20,763][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts gdb1:rgw.gdb1
[2017-07-07 01:49:21,000][gdb1][DEBUG ] connection detected need for sudo
[2017-07-07 01:49:21,227][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-07 01:49:21,228][gdb1][DEBUG ] detect platform information from remote host
[2017-07-07 01:49:21,244][gdb1][DEBUG ] detect machine type
[2017-07-07 01:49:21,248][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 01:49:21,248][ceph_deploy.rgw][DEBUG ] remote host will use systemd
[2017-07-07 01:49:21,248][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to gdb1
[2017-07-07 01:49:21,248][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 01:49:21,251][gdb1][WARNING] rgw keyring does not exist yet, creating one
[2017-07-07 01:49:21,251][gdb1][DEBUG ] create a keyring file
[2017-07-07 01:49:21,253][gdb1][DEBUG ] create path recursively if it doesn't exist
[2017-07-07 01:49:21,255][gdb1][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.gdb1 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.gdb1/keyring
[2017-07-07 01:49:21,425][gdb1][INFO  ] Running command: sudo systemctl enable ceph-radosgw@rgw.gdb1
[2017-07-07 01:49:21,494][gdb1][INFO  ] Running command: sudo systemctl start ceph-radosgw@rgw.gdb1
[2017-07-07 01:49:21,562][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-07 01:49:21,629][ceph_deploy.rgw][INFO  ] The Ceph Object Gateway (RGW) is now running on host gdb1 and default port 7480
[2017-07-07 20:44:40,883][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 20:44:40,885][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-07-07 20:44:40,885][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 20:44:40,885][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 20:44:40,885][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 20:44:40,885][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 20:44:40,885][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 20:44:40,885][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fdb5fee3128>
[2017-07-07 20:44:40,885][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 20:44:40,885][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-07 20:44:40,885][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7fdb607f01b8>
[2017-07-07 20:44:40,885][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 20:44:40,885][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 20:44:40,886][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-07-07 20:44:40,886][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-07-07 20:44:40,886][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-07-07 20:44:40,886][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-07-07 20:44:40,922][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 20:44:40,937][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 20:44:40,938][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 20:44:40,955][gdb3][DEBUG ] detect machine type
[2017-07-07 20:44:40,957][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 20:44:40,957][gdb3][INFO  ] Purging Ceph on gdb3
[2017-07-07 20:44:40,958][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-07-07 20:44:40,998][gdb3][DEBUG ] Reading package lists...
[2017-07-07 20:44:41,162][gdb3][DEBUG ] Building dependency tree...
[2017-07-07 20:44:41,162][gdb3][DEBUG ] Reading state information...
[2017-07-07 20:44:41,226][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-07-07 20:44:41,226][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-07-07 20:44:41,227][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-07-07 20:44:41,227][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-07-07 20:44:41,227][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-07-07 20:44:41,227][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-07-07 20:44:41,227][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1016 linux-aws-headers-4.4.0-1017
[2017-07-07 20:44:41,227][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1018 linux-headers-4.4.0-1013-aws
[2017-07-07 20:44:41,227][gdb3][DEBUG ]   linux-headers-4.4.0-1016-aws linux-headers-4.4.0-1017-aws
[2017-07-07 20:44:41,227][gdb3][DEBUG ]   linux-headers-4.4.0-1018-aws linux-image-4.4.0-1013-aws
[2017-07-07 20:44:41,227][gdb3][DEBUG ]   linux-image-4.4.0-1016-aws linux-image-4.4.0-1017-aws
[2017-07-07 20:44:41,227][gdb3][DEBUG ]   linux-image-4.4.0-1018-aws ntp python-blinker python-cephfs
[2017-07-07 20:44:41,227][gdb3][DEBUG ]   python-cffi-backend python-chardet python-cryptography python-enum34
[2017-07-07 20:44:41,227][gdb3][DEBUG ]   python-flask python-idna python-ipaddress python-itsdangerous python-jinja2
[2017-07-07 20:44:41,228][gdb3][DEBUG ]   python-markupsafe python-ndg-httpsclient python-openssl python-pyasn1
[2017-07-07 20:44:41,228][gdb3][DEBUG ]   python-pyinotify python-rados python-rbd python-requests python-rgw
[2017-07-07 20:44:41,228][gdb3][DEBUG ]   python-six python-urllib3 python-werkzeug
[2017-07-07 20:44:41,228][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-07-07 20:44:41,292][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-07-07 20:44:41,292][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-07-07 20:44:41,556][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 61 not upgraded.
[2017-07-07 20:44:41,557][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-07-07 20:44:41,971][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 179644 files and directories currently installed.)
[2017-07-07 20:44:41,972][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-07-07 20:44:42,187][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-07-07 20:44:42,251][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-07-07 20:44:42,315][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-07-07 20:44:42,530][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-07-07 20:44:42,645][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-07-07 20:44:42,809][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-07-07 20:44:42,876][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-07-07 20:44:42,892][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-07-07 20:44:43,107][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-07-07 20:44:43,139][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-07-07 20:44:43,171][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-07-07 20:44:43,336][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-07-07 20:44:43,336][gdb3][DEBUG ] dpkg: warning: while removing ceph-base, directory '/var/lib/ceph/tmp' not empty so not removed
[2017-07-07 20:44:43,368][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-07-07 20:44:43,532][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-07-07 20:44:43,596][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-07-07 20:44:43,596][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-07-07 20:44:43,760][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu9) ...
[2017-07-07 20:44:44,627][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-07-07 20:44:44,793][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 20:44:44,793][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-07-07 20:44:44,793][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 20:44:44,793][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 20:44:44,793][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 20:44:44,793][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 20:44:44,793][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 20:44:44,793][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fb7b6af27a0>
[2017-07-07 20:44:44,793][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 20:44:44,793][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-07 20:44:44,793][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7fb7b73ff230>
[2017-07-07 20:44:44,794][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 20:44:44,794][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 20:44:44,794][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-07-07 20:44:44,820][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 20:44:44,834][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 20:44:44,834][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 20:44:44,850][gdb3][DEBUG ] detect machine type
[2017-07-07 20:44:44,853][gdb3][DEBUG ] find the location of an executable
[2017-07-07 20:44:44,868][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 20:44:44,883][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 20:44:44,884][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 20:44:44,900][gdb3][DEBUG ] detect machine type
[2017-07-07 20:44:44,903][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 20:44:44,903][gdb3][INFO  ] purging data on gdb3
[2017-07-07 20:44:44,904][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-07-07 20:44:44,916][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-07-07 20:44:45,087][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 20:44:45,088][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-07-07 20:44:45,088][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 20:44:45,088][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 20:44:45,088][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 20:44:45,088][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 20:44:45,088][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 20:44:45,088][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f45d0288a70>
[2017-07-07 20:44:45,088][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 20:44:45,088][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7f45d0b4b848>
[2017-07-07 20:44:45,088][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 20:44:45,088][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 20:45:56,687][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 20:45:56,688][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-07-07 20:45:56,688][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 20:45:56,688][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 20:45:56,688][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 20:45:56,688][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 20:45:56,688][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 20:45:56,688][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3f527745f0>
[2017-07-07 20:45:56,688][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 20:45:56,688][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-07-07 20:45:56,688][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-07-07 20:45:56,688][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f3f52df8758>
[2017-07-07 20:45:56,688][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-07-07 20:45:56,688][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 20:45:56,689][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-07-07 20:45:56,689][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 20:45:56,689][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-07-07 20:45:56,689][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-07-07 20:45:56,689][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-07-07 20:45:56,715][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 20:45:56,729][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 20:45:56,729][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 20:45:56,746][gdb3][DEBUG ] detect machine type
[2017-07-07 20:45:56,749][gdb3][DEBUG ] find the location of an executable
[2017-07-07 20:45:56,750][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-07-07 20:45:56,761][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-07-07 20:45:56,767][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-07-07 20:45:56,767][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-07-07 20:45:56,768][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-07-07 20:45:56,768][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-07-07 20:45:56,768][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-07-07 20:45:56,768][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-07-07 20:45:56,768][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-07-07 20:45:56,768][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-07-07 20:45:56,932][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 20:45:56,933][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-07-07 20:45:56,933][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 20:45:56,933][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 20:45:56,933][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 20:45:56,933][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 20:45:56,933][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-07-07 20:45:56,933][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 20:45:56,933][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f370f427ef0>
[2017-07-07 20:45:56,933][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 20:45:56,933][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f370f3fbb18>
[2017-07-07 20:45:56,933][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 20:45:56,933][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-07-07 20:45:56,933][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 20:45:56,934][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-07-07 20:45:56,934][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-07-07 20:45:56,960][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 20:45:56,974][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 20:45:56,975][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 20:45:56,992][gdb3][DEBUG ] detect machine type
[2017-07-07 20:45:56,994][gdb3][DEBUG ] find the location of an executable
[2017-07-07 20:45:56,994][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-07-07 20:45:56,994][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-07-07 20:45:56,995][gdb3][DEBUG ] get remote short hostname
[2017-07-07 20:45:56,995][gdb3][DEBUG ] deploying mon to gdb3
[2017-07-07 20:45:56,995][gdb3][DEBUG ] get remote short hostname
[2017-07-07 20:45:56,995][gdb3][DEBUG ] remote hostname: gdb3
[2017-07-07 20:45:56,996][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 20:45:56,997][gdb3][DEBUG ] create the mon path if it does not exist
[2017-07-07 20:45:56,997][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-07 20:45:56,998][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-07 20:45:56,998][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-07 20:45:56,998][gdb3][DEBUG ] create the monitor keyring file
[2017-07-07 20:45:56,999][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-07-07 20:45:57,037][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-07-07 20:45:57,038][gdb3][DEBUG ] ceph-mon: set fsid to c730bc72-9c9e-4b40-9b40-2daa6f3f2a83
[2017-07-07 20:45:57,039][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-07-07 20:45:57,042][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-07 20:45:57,043][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-07-07 20:45:57,043][gdb3][DEBUG ] create the init path if it does not exist
[2017-07-07 20:45:57,044][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-07 20:45:57,120][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-07-07 20:45:57,194][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-07-07 20:45:59,264][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 20:45:59,329][gdb3][DEBUG ] ********************************************************************************
[2017-07-07 20:45:59,329][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-07-07 20:45:59,329][gdb3][DEBUG ] {
[2017-07-07 20:45:59,330][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-07-07 20:45:59,330][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-07-07 20:45:59,330][gdb3][DEBUG ]   "features": {
[2017-07-07 20:45:59,330][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-07-07 20:45:59,330][gdb3][DEBUG ]     "quorum_mon": [
[2017-07-07 20:45:59,330][gdb3][DEBUG ]       "kraken", 
[2017-07-07 20:45:59,330][gdb3][DEBUG ]       "luminous"
[2017-07-07 20:45:59,330][gdb3][DEBUG ]     ], 
[2017-07-07 20:45:59,330][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-07-07 20:45:59,330][gdb3][DEBUG ]     "required_mon": [
[2017-07-07 20:45:59,331][gdb3][DEBUG ]       "kraken", 
[2017-07-07 20:45:59,331][gdb3][DEBUG ]       "luminous"
[2017-07-07 20:45:59,331][gdb3][DEBUG ]     ]
[2017-07-07 20:45:59,331][gdb3][DEBUG ]   }, 
[2017-07-07 20:45:59,331][gdb3][DEBUG ]   "monmap": {
[2017-07-07 20:45:59,331][gdb3][DEBUG ]     "created": "2017-07-07 20:45:57.022475", 
[2017-07-07 20:45:59,331][gdb3][DEBUG ]     "epoch": 2, 
[2017-07-07 20:45:59,331][gdb3][DEBUG ]     "features": {
[2017-07-07 20:45:59,332][gdb3][DEBUG ]       "optional": [], 
[2017-07-07 20:45:59,332][gdb3][DEBUG ]       "persistent": [
[2017-07-07 20:45:59,332][gdb3][DEBUG ]         "kraken", 
[2017-07-07 20:45:59,332][gdb3][DEBUG ]         "luminous"
[2017-07-07 20:45:59,332][gdb3][DEBUG ]       ]
[2017-07-07 20:45:59,332][gdb3][DEBUG ]     }, 
[2017-07-07 20:45:59,332][gdb3][DEBUG ]     "fsid": "c730bc72-9c9e-4b40-9b40-2daa6f3f2a83", 
[2017-07-07 20:45:59,332][gdb3][DEBUG ]     "modified": "2017-07-07 20:45:57.280482", 
[2017-07-07 20:45:59,332][gdb3][DEBUG ]     "mons": [
[2017-07-07 20:45:59,332][gdb3][DEBUG ]       {
[2017-07-07 20:45:59,332][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-07-07 20:45:59,332][gdb3][DEBUG ]         "name": "gdb3", 
[2017-07-07 20:45:59,332][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-07-07 20:45:59,333][gdb3][DEBUG ]         "rank": 0
[2017-07-07 20:45:59,333][gdb3][DEBUG ]       }
[2017-07-07 20:45:59,333][gdb3][DEBUG ]     ]
[2017-07-07 20:45:59,333][gdb3][DEBUG ]   }, 
[2017-07-07 20:45:59,333][gdb3][DEBUG ]   "name": "gdb3", 
[2017-07-07 20:45:59,333][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-07-07 20:45:59,333][gdb3][DEBUG ]   "quorum": [
[2017-07-07 20:45:59,333][gdb3][DEBUG ]     0
[2017-07-07 20:45:59,333][gdb3][DEBUG ]   ], 
[2017-07-07 20:45:59,333][gdb3][DEBUG ]   "rank": 0, 
[2017-07-07 20:45:59,333][gdb3][DEBUG ]   "state": "leader", 
[2017-07-07 20:45:59,333][gdb3][DEBUG ]   "sync_provider": []
[2017-07-07 20:45:59,333][gdb3][DEBUG ] }
[2017-07-07 20:45:59,333][gdb3][DEBUG ] ********************************************************************************
[2017-07-07 20:45:59,333][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-07-07 20:45:59,334][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 20:45:59,399][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-07-07 20:45:59,418][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 20:45:59,432][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 20:45:59,433][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 20:45:59,449][gdb3][DEBUG ] detect machine type
[2017-07-07 20:45:59,452][gdb3][DEBUG ] find the location of an executable
[2017-07-07 20:45:59,453][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 20:45:59,518][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-07-07 20:45:59,519][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-07-07 20:45:59,519][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-07-07 20:45:59,520][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpHJd9Tu
[2017-07-07 20:45:59,536][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 20:45:59,550][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 20:45:59,550][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 20:45:59,567][gdb3][DEBUG ] detect machine type
[2017-07-07 20:45:59,569][gdb3][DEBUG ] get remote short hostname
[2017-07-07 20:45:59,569][gdb3][DEBUG ] fetch remote file
[2017-07-07 20:45:59,571][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 20:45:59,637][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-07-07 20:45:59,803][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-07-07 20:45:59,969][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-07-07 20:46:00,135][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-07-07 20:46:00,301][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-07-07 20:46:00,468][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-07-07 20:46:00,634][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-07-07 20:46:00,801][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-07-07 20:46:00,967][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-07-07 20:46:01,133][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-07-07 20:46:01,299][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-07-07 20:46:01,299][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-07-07 20:46:01,300][ceph_deploy.gatherkeys][INFO  ] Replacing 'ceph.bootstrap-mgr.keyring' and backing up old key as 'ceph.bootstrap-mgr.keyring-20170707204601'
[2017-07-07 20:46:01,300][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-07-07 20:46:01,300][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-07-07 20:46:01,300][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-07-07 20:46:01,300][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpHJd9Tu
[2017-07-07 20:46:01,492][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 20:46:01,492][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-07-07 20:46:01,492][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 20:46:01,492][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 20:46:01,492][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 20:46:01,492][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 20:46:01,492][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 20:46:01,492][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0305c545a8>
[2017-07-07 20:46:01,492][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 20:46:01,493][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-07-07 20:46:01,493][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f030656b938>
[2017-07-07 20:46:01,493][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 20:46:01,493][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 20:46:01,493][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-07-07 20:46:01,519][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 20:46:01,534][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 20:46:01,534][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 20:46:01,550][gdb3][DEBUG ] detect machine type
[2017-07-07 20:46:01,553][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 20:46:39,053][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 20:46:39,054][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb1
[2017-07-07 20:46:39,054][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 20:46:39,054][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 20:46:39,054][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 20:46:39,054][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-07 20:46:39,054][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 20:46:39,054][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0931ac45a8>
[2017-07-07 20:46:39,054][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 20:46:39,054][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-07-07 20:46:39,054][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f09323db938>
[2017-07-07 20:46:39,054][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 20:46:39,054][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 20:46:39,054][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-07-07 20:46:39,371][gdb1][DEBUG ] connection detected need for sudo
[2017-07-07 20:46:39,599][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-07 20:46:39,600][gdb1][DEBUG ] detect platform information from remote host
[2017-07-07 20:46:39,628][gdb1][DEBUG ] detect machine type
[2017-07-07 20:46:39,632][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 20:46:39,807][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 20:46:39,808][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-07-07 20:46:39,808][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 20:46:39,808][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 20:46:39,808][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-07 20:46:39,808][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-07 20:46:39,808][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-07 20:46:39,808][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 20:46:39,808][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-07 20:46:39,808][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-07 20:46:39,808][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 20:46:39,808][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-07 20:46:39,808][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-07 20:46:39,808][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 20:46:39,809][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f77fe4ad998>
[2017-07-07 20:46:39,809][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 20:46:39,809][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-07 20:46:39,809][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f77fe703aa0>
[2017-07-07 20:46:39,809][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 20:46:39,809][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 20:46:39,809][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-07 20:46:39,809][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-07-07 20:46:40,047][gdb1][DEBUG ] connection detected need for sudo
[2017-07-07 20:46:40,279][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-07 20:46:40,279][gdb1][DEBUG ] detect platform information from remote host
[2017-07-07 20:46:40,296][gdb1][DEBUG ] detect machine type
[2017-07-07 20:46:40,300][gdb1][DEBUG ] find the location of an executable
[2017-07-07 20:46:40,301][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 20:46:40,301][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-07-07 20:46:40,301][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 20:46:40,303][gdb1][WARNING] osd keyring does not exist yet, creating one
[2017-07-07 20:46:40,303][gdb1][DEBUG ] create a keyring file
[2017-07-07 20:46:40,305][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-07-07 20:46:40,305][gdb1][DEBUG ] find the location of an executable
[2017-07-07 20:46:40,307][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-07 20:46:40,628][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-07 20:46:40,743][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-07 20:46:40,750][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-07 20:46:40,766][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-07 20:46:40,773][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-07 20:46:40,789][gdb1][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-07-07 20:46:40,789][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.2343.tmp
[2017-07-07 20:46:40,791][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.2343.tmp
[2017-07-07 20:46:40,794][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.2343.tmp
[2017-07-07 20:46:45,815][gdb1][INFO  ] checking OSD status...
[2017-07-07 20:46:45,815][gdb1][DEBUG ] find the location of an executable
[2017-07-07 20:46:45,818][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-07 20:46:46,033][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-07-07 20:46:46,199][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 20:46:46,199][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-07-07 20:46:46,199][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 20:46:46,199][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 20:46:46,199][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 20:46:46,199][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 20:46:46,199][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-07 20:46:46,199][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 20:46:46,199][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f185d5de998>
[2017-07-07 20:46:46,200][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 20:46:46,200][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f185d834aa0>
[2017-07-07 20:46:46,200][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 20:46:46,200][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 20:46:46,200][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-07 20:46:46,200][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-07-07 20:46:46,440][gdb1][DEBUG ] connection detected need for sudo
[2017-07-07 20:46:46,667][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-07 20:46:46,668][gdb1][DEBUG ] detect platform information from remote host
[2017-07-07 20:46:46,684][gdb1][DEBUG ] detect machine type
[2017-07-07 20:46:46,688][gdb1][DEBUG ] find the location of an executable
[2017-07-07 20:46:46,689][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 20:46:46,689][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-07-07 20:46:46,689][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-07 20:46:46,689][gdb1][DEBUG ] find the location of an executable
[2017-07-07 20:46:46,692][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-07 20:46:46,862][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-07-07 20:46:46,862][gdb1][WARNING] activate: Cluster uuid is c730bc72-9c9e-4b40-9b40-2daa6f3f2a83
[2017-07-07 20:46:46,862][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-07 20:46:46,862][gdb1][WARNING] activate: Cluster name is ceph
[2017-07-07 20:46:46,863][gdb1][WARNING] activate: OSD uuid is da5d8a6f-1a06-4f24-8fd7-37f46f31a091
[2017-07-07 20:46:46,863][gdb1][WARNING] allocate_osd_id: Allocating OSD id...
[2017-07-07 20:46:46,863][gdb1][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise da5d8a6f-1a06-4f24-8fd7-37f46f31a091
[2017-07-07 20:46:47,027][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.2461.tmp
[2017-07-07 20:46:47,027][gdb1][WARNING] activate: OSD id is 0
[2017-07-07 20:46:47,027][gdb1][WARNING] activate: Initializing OSD...
[2017-07-07 20:46:47,027][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-07-07 20:46:47,141][gdb1][WARNING] got monmap epoch 2
[2017-07-07 20:46:47,142][gdb1][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 0 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid da5d8a6f-1a06-4f24-8fd7-37f46f31a091 --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-07-07 20:46:47,173][gdb1][WARNING] activate: Marking with init system systemd
[2017-07-07 20:46:47,174][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-07-07 20:46:47,174][gdb1][WARNING] activate: Authorizing OSD key...
[2017-07-07 20:46:47,174][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.0 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-07-07 20:46:47,338][gdb1][WARNING] added key for osd.0
[2017-07-07 20:46:47,338][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.2461.tmp
[2017-07-07 20:46:47,339][gdb1][WARNING] activate: ceph osd.0 data dir is ready at /mnt/memstore
[2017-07-07 20:46:47,339][gdb1][WARNING] activate_dir: Creating symlink /var/lib/ceph/osd/ceph-0 -> /mnt/memstore
[2017-07-07 20:46:47,339][gdb1][WARNING] start_daemon: Starting ceph osd.0...
[2017-07-07 20:46:47,339][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0
[2017-07-07 20:46:47,339][gdb1][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service.
[2017-07-07 20:46:47,403][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0 --runtime
[2017-07-07 20:46:47,435][gdb1][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@0
[2017-07-07 20:46:47,438][gdb1][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service to /lib/systemd/system/ceph-osd@.service.
[2017-07-07 20:46:47,502][gdb1][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@0
[2017-07-07 20:46:52,621][gdb1][INFO  ] checking OSD status...
[2017-07-07 20:46:52,622][gdb1][DEBUG ] find the location of an executable
[2017-07-07 20:46:52,625][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-07 20:46:52,792][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-07 20:47:05,676][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 20:47:05,677][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy rgw create gdb1
[2017-07-07 20:47:05,677][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 20:47:05,677][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 20:47:05,677][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 20:47:05,677][ceph_deploy.cli][INFO  ]  rgw                           : [('gdb1', 'rgw.gdb1')]
[2017-07-07 20:47:05,677][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 20:47:05,677][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-07 20:47:05,677][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 20:47:05,677][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f8402cc4830>
[2017-07-07 20:47:05,677][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 20:47:05,677][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7f8403385758>
[2017-07-07 20:47:05,677][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 20:47:05,677][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 20:47:05,678][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts gdb1:rgw.gdb1
[2017-07-07 20:47:05,924][gdb1][DEBUG ] connection detected need for sudo
[2017-07-07 20:47:06,155][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-07 20:47:06,156][gdb1][DEBUG ] detect platform information from remote host
[2017-07-07 20:47:06,172][gdb1][DEBUG ] detect machine type
[2017-07-07 20:47:06,176][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 20:47:06,176][ceph_deploy.rgw][DEBUG ] remote host will use systemd
[2017-07-07 20:47:06,176][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to gdb1
[2017-07-07 20:47:06,176][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 20:47:06,179][gdb1][WARNING] rgw keyring does not exist yet, creating one
[2017-07-07 20:47:06,179][gdb1][DEBUG ] create a keyring file
[2017-07-07 20:47:06,181][gdb1][DEBUG ] create path recursively if it doesn't exist
[2017-07-07 20:47:06,183][gdb1][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.gdb1 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.gdb1/keyring
[2017-07-07 20:47:06,354][gdb1][INFO  ] Running command: sudo systemctl enable ceph-radosgw@rgw.gdb1
[2017-07-07 20:47:06,424][gdb1][INFO  ] Running command: sudo systemctl start ceph-radosgw@rgw.gdb1
[2017-07-07 20:47:06,493][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-07 20:47:06,560][ceph_deploy.rgw][INFO  ] The Ceph Object Gateway (RGW) is now running on host gdb1 and default port 7480
[2017-07-07 21:19:48,656][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:19:48,657][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-07-07 21:19:48,657][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:19:48,658][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:19:48,658][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:19:48,658][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:19:48,658][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:19:48,658][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f25fff27128>
[2017-07-07 21:19:48,658][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:19:48,658][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-07 21:19:48,658][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f26008341b8>
[2017-07-07 21:19:48,658][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:19:48,658][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:19:48,658][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-07-07 21:19:48,658][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-07-07 21:19:48,658][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-07-07 21:19:48,658][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-07-07 21:19:48,695][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:19:48,708][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:19:48,710][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:19:48,725][gdb3][DEBUG ] detect machine type
[2017-07-07 21:19:48,728][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 21:19:48,728][gdb3][INFO  ] Purging Ceph on gdb3
[2017-07-07 21:19:48,729][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-07-07 21:19:49,001][gdb3][DEBUG ] Reading package lists...
[2017-07-07 21:19:49,165][gdb3][DEBUG ] Building dependency tree...
[2017-07-07 21:19:49,166][gdb3][DEBUG ] Reading state information...
[2017-07-07 21:19:49,230][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-07-07 21:19:49,230][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-07-07 21:19:49,230][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-07-07 21:19:49,230][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-07-07 21:19:49,230][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-07-07 21:19:49,230][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-07-07 21:19:49,230][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1016 linux-aws-headers-4.4.0-1017
[2017-07-07 21:19:49,230][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1018 linux-headers-4.4.0-1013-aws
[2017-07-07 21:19:49,230][gdb3][DEBUG ]   linux-headers-4.4.0-1016-aws linux-headers-4.4.0-1017-aws
[2017-07-07 21:19:49,230][gdb3][DEBUG ]   linux-headers-4.4.0-1018-aws linux-image-4.4.0-1013-aws
[2017-07-07 21:19:49,230][gdb3][DEBUG ]   linux-image-4.4.0-1016-aws linux-image-4.4.0-1017-aws
[2017-07-07 21:19:49,231][gdb3][DEBUG ]   linux-image-4.4.0-1018-aws ntp python-blinker python-cephfs
[2017-07-07 21:19:49,231][gdb3][DEBUG ]   python-cffi-backend python-chardet python-cryptography python-enum34
[2017-07-07 21:19:49,231][gdb3][DEBUG ]   python-flask python-idna python-ipaddress python-itsdangerous python-jinja2
[2017-07-07 21:19:49,231][gdb3][DEBUG ]   python-markupsafe python-ndg-httpsclient python-openssl python-pyasn1
[2017-07-07 21:19:49,231][gdb3][DEBUG ]   python-pyinotify python-rados python-rbd python-requests python-rgw
[2017-07-07 21:19:49,231][gdb3][DEBUG ]   python-six python-urllib3 python-werkzeug
[2017-07-07 21:19:49,231][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-07-07 21:19:49,263][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-07-07 21:19:49,263][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-07-07 21:19:49,577][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 61 not upgraded.
[2017-07-07 21:19:49,578][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-07-07 21:19:50,043][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 179644 files and directories currently installed.)
[2017-07-07 21:19:50,043][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-07-07 21:19:50,210][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-07-07 21:19:50,324][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-07-07 21:19:50,389][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-07-07 21:19:50,607][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-07-07 21:19:50,721][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-07-07 21:19:50,887][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-07-07 21:19:50,951][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-07-07 21:19:50,967][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-07-07 21:19:51,132][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-07-07 21:19:51,196][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-07-07 21:19:51,228][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-07-07 21:19:51,392][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-07-07 21:19:51,393][gdb3][DEBUG ] dpkg: warning: while removing ceph-base, directory '/var/lib/ceph/tmp' not empty so not removed
[2017-07-07 21:19:51,424][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-07-07 21:19:51,589][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-07-07 21:19:51,653][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-07-07 21:19:51,653][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-07-07 21:19:51,867][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu9) ...
[2017-07-07 21:19:52,984][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-07-07 21:19:53,151][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:19:53,151][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-07-07 21:19:53,151][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:19:53,151][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:19:53,151][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:19:53,152][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:19:53,152][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:19:53,152][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7c12e917a0>
[2017-07-07 21:19:53,152][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:19:53,152][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-07 21:19:53,152][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f7c1379e230>
[2017-07-07 21:19:53,152][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:19:53,152][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:19:53,152][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-07-07 21:19:53,178][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:19:53,192][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:19:53,192][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:19:53,209][gdb3][DEBUG ] detect machine type
[2017-07-07 21:19:53,211][gdb3][DEBUG ] find the location of an executable
[2017-07-07 21:19:53,227][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:19:53,240][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:19:53,241][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:19:53,258][gdb3][DEBUG ] detect machine type
[2017-07-07 21:19:53,260][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 21:19:53,260][gdb3][INFO  ] purging data on gdb3
[2017-07-07 21:19:53,261][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-07-07 21:19:53,274][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-07-07 21:19:53,443][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:19:53,444][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-07-07 21:19:53,444][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:19:53,444][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:19:53,444][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:19:53,444][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:19:53,444][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:19:53,444][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f414beb3a70>
[2017-07-07 21:19:53,444][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:19:53,444][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7f414c776848>
[2017-07-07 21:19:53,444][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:19:53,444][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:20:08,686][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:20:08,687][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-07-07 21:20:08,687][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:20:08,687][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:20:08,687][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:20:08,687][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:20:08,687][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:20:08,688][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f38bfbe45f0>
[2017-07-07 21:20:08,688][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:20:08,688][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-07-07 21:20:08,688][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-07-07 21:20:08,688][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f38c0268758>
[2017-07-07 21:20:08,688][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-07-07 21:20:08,688][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:20:08,688][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-07-07 21:20:08,688][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:20:08,689][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-07-07 21:20:08,689][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-07-07 21:20:08,689][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-07-07 21:20:08,714][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:20:08,730][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:20:08,730][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:20:08,747][gdb3][DEBUG ] detect machine type
[2017-07-07 21:20:08,749][gdb3][DEBUG ] find the location of an executable
[2017-07-07 21:20:08,751][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-07-07 21:20:08,762][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-07-07 21:20:08,768][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-07-07 21:20:08,768][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-07-07 21:20:08,769][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-07-07 21:20:08,769][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-07-07 21:20:08,769][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-07-07 21:20:08,769][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-07-07 21:20:08,769][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-07-07 21:20:08,769][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-07-07 21:20:08,934][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:20:08,934][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-07-07 21:20:08,934][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:20:08,934][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:20:08,934][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:20:08,934][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:20:08,935][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-07-07 21:20:08,935][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:20:08,935][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fbc80072ef0>
[2017-07-07 21:20:08,935][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:20:08,935][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7fbc80046b18>
[2017-07-07 21:20:08,935][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:20:08,935][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-07-07 21:20:08,935][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:20:08,936][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-07-07 21:20:08,936][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-07-07 21:20:08,962][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:20:08,976][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:20:08,977][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:20:08,993][gdb3][DEBUG ] detect machine type
[2017-07-07 21:20:08,995][gdb3][DEBUG ] find the location of an executable
[2017-07-07 21:20:08,996][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-07-07 21:20:08,996][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-07-07 21:20:08,996][gdb3][DEBUG ] get remote short hostname
[2017-07-07 21:20:08,996][gdb3][DEBUG ] deploying mon to gdb3
[2017-07-07 21:20:08,996][gdb3][DEBUG ] get remote short hostname
[2017-07-07 21:20:08,997][gdb3][DEBUG ] remote hostname: gdb3
[2017-07-07 21:20:08,997][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 21:20:08,999][gdb3][DEBUG ] create the mon path if it does not exist
[2017-07-07 21:20:08,999][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-07 21:20:08,999][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-07 21:20:09,000][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-07 21:20:09,000][gdb3][DEBUG ] create the monitor keyring file
[2017-07-07 21:20:09,001][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-07-07 21:20:09,039][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-07-07 21:20:09,040][gdb3][DEBUG ] ceph-mon: set fsid to e097e83f-df52-465b-98ce-0883285fcb6a
[2017-07-07 21:20:09,043][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-07-07 21:20:09,051][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-07 21:20:09,051][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-07-07 21:20:09,052][gdb3][DEBUG ] create the init path if it does not exist
[2017-07-07 21:20:09,053][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-07 21:20:09,121][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-07-07 21:20:09,189][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-07-07 21:20:11,259][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 21:20:11,324][gdb3][DEBUG ] ********************************************************************************
[2017-07-07 21:20:11,325][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-07-07 21:20:11,325][gdb3][DEBUG ] {
[2017-07-07 21:20:11,325][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-07-07 21:20:11,325][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-07-07 21:20:11,325][gdb3][DEBUG ]   "features": {
[2017-07-07 21:20:11,325][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-07-07 21:20:11,325][gdb3][DEBUG ]     "quorum_mon": [
[2017-07-07 21:20:11,326][gdb3][DEBUG ]       "kraken", 
[2017-07-07 21:20:11,326][gdb3][DEBUG ]       "luminous"
[2017-07-07 21:20:11,326][gdb3][DEBUG ]     ], 
[2017-07-07 21:20:11,326][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-07-07 21:20:11,326][gdb3][DEBUG ]     "required_mon": [
[2017-07-07 21:20:11,326][gdb3][DEBUG ]       "kraken", 
[2017-07-07 21:20:11,326][gdb3][DEBUG ]       "luminous"
[2017-07-07 21:20:11,326][gdb3][DEBUG ]     ]
[2017-07-07 21:20:11,326][gdb3][DEBUG ]   }, 
[2017-07-07 21:20:11,326][gdb3][DEBUG ]   "monmap": {
[2017-07-07 21:20:11,326][gdb3][DEBUG ]     "created": "2017-07-07 21:20:09.024868", 
[2017-07-07 21:20:11,327][gdb3][DEBUG ]     "epoch": 2, 
[2017-07-07 21:20:11,327][gdb3][DEBUG ]     "features": {
[2017-07-07 21:20:11,327][gdb3][DEBUG ]       "optional": [], 
[2017-07-07 21:20:11,327][gdb3][DEBUG ]       "persistent": [
[2017-07-07 21:20:11,327][gdb3][DEBUG ]         "kraken", 
[2017-07-07 21:20:11,327][gdb3][DEBUG ]         "luminous"
[2017-07-07 21:20:11,327][gdb3][DEBUG ]       ]
[2017-07-07 21:20:11,327][gdb3][DEBUG ]     }, 
[2017-07-07 21:20:11,327][gdb3][DEBUG ]     "fsid": "e097e83f-df52-465b-98ce-0883285fcb6a", 
[2017-07-07 21:20:11,328][gdb3][DEBUG ]     "modified": "2017-07-07 21:20:09.284453", 
[2017-07-07 21:20:11,328][gdb3][DEBUG ]     "mons": [
[2017-07-07 21:20:11,328][gdb3][DEBUG ]       {
[2017-07-07 21:20:11,328][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-07-07 21:20:11,328][gdb3][DEBUG ]         "name": "gdb3", 
[2017-07-07 21:20:11,328][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-07-07 21:20:11,328][gdb3][DEBUG ]         "rank": 0
[2017-07-07 21:20:11,328][gdb3][DEBUG ]       }
[2017-07-07 21:20:11,328][gdb3][DEBUG ]     ]
[2017-07-07 21:20:11,328][gdb3][DEBUG ]   }, 
[2017-07-07 21:20:11,328][gdb3][DEBUG ]   "name": "gdb3", 
[2017-07-07 21:20:11,328][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-07-07 21:20:11,328][gdb3][DEBUG ]   "quorum": [
[2017-07-07 21:20:11,328][gdb3][DEBUG ]     0
[2017-07-07 21:20:11,328][gdb3][DEBUG ]   ], 
[2017-07-07 21:20:11,328][gdb3][DEBUG ]   "rank": 0, 
[2017-07-07 21:20:11,329][gdb3][DEBUG ]   "state": "leader", 
[2017-07-07 21:20:11,329][gdb3][DEBUG ]   "sync_provider": []
[2017-07-07 21:20:11,329][gdb3][DEBUG ] }
[2017-07-07 21:20:11,329][gdb3][DEBUG ] ********************************************************************************
[2017-07-07 21:20:11,329][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-07-07 21:20:11,330][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 21:20:11,395][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-07-07 21:20:11,413][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:20:11,427][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:20:11,428][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:20:11,445][gdb3][DEBUG ] detect machine type
[2017-07-07 21:20:11,447][gdb3][DEBUG ] find the location of an executable
[2017-07-07 21:20:11,448][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 21:20:11,513][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-07-07 21:20:11,513][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-07-07 21:20:11,513][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-07-07 21:20:11,515][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpas15Z_
[2017-07-07 21:20:11,530][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:20:11,544][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:20:11,545][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:20:11,561][gdb3][DEBUG ] detect machine type
[2017-07-07 21:20:11,563][gdb3][DEBUG ] get remote short hostname
[2017-07-07 21:20:11,564][gdb3][DEBUG ] fetch remote file
[2017-07-07 21:20:11,565][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 21:20:11,631][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-07-07 21:20:11,797][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-07-07 21:20:11,963][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-07-07 21:20:12,129][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-07-07 21:20:12,346][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-07-07 21:20:12,512][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-07-07 21:20:12,678][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-07-07 21:20:12,844][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-07-07 21:20:13,010][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-07-07 21:20:13,176][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-07-07 21:20:13,342][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-07-07 21:20:13,342][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-07-07 21:20:13,343][ceph_deploy.gatherkeys][INFO  ] Replacing 'ceph.bootstrap-mgr.keyring' and backing up old key as 'ceph.bootstrap-mgr.keyring-20170707212013'
[2017-07-07 21:20:13,343][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-07-07 21:20:13,343][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-07-07 21:20:13,343][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-07-07 21:20:13,344][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpas15Z_
[2017-07-07 21:20:13,525][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:20:13,526][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-07-07 21:20:13,526][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:20:13,526][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:20:13,526][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:20:13,526][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:20:13,526][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:20:13,526][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6b603d85a8>
[2017-07-07 21:20:13,526][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:20:13,526][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-07-07 21:20:13,526][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f6b60cef938>
[2017-07-07 21:20:13,526][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:20:13,526][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:20:13,527][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-07-07 21:20:13,553][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:20:13,567][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:20:13,568][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:20:13,585][gdb3][DEBUG ] detect machine type
[2017-07-07 21:20:13,587][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 21:21:00,648][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:21:00,648][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-07-07 21:21:00,648][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:21:00,649][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:21:00,649][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:21:00,649][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:21:00,649][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:21:00,649][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f17f9a335f0>
[2017-07-07 21:21:00,649][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:21:00,649][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-07-07 21:21:00,649][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-07-07 21:21:00,649][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f17fa0b7758>
[2017-07-07 21:21:00,649][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-07-07 21:21:00,649][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:21:00,649][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-07-07 21:21:00,649][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:21:00,649][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-07-07 21:21:00,649][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-07-07 21:21:00,650][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-07-07 21:21:00,676][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:21:00,690][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:21:00,690][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:21:00,707][gdb3][DEBUG ] detect machine type
[2017-07-07 21:21:00,709][gdb3][DEBUG ] find the location of an executable
[2017-07-07 21:21:00,710][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-07-07 21:21:00,721][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-07-07 21:21:00,728][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-07-07 21:21:00,728][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-07-07 21:21:00,728][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-07-07 21:21:00,728][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-07-07 21:21:00,728][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-07-07 21:21:00,728][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-07-07 21:21:00,728][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-07-07 21:21:00,729][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-07-07 21:21:00,894][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:21:00,894][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-07-07 21:21:00,894][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:21:00,894][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:21:00,894][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:21:00,894][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:21:00,894][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-07-07 21:21:00,895][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:21:00,895][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f1b0a104ef0>
[2017-07-07 21:21:00,895][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:21:00,895][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f1b0a0d8b18>
[2017-07-07 21:21:00,895][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:21:00,895][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-07-07 21:21:00,895][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:21:00,896][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-07-07 21:21:00,896][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-07-07 21:21:00,922][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:21:00,936][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:21:00,936][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:21:00,953][gdb3][DEBUG ] detect machine type
[2017-07-07 21:21:00,955][gdb3][DEBUG ] find the location of an executable
[2017-07-07 21:21:00,956][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-07-07 21:21:00,956][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-07-07 21:21:00,956][gdb3][DEBUG ] get remote short hostname
[2017-07-07 21:21:00,956][gdb3][DEBUG ] deploying mon to gdb3
[2017-07-07 21:21:00,956][gdb3][DEBUG ] get remote short hostname
[2017-07-07 21:21:00,957][gdb3][DEBUG ] remote hostname: gdb3
[2017-07-07 21:21:00,957][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 21:21:00,961][ceph_deploy.mon][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite
[2017-07-07 21:21:00,961][ceph_deploy][ERROR ] GenericError: Failed to create 1 monitors

[2017-07-07 21:21:01,144][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:21:01,144][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-07-07 21:21:01,144][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:21:01,144][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:21:01,144][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:21:01,144][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:21:01,144][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:21:01,144][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f1cb4c8e5a8>
[2017-07-07 21:21:01,145][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:21:01,145][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-07-07 21:21:01,145][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f1cb55a5938>
[2017-07-07 21:21:01,145][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:21:01,145][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:21:01,145][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-07-07 21:21:01,172][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:21:01,186][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:21:01,187][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:21:01,204][gdb3][DEBUG ] detect machine type
[2017-07-07 21:21:01,207][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 21:21:01,208][ceph_deploy.admin][ERROR ] RuntimeError: config file /etc/ceph/ceph.conf exists with different content; use --overwrite-conf to overwrite
[2017-07-07 21:21:01,208][ceph_deploy][ERROR ] GenericError: Failed to configure 1 admin hosts

[2017-07-07 21:21:15,502][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:21:15,503][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-07-07 21:21:15,503][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:21:15,503][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:21:15,503][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:21:15,503][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:21:15,503][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:21:15,503][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fac91b70128>
[2017-07-07 21:21:15,503][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:21:15,503][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-07 21:21:15,504][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7fac9247d1b8>
[2017-07-07 21:21:15,504][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:21:15,504][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:21:15,504][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-07-07 21:21:15,504][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-07-07 21:21:15,504][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-07-07 21:21:15,504][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-07-07 21:21:15,531][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:21:15,545][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:21:15,546][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:21:15,562][gdb3][DEBUG ] detect machine type
[2017-07-07 21:21:15,564][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 21:21:15,564][gdb3][INFO  ] Purging Ceph on gdb3
[2017-07-07 21:21:15,565][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-07-07 21:21:15,603][gdb3][DEBUG ] Reading package lists...
[2017-07-07 21:21:15,768][gdb3][DEBUG ] Building dependency tree...
[2017-07-07 21:21:15,768][gdb3][DEBUG ] Reading state information...
[2017-07-07 21:21:15,832][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-07-07 21:21:15,832][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-07-07 21:21:15,832][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-07-07 21:21:15,833][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-07-07 21:21:15,833][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-07-07 21:21:15,833][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-07-07 21:21:15,833][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1016 linux-aws-headers-4.4.0-1017
[2017-07-07 21:21:15,833][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1018 linux-headers-4.4.0-1013-aws
[2017-07-07 21:21:15,833][gdb3][DEBUG ]   linux-headers-4.4.0-1016-aws linux-headers-4.4.0-1017-aws
[2017-07-07 21:21:15,833][gdb3][DEBUG ]   linux-headers-4.4.0-1018-aws linux-image-4.4.0-1013-aws
[2017-07-07 21:21:15,833][gdb3][DEBUG ]   linux-image-4.4.0-1016-aws linux-image-4.4.0-1017-aws
[2017-07-07 21:21:15,833][gdb3][DEBUG ]   linux-image-4.4.0-1018-aws ntp python-blinker python-cephfs
[2017-07-07 21:21:15,834][gdb3][DEBUG ]   python-cffi-backend python-chardet python-cryptography python-enum34
[2017-07-07 21:21:15,834][gdb3][DEBUG ]   python-flask python-idna python-ipaddress python-itsdangerous python-jinja2
[2017-07-07 21:21:15,834][gdb3][DEBUG ]   python-markupsafe python-ndg-httpsclient python-openssl python-pyasn1
[2017-07-07 21:21:15,834][gdb3][DEBUG ]   python-pyinotify python-rados python-rbd python-requests python-rgw
[2017-07-07 21:21:15,834][gdb3][DEBUG ]   python-six python-urllib3 python-werkzeug
[2017-07-07 21:21:15,834][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-07-07 21:21:15,898][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-07-07 21:21:15,898][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-07-07 21:21:16,013][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 61 not upgraded.
[2017-07-07 21:21:16,013][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-07-07 21:21:16,077][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 179644 files and directories currently installed.)
[2017-07-07 21:21:16,077][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-07-07 21:21:16,242][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-07-07 21:21:16,356][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-07-07 21:21:16,388][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-07-07 21:21:16,602][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-07-07 21:21:16,720][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-07-07 21:21:16,885][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-07-07 21:21:16,949][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-07-07 21:21:16,965][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-07-07 21:21:17,129][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-07-07 21:21:17,196][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-07-07 21:21:17,212][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-07-07 21:21:17,376][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-07-07 21:21:17,440][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-07-07 21:21:17,554][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-07-07 21:21:17,669][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-07-07 21:21:17,669][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-07-07 21:21:17,783][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu9) ...
[2017-07-07 21:21:18,599][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-07-07 21:21:18,765][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:21:18,765][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-07-07 21:21:18,765][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:21:18,765][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:21:18,766][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:21:18,766][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:21:18,766][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:21:18,766][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9b9ca427a0>
[2017-07-07 21:21:18,766][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:21:18,766][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-07 21:21:18,766][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f9b9d34f230>
[2017-07-07 21:21:18,766][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:21:18,766][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:21:18,766][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-07-07 21:21:18,793][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:21:18,806][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:21:18,807][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:21:18,824][gdb3][DEBUG ] detect machine type
[2017-07-07 21:21:18,826][gdb3][DEBUG ] find the location of an executable
[2017-07-07 21:21:18,842][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:21:18,855][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:21:18,855][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:21:18,872][gdb3][DEBUG ] detect machine type
[2017-07-07 21:21:18,874][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 21:21:18,875][gdb3][INFO  ] purging data on gdb3
[2017-07-07 21:21:18,875][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-07-07 21:21:18,888][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-07-07 21:21:19,058][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:21:19,058][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-07-07 21:21:19,058][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:21:19,058][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:21:19,058][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:21:19,058][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:21:19,058][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:21:19,058][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ffa8e480a70>
[2017-07-07 21:21:19,058][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:21:19,058][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7ffa8ed43848>
[2017-07-07 21:21:19,059][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:21:19,059][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:21:36,719][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:21:36,720][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-07-07 21:21:36,720][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:21:36,720][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:21:36,720][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:21:36,720][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:21:36,720][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:21:36,720][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f153cbbd5f0>
[2017-07-07 21:21:36,720][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:21:36,720][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-07-07 21:21:36,720][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-07-07 21:21:36,720][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f153d241758>
[2017-07-07 21:21:36,720][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-07-07 21:21:36,720][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:21:36,720][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-07-07 21:21:36,721][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:21:36,721][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-07-07 21:21:36,721][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-07-07 21:21:36,721][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-07-07 21:21:36,747][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:21:36,761][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:21:36,762][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:21:36,778][gdb3][DEBUG ] detect machine type
[2017-07-07 21:21:36,781][gdb3][DEBUG ] find the location of an executable
[2017-07-07 21:21:36,782][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-07-07 21:21:36,794][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-07-07 21:21:36,800][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-07-07 21:21:36,800][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-07-07 21:21:36,801][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-07-07 21:21:36,801][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-07-07 21:21:36,801][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-07-07 21:21:36,801][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-07-07 21:21:36,801][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-07-07 21:21:36,801][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-07-07 21:21:36,968][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:21:36,969][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-07-07 21:21:36,969][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:21:36,969][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:21:36,969][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:21:36,969][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:21:36,969][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-07-07 21:21:36,969][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:21:36,969][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fdb8cbdcef0>
[2017-07-07 21:21:36,969][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:21:36,969][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7fdb8cbb0b18>
[2017-07-07 21:21:36,969][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:21:36,969][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-07-07 21:21:36,969][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:21:36,970][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-07-07 21:21:36,970][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-07-07 21:21:36,996][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:21:37,010][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:21:37,011][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:21:37,027][gdb3][DEBUG ] detect machine type
[2017-07-07 21:21:37,029][gdb3][DEBUG ] find the location of an executable
[2017-07-07 21:21:37,030][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-07-07 21:21:37,030][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-07-07 21:21:37,030][gdb3][DEBUG ] get remote short hostname
[2017-07-07 21:21:37,030][gdb3][DEBUG ] deploying mon to gdb3
[2017-07-07 21:21:37,030][gdb3][DEBUG ] get remote short hostname
[2017-07-07 21:21:37,030][gdb3][DEBUG ] remote hostname: gdb3
[2017-07-07 21:21:37,031][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 21:21:37,032][gdb3][DEBUG ] create the mon path if it does not exist
[2017-07-07 21:21:37,033][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-07 21:21:37,033][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-07 21:21:37,033][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-07 21:21:37,033][gdb3][DEBUG ] create the monitor keyring file
[2017-07-07 21:21:37,035][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-07-07 21:21:37,073][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-07-07 21:21:37,073][gdb3][DEBUG ] ceph-mon: set fsid to 158d43cc-7472-4f5d-94a3-bcc50071c5d2
[2017-07-07 21:21:37,074][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-07-07 21:21:37,078][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-07 21:21:37,078][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-07-07 21:21:37,078][gdb3][DEBUG ] create the init path if it does not exist
[2017-07-07 21:21:37,080][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-07 21:21:37,147][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-07-07 21:21:37,215][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-07-07 21:21:39,253][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 21:21:39,319][gdb3][DEBUG ] ********************************************************************************
[2017-07-07 21:21:39,319][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-07-07 21:21:39,319][gdb3][DEBUG ] {
[2017-07-07 21:21:39,319][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-07-07 21:21:39,319][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-07-07 21:21:39,319][gdb3][DEBUG ]   "features": {
[2017-07-07 21:21:39,319][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-07-07 21:21:39,319][gdb3][DEBUG ]     "quorum_mon": [
[2017-07-07 21:21:39,320][gdb3][DEBUG ]       "kraken", 
[2017-07-07 21:21:39,320][gdb3][DEBUG ]       "luminous"
[2017-07-07 21:21:39,320][gdb3][DEBUG ]     ], 
[2017-07-07 21:21:39,320][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-07-07 21:21:39,320][gdb3][DEBUG ]     "required_mon": [
[2017-07-07 21:21:39,320][gdb3][DEBUG ]       "kraken", 
[2017-07-07 21:21:39,320][gdb3][DEBUG ]       "luminous"
[2017-07-07 21:21:39,320][gdb3][DEBUG ]     ]
[2017-07-07 21:21:39,320][gdb3][DEBUG ]   }, 
[2017-07-07 21:21:39,320][gdb3][DEBUG ]   "monmap": {
[2017-07-07 21:21:39,320][gdb3][DEBUG ]     "created": "2017-07-07 21:21:37.058085", 
[2017-07-07 21:21:39,320][gdb3][DEBUG ]     "epoch": 2, 
[2017-07-07 21:21:39,320][gdb3][DEBUG ]     "features": {
[2017-07-07 21:21:39,320][gdb3][DEBUG ]       "optional": [], 
[2017-07-07 21:21:39,320][gdb3][DEBUG ]       "persistent": [
[2017-07-07 21:21:39,320][gdb3][DEBUG ]         "kraken", 
[2017-07-07 21:21:39,321][gdb3][DEBUG ]         "luminous"
[2017-07-07 21:21:39,321][gdb3][DEBUG ]       ]
[2017-07-07 21:21:39,321][gdb3][DEBUG ]     }, 
[2017-07-07 21:21:39,321][gdb3][DEBUG ]     "fsid": "158d43cc-7472-4f5d-94a3-bcc50071c5d2", 
[2017-07-07 21:21:39,321][gdb3][DEBUG ]     "modified": "2017-07-07 21:21:37.296398", 
[2017-07-07 21:21:39,321][gdb3][DEBUG ]     "mons": [
[2017-07-07 21:21:39,321][gdb3][DEBUG ]       {
[2017-07-07 21:21:39,321][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-07-07 21:21:39,321][gdb3][DEBUG ]         "name": "gdb3", 
[2017-07-07 21:21:39,321][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-07-07 21:21:39,321][gdb3][DEBUG ]         "rank": 0
[2017-07-07 21:21:39,321][gdb3][DEBUG ]       }
[2017-07-07 21:21:39,321][gdb3][DEBUG ]     ]
[2017-07-07 21:21:39,321][gdb3][DEBUG ]   }, 
[2017-07-07 21:21:39,321][gdb3][DEBUG ]   "name": "gdb3", 
[2017-07-07 21:21:39,321][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-07-07 21:21:39,321][gdb3][DEBUG ]   "quorum": [
[2017-07-07 21:21:39,322][gdb3][DEBUG ]     0
[2017-07-07 21:21:39,322][gdb3][DEBUG ]   ], 
[2017-07-07 21:21:39,322][gdb3][DEBUG ]   "rank": 0, 
[2017-07-07 21:21:39,322][gdb3][DEBUG ]   "state": "leader", 
[2017-07-07 21:21:39,322][gdb3][DEBUG ]   "sync_provider": []
[2017-07-07 21:21:39,322][gdb3][DEBUG ] }
[2017-07-07 21:21:39,322][gdb3][DEBUG ] ********************************************************************************
[2017-07-07 21:21:39,322][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-07-07 21:21:39,323][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 21:21:39,388][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-07-07 21:21:39,403][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:21:39,418][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:21:39,418][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:21:39,435][gdb3][DEBUG ] detect machine type
[2017-07-07 21:21:39,437][gdb3][DEBUG ] find the location of an executable
[2017-07-07 21:21:39,438][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 21:21:39,503][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-07-07 21:21:39,504][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-07-07 21:21:39,504][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-07-07 21:21:39,505][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpYkh2_f
[2017-07-07 21:21:39,521][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:21:39,535][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:21:39,535][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:21:39,551][gdb3][DEBUG ] detect machine type
[2017-07-07 21:21:39,554][gdb3][DEBUG ] get remote short hostname
[2017-07-07 21:21:39,554][gdb3][DEBUG ] fetch remote file
[2017-07-07 21:21:39,555][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 21:21:39,621][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-07-07 21:21:39,787][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-07-07 21:21:39,954][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-07-07 21:21:40,120][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-07-07 21:21:40,286][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-07-07 21:21:40,452][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-07-07 21:21:40,619][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-07-07 21:21:40,785][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-07-07 21:21:40,951][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-07-07 21:21:41,117][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-07-07 21:21:41,283][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-07-07 21:21:41,283][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-07-07 21:21:41,283][ceph_deploy.gatherkeys][INFO  ] Replacing 'ceph.bootstrap-mgr.keyring' and backing up old key as 'ceph.bootstrap-mgr.keyring-20170707212141'
[2017-07-07 21:21:41,283][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-07-07 21:21:41,283][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-07-07 21:21:41,284][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-07-07 21:21:41,284][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpYkh2_f
[2017-07-07 21:21:41,463][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:21:41,463][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-07-07 21:21:41,463][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:21:41,464][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:21:41,464][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:21:41,464][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:21:41,464][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:21:41,464][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3e83c375a8>
[2017-07-07 21:21:41,464][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:21:41,464][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-07-07 21:21:41,464][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f3e8454e938>
[2017-07-07 21:21:41,464][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:21:41,464][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:21:41,464][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-07-07 21:21:41,490][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:21:41,504][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:21:41,505][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:21:41,521][gdb3][DEBUG ] detect machine type
[2017-07-07 21:21:41,523][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 21:21:44,543][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:21:44,544][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb2
[2017-07-07 21:21:44,544][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:21:44,544][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:21:44,544][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:21:44,544][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-07 21:21:44,544][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:21:44,544][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa64a61c5a8>
[2017-07-07 21:21:44,544][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:21:44,544][ceph_deploy.cli][INFO  ]  client                        : ['gdb2']
[2017-07-07 21:21:44,544][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fa64af33938>
[2017-07-07 21:21:44,544][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:21:44,544][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:21:44,544][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb2
[2017-07-07 21:21:45,284][ceph_deploy][ERROR ] KeyboardInterrupt

[2017-07-07 21:21:45,452][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:21:45,453][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb2:/mnt/memstore
[2017-07-07 21:21:45,453][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:21:45,453][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:21:45,453][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-07 21:21:45,453][ceph_deploy.cli][INFO  ]  disk                          : [('gdb2', '/mnt/memstore', None)]
[2017-07-07 21:21:45,453][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-07 21:21:45,453][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:21:45,454][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-07 21:21:45,454][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-07 21:21:45,454][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:21:45,454][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-07 21:21:45,454][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-07 21:21:45,454][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:21:45,454][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6544cc6998>
[2017-07-07 21:21:45,454][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:21:45,454][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-07 21:21:45,454][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f6544f1caa0>
[2017-07-07 21:21:45,455][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:21:45,455][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:21:45,455][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-07 21:21:45,455][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb2:/mnt/memstore:
[2017-07-07 21:21:46,912][ceph_deploy][ERROR ] KeyboardInterrupt

[2017-07-07 21:21:47,076][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:21:47,076][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb2:/mnt/memstore
[2017-07-07 21:21:47,077][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:21:47,077][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:21:47,077][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:21:47,077][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:21:47,077][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-07 21:21:47,077][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:21:47,077][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa4577bd998>
[2017-07-07 21:21:47,077][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:21:47,077][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fa457a13aa0>
[2017-07-07 21:21:47,077][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:21:47,077][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:21:47,077][ceph_deploy.cli][INFO  ]  disk                          : [('gdb2', '/mnt/memstore', None)]
[2017-07-07 21:21:47,078][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb2:/mnt/memstore:
[2017-07-07 21:21:47,569][ceph_deploy][ERROR ] RuntimeError: connecting to host: gdb2 resulted in errors: HostNotFound gdb2

[2017-07-07 21:21:54,346][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:21:54,346][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-07-07 21:21:54,346][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:21:54,346][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:21:54,346][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:21:54,347][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:21:54,347][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:21:54,347][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f85b0d09128>
[2017-07-07 21:21:54,347][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:21:54,347][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-07 21:21:54,347][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f85b16161b8>
[2017-07-07 21:21:54,347][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:21:54,347][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:21:54,347][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-07-07 21:21:54,347][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-07-07 21:21:54,347][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-07-07 21:21:54,347][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-07-07 21:21:54,373][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:21:54,388][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:21:54,388][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:21:54,405][gdb3][DEBUG ] detect machine type
[2017-07-07 21:21:54,407][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 21:21:54,407][gdb3][INFO  ] Purging Ceph on gdb3
[2017-07-07 21:21:54,408][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-07-07 21:21:54,446][gdb3][DEBUG ] Reading package lists...
[2017-07-07 21:21:54,610][gdb3][DEBUG ] Building dependency tree...
[2017-07-07 21:21:54,611][gdb3][DEBUG ] Reading state information...
[2017-07-07 21:21:54,675][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-07-07 21:21:54,675][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-07-07 21:21:54,675][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-07-07 21:21:54,675][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-07-07 21:21:54,675][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-07-07 21:21:54,676][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-07-07 21:21:54,676][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1016 linux-aws-headers-4.4.0-1017
[2017-07-07 21:21:54,676][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1018 linux-headers-4.4.0-1013-aws
[2017-07-07 21:21:54,676][gdb3][DEBUG ]   linux-headers-4.4.0-1016-aws linux-headers-4.4.0-1017-aws
[2017-07-07 21:21:54,676][gdb3][DEBUG ]   linux-headers-4.4.0-1018-aws linux-image-4.4.0-1013-aws
[2017-07-07 21:21:54,676][gdb3][DEBUG ]   linux-image-4.4.0-1016-aws linux-image-4.4.0-1017-aws
[2017-07-07 21:21:54,676][gdb3][DEBUG ]   linux-image-4.4.0-1018-aws ntp python-blinker python-cephfs
[2017-07-07 21:21:54,676][gdb3][DEBUG ]   python-cffi-backend python-chardet python-cryptography python-enum34
[2017-07-07 21:21:54,676][gdb3][DEBUG ]   python-flask python-idna python-ipaddress python-itsdangerous python-jinja2
[2017-07-07 21:21:54,677][gdb3][DEBUG ]   python-markupsafe python-ndg-httpsclient python-openssl python-pyasn1
[2017-07-07 21:21:54,677][gdb3][DEBUG ]   python-pyinotify python-rados python-rbd python-requests python-rgw
[2017-07-07 21:21:54,677][gdb3][DEBUG ]   python-six python-urllib3 python-werkzeug
[2017-07-07 21:21:54,677][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-07-07 21:21:54,741][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-07-07 21:21:54,741][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-07-07 21:21:54,855][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 61 not upgraded.
[2017-07-07 21:21:54,855][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-07-07 21:21:54,919][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 179644 files and directories currently installed.)
[2017-07-07 21:21:54,920][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-07-07 21:21:55,086][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-07-07 21:21:55,200][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-07-07 21:21:55,216][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-07-07 21:21:55,430][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-07-07 21:21:55,545][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-07-07 21:21:55,711][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-07-07 21:21:55,775][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-07-07 21:21:55,791][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-07-07 21:21:55,956][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-07-07 21:21:56,020][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-07-07 21:21:56,052][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-07-07 21:21:56,216][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-07-07 21:21:56,280][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-07-07 21:21:56,394][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-07-07 21:21:56,508][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-07-07 21:21:56,509][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-07-07 21:21:56,623][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu9) ...
[2017-07-07 21:21:57,489][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-07-07 21:21:57,653][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:21:57,653][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-07-07 21:21:57,653][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:21:57,654][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:21:57,654][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:21:57,654][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:21:57,654][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:21:57,654][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f4e1c2747a0>
[2017-07-07 21:21:57,654][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:21:57,654][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-07 21:21:57,654][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f4e1cb81230>
[2017-07-07 21:21:57,654][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:21:57,654][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:21:57,654][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-07-07 21:21:57,680][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:21:57,694][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:21:57,695][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:21:57,711][gdb3][DEBUG ] detect machine type
[2017-07-07 21:21:57,714][gdb3][DEBUG ] find the location of an executable
[2017-07-07 21:21:57,729][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:21:57,743][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:21:57,743][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:21:57,759][gdb3][DEBUG ] detect machine type
[2017-07-07 21:21:57,762][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 21:21:57,762][gdb3][INFO  ] purging data on gdb3
[2017-07-07 21:21:57,763][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-07-07 21:21:57,776][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-07-07 21:21:57,946][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:21:57,947][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-07-07 21:21:57,947][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:21:57,947][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:21:57,947][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:21:57,947][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:21:57,947][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:21:57,947][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f98604e9a70>
[2017-07-07 21:21:57,947][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:21:57,947][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7f9860dac848>
[2017-07-07 21:21:57,947][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:21:57,948][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:22:10,603][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:22:10,603][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-07-07 21:22:10,603][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:22:10,603][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:22:10,603][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:22:10,603][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:22:10,603][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:22:10,603][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f739fdc45f0>
[2017-07-07 21:22:10,603][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:22:10,604][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-07-07 21:22:10,604][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-07-07 21:22:10,604][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f73a0448758>
[2017-07-07 21:22:10,604][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-07-07 21:22:10,604][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:22:10,604][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-07-07 21:22:10,604][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:22:10,604][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-07-07 21:22:10,604][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-07-07 21:22:10,604][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-07-07 21:22:10,630][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:22:10,644][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:22:10,645][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:22:10,661][gdb3][DEBUG ] detect machine type
[2017-07-07 21:22:10,664][gdb3][DEBUG ] find the location of an executable
[2017-07-07 21:22:10,665][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-07-07 21:22:10,676][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-07-07 21:22:10,682][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-07-07 21:22:10,682][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-07-07 21:22:10,683][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-07-07 21:22:10,683][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-07-07 21:22:10,683][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-07-07 21:22:10,683][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-07-07 21:22:10,683][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-07-07 21:22:10,683][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-07-07 21:22:10,847][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:22:10,847][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-07-07 21:22:10,847][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:22:10,847][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:22:10,847][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:22:10,847][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:22:10,848][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-07-07 21:22:10,848][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:22:10,848][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f8ae280fef0>
[2017-07-07 21:22:10,848][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:22:10,848][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f8ae27e3b18>
[2017-07-07 21:22:10,848][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:22:10,848][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-07-07 21:22:10,848][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:22:10,849][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-07-07 21:22:10,849][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-07-07 21:22:10,875][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:22:10,888][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:22:10,889][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:22:10,905][gdb3][DEBUG ] detect machine type
[2017-07-07 21:22:10,907][gdb3][DEBUG ] find the location of an executable
[2017-07-07 21:22:10,908][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-07-07 21:22:10,908][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-07-07 21:22:10,908][gdb3][DEBUG ] get remote short hostname
[2017-07-07 21:22:10,908][gdb3][DEBUG ] deploying mon to gdb3
[2017-07-07 21:22:10,908][gdb3][DEBUG ] get remote short hostname
[2017-07-07 21:22:10,909][gdb3][DEBUG ] remote hostname: gdb3
[2017-07-07 21:22:10,909][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 21:22:10,911][gdb3][DEBUG ] create the mon path if it does not exist
[2017-07-07 21:22:10,911][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-07 21:22:10,911][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-07 21:22:10,912][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-07 21:22:10,912][gdb3][DEBUG ] create the monitor keyring file
[2017-07-07 21:22:10,913][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-07-07 21:22:10,951][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-07-07 21:22:10,951][gdb3][DEBUG ] ceph-mon: set fsid to bc1f2dc1-bfd2-446e-8c60-11bdbaffa38a
[2017-07-07 21:22:10,953][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-07-07 21:22:10,956][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-07 21:22:10,957][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-07-07 21:22:10,957][gdb3][DEBUG ] create the init path if it does not exist
[2017-07-07 21:22:10,958][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-07 21:22:11,026][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-07-07 21:22:11,094][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-07-07 21:22:13,131][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 21:22:13,196][gdb3][DEBUG ] ********************************************************************************
[2017-07-07 21:22:13,197][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-07-07 21:22:13,197][gdb3][DEBUG ] {
[2017-07-07 21:22:13,197][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-07-07 21:22:13,197][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-07-07 21:22:13,197][gdb3][DEBUG ]   "features": {
[2017-07-07 21:22:13,197][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-07-07 21:22:13,197][gdb3][DEBUG ]     "quorum_mon": [
[2017-07-07 21:22:13,197][gdb3][DEBUG ]       "kraken", 
[2017-07-07 21:22:13,197][gdb3][DEBUG ]       "luminous"
[2017-07-07 21:22:13,197][gdb3][DEBUG ]     ], 
[2017-07-07 21:22:13,198][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-07-07 21:22:13,198][gdb3][DEBUG ]     "required_mon": [
[2017-07-07 21:22:13,198][gdb3][DEBUG ]       "kraken", 
[2017-07-07 21:22:13,198][gdb3][DEBUG ]       "luminous"
[2017-07-07 21:22:13,198][gdb3][DEBUG ]     ]
[2017-07-07 21:22:13,198][gdb3][DEBUG ]   }, 
[2017-07-07 21:22:13,198][gdb3][DEBUG ]   "monmap": {
[2017-07-07 21:22:13,198][gdb3][DEBUG ]     "created": "2017-07-07 21:22:10.936915", 
[2017-07-07 21:22:13,198][gdb3][DEBUG ]     "epoch": 2, 
[2017-07-07 21:22:13,198][gdb3][DEBUG ]     "features": {
[2017-07-07 21:22:13,198][gdb3][DEBUG ]       "optional": [], 
[2017-07-07 21:22:13,198][gdb3][DEBUG ]       "persistent": [
[2017-07-07 21:22:13,198][gdb3][DEBUG ]         "kraken", 
[2017-07-07 21:22:13,198][gdb3][DEBUG ]         "luminous"
[2017-07-07 21:22:13,198][gdb3][DEBUG ]       ]
[2017-07-07 21:22:13,198][gdb3][DEBUG ]     }, 
[2017-07-07 21:22:13,198][gdb3][DEBUG ]     "fsid": "bc1f2dc1-bfd2-446e-8c60-11bdbaffa38a", 
[2017-07-07 21:22:13,198][gdb3][DEBUG ]     "modified": "2017-07-07 21:22:11.170668", 
[2017-07-07 21:22:13,199][gdb3][DEBUG ]     "mons": [
[2017-07-07 21:22:13,199][gdb3][DEBUG ]       {
[2017-07-07 21:22:13,199][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-07-07 21:22:13,199][gdb3][DEBUG ]         "name": "gdb3", 
[2017-07-07 21:22:13,199][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-07-07 21:22:13,199][gdb3][DEBUG ]         "rank": 0
[2017-07-07 21:22:13,199][gdb3][DEBUG ]       }
[2017-07-07 21:22:13,199][gdb3][DEBUG ]     ]
[2017-07-07 21:22:13,199][gdb3][DEBUG ]   }, 
[2017-07-07 21:22:13,199][gdb3][DEBUG ]   "name": "gdb3", 
[2017-07-07 21:22:13,199][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-07-07 21:22:13,199][gdb3][DEBUG ]   "quorum": [
[2017-07-07 21:22:13,199][gdb3][DEBUG ]     0
[2017-07-07 21:22:13,199][gdb3][DEBUG ]   ], 
[2017-07-07 21:22:13,199][gdb3][DEBUG ]   "rank": 0, 
[2017-07-07 21:22:13,199][gdb3][DEBUG ]   "state": "leader", 
[2017-07-07 21:22:13,199][gdb3][DEBUG ]   "sync_provider": []
[2017-07-07 21:22:13,200][gdb3][DEBUG ] }
[2017-07-07 21:22:13,200][gdb3][DEBUG ] ********************************************************************************
[2017-07-07 21:22:13,200][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-07-07 21:22:13,201][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 21:22:13,266][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-07-07 21:22:13,281][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:22:13,296][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:22:13,296][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:22:13,313][gdb3][DEBUG ] detect machine type
[2017-07-07 21:22:13,315][gdb3][DEBUG ] find the location of an executable
[2017-07-07 21:22:13,317][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 21:22:13,382][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-07-07 21:22:13,382][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-07-07 21:22:13,382][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-07-07 21:22:13,384][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpdjE5ZS
[2017-07-07 21:22:13,399][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:22:13,413][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:22:13,413][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:22:13,429][gdb3][DEBUG ] detect machine type
[2017-07-07 21:22:13,432][gdb3][DEBUG ] get remote short hostname
[2017-07-07 21:22:13,432][gdb3][DEBUG ] fetch remote file
[2017-07-07 21:22:13,433][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 21:22:13,499][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-07-07 21:22:13,665][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-07-07 21:22:13,832][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-07-07 21:22:13,998][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-07-07 21:22:14,164][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-07-07 21:22:14,330][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-07-07 21:22:14,496][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-07-07 21:22:14,663][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-07-07 21:22:14,829][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-07-07 21:22:14,995][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-07-07 21:22:15,160][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-07-07 21:22:15,161][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-07-07 21:22:15,161][ceph_deploy.gatherkeys][INFO  ] Replacing 'ceph.bootstrap-mgr.keyring' and backing up old key as 'ceph.bootstrap-mgr.keyring-20170707212215'
[2017-07-07 21:22:15,161][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-07-07 21:22:15,161][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-07-07 21:22:15,161][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-07-07 21:22:15,161][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpdjE5ZS
[2017-07-07 21:22:15,341][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:22:15,341][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-07-07 21:22:15,341][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:22:15,341][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:22:15,342][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:22:15,342][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:22:15,342][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:22:15,342][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f46189505a8>
[2017-07-07 21:22:15,342][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:22:15,342][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-07-07 21:22:15,342][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f4619267938>
[2017-07-07 21:22:15,342][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:22:15,342][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:22:15,342][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-07-07 21:22:15,368][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:22:15,383][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:22:15,383][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:22:15,400][gdb3][DEBUG ] detect machine type
[2017-07-07 21:22:15,402][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 21:22:20,422][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:22:20,422][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb1
[2017-07-07 21:22:20,422][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:22:20,422][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:22:20,422][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:22:20,422][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-07 21:22:20,423][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:22:20,423][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f391239f5a8>
[2017-07-07 21:22:20,423][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:22:20,423][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-07-07 21:22:20,423][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f3912cb6938>
[2017-07-07 21:22:20,423][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:22:20,423][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:22:20,423][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-07-07 21:22:20,863][gdb1][DEBUG ] connection detected need for sudo
[2017-07-07 21:22:21,113][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-07 21:22:21,114][gdb1][DEBUG ] detect platform information from remote host
[2017-07-07 21:22:21,139][gdb1][DEBUG ] detect machine type
[2017-07-07 21:22:21,142][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 21:22:21,328][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:22:21,328][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-07-07 21:22:21,328][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:22:21,328][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:22:21,328][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-07 21:22:21,328][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-07 21:22:21,328][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-07 21:22:21,329][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:22:21,329][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-07 21:22:21,329][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-07 21:22:21,329][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:22:21,329][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-07 21:22:21,329][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-07 21:22:21,329][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:22:21,329][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f8fcdb25998>
[2017-07-07 21:22:21,329][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:22:21,329][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-07 21:22:21,329][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f8fcdd7baa0>
[2017-07-07 21:22:21,329][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:22:21,329][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:22:21,329][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-07 21:22:21,330][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-07-07 21:22:21,572][gdb1][DEBUG ] connection detected need for sudo
[2017-07-07 21:22:21,799][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-07 21:22:21,800][gdb1][DEBUG ] detect platform information from remote host
[2017-07-07 21:22:21,817][gdb1][DEBUG ] detect machine type
[2017-07-07 21:22:21,820][gdb1][DEBUG ] find the location of an executable
[2017-07-07 21:22:21,821][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 21:22:21,821][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-07-07 21:22:21,821][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 21:22:21,824][gdb1][WARNING] osd keyring does not exist yet, creating one
[2017-07-07 21:22:21,824][gdb1][DEBUG ] create a keyring file
[2017-07-07 21:22:21,827][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-07-07 21:22:21,827][gdb1][DEBUG ] find the location of an executable
[2017-07-07 21:22:21,829][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-07 21:22:22,200][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-07 21:22:22,200][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-07 21:22:22,204][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-07 21:22:22,219][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-07 21:22:22,235][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-07 21:22:22,242][gdb1][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-07-07 21:22:22,244][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.2506.tmp
[2017-07-07 21:22:22,247][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.2506.tmp
[2017-07-07 21:22:22,250][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.2506.tmp
[2017-07-07 21:22:27,271][gdb1][INFO  ] checking OSD status...
[2017-07-07 21:22:27,272][gdb1][DEBUG ] find the location of an executable
[2017-07-07 21:22:27,274][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-07 21:22:27,490][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-07-07 21:22:27,655][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:22:27,655][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-07-07 21:22:27,655][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:22:27,655][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:22:27,655][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:22:27,655][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:22:27,656][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-07 21:22:27,656][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:22:27,656][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f91a7f67998>
[2017-07-07 21:22:27,656][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:22:27,656][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f91a81bdaa0>
[2017-07-07 21:22:27,656][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:22:27,656][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:22:27,656][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-07 21:22:27,656][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-07-07 21:22:27,900][gdb1][DEBUG ] connection detected need for sudo
[2017-07-07 21:22:28,091][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-07 21:22:28,092][gdb1][DEBUG ] detect platform information from remote host
[2017-07-07 21:22:28,108][gdb1][DEBUG ] detect machine type
[2017-07-07 21:22:28,112][gdb1][DEBUG ] find the location of an executable
[2017-07-07 21:22:28,112][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 21:22:28,113][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-07-07 21:22:28,113][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-07 21:22:28,113][gdb1][DEBUG ] find the location of an executable
[2017-07-07 21:22:28,115][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-07 21:22:28,285][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-07-07 21:22:28,286][gdb1][WARNING] activate: Cluster uuid is bc1f2dc1-bfd2-446e-8c60-11bdbaffa38a
[2017-07-07 21:22:28,286][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-07 21:22:28,286][gdb1][WARNING] activate: Cluster name is ceph
[2017-07-07 21:22:28,286][gdb1][WARNING] activate: OSD uuid is 65b3ae59-9404-4d63-abd4-dae542f9d0d2
[2017-07-07 21:22:28,286][gdb1][WARNING] allocate_osd_id: Allocating OSD id...
[2017-07-07 21:22:28,286][gdb1][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 65b3ae59-9404-4d63-abd4-dae542f9d0d2
[2017-07-07 21:22:28,450][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.2623.tmp
[2017-07-07 21:22:28,450][gdb1][WARNING] activate: OSD id is 0
[2017-07-07 21:22:28,450][gdb1][WARNING] activate: Initializing OSD...
[2017-07-07 21:22:28,451][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-07-07 21:22:28,615][gdb1][WARNING] got monmap epoch 2
[2017-07-07 21:22:28,615][gdb1][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 0 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid 65b3ae59-9404-4d63-abd4-dae542f9d0d2 --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-07-07 21:22:28,631][gdb1][WARNING] activate: Marking with init system systemd
[2017-07-07 21:22:28,631][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-07-07 21:22:28,631][gdb1][WARNING] activate: Authorizing OSD key...
[2017-07-07 21:22:28,631][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.0 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-07-07 21:22:28,795][gdb1][WARNING] added key for osd.0
[2017-07-07 21:22:28,795][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.2623.tmp
[2017-07-07 21:22:28,795][gdb1][WARNING] activate: ceph osd.0 data dir is ready at /mnt/memstore
[2017-07-07 21:22:28,795][gdb1][WARNING] activate_dir: Creating symlink /var/lib/ceph/osd/ceph-0 -> /mnt/memstore
[2017-07-07 21:22:28,796][gdb1][WARNING] start_daemon: Starting ceph osd.0...
[2017-07-07 21:22:28,796][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0
[2017-07-07 21:22:28,797][gdb1][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service.
[2017-07-07 21:22:28,961][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0 --runtime
[2017-07-07 21:22:29,025][gdb1][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@0
[2017-07-07 21:22:29,028][gdb1][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service to /lib/systemd/system/ceph-osd@.service.
[2017-07-07 21:22:29,092][gdb1][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@0
[2017-07-07 21:22:34,212][gdb1][INFO  ] checking OSD status...
[2017-07-07 21:22:34,212][gdb1][DEBUG ] find the location of an executable
[2017-07-07 21:22:34,215][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-07 21:22:34,382][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-07 21:22:43,285][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:22:43,286][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy rgw create gdb1
[2017-07-07 21:22:43,286][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:22:43,286][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:22:43,286][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:22:43,286][ceph_deploy.cli][INFO  ]  rgw                           : [('gdb1', 'rgw.gdb1')]
[2017-07-07 21:22:43,286][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:22:43,286][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-07 21:22:43,286][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:22:43,286][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9fafc3d830>
[2017-07-07 21:22:43,286][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:22:43,286][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7f9fb02fe758>
[2017-07-07 21:22:43,286][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:22:43,286][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:22:43,287][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts gdb1:rgw.gdb1
[2017-07-07 21:22:43,528][gdb1][DEBUG ] connection detected need for sudo
[2017-07-07 21:22:43,719][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-07 21:22:43,720][gdb1][DEBUG ] detect platform information from remote host
[2017-07-07 21:22:43,736][gdb1][DEBUG ] detect machine type
[2017-07-07 21:22:43,740][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 21:22:43,740][ceph_deploy.rgw][DEBUG ] remote host will use systemd
[2017-07-07 21:22:43,740][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to gdb1
[2017-07-07 21:22:43,740][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 21:22:43,743][gdb1][WARNING] rgw keyring does not exist yet, creating one
[2017-07-07 21:22:43,743][gdb1][DEBUG ] create a keyring file
[2017-07-07 21:22:43,744][gdb1][DEBUG ] create path recursively if it doesn't exist
[2017-07-07 21:22:43,747][gdb1][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.gdb1 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.gdb1/keyring
[2017-07-07 21:22:43,917][gdb1][INFO  ] Running command: sudo systemctl enable ceph-radosgw@rgw.gdb1
[2017-07-07 21:22:43,987][gdb1][INFO  ] Running command: sudo systemctl start ceph-radosgw@rgw.gdb1
[2017-07-07 21:22:44,055][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-07 21:22:44,173][ceph_deploy.rgw][INFO  ] The Ceph Object Gateway (RGW) is now running on host gdb1 and default port 7480
[2017-07-07 21:27:01,062][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:27:01,062][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-07-07 21:27:01,062][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:27:01,062][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:27:01,062][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:27:01,062][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:27:01,062][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:27:01,062][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fdc177dd128>
[2017-07-07 21:27:01,062][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:27:01,062][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-07 21:27:01,063][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7fdc180ea1b8>
[2017-07-07 21:27:01,063][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:27:01,063][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:27:01,063][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-07-07 21:27:01,063][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-07-07 21:27:01,063][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-07-07 21:27:01,063][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-07-07 21:27:01,090][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:27:01,104][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:27:01,105][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:27:01,121][gdb3][DEBUG ] detect machine type
[2017-07-07 21:27:01,124][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 21:27:01,124][gdb3][INFO  ] Purging Ceph on gdb3
[2017-07-07 21:27:01,125][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-07-07 21:27:01,164][gdb3][DEBUG ] Reading package lists...
[2017-07-07 21:27:01,328][gdb3][DEBUG ] Building dependency tree...
[2017-07-07 21:27:01,328][gdb3][DEBUG ] Reading state information...
[2017-07-07 21:27:01,443][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-07-07 21:27:01,443][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-07-07 21:27:01,443][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-07-07 21:27:01,443][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-07-07 21:27:01,444][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-07-07 21:27:01,444][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-07-07 21:27:01,444][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1016 linux-aws-headers-4.4.0-1017
[2017-07-07 21:27:01,444][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1018 linux-headers-4.4.0-1013-aws
[2017-07-07 21:27:01,444][gdb3][DEBUG ]   linux-headers-4.4.0-1016-aws linux-headers-4.4.0-1017-aws
[2017-07-07 21:27:01,444][gdb3][DEBUG ]   linux-headers-4.4.0-1018-aws linux-image-4.4.0-1013-aws
[2017-07-07 21:27:01,444][gdb3][DEBUG ]   linux-image-4.4.0-1016-aws linux-image-4.4.0-1017-aws
[2017-07-07 21:27:01,445][gdb3][DEBUG ]   linux-image-4.4.0-1018-aws ntp python-blinker python-cephfs
[2017-07-07 21:27:01,445][gdb3][DEBUG ]   python-cffi-backend python-chardet python-cryptography python-enum34
[2017-07-07 21:27:01,445][gdb3][DEBUG ]   python-flask python-idna python-ipaddress python-itsdangerous python-jinja2
[2017-07-07 21:27:01,445][gdb3][DEBUG ]   python-markupsafe python-ndg-httpsclient python-openssl python-pyasn1
[2017-07-07 21:27:01,445][gdb3][DEBUG ]   python-pyinotify python-rados python-rbd python-requests python-rgw
[2017-07-07 21:27:01,445][gdb3][DEBUG ]   python-six python-urllib3 python-werkzeug
[2017-07-07 21:27:01,445][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-07-07 21:27:01,445][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-07-07 21:27:01,445][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-07-07 21:27:01,610][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 61 not upgraded.
[2017-07-07 21:27:01,610][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-07-07 21:27:01,642][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 179644 files and directories currently installed.)
[2017-07-07 21:27:01,643][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-07-07 21:27:01,861][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-07-07 21:27:01,975][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-07-07 21:27:01,991][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-07-07 21:27:02,255][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-07-07 21:27:02,369][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-07-07 21:27:02,535][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-07-07 21:27:02,567][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-07-07 21:27:02,599][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-07-07 21:27:02,763][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-07-07 21:27:02,827][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-07-07 21:27:02,859][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-07-07 21:27:03,024][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-07-07 21:27:03,055][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-07-07 21:27:03,220][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-07-07 21:27:03,284][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-07-07 21:27:03,284][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-07-07 21:27:03,398][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu9) ...
[2017-07-07 21:27:04,214][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-07-07 21:27:04,381][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:27:04,381][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-07-07 21:27:04,381][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:27:04,381][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:27:04,381][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:27:04,381][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:27:04,381][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:27:04,381][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fdbeeaff7a0>
[2017-07-07 21:27:04,381][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:27:04,381][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-07 21:27:04,382][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7fdbef40c230>
[2017-07-07 21:27:04,382][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:27:04,382][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:27:04,382][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-07-07 21:27:04,408][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:27:04,422][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:27:04,422][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:27:04,439][gdb3][DEBUG ] detect machine type
[2017-07-07 21:27:04,442][gdb3][DEBUG ] find the location of an executable
[2017-07-07 21:27:04,457][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:27:04,471][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:27:04,472][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:27:04,488][gdb3][DEBUG ] detect machine type
[2017-07-07 21:27:04,490][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 21:27:04,491][gdb3][INFO  ] purging data on gdb3
[2017-07-07 21:27:04,492][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-07-07 21:27:04,505][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-07-07 21:27:04,676][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:27:04,676][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-07-07 21:27:04,677][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:27:04,677][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:27:04,677][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:27:04,677][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:27:04,677][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:27:04,677][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fdf21e44a70>
[2017-07-07 21:27:04,677][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:27:04,677][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7fdf22707848>
[2017-07-07 21:27:04,677][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:27:04,677][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:27:33,556][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:27:33,556][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-07-07 21:27:33,556][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:27:33,556][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:27:33,556][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:27:33,556][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:27:33,556][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:27:33,556][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7efcd454f5f0>
[2017-07-07 21:27:33,557][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:27:33,557][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-07-07 21:27:33,557][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-07-07 21:27:33,557][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7efcd4bd3758>
[2017-07-07 21:27:33,557][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-07-07 21:27:33,557][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:27:33,557][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-07-07 21:27:33,557][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:27:33,557][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-07-07 21:27:33,557][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-07-07 21:27:33,557][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-07-07 21:27:33,583][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:27:33,597][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:27:33,598][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:27:33,614][gdb3][DEBUG ] detect machine type
[2017-07-07 21:27:33,616][gdb3][DEBUG ] find the location of an executable
[2017-07-07 21:27:33,617][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-07-07 21:27:33,629][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-07-07 21:27:33,635][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-07-07 21:27:33,635][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-07-07 21:27:33,635][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-07-07 21:27:33,635][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-07-07 21:27:33,635][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-07-07 21:27:33,635][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-07-07 21:27:33,636][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-07-07 21:27:33,636][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-07-07 21:27:33,801][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:27:33,801][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-07-07 21:27:33,801][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:27:33,801][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:27:33,801][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:27:33,801][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:27:33,802][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-07-07 21:27:33,802][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:27:33,802][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f4bc06c5ef0>
[2017-07-07 21:27:33,802][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:27:33,802][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f4bc0699b18>
[2017-07-07 21:27:33,802][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:27:33,802][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-07-07 21:27:33,802][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:27:33,803][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-07-07 21:27:33,803][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-07-07 21:27:33,829][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:27:33,843][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:27:33,843][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:27:33,860][gdb3][DEBUG ] detect machine type
[2017-07-07 21:27:33,862][gdb3][DEBUG ] find the location of an executable
[2017-07-07 21:27:33,862][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-07-07 21:27:33,862][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-07-07 21:27:33,862][gdb3][DEBUG ] get remote short hostname
[2017-07-07 21:27:33,863][gdb3][DEBUG ] deploying mon to gdb3
[2017-07-07 21:27:33,863][gdb3][DEBUG ] get remote short hostname
[2017-07-07 21:27:33,863][gdb3][DEBUG ] remote hostname: gdb3
[2017-07-07 21:27:33,864][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 21:27:33,865][gdb3][DEBUG ] create the mon path if it does not exist
[2017-07-07 21:27:33,865][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-07 21:27:33,866][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-07 21:27:33,866][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-07 21:27:33,866][gdb3][DEBUG ] create the monitor keyring file
[2017-07-07 21:27:33,867][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-07-07 21:27:33,905][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-07-07 21:27:33,905][gdb3][DEBUG ] ceph-mon: set fsid to ba6e8ad7-ccd2-4a22-80a3-d9052c5f635c
[2017-07-07 21:27:33,913][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-07-07 21:27:33,914][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-07 21:27:33,915][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-07-07 21:27:33,915][gdb3][DEBUG ] create the init path if it does not exist
[2017-07-07 21:27:33,916][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-07 21:27:33,989][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-07-07 21:27:34,057][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-07-07 21:27:36,128][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 21:27:36,193][gdb3][DEBUG ] ********************************************************************************
[2017-07-07 21:27:36,193][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-07-07 21:27:36,193][gdb3][DEBUG ] {
[2017-07-07 21:27:36,193][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-07-07 21:27:36,193][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-07-07 21:27:36,193][gdb3][DEBUG ]   "features": {
[2017-07-07 21:27:36,193][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-07-07 21:27:36,193][gdb3][DEBUG ]     "quorum_mon": [
[2017-07-07 21:27:36,193][gdb3][DEBUG ]       "kraken", 
[2017-07-07 21:27:36,193][gdb3][DEBUG ]       "luminous"
[2017-07-07 21:27:36,194][gdb3][DEBUG ]     ], 
[2017-07-07 21:27:36,194][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-07-07 21:27:36,194][gdb3][DEBUG ]     "required_mon": [
[2017-07-07 21:27:36,194][gdb3][DEBUG ]       "kraken", 
[2017-07-07 21:27:36,194][gdb3][DEBUG ]       "luminous"
[2017-07-07 21:27:36,194][gdb3][DEBUG ]     ]
[2017-07-07 21:27:36,194][gdb3][DEBUG ]   }, 
[2017-07-07 21:27:36,194][gdb3][DEBUG ]   "monmap": {
[2017-07-07 21:27:36,194][gdb3][DEBUG ]     "created": "2017-07-07 21:27:33.891015", 
[2017-07-07 21:27:36,194][gdb3][DEBUG ]     "epoch": 2, 
[2017-07-07 21:27:36,194][gdb3][DEBUG ]     "features": {
[2017-07-07 21:27:36,194][gdb3][DEBUG ]       "optional": [], 
[2017-07-07 21:27:36,194][gdb3][DEBUG ]       "persistent": [
[2017-07-07 21:27:36,194][gdb3][DEBUG ]         "kraken", 
[2017-07-07 21:27:36,194][gdb3][DEBUG ]         "luminous"
[2017-07-07 21:27:36,194][gdb3][DEBUG ]       ]
[2017-07-07 21:27:36,195][gdb3][DEBUG ]     }, 
[2017-07-07 21:27:36,195][gdb3][DEBUG ]     "fsid": "ba6e8ad7-ccd2-4a22-80a3-d9052c5f635c", 
[2017-07-07 21:27:36,195][gdb3][DEBUG ]     "modified": "2017-07-07 21:27:34.145735", 
[2017-07-07 21:27:36,195][gdb3][DEBUG ]     "mons": [
[2017-07-07 21:27:36,195][gdb3][DEBUG ]       {
[2017-07-07 21:27:36,195][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-07-07 21:27:36,195][gdb3][DEBUG ]         "name": "gdb3", 
[2017-07-07 21:27:36,195][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-07-07 21:27:36,195][gdb3][DEBUG ]         "rank": 0
[2017-07-07 21:27:36,195][gdb3][DEBUG ]       }
[2017-07-07 21:27:36,195][gdb3][DEBUG ]     ]
[2017-07-07 21:27:36,195][gdb3][DEBUG ]   }, 
[2017-07-07 21:27:36,195][gdb3][DEBUG ]   "name": "gdb3", 
[2017-07-07 21:27:36,195][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-07-07 21:27:36,195][gdb3][DEBUG ]   "quorum": [
[2017-07-07 21:27:36,195][gdb3][DEBUG ]     0
[2017-07-07 21:27:36,195][gdb3][DEBUG ]   ], 
[2017-07-07 21:27:36,196][gdb3][DEBUG ]   "rank": 0, 
[2017-07-07 21:27:36,196][gdb3][DEBUG ]   "state": "leader", 
[2017-07-07 21:27:36,196][gdb3][DEBUG ]   "sync_provider": []
[2017-07-07 21:27:36,196][gdb3][DEBUG ] }
[2017-07-07 21:27:36,196][gdb3][DEBUG ] ********************************************************************************
[2017-07-07 21:27:36,196][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-07-07 21:27:36,197][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 21:27:36,262][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-07-07 21:27:36,278][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:27:36,291][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:27:36,292][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:27:36,308][gdb3][DEBUG ] detect machine type
[2017-07-07 21:27:36,311][gdb3][DEBUG ] find the location of an executable
[2017-07-07 21:27:36,312][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 21:27:36,377][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-07-07 21:27:36,377][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-07-07 21:27:36,377][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-07-07 21:27:36,379][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpEsj4iz
[2017-07-07 21:27:36,395][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:27:36,409][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:27:36,409][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:27:36,426][gdb3][DEBUG ] detect machine type
[2017-07-07 21:27:36,428][gdb3][DEBUG ] get remote short hostname
[2017-07-07 21:27:36,428][gdb3][DEBUG ] fetch remote file
[2017-07-07 21:27:36,429][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 21:27:36,495][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-07-07 21:27:36,662][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-07-07 21:27:36,828][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-07-07 21:27:36,994][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-07-07 21:27:37,160][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-07-07 21:27:37,326][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-07-07 21:27:37,493][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-07-07 21:27:37,659][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-07-07 21:27:37,875][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-07-07 21:27:38,041][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-07-07 21:27:38,207][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-07-07 21:27:38,207][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-07-07 21:27:38,207][ceph_deploy.gatherkeys][INFO  ] Replacing 'ceph.bootstrap-mgr.keyring' and backing up old key as 'ceph.bootstrap-mgr.keyring-20170707212738'
[2017-07-07 21:27:38,207][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-07-07 21:27:38,208][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-07-07 21:27:38,208][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-07-07 21:27:38,208][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpEsj4iz
[2017-07-07 21:27:38,387][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:27:38,387][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-07-07 21:27:38,387][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:27:38,387][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:27:38,387][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:27:38,387][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:27:38,387][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:27:38,387][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ff77c7595a8>
[2017-07-07 21:27:38,387][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:27:38,388][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-07-07 21:27:38,388][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7ff77d070938>
[2017-07-07 21:27:38,388][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:27:38,388][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:27:38,388][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-07-07 21:27:38,414][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:27:38,427][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:27:38,428][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:27:38,444][gdb3][DEBUG ] detect machine type
[2017-07-07 21:27:38,447][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 21:28:00,429][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:28:00,429][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb1
[2017-07-07 21:28:00,429][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:28:00,429][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:28:00,429][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:28:00,429][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-07 21:28:00,430][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:28:00,430][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6e7ecff5a8>
[2017-07-07 21:28:00,430][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:28:00,430][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-07-07 21:28:00,430][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f6e7f616938>
[2017-07-07 21:28:00,430][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:28:00,430][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:28:00,430][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-07-07 21:28:00,672][gdb1][DEBUG ] connection detected need for sudo
[2017-07-07 21:28:00,900][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-07 21:28:00,900][gdb1][DEBUG ] detect platform information from remote host
[2017-07-07 21:28:00,917][gdb1][DEBUG ] detect machine type
[2017-07-07 21:28:00,921][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 21:28:01,092][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:28:01,093][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-07-07 21:28:01,093][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:28:01,093][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:28:01,093][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-07 21:28:01,093][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-07 21:28:01,093][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-07 21:28:01,093][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:28:01,093][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-07 21:28:01,093][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-07 21:28:01,093][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:28:01,093][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-07 21:28:01,093][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-07 21:28:01,093][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:28:01,094][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f498bfb7998>
[2017-07-07 21:28:01,094][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:28:01,094][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-07 21:28:01,094][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f498c20daa0>
[2017-07-07 21:28:01,094][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:28:01,094][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:28:01,094][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-07 21:28:01,094][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-07-07 21:28:01,336][gdb1][DEBUG ] connection detected need for sudo
[2017-07-07 21:28:01,568][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-07 21:28:01,568][gdb1][DEBUG ] detect platform information from remote host
[2017-07-07 21:28:01,584][gdb1][DEBUG ] detect machine type
[2017-07-07 21:28:01,588][gdb1][DEBUG ] find the location of an executable
[2017-07-07 21:28:01,589][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 21:28:01,589][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-07-07 21:28:01,590][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 21:28:01,592][gdb1][WARNING] osd keyring does not exist yet, creating one
[2017-07-07 21:28:01,593][gdb1][DEBUG ] create a keyring file
[2017-07-07 21:28:01,595][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-07-07 21:28:01,595][gdb1][DEBUG ] find the location of an executable
[2017-07-07 21:28:01,597][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-07 21:28:01,768][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-07 21:28:01,768][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-07 21:28:01,768][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-07 21:28:01,769][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-07 21:28:01,785][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-07 21:28:01,793][gdb1][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-07-07 21:28:01,808][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.4440.tmp
[2017-07-07 21:28:01,812][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.4440.tmp
[2017-07-07 21:28:01,815][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.4440.tmp
[2017-07-07 21:28:06,836][gdb1][INFO  ] checking OSD status...
[2017-07-07 21:28:06,836][gdb1][DEBUG ] find the location of an executable
[2017-07-07 21:28:06,839][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-07 21:28:07,004][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-07-07 21:28:07,170][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:28:07,170][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-07-07 21:28:07,170][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:28:07,170][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:28:07,170][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:28:07,170][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:28:07,170][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-07 21:28:07,171][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:28:07,171][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7a33208998>
[2017-07-07 21:28:07,171][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:28:07,171][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f7a3345eaa0>
[2017-07-07 21:28:07,171][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:28:07,171][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:28:07,171][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-07 21:28:07,171][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-07-07 21:28:07,412][gdb1][DEBUG ] connection detected need for sudo
[2017-07-07 21:28:07,644][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-07 21:28:07,644][gdb1][DEBUG ] detect platform information from remote host
[2017-07-07 21:28:07,661][gdb1][DEBUG ] detect machine type
[2017-07-07 21:28:07,665][gdb1][DEBUG ] find the location of an executable
[2017-07-07 21:28:07,666][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 21:28:07,666][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-07-07 21:28:07,666][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-07 21:28:07,666][gdb1][DEBUG ] find the location of an executable
[2017-07-07 21:28:07,668][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-07 21:28:07,839][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-07-07 21:28:07,839][gdb1][WARNING] activate: Cluster uuid is ba6e8ad7-ccd2-4a22-80a3-d9052c5f635c
[2017-07-07 21:28:07,839][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-07 21:28:07,839][gdb1][WARNING] activate: Cluster name is ceph
[2017-07-07 21:28:07,839][gdb1][WARNING] activate: OSD uuid is 01007f7b-2f06-4085-8735-27f1cf2c2e4a
[2017-07-07 21:28:07,839][gdb1][WARNING] allocate_osd_id: Allocating OSD id...
[2017-07-07 21:28:07,839][gdb1][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 01007f7b-2f06-4085-8735-27f1cf2c2e4a
[2017-07-07 21:28:08,003][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.4560.tmp
[2017-07-07 21:28:08,004][gdb1][WARNING] activate: OSD id is 0
[2017-07-07 21:28:08,004][gdb1][WARNING] activate: Initializing OSD...
[2017-07-07 21:28:08,004][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-07-07 21:28:08,118][gdb1][WARNING] got monmap epoch 2
[2017-07-07 21:28:08,125][gdb1][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 0 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid 01007f7b-2f06-4085-8735-27f1cf2c2e4a --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-07-07 21:28:08,157][gdb1][WARNING] activate: Marking with init system systemd
[2017-07-07 21:28:08,157][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-07-07 21:28:08,157][gdb1][WARNING] activate: Authorizing OSD key...
[2017-07-07 21:28:08,158][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.0 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-07-07 21:28:08,322][gdb1][WARNING] added key for osd.0
[2017-07-07 21:28:08,322][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.4560.tmp
[2017-07-07 21:28:08,322][gdb1][WARNING] activate: ceph osd.0 data dir is ready at /mnt/memstore
[2017-07-07 21:28:08,322][gdb1][WARNING] activate_dir: Creating symlink /var/lib/ceph/osd/ceph-0 -> /mnt/memstore
[2017-07-07 21:28:08,322][gdb1][WARNING] start_daemon: Starting ceph osd.0...
[2017-07-07 21:28:08,322][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0
[2017-07-07 21:28:08,324][gdb1][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service.
[2017-07-07 21:28:08,388][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0 --runtime
[2017-07-07 21:28:08,452][gdb1][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@0
[2017-07-07 21:28:08,452][gdb1][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service to /lib/systemd/system/ceph-osd@.service.
[2017-07-07 21:28:08,516][gdb1][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@0
[2017-07-07 21:28:13,521][gdb1][INFO  ] checking OSD status...
[2017-07-07 21:28:13,522][gdb1][DEBUG ] find the location of an executable
[2017-07-07 21:28:13,525][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-07 21:28:13,690][gdb1][WARNING] there is 1 OSD down
[2017-07-07 21:28:13,690][gdb1][WARNING] there is 1 OSD out
[2017-07-07 21:28:13,693][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-07 21:28:19,619][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:28:19,619][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy rgw create gdb1
[2017-07-07 21:28:19,619][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:28:19,619][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:28:19,620][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:28:19,620][ceph_deploy.cli][INFO  ]  rgw                           : [('gdb1', 'rgw.gdb1')]
[2017-07-07 21:28:19,620][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:28:19,620][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-07 21:28:19,620][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:28:19,620][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f81daea0830>
[2017-07-07 21:28:19,620][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:28:19,620][ceph_deploy.cli][INFO  ]  func                          : <function rgw at 0x7f81db561758>
[2017-07-07 21:28:19,620][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:28:19,620][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:28:19,620][ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts gdb1:rgw.gdb1
[2017-07-07 21:28:19,860][gdb1][DEBUG ] connection detected need for sudo
[2017-07-07 21:28:20,091][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-07 21:28:20,092][gdb1][DEBUG ] detect platform information from remote host
[2017-07-07 21:28:20,108][gdb1][DEBUG ] detect machine type
[2017-07-07 21:28:20,112][ceph_deploy.rgw][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 21:28:20,113][ceph_deploy.rgw][DEBUG ] remote host will use systemd
[2017-07-07 21:28:20,113][ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to gdb1
[2017-07-07 21:28:20,113][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 21:28:20,115][gdb1][WARNING] rgw keyring does not exist yet, creating one
[2017-07-07 21:28:20,115][gdb1][DEBUG ] create a keyring file
[2017-07-07 21:28:20,117][gdb1][DEBUG ] create path recursively if it doesn't exist
[2017-07-07 21:28:20,120][gdb1][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-rgw --keyring /var/lib/ceph/bootstrap-rgw/ceph.keyring auth get-or-create client.rgw.gdb1 osd allow rwx mon allow rw -o /var/lib/ceph/radosgw/ceph-rgw.gdb1/keyring
[2017-07-07 21:28:20,290][gdb1][INFO  ] Running command: sudo systemctl enable ceph-radosgw@rgw.gdb1
[2017-07-07 21:28:20,359][gdb1][INFO  ] Running command: sudo systemctl start ceph-radosgw@rgw.gdb1
[2017-07-07 21:28:20,371][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-07 21:28:20,437][ceph_deploy.rgw][INFO  ] The Ceph Object Gateway (RGW) is now running on host gdb1 and default port 7480
[2017-07-07 21:33:55,606][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:33:55,606][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-07-07 21:33:55,606][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:33:55,607][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:33:55,607][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:33:55,607][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:33:55,607][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:33:55,607][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9ca8d82128>
[2017-07-07 21:33:55,607][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:33:55,607][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-07 21:33:55,607][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7f9ca968f1b8>
[2017-07-07 21:33:55,607][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:33:55,607][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:33:55,607][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-07-07 21:33:55,607][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-07-07 21:33:55,607][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-07-07 21:33:55,607][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-07-07 21:33:55,633][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:33:55,648][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:33:55,648][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:33:55,665][gdb3][DEBUG ] detect machine type
[2017-07-07 21:33:55,667][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 21:33:55,667][gdb3][INFO  ] Purging Ceph on gdb3
[2017-07-07 21:33:55,668][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-07-07 21:33:55,707][gdb3][DEBUG ] Reading package lists...
[2017-07-07 21:33:55,871][gdb3][DEBUG ] Building dependency tree...
[2017-07-07 21:33:55,871][gdb3][DEBUG ] Reading state information...
[2017-07-07 21:33:55,936][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-07-07 21:33:55,936][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-07-07 21:33:55,936][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-07-07 21:33:55,936][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-07-07 21:33:55,936][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-07-07 21:33:55,936][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-07-07 21:33:55,937][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1016 linux-aws-headers-4.4.0-1017
[2017-07-07 21:33:55,937][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1018 linux-headers-4.4.0-1013-aws
[2017-07-07 21:33:55,937][gdb3][DEBUG ]   linux-headers-4.4.0-1016-aws linux-headers-4.4.0-1017-aws
[2017-07-07 21:33:55,937][gdb3][DEBUG ]   linux-headers-4.4.0-1018-aws linux-image-4.4.0-1013-aws
[2017-07-07 21:33:55,937][gdb3][DEBUG ]   linux-image-4.4.0-1016-aws linux-image-4.4.0-1017-aws
[2017-07-07 21:33:55,937][gdb3][DEBUG ]   linux-image-4.4.0-1018-aws ntp python-blinker python-cephfs
[2017-07-07 21:33:55,937][gdb3][DEBUG ]   python-cffi-backend python-chardet python-cryptography python-enum34
[2017-07-07 21:33:55,937][gdb3][DEBUG ]   python-flask python-idna python-ipaddress python-itsdangerous python-jinja2
[2017-07-07 21:33:55,937][gdb3][DEBUG ]   python-markupsafe python-ndg-httpsclient python-openssl python-pyasn1
[2017-07-07 21:33:55,937][gdb3][DEBUG ]   python-pyinotify python-rados python-rbd python-requests python-rgw
[2017-07-07 21:33:55,938][gdb3][DEBUG ]   python-six python-urllib3 python-werkzeug
[2017-07-07 21:33:55,938][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-07-07 21:33:55,970][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-07-07 21:33:55,970][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-07-07 21:33:56,084][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 61 not upgraded.
[2017-07-07 21:33:56,084][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-07-07 21:33:56,148][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 179644 files and directories currently installed.)
[2017-07-07 21:33:56,164][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-07-07 21:33:56,329][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-07-07 21:33:56,444][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-07-07 21:33:56,476][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-07-07 21:33:56,691][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-07-07 21:33:56,805][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-07-07 21:33:56,969][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-07-07 21:33:57,033][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-07-07 21:33:57,065][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-07-07 21:33:57,231][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-07-07 21:33:57,295][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-07-07 21:33:57,311][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-07-07 21:33:57,475][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-07-07 21:33:57,539][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-07-07 21:33:57,653][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-07-07 21:33:57,768][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-07-07 21:33:57,768][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-07-07 21:33:57,882][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu9) ...
[2017-07-07 21:33:58,699][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-07-07 21:33:58,867][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:33:58,868][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-07-07 21:33:58,868][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:33:58,868][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:33:58,868][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:33:58,868][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:33:58,868][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:33:58,868][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f96185b77a0>
[2017-07-07 21:33:58,868][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:33:58,868][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-07 21:33:58,868][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f9618ec4230>
[2017-07-07 21:33:58,868][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:33:58,868][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:33:58,868][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-07-07 21:33:58,894][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:33:58,908][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:33:58,908][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:33:58,925][gdb3][DEBUG ] detect machine type
[2017-07-07 21:33:58,927][gdb3][DEBUG ] find the location of an executable
[2017-07-07 21:33:58,943][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:33:58,957][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:33:58,957][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:33:58,974][gdb3][DEBUG ] detect machine type
[2017-07-07 21:33:58,976][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 21:33:58,976][gdb3][INFO  ] purging data on gdb3
[2017-07-07 21:33:58,977][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-07-07 21:33:58,990][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-07-07 21:33:59,159][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:33:59,160][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-07-07 21:33:59,160][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:33:59,160][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:33:59,160][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:33:59,160][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:33:59,160][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:33:59,160][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7cef6e7a70>
[2017-07-07 21:33:59,160][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:33:59,160][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7f7ceffaa848>
[2017-07-07 21:33:59,160][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:33:59,161][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:37:19,148][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:37:19,148][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-07-07 21:37:19,148][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:37:19,149][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:37:19,149][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:37:19,149][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:37:19,149][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:37:19,149][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ff3139cc128>
[2017-07-07 21:37:19,149][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:37:19,149][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-07 21:37:19,149][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7ff3142d91b8>
[2017-07-07 21:37:19,149][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:37:19,149][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:37:19,149][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-07-07 21:37:19,149][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-07-07 21:37:19,149][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-07-07 21:37:19,149][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-07-07 21:37:19,176][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:37:19,190][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:37:19,190][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:37:19,207][gdb3][DEBUG ] detect machine type
[2017-07-07 21:37:19,209][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 21:37:19,209][gdb3][INFO  ] Purging Ceph on gdb3
[2017-07-07 21:37:19,210][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-07-07 21:37:19,248][gdb3][DEBUG ] Reading package lists...
[2017-07-07 21:37:19,412][gdb3][DEBUG ] Building dependency tree...
[2017-07-07 21:37:19,413][gdb3][DEBUG ] Reading state information...
[2017-07-07 21:37:19,477][gdb3][DEBUG ] Package 'ceph' is not installed, so not removed
[2017-07-07 21:37:19,477][gdb3][DEBUG ] Package 'ceph-common' is not installed, so not removed
[2017-07-07 21:37:19,477][gdb3][DEBUG ] Package 'ceph-mds' is not installed, so not removed
[2017-07-07 21:37:19,477][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-07-07 21:37:19,477][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-07-07 21:37:19,477][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-07-07 21:37:19,477][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-07-07 21:37:19,477][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-07-07 21:37:19,477][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-07-07 21:37:19,477][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1016 linux-aws-headers-4.4.0-1017
[2017-07-07 21:37:19,477][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1018 linux-headers-4.4.0-1013-aws
[2017-07-07 21:37:19,478][gdb3][DEBUG ]   linux-headers-4.4.0-1016-aws linux-headers-4.4.0-1017-aws
[2017-07-07 21:37:19,478][gdb3][DEBUG ]   linux-headers-4.4.0-1018-aws linux-image-4.4.0-1013-aws
[2017-07-07 21:37:19,478][gdb3][DEBUG ]   linux-image-4.4.0-1016-aws linux-image-4.4.0-1017-aws
[2017-07-07 21:37:19,478][gdb3][DEBUG ]   linux-image-4.4.0-1018-aws ntp python-blinker python-cephfs
[2017-07-07 21:37:19,478][gdb3][DEBUG ]   python-cffi-backend python-chardet python-cryptography python-enum34
[2017-07-07 21:37:19,478][gdb3][DEBUG ]   python-flask python-idna python-ipaddress python-itsdangerous python-jinja2
[2017-07-07 21:37:19,478][gdb3][DEBUG ]   python-markupsafe python-ndg-httpsclient python-openssl python-pyasn1
[2017-07-07 21:37:19,478][gdb3][DEBUG ]   python-pyinotify python-rados python-rbd python-requests python-rgw
[2017-07-07 21:37:19,478][gdb3][DEBUG ]   python-six python-urllib3 python-werkzeug
[2017-07-07 21:37:19,478][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-07-07 21:37:19,486][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 0 to remove and 61 not upgraded.
[2017-07-07 21:37:19,654][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:37:19,655][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-07-07 21:37:19,655][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:37:19,655][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:37:19,655][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:37:19,655][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:37:19,655][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:37:19,655][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f19d55a87a0>
[2017-07-07 21:37:19,655][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:37:19,655][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-07 21:37:19,655][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f19d5eb5230>
[2017-07-07 21:37:19,655][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:37:19,655][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:37:19,655][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-07-07 21:37:19,681][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:37:19,695][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:37:19,696][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:37:19,712][gdb3][DEBUG ] detect machine type
[2017-07-07 21:37:19,715][gdb3][DEBUG ] find the location of an executable
[2017-07-07 21:37:19,730][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:37:19,743][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:37:19,744][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:37:19,760][gdb3][DEBUG ] detect machine type
[2017-07-07 21:37:19,762][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 21:37:19,763][gdb3][INFO  ] purging data on gdb3
[2017-07-07 21:37:19,763][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-07-07 21:37:19,776][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-07-07 21:37:19,947][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:37:19,947][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-07-07 21:37:19,947][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:37:19,947][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:37:19,947][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:37:19,947][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:37:19,947][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:37:19,948][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7586894a70>
[2017-07-07 21:37:19,948][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:37:19,948][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7f7587157848>
[2017-07-07 21:37:19,948][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:37:19,948][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:37:32,493][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:37:32,493][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-07-07 21:37:32,493][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:37:32,494][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:37:32,494][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:37:32,494][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:37:32,494][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:37:32,494][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7facc25fd5f0>
[2017-07-07 21:37:32,494][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:37:32,494][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-07-07 21:37:32,494][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-07-07 21:37:32,495][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7facc2c81758>
[2017-07-07 21:37:32,495][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-07-07 21:37:32,495][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:37:32,495][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-07-07 21:37:32,495][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:37:32,495][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-07-07 21:37:32,495][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-07-07 21:37:32,495][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-07-07 21:37:32,522][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:37:32,535][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:37:32,536][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:37:32,552][gdb3][DEBUG ] detect machine type
[2017-07-07 21:37:32,555][gdb3][DEBUG ] find the location of an executable
[2017-07-07 21:37:32,556][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-07-07 21:37:32,567][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-07-07 21:37:32,574][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-07-07 21:37:32,574][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-07-07 21:37:32,574][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-07-07 21:37:32,574][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-07-07 21:37:32,574][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-07-07 21:37:32,574][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-07-07 21:37:32,574][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-07-07 21:37:32,575][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-07-07 21:37:32,741][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:37:32,741][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-07-07 21:37:32,742][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:37:32,742][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:37:32,742][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:37:32,742][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:37:32,742][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-07-07 21:37:32,742][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:37:32,742][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0317371ef0>
[2017-07-07 21:37:32,742][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:37:32,743][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f0317345b18>
[2017-07-07 21:37:32,743][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:37:32,743][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-07-07 21:37:32,743][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:37:32,744][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-07-07 21:37:32,744][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-07-07 21:37:32,770][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:37:32,784][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:37:32,784][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:37:32,801][gdb3][DEBUG ] detect machine type
[2017-07-07 21:37:32,803][gdb3][DEBUG ] find the location of an executable
[2017-07-07 21:37:32,804][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-07-07 21:37:32,804][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-07-07 21:37:32,804][gdb3][DEBUG ] get remote short hostname
[2017-07-07 21:37:32,804][gdb3][DEBUG ] deploying mon to gdb3
[2017-07-07 21:37:32,804][gdb3][DEBUG ] get remote short hostname
[2017-07-07 21:37:32,805][gdb3][DEBUG ] remote hostname: gdb3
[2017-07-07 21:37:32,805][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 21:37:32,807][gdb3][DEBUG ] create the mon path if it does not exist
[2017-07-07 21:37:32,807][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-07 21:37:32,807][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-07 21:37:32,808][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-07 21:37:32,808][gdb3][DEBUG ] create the monitor keyring file
[2017-07-07 21:37:32,809][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-07-07 21:37:32,847][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-07-07 21:37:32,847][gdb3][DEBUG ] ceph-mon: set fsid to 82493c0e-496b-4a92-ae1c-a9804191f3c2
[2017-07-07 21:37:32,851][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-07-07 21:37:32,852][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-07 21:37:32,853][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-07-07 21:37:32,853][gdb3][DEBUG ] create the init path if it does not exist
[2017-07-07 21:37:32,854][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-07 21:37:32,922][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-07-07 21:37:32,997][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-07-07 21:37:35,035][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 21:37:35,100][gdb3][DEBUG ] ********************************************************************************
[2017-07-07 21:37:35,101][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-07-07 21:37:35,101][gdb3][DEBUG ] {
[2017-07-07 21:37:35,101][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-07-07 21:37:35,101][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-07-07 21:37:35,101][gdb3][DEBUG ]   "features": {
[2017-07-07 21:37:35,101][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-07-07 21:37:35,101][gdb3][DEBUG ]     "quorum_mon": [
[2017-07-07 21:37:35,101][gdb3][DEBUG ]       "kraken", 
[2017-07-07 21:37:35,101][gdb3][DEBUG ]       "luminous"
[2017-07-07 21:37:35,102][gdb3][DEBUG ]     ], 
[2017-07-07 21:37:35,102][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-07-07 21:37:35,102][gdb3][DEBUG ]     "required_mon": [
[2017-07-07 21:37:35,102][gdb3][DEBUG ]       "kraken", 
[2017-07-07 21:37:35,102][gdb3][DEBUG ]       "luminous"
[2017-07-07 21:37:35,102][gdb3][DEBUG ]     ]
[2017-07-07 21:37:35,102][gdb3][DEBUG ]   }, 
[2017-07-07 21:37:35,102][gdb3][DEBUG ]   "monmap": {
[2017-07-07 21:37:35,102][gdb3][DEBUG ]     "created": "2017-07-07 21:37:32.832271", 
[2017-07-07 21:37:35,102][gdb3][DEBUG ]     "epoch": 2, 
[2017-07-07 21:37:35,102][gdb3][DEBUG ]     "features": {
[2017-07-07 21:37:35,102][gdb3][DEBUG ]       "optional": [], 
[2017-07-07 21:37:35,102][gdb3][DEBUG ]       "persistent": [
[2017-07-07 21:37:35,102][gdb3][DEBUG ]         "kraken", 
[2017-07-07 21:37:35,102][gdb3][DEBUG ]         "luminous"
[2017-07-07 21:37:35,102][gdb3][DEBUG ]       ]
[2017-07-07 21:37:35,103][gdb3][DEBUG ]     }, 
[2017-07-07 21:37:35,103][gdb3][DEBUG ]     "fsid": "82493c0e-496b-4a92-ae1c-a9804191f3c2", 
[2017-07-07 21:37:35,103][gdb3][DEBUG ]     "modified": "2017-07-07 21:37:33.085407", 
[2017-07-07 21:37:35,103][gdb3][DEBUG ]     "mons": [
[2017-07-07 21:37:35,103][gdb3][DEBUG ]       {
[2017-07-07 21:37:35,103][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-07-07 21:37:35,103][gdb3][DEBUG ]         "name": "gdb3", 
[2017-07-07 21:37:35,103][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-07-07 21:37:35,103][gdb3][DEBUG ]         "rank": 0
[2017-07-07 21:37:35,103][gdb3][DEBUG ]       }
[2017-07-07 21:37:35,103][gdb3][DEBUG ]     ]
[2017-07-07 21:37:35,103][gdb3][DEBUG ]   }, 
[2017-07-07 21:37:35,103][gdb3][DEBUG ]   "name": "gdb3", 
[2017-07-07 21:37:35,103][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-07-07 21:37:35,103][gdb3][DEBUG ]   "quorum": [
[2017-07-07 21:37:35,103][gdb3][DEBUG ]     0
[2017-07-07 21:37:35,104][gdb3][DEBUG ]   ], 
[2017-07-07 21:37:35,104][gdb3][DEBUG ]   "rank": 0, 
[2017-07-07 21:37:35,104][gdb3][DEBUG ]   "state": "leader", 
[2017-07-07 21:37:35,104][gdb3][DEBUG ]   "sync_provider": []
[2017-07-07 21:37:35,104][gdb3][DEBUG ] }
[2017-07-07 21:37:35,104][gdb3][DEBUG ] ********************************************************************************
[2017-07-07 21:37:35,104][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-07-07 21:37:35,105][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 21:37:35,170][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-07-07 21:37:35,185][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:37:35,199][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:37:35,200][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:37:35,216][gdb3][DEBUG ] detect machine type
[2017-07-07 21:37:35,218][gdb3][DEBUG ] find the location of an executable
[2017-07-07 21:37:35,219][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 21:37:35,284][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-07-07 21:37:35,285][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-07-07 21:37:35,285][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-07-07 21:37:35,287][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpU3h8JZ
[2017-07-07 21:37:35,301][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:37:35,315][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:37:35,316][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:37:35,332][gdb3][DEBUG ] detect machine type
[2017-07-07 21:37:35,335][gdb3][DEBUG ] get remote short hostname
[2017-07-07 21:37:35,335][gdb3][DEBUG ] fetch remote file
[2017-07-07 21:37:35,336][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-07 21:37:35,402][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-07-07 21:37:35,568][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-07-07 21:37:35,734][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-07-07 21:37:35,901][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-07-07 21:37:36,067][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-07-07 21:37:36,233][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-07-07 21:37:36,399][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-07-07 21:37:36,566][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-07-07 21:37:36,732][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-07-07 21:37:36,898][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-07-07 21:37:37,063][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-07-07 21:37:37,063][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-07-07 21:37:37,064][ceph_deploy.gatherkeys][INFO  ] Replacing 'ceph.bootstrap-mgr.keyring' and backing up old key as 'ceph.bootstrap-mgr.keyring-20170707213737'
[2017-07-07 21:37:37,064][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-07-07 21:37:37,064][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-07-07 21:37:37,064][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-07-07 21:37:37,064][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpU3h8JZ
[2017-07-07 21:37:37,243][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:37:37,244][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-07-07 21:37:37,244][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:37:37,244][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:37:37,244][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:37:37,244][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:37:37,244][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:37:37,244][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9b6e5e25a8>
[2017-07-07 21:37:37,244][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:37:37,244][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-07-07 21:37:37,245][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f9b6eef9938>
[2017-07-07 21:37:37,245][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:37:37,245][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:37:37,245][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-07-07 21:37:37,271][gdb3][DEBUG ] connection detected need for sudo
[2017-07-07 21:37:37,285][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-07 21:37:37,286][gdb3][DEBUG ] detect platform information from remote host
[2017-07-07 21:37:37,302][gdb3][DEBUG ] detect machine type
[2017-07-07 21:37:37,304][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 21:37:42,319][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:37:42,319][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb1
[2017-07-07 21:37:42,319][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:37:42,320][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:37:42,320][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:37:42,320][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-07 21:37:42,320][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:37:42,320][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7faf837c55a8>
[2017-07-07 21:37:42,320][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:37:42,320][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-07-07 21:37:42,320][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7faf840dc938>
[2017-07-07 21:37:42,320][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:37:42,320][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:37:42,320][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-07-07 21:37:42,633][gdb1][DEBUG ] connection detected need for sudo
[2017-07-07 21:37:42,875][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-07 21:37:42,875][gdb1][DEBUG ] detect platform information from remote host
[2017-07-07 21:37:42,904][gdb1][DEBUG ] detect machine type
[2017-07-07 21:37:42,908][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 21:37:43,083][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:37:43,084][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-07-07 21:37:43,084][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:37:43,084][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:37:43,084][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-07 21:37:43,084][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-07 21:37:43,084][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-07 21:37:43,084][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:37:43,084][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-07 21:37:43,084][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-07 21:37:43,084][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:37:43,085][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-07 21:37:43,085][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-07 21:37:43,085][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:37:43,085][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f87a5bba998>
[2017-07-07 21:37:43,085][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:37:43,085][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-07 21:37:43,085][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f87a5e10aa0>
[2017-07-07 21:37:43,085][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:37:43,085][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:37:43,085][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-07 21:37:43,085][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-07-07 21:37:43,324][gdb1][DEBUG ] connection detected need for sudo
[2017-07-07 21:37:43,511][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-07 21:37:43,512][gdb1][DEBUG ] detect platform information from remote host
[2017-07-07 21:37:43,528][gdb1][DEBUG ] detect machine type
[2017-07-07 21:37:43,532][gdb1][DEBUG ] find the location of an executable
[2017-07-07 21:37:43,533][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 21:37:43,533][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-07-07 21:37:43,533][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-07 21:37:43,538][gdb1][WARNING] osd keyring does not exist yet, creating one
[2017-07-07 21:37:43,538][gdb1][DEBUG ] create a keyring file
[2017-07-07 21:37:43,540][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-07-07 21:37:43,540][gdb1][DEBUG ] find the location of an executable
[2017-07-07 21:37:43,542][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-07 21:37:43,913][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-07 21:37:44,078][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-07 21:37:44,078][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-07 21:37:44,078][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-07 21:37:44,078][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-07 21:37:44,094][gdb1][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-07-07 21:37:44,094][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.2227.tmp
[2017-07-07 21:37:44,097][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.2227.tmp
[2017-07-07 21:37:44,101][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.2227.tmp
[2017-07-07 21:37:49,121][gdb1][INFO  ] checking OSD status...
[2017-07-07 21:37:49,122][gdb1][DEBUG ] find the location of an executable
[2017-07-07 21:37:49,124][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-07 21:37:49,490][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-07-07 21:37:49,654][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-07 21:37:49,654][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-07-07 21:37:49,654][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-07 21:37:49,654][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-07 21:37:49,654][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-07 21:37:49,654][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-07 21:37:49,654][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-07 21:37:49,654][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-07 21:37:49,655][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f32265aa998>
[2017-07-07 21:37:49,655][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-07 21:37:49,655][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f3226800aa0>
[2017-07-07 21:37:49,655][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-07 21:37:49,655][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-07 21:37:49,655][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-07 21:37:49,655][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-07-07 21:37:49,896][gdb1][DEBUG ] connection detected need for sudo
[2017-07-07 21:37:50,087][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-07 21:37:50,088][gdb1][DEBUG ] detect platform information from remote host
[2017-07-07 21:37:50,104][gdb1][DEBUG ] detect machine type
[2017-07-07 21:37:50,108][gdb1][DEBUG ] find the location of an executable
[2017-07-07 21:37:50,109][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-07 21:37:50,109][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-07-07 21:37:50,109][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-07 21:37:50,109][gdb1][DEBUG ] find the location of an executable
[2017-07-07 21:37:50,111][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-07 21:37:50,282][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-07-07 21:37:50,282][gdb1][WARNING] activate: Cluster uuid is 82493c0e-496b-4a92-ae1c-a9804191f3c2
[2017-07-07 21:37:50,282][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-07 21:37:50,282][gdb1][WARNING] activate: Cluster name is ceph
[2017-07-07 21:37:50,283][gdb1][WARNING] activate: OSD uuid is fa31aa1c-bd8b-4b4d-84ec-a6d51412a1f7
[2017-07-07 21:37:50,283][gdb1][WARNING] allocate_osd_id: Allocating OSD id...
[2017-07-07 21:37:50,283][gdb1][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise fa31aa1c-bd8b-4b4d-84ec-a6d51412a1f7
[2017-07-07 21:37:50,447][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.2346.tmp
[2017-07-07 21:37:50,447][gdb1][WARNING] activate: OSD id is 0
[2017-07-07 21:37:50,447][gdb1][WARNING] activate: Initializing OSD...
[2017-07-07 21:37:50,447][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-07-07 21:37:50,561][gdb1][WARNING] got monmap epoch 2
[2017-07-07 21:37:50,562][gdb1][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 0 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid fa31aa1c-bd8b-4b4d-84ec-a6d51412a1f7 --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-07-07 21:37:50,626][gdb1][WARNING] activate: Marking with init system systemd
[2017-07-07 21:37:50,626][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-07-07 21:37:50,626][gdb1][WARNING] activate: Authorizing OSD key...
[2017-07-07 21:37:50,626][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.0 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-07-07 21:37:50,740][gdb1][WARNING] added key for osd.0
[2017-07-07 21:37:50,756][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.2346.tmp
[2017-07-07 21:37:50,756][gdb1][WARNING] activate: ceph osd.0 data dir is ready at /mnt/memstore
[2017-07-07 21:37:50,756][gdb1][WARNING] activate_dir: Creating symlink /var/lib/ceph/osd/ceph-0 -> /mnt/memstore
[2017-07-07 21:37:50,756][gdb1][WARNING] start_daemon: Starting ceph osd.0...
[2017-07-07 21:37:50,756][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0
[2017-07-07 21:37:50,764][gdb1][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service.
[2017-07-07 21:37:50,828][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0 --runtime
[2017-07-07 21:37:50,892][gdb1][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@0
[2017-07-07 21:37:50,892][gdb1][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service to /lib/systemd/system/ceph-osd@.service.
[2017-07-07 21:37:50,924][gdb1][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@0
[2017-07-07 21:37:56,043][gdb1][INFO  ] checking OSD status...
[2017-07-07 21:37:56,043][gdb1][DEBUG ] find the location of an executable
[2017-07-07 21:37:56,046][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-07 21:37:56,214][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-10 20:32:22,638][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-10 20:32:22,639][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purge gdb3
[2017-07-10 20:32:22,640][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-10 20:32:22,640][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-10 20:32:22,640][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-10 20:32:22,640][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-10 20:32:22,640][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-10 20:32:22,640][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7ff4c03f4128>
[2017-07-10 20:32:22,640][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-10 20:32:22,640][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-10 20:32:22,640][ceph_deploy.cli][INFO  ]  func                          : <function purge at 0x7ff4c0d011b8>
[2017-07-10 20:32:22,640][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-10 20:32:22,640][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-10 20:32:22,640][ceph_deploy.install][INFO  ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm
[2017-07-10 20:32:22,640][ceph_deploy.install][INFO  ] like: librbd1 and librados2
[2017-07-10 20:32:22,641][ceph_deploy.install][DEBUG ] Purging on cluster ceph hosts gdb3
[2017-07-10 20:32:22,641][ceph_deploy.install][DEBUG ] Detecting platform for host gdb3 ...
[2017-07-10 20:32:22,677][gdb3][DEBUG ] connection detected need for sudo
[2017-07-10 20:32:22,691][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-10 20:32:22,693][gdb3][DEBUG ] detect platform information from remote host
[2017-07-10 20:32:22,709][gdb3][DEBUG ] detect machine type
[2017-07-10 20:32:22,711][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-10 20:32:22,711][gdb3][INFO  ] Purging Ceph on gdb3
[2017-07-10 20:32:22,712][gdb3][INFO  ] Running command: sudo env DEBIAN_FRONTEND=noninteractive DEBIAN_PRIORITY=critical apt-get --assume-yes -q -f --force-yes remove --purge ceph ceph-mds ceph-common ceph-fs-common radosgw
[2017-07-10 20:32:22,752][gdb3][DEBUG ] Reading package lists...
[2017-07-10 20:32:22,917][gdb3][DEBUG ] Building dependency tree...
[2017-07-10 20:32:22,917][gdb3][DEBUG ] Reading state information...
[2017-07-10 20:32:22,981][gdb3][DEBUG ] Package 'radosgw' is not installed, so not removed
[2017-07-10 20:32:22,981][gdb3][DEBUG ] Package 'ceph-fs-common' is not installed, so not removed
[2017-07-10 20:32:22,981][gdb3][DEBUG ] The following packages were automatically installed and are no longer required:
[2017-07-10 20:32:22,981][gdb3][DEBUG ]   ceph-fuse javascript-common libcephfs2 libgoogle-perftools4 libjs-jquery
[2017-07-10 20:32:22,981][gdb3][DEBUG ]   libleveldb1v5 libopts25 libpython2.7 libradosstriper1 librgw2 libsnappy1v5
[2017-07-10 20:32:22,982][gdb3][DEBUG ]   libtcmalloc-minimal4 libunwind8 linux-aws-headers-4.4.0-1013
[2017-07-10 20:32:22,982][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1016 linux-aws-headers-4.4.0-1017
[2017-07-10 20:32:22,982][gdb3][DEBUG ]   linux-aws-headers-4.4.0-1018 linux-headers-4.4.0-1013-aws
[2017-07-10 20:32:22,982][gdb3][DEBUG ]   linux-headers-4.4.0-1016-aws linux-headers-4.4.0-1017-aws
[2017-07-10 20:32:22,982][gdb3][DEBUG ]   linux-headers-4.4.0-1018-aws linux-image-4.4.0-1013-aws
[2017-07-10 20:32:22,982][gdb3][DEBUG ]   linux-image-4.4.0-1016-aws linux-image-4.4.0-1017-aws
[2017-07-10 20:32:22,982][gdb3][DEBUG ]   linux-image-4.4.0-1018-aws ntp python-blinker python-cephfs
[2017-07-10 20:32:22,982][gdb3][DEBUG ]   python-cffi-backend python-chardet python-cryptography python-enum34
[2017-07-10 20:32:22,983][gdb3][DEBUG ]   python-flask python-idna python-ipaddress python-itsdangerous python-jinja2
[2017-07-10 20:32:22,983][gdb3][DEBUG ]   python-markupsafe python-ndg-httpsclient python-openssl python-pyasn1
[2017-07-10 20:32:22,983][gdb3][DEBUG ]   python-pyinotify python-rados python-rbd python-requests python-rgw
[2017-07-10 20:32:22,983][gdb3][DEBUG ]   python-six python-urllib3 python-werkzeug
[2017-07-10 20:32:22,983][gdb3][DEBUG ] Use 'sudo apt autoremove' to remove them.
[2017-07-10 20:32:23,015][gdb3][DEBUG ] The following packages will be REMOVED:
[2017-07-10 20:32:23,015][gdb3][DEBUG ]   ceph* ceph-base* ceph-common* ceph-mds* ceph-mgr* ceph-mon* ceph-osd*
[2017-07-10 20:32:23,280][gdb3][DEBUG ] 0 upgraded, 0 newly installed, 7 to remove and 61 not upgraded.
[2017-07-10 20:32:23,280][gdb3][DEBUG ] After this operation, 284 MB disk space will be freed.
[2017-07-10 20:32:23,745][gdb3][DEBUG ] (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 179644 files and directories currently installed.)
[2017-07-10 20:32:23,745][gdb3][DEBUG ] Removing ceph-mds (12.0.1-1) ...
[2017-07-10 20:32:23,911][gdb3][DEBUG ] Purging configuration files for ceph-mds (12.0.1-1) ...
[2017-07-10 20:32:24,025][gdb3][DEBUG ] Removing ceph (12.0.1-1) ...
[2017-07-10 20:32:24,057][gdb3][DEBUG ] Removing ceph-osd (12.0.1-1) ...
[2017-07-10 20:32:24,324][gdb3][DEBUG ] Purging configuration files for ceph-osd (12.0.1-1) ...
[2017-07-10 20:32:24,438][gdb3][DEBUG ] Removing ceph-mon (12.0.1-1) ...
[2017-07-10 20:32:24,552][gdb3][DEBUG ] Purging configuration files for ceph-mon (12.0.1-1) ...
[2017-07-10 20:32:24,666][gdb3][DEBUG ] dpkg: warning: while removing ceph-mon, directory '/var/lib/ceph/mon' not empty so not removed
[2017-07-10 20:32:24,674][gdb3][DEBUG ] Removing ceph-mgr (12.0.1-1) ...
[2017-07-10 20:32:24,849][gdb3][DEBUG ] Purging configuration files for ceph-mgr (12.0.1-1) ...
[2017-07-10 20:32:24,915][gdb3][DEBUG ] dpkg: warning: while removing ceph-mgr, directory '/var/lib/ceph/mgr' not empty so not removed
[2017-07-10 20:32:24,946][gdb3][DEBUG ] Removing ceph-base (12.0.1-1) ...
[2017-07-10 20:32:25,111][gdb3][DEBUG ] Purging configuration files for ceph-base (12.0.1-1) ...
[2017-07-10 20:32:25,111][gdb3][DEBUG ] dpkg: warning: while removing ceph-base, directory '/var/lib/ceph/tmp' not empty so not removed
[2017-07-10 20:32:25,175][gdb3][DEBUG ] Removing ceph-common (12.0.1-1) ...
[2017-07-10 20:32:25,289][gdb3][DEBUG ] Purging configuration files for ceph-common (12.0.1-1) ...
[2017-07-10 20:32:25,403][gdb3][DEBUG ] dpkg: warning: while removing ceph-common, directory '/var/lib/ceph' not empty so not removed
[2017-07-10 20:32:25,403][gdb3][DEBUG ] Processing triggers for man-db (2.7.5-1) ...
[2017-07-10 20:32:25,568][gdb3][DEBUG ] Processing triggers for libc-bin (2.23-0ubuntu9) ...
[2017-07-10 20:32:26,384][gdb3][WARNING] W: --force-yes is deprecated, use one of the options starting with --allow instead.
[2017-07-10 20:32:26,557][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-10 20:32:26,557][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy purgedata gdb3
[2017-07-10 20:32:26,557][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-10 20:32:26,557][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-10 20:32:26,557][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-10 20:32:26,557][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-10 20:32:26,557][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-10 20:32:26,557][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3265cd27a0>
[2017-07-10 20:32:26,557][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-10 20:32:26,558][ceph_deploy.cli][INFO  ]  host                          : ['gdb3']
[2017-07-10 20:32:26,558][ceph_deploy.cli][INFO  ]  func                          : <function purgedata at 0x7f32665df230>
[2017-07-10 20:32:26,558][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-10 20:32:26,558][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-10 20:32:26,558][ceph_deploy.install][DEBUG ] Purging data from cluster ceph hosts gdb3
[2017-07-10 20:32:26,584][gdb3][DEBUG ] connection detected need for sudo
[2017-07-10 20:32:26,598][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-10 20:32:26,599][gdb3][DEBUG ] detect platform information from remote host
[2017-07-10 20:32:26,615][gdb3][DEBUG ] detect machine type
[2017-07-10 20:32:26,618][gdb3][DEBUG ] find the location of an executable
[2017-07-10 20:32:26,633][gdb3][DEBUG ] connection detected need for sudo
[2017-07-10 20:32:26,647][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-10 20:32:26,647][gdb3][DEBUG ] detect platform information from remote host
[2017-07-10 20:32:26,664][gdb3][DEBUG ] detect machine type
[2017-07-10 20:32:26,666][ceph_deploy.install][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-10 20:32:26,666][gdb3][INFO  ] purging data on gdb3
[2017-07-10 20:32:26,667][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /var/lib/ceph
[2017-07-10 20:32:26,680][gdb3][INFO  ] Running command: sudo rm -rf --one-file-system -- /etc/ceph/
[2017-07-10 20:32:26,851][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-10 20:32:26,852][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy forgetkeys
[2017-07-10 20:32:26,852][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-10 20:32:26,852][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-10 20:32:26,852][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-10 20:32:26,852][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-10 20:32:26,852][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-10 20:32:26,852][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fbff5b23a70>
[2017-07-10 20:32:26,852][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-10 20:32:26,852][ceph_deploy.cli][INFO  ]  func                          : <function forgetkeys at 0x7fbff63e6848>
[2017-07-10 20:32:26,852][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-10 20:32:26,852][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-10 20:32:48,315][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-10 20:32:48,315][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy new gdb3
[2017-07-10 20:32:48,315][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-10 20:32:48,315][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-10 20:32:48,316][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-10 20:32:48,316][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-10 20:32:48,316][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-10 20:32:48,316][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f2b7e1b35f0>
[2017-07-10 20:32:48,316][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-10 20:32:48,316][ceph_deploy.cli][INFO  ]  ssh_copykey                   : True
[2017-07-10 20:32:48,316][ceph_deploy.cli][INFO  ]  mon                           : ['gdb3']
[2017-07-10 20:32:48,316][ceph_deploy.cli][INFO  ]  func                          : <function new at 0x7f2b7e837758>
[2017-07-10 20:32:48,317][ceph_deploy.cli][INFO  ]  public_network                : None
[2017-07-10 20:32:48,317][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-10 20:32:48,317][ceph_deploy.cli][INFO  ]  cluster_network               : None
[2017-07-10 20:32:48,317][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-10 20:32:48,317][ceph_deploy.cli][INFO  ]  fsid                          : None
[2017-07-10 20:32:48,317][ceph_deploy.new][DEBUG ] Creating new cluster named ceph
[2017-07-10 20:32:48,317][ceph_deploy.new][INFO  ] making sure passwordless SSH succeeds
[2017-07-10 20:32:48,343][gdb3][DEBUG ] connection detected need for sudo
[2017-07-10 20:32:48,357][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-10 20:32:48,358][gdb3][DEBUG ] detect platform information from remote host
[2017-07-10 20:32:48,375][gdb3][DEBUG ] detect machine type
[2017-07-10 20:32:48,377][gdb3][DEBUG ] find the location of an executable
[2017-07-10 20:32:48,378][gdb3][INFO  ] Running command: sudo /bin/ip link show
[2017-07-10 20:32:48,389][gdb3][INFO  ] Running command: sudo /bin/ip addr show
[2017-07-10 20:32:48,395][gdb3][DEBUG ] IP addresses found: [u'172.31.22.186']
[2017-07-10 20:32:48,396][ceph_deploy.new][DEBUG ] Resolving host gdb3
[2017-07-10 20:32:48,396][ceph_deploy.new][DEBUG ] Monitor gdb3 at 172.31.22.186
[2017-07-10 20:32:48,396][ceph_deploy.new][DEBUG ] Monitor initial members are ['gdb3']
[2017-07-10 20:32:48,396][ceph_deploy.new][DEBUG ] Monitor addrs are ['172.31.22.186']
[2017-07-10 20:32:48,396][ceph_deploy.new][DEBUG ] Creating a random mon key...
[2017-07-10 20:32:48,396][ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring...
[2017-07-10 20:32:48,396][ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf...
[2017-07-10 20:32:48,563][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-10 20:32:48,563][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mon create-initial
[2017-07-10 20:32:48,563][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-10 20:32:48,564][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-10 20:32:48,564][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-10 20:32:48,564][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-10 20:32:48,564][ceph_deploy.cli][INFO  ]  subcommand                    : create-initial
[2017-07-10 20:32:48,564][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-10 20:32:48,564][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f3eefd01ef0>
[2017-07-10 20:32:48,564][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-10 20:32:48,564][ceph_deploy.cli][INFO  ]  func                          : <function mon at 0x7f3eefcd5b18>
[2017-07-10 20:32:48,564][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-10 20:32:48,564][ceph_deploy.cli][INFO  ]  keyrings                      : None
[2017-07-10 20:32:48,564][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-10 20:32:48,565][ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts gdb3
[2017-07-10 20:32:48,565][ceph_deploy.mon][DEBUG ] detecting platform for host gdb3 ...
[2017-07-10 20:32:48,591][gdb3][DEBUG ] connection detected need for sudo
[2017-07-10 20:32:48,607][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-10 20:32:48,607][gdb3][DEBUG ] detect platform information from remote host
[2017-07-10 20:32:48,624][gdb3][DEBUG ] detect machine type
[2017-07-10 20:32:48,627][gdb3][DEBUG ] find the location of an executable
[2017-07-10 20:32:48,627][ceph_deploy.mon][INFO  ] distro info: Ubuntu 16.04 xenial
[2017-07-10 20:32:48,627][gdb3][DEBUG ] determining if provided host has same hostname in remote
[2017-07-10 20:32:48,627][gdb3][DEBUG ] get remote short hostname
[2017-07-10 20:32:48,627][gdb3][DEBUG ] deploying mon to gdb3
[2017-07-10 20:32:48,627][gdb3][DEBUG ] get remote short hostname
[2017-07-10 20:32:48,628][gdb3][DEBUG ] remote hostname: gdb3
[2017-07-10 20:32:48,628][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-10 20:32:48,630][gdb3][DEBUG ] create the mon path if it does not exist
[2017-07-10 20:32:48,630][gdb3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-10 20:32:48,630][gdb3][DEBUG ] done path does not exist: /var/lib/ceph/mon/ceph-gdb3/done
[2017-07-10 20:32:48,631][gdb3][INFO  ] creating keyring file: /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-10 20:32:48,631][gdb3][DEBUG ] create the monitor keyring file
[2017-07-10 20:32:48,632][gdb3][INFO  ] Running command: sudo ceph-mon --cluster ceph --mkfs -i gdb3 --keyring /var/lib/ceph/tmp/ceph-gdb3.mon.keyring --setuser 64045 --setgroup 64045
[2017-07-10 20:32:48,702][gdb3][DEBUG ] ceph-mon: mon.noname-a 172.31.22.186:6789/0 is local, renaming to mon.gdb3
[2017-07-10 20:32:48,702][gdb3][DEBUG ] ceph-mon: set fsid to 18df7c5e-0a65-4855-b069-07e8ad8e79b6
[2017-07-10 20:32:48,702][gdb3][DEBUG ] ceph-mon: created monfs at /var/lib/ceph/mon/ceph-gdb3 for mon.gdb3
[2017-07-10 20:32:48,702][gdb3][INFO  ] unlinking keyring file /var/lib/ceph/tmp/ceph-gdb3.mon.keyring
[2017-07-10 20:32:48,703][gdb3][DEBUG ] create a done file to avoid re-doing the mon deployment
[2017-07-10 20:32:48,703][gdb3][DEBUG ] create the init path if it does not exist
[2017-07-10 20:32:48,704][gdb3][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-10 20:32:48,774][gdb3][INFO  ] Running command: sudo systemctl enable ceph-mon@gdb3
[2017-07-10 20:32:48,843][gdb3][INFO  ] Running command: sudo systemctl start ceph-mon@gdb3
[2017-07-10 20:32:50,913][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-10 20:32:51,028][gdb3][DEBUG ] ********************************************************************************
[2017-07-10 20:32:51,029][gdb3][DEBUG ] status for monitor: mon.gdb3
[2017-07-10 20:32:51,029][gdb3][DEBUG ] {
[2017-07-10 20:32:51,029][gdb3][DEBUG ]   "election_epoch": 4, 
[2017-07-10 20:32:51,029][gdb3][DEBUG ]   "extra_probe_peers": [], 
[2017-07-10 20:32:51,029][gdb3][DEBUG ]   "features": {
[2017-07-10 20:32:51,029][gdb3][DEBUG ]     "quorum_con": "1152323339925389307", 
[2017-07-10 20:32:51,029][gdb3][DEBUG ]     "quorum_mon": [
[2017-07-10 20:32:51,029][gdb3][DEBUG ]       "kraken", 
[2017-07-10 20:32:51,029][gdb3][DEBUG ]       "luminous"
[2017-07-10 20:32:51,029][gdb3][DEBUG ]     ], 
[2017-07-10 20:32:51,029][gdb3][DEBUG ]     "required_con": "153140804152475648", 
[2017-07-10 20:32:51,029][gdb3][DEBUG ]     "required_mon": [
[2017-07-10 20:32:51,029][gdb3][DEBUG ]       "kraken", 
[2017-07-10 20:32:51,029][gdb3][DEBUG ]       "luminous"
[2017-07-10 20:32:51,030][gdb3][DEBUG ]     ]
[2017-07-10 20:32:51,030][gdb3][DEBUG ]   }, 
[2017-07-10 20:32:51,030][gdb3][DEBUG ]   "monmap": {
[2017-07-10 20:32:51,030][gdb3][DEBUG ]     "created": "2017-07-10 20:32:48.678556", 
[2017-07-10 20:32:51,030][gdb3][DEBUG ]     "epoch": 2, 
[2017-07-10 20:32:51,030][gdb3][DEBUG ]     "features": {
[2017-07-10 20:32:51,030][gdb3][DEBUG ]       "optional": [], 
[2017-07-10 20:32:51,030][gdb3][DEBUG ]       "persistent": [
[2017-07-10 20:32:51,030][gdb3][DEBUG ]         "kraken", 
[2017-07-10 20:32:51,030][gdb3][DEBUG ]         "luminous"
[2017-07-10 20:32:51,030][gdb3][DEBUG ]       ]
[2017-07-10 20:32:51,030][gdb3][DEBUG ]     }, 
[2017-07-10 20:32:51,030][gdb3][DEBUG ]     "fsid": "18df7c5e-0a65-4855-b069-07e8ad8e79b6", 
[2017-07-10 20:32:51,030][gdb3][DEBUG ]     "modified": "2017-07-10 20:32:48.924634", 
[2017-07-10 20:32:51,030][gdb3][DEBUG ]     "mons": [
[2017-07-10 20:32:51,030][gdb3][DEBUG ]       {
[2017-07-10 20:32:51,031][gdb3][DEBUG ]         "addr": "172.31.22.186:6789/0", 
[2017-07-10 20:32:51,031][gdb3][DEBUG ]         "name": "gdb3", 
[2017-07-10 20:32:51,031][gdb3][DEBUG ]         "public_addr": "172.31.22.186:6789/0", 
[2017-07-10 20:32:51,031][gdb3][DEBUG ]         "rank": 0
[2017-07-10 20:32:51,031][gdb3][DEBUG ]       }
[2017-07-10 20:32:51,031][gdb3][DEBUG ]     ]
[2017-07-10 20:32:51,031][gdb3][DEBUG ]   }, 
[2017-07-10 20:32:51,031][gdb3][DEBUG ]   "name": "gdb3", 
[2017-07-10 20:32:51,031][gdb3][DEBUG ]   "outside_quorum": [], 
[2017-07-10 20:32:51,031][gdb3][DEBUG ]   "quorum": [
[2017-07-10 20:32:51,031][gdb3][DEBUG ]     0
[2017-07-10 20:32:51,031][gdb3][DEBUG ]   ], 
[2017-07-10 20:32:51,031][gdb3][DEBUG ]   "rank": 0, 
[2017-07-10 20:32:51,031][gdb3][DEBUG ]   "state": "leader", 
[2017-07-10 20:32:51,031][gdb3][DEBUG ]   "sync_provider": []
[2017-07-10 20:32:51,031][gdb3][DEBUG ] }
[2017-07-10 20:32:51,031][gdb3][DEBUG ] ********************************************************************************
[2017-07-10 20:32:51,032][gdb3][INFO  ] monitor: mon.gdb3 is running
[2017-07-10 20:32:51,032][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-10 20:32:51,098][ceph_deploy.mon][INFO  ] processing monitor mon.gdb3
[2017-07-10 20:32:51,113][gdb3][DEBUG ] connection detected need for sudo
[2017-07-10 20:32:51,127][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-10 20:32:51,127][gdb3][DEBUG ] detect platform information from remote host
[2017-07-10 20:32:51,143][gdb3][DEBUG ] detect machine type
[2017-07-10 20:32:51,146][gdb3][DEBUG ] find the location of an executable
[2017-07-10 20:32:51,147][gdb3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-10 20:32:51,212][ceph_deploy.mon][INFO  ] mon.gdb3 monitor has reached quorum!
[2017-07-10 20:32:51,212][ceph_deploy.mon][INFO  ] all initial monitors are running and have formed quorum
[2017-07-10 20:32:51,212][ceph_deploy.mon][INFO  ] Running gatherkeys...
[2017-07-10 20:32:51,214][ceph_deploy.gatherkeys][INFO  ] Storing keys in temp directory /tmp/tmpTsBJgF
[2017-07-10 20:32:51,230][gdb3][DEBUG ] connection detected need for sudo
[2017-07-10 20:32:51,243][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-10 20:32:51,244][gdb3][DEBUG ] detect platform information from remote host
[2017-07-10 20:32:51,260][gdb3][DEBUG ] detect machine type
[2017-07-10 20:32:51,263][gdb3][DEBUG ] get remote short hostname
[2017-07-10 20:32:51,263][gdb3][DEBUG ] fetch remote file
[2017-07-10 20:32:51,264][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --admin-daemon=/var/run/ceph/ceph-mon.gdb3.asok mon_status
[2017-07-10 20:32:51,330][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.admin
[2017-07-10 20:32:51,496][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.admin osd allow * mds allow * mon allow * mgr allow *
[2017-07-10 20:32:51,713][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mds
[2017-07-10 20:32:51,879][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mds mon allow profile bootstrap-mds
[2017-07-10 20:32:52,045][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-mgr
[2017-07-10 20:32:52,212][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr
[2017-07-10 20:32:52,378][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-osd
[2017-07-10 20:32:52,544][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-osd mon allow profile bootstrap-osd
[2017-07-10 20:32:52,710][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get client.bootstrap-rgw
[2017-07-10 20:32:52,876][gdb3][INFO  ] Running command: sudo /usr/bin/ceph --connect-timeout=25 --cluster=ceph --name mon. --keyring=/var/lib/ceph/mon/ceph-gdb3/keyring auth get-or-create client.bootstrap-rgw mon allow profile bootstrap-rgw
[2017-07-10 20:32:53,042][ceph_deploy.gatherkeys][INFO  ] Storing ceph.client.admin.keyring
[2017-07-10 20:32:53,042][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-mds.keyring
[2017-07-10 20:32:53,042][ceph_deploy.gatherkeys][INFO  ] Replacing 'ceph.bootstrap-mgr.keyring' and backing up old key as 'ceph.bootstrap-mgr.keyring-20170710203253'
[2017-07-10 20:32:53,042][ceph_deploy.gatherkeys][INFO  ] keyring 'ceph.mon.keyring' already exists
[2017-07-10 20:32:53,042][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-osd.keyring
[2017-07-10 20:32:53,042][ceph_deploy.gatherkeys][INFO  ] Storing ceph.bootstrap-rgw.keyring
[2017-07-10 20:32:53,043][ceph_deploy.gatherkeys][INFO  ] Destroy temp directory /tmp/tmpTsBJgF
[2017-07-10 20:32:53,227][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-10 20:32:53,227][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy admin gdb3
[2017-07-10 20:32:53,227][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-10 20:32:53,227][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-10 20:32:53,227][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-10 20:32:53,227][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-10 20:32:53,227][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-10 20:32:53,227][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f4adbe855a8>
[2017-07-10 20:32:53,227][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-10 20:32:53,227][ceph_deploy.cli][INFO  ]  client                        : ['gdb3']
[2017-07-10 20:32:53,228][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f4adc79c938>
[2017-07-10 20:32:53,228][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-10 20:32:53,228][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-10 20:32:53,228][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb3
[2017-07-10 20:32:53,254][gdb3][DEBUG ] connection detected need for sudo
[2017-07-10 20:32:53,268][gdb3][DEBUG ] connected to host: gdb3 
[2017-07-10 20:32:53,268][gdb3][DEBUG ] detect platform information from remote host
[2017-07-10 20:32:53,285][gdb3][DEBUG ] detect machine type
[2017-07-10 20:32:53,287][gdb3][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-10 20:33:04,426][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-10 20:33:04,426][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb1
[2017-07-10 20:33:04,426][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-10 20:33:04,426][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-10 20:33:04,426][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-10 20:33:04,426][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-10 20:33:04,426][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-10 20:33:04,426][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fc89713c5a8>
[2017-07-10 20:33:04,427][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-10 20:33:04,427][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-07-10 20:33:04,427][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7fc897a53938>
[2017-07-10 20:33:04,427][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-10 20:33:04,427][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-10 20:33:04,427][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-07-10 20:33:04,684][gdb1][DEBUG ] connection detected need for sudo
[2017-07-10 20:33:04,917][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-10 20:33:04,918][gdb1][DEBUG ] detect platform information from remote host
[2017-07-10 20:33:04,935][gdb1][DEBUG ] detect machine type
[2017-07-10 20:33:04,939][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-10 20:33:05,112][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-10 20:33:05,112][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-07-10 20:33:05,113][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-10 20:33:05,113][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-10 20:33:05,113][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-10 20:33:05,113][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-10 20:33:05,113][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-10 20:33:05,113][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-10 20:33:05,113][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-10 20:33:05,113][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-10 20:33:05,113][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-10 20:33:05,113][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-10 20:33:05,113][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-10 20:33:05,113][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-10 20:33:05,113][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f795d903998>
[2017-07-10 20:33:05,114][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-10 20:33:05,114][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-10 20:33:05,114][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f795db59aa0>
[2017-07-10 20:33:05,114][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-10 20:33:05,114][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-10 20:33:05,114][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-10 20:33:05,114][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-07-10 20:33:05,358][gdb1][DEBUG ] connection detected need for sudo
[2017-07-10 20:33:05,589][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-10 20:33:05,590][gdb1][DEBUG ] detect platform information from remote host
[2017-07-10 20:33:05,606][gdb1][DEBUG ] detect machine type
[2017-07-10 20:33:05,610][gdb1][DEBUG ] find the location of an executable
[2017-07-10 20:33:05,611][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-10 20:33:05,611][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-07-10 20:33:05,611][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-10 20:33:05,614][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-07-10 20:33:05,614][gdb1][DEBUG ] find the location of an executable
[2017-07-10 20:33:05,616][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-10 20:33:05,787][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-10 20:33:05,787][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-10 20:33:05,788][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-10 20:33:05,791][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-10 20:33:05,807][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-10 20:33:05,814][gdb1][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-07-10 20:33:05,816][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.3234.tmp
[2017-07-10 20:33:05,819][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.3234.tmp
[2017-07-10 20:33:05,822][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.3234.tmp
[2017-07-10 20:33:10,843][gdb1][INFO  ] checking OSD status...
[2017-07-10 20:33:10,844][gdb1][DEBUG ] find the location of an executable
[2017-07-10 20:33:10,846][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-10 20:33:11,061][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-07-10 20:33:11,228][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-10 20:33:11,229][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-07-10 20:33:11,229][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-10 20:33:11,229][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-10 20:33:11,229][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-10 20:33:11,229][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-10 20:33:11,229][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-10 20:33:11,229][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-10 20:33:11,229][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f2c0fa55998>
[2017-07-10 20:33:11,229][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-10 20:33:11,229][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f2c0fcabaa0>
[2017-07-10 20:33:11,229][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-10 20:33:11,230][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-10 20:33:11,230][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-10 20:33:11,230][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-07-10 20:33:11,474][gdb1][DEBUG ] connection detected need for sudo
[2017-07-10 20:33:11,705][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-10 20:33:11,706][gdb1][DEBUG ] detect platform information from remote host
[2017-07-10 20:33:11,722][gdb1][DEBUG ] detect machine type
[2017-07-10 20:33:11,725][gdb1][DEBUG ] find the location of an executable
[2017-07-10 20:33:11,726][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-10 20:33:11,726][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-07-10 20:33:11,726][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-10 20:33:11,727][gdb1][DEBUG ] find the location of an executable
[2017-07-10 20:33:11,728][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-10 20:33:11,899][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-07-10 20:33:11,899][gdb1][WARNING] activate: Cluster uuid is 18df7c5e-0a65-4855-b069-07e8ad8e79b6
[2017-07-10 20:33:11,899][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-10 20:33:11,899][gdb1][WARNING] activate: Cluster name is ceph
[2017-07-10 20:33:11,899][gdb1][WARNING] activate: OSD uuid is f01f0de8-37b5-4155-880c-e066427b5708
[2017-07-10 20:33:11,900][gdb1][WARNING] allocate_osd_id: Allocating OSD id...
[2017-07-10 20:33:11,900][gdb1][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise f01f0de8-37b5-4155-880c-e066427b5708
[2017-07-10 20:33:11,964][gdb1][WARNING] Traceback (most recent call last):
[2017-07-10 20:33:11,964][gdb1][WARNING]   File "/usr/local/bin/ceph-disk", line 9, in <module>
[2017-07-10 20:33:11,964][gdb1][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-07-10 20:33:11,964][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5653, in run
[2017-07-10 20:33:11,964][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 5604, in main
[2017-07-10 20:33:11,964][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3713, in main_activate
[2017-07-10 20:33:11,964][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3533, in activate_dir
[2017-07-10 20:33:11,964][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 3625, in activate
[2017-07-10 20:33:11,964][gdb1][WARNING]   File "build/bdist.linux-x86_64/egg/ceph_disk/main.py", line 1075, in allocate_osd_id
[2017-07-10 20:33:11,964][gdb1][WARNING] ceph_disk.main.Error: Error: ceph osd create failed: Command '/usr/bin/ceph' returned non-zero exit status 1: 2017-07-10 20:33:11.914354 7f2148975700  0 librados: client.bootstrap-osd authentication error (1) Operation not permitted
[2017-07-10 20:33:11,964][gdb1][WARNING] error connecting to the cluster
[2017-07-10 20:33:11,965][gdb1][WARNING] 
[2017-07-10 20:33:11,965][gdb1][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-07-10 20:33:11,966][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-07-10 20:33:19,789][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-10 20:33:19,790][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-07-10 20:33:19,790][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-10 20:33:19,790][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-10 20:33:19,790][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-10 20:33:19,790][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-10 20:33:19,790][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-10 20:33:19,790][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f0841b095a8>
[2017-07-10 20:33:19,790][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-10 20:33:19,790][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-07-10 20:33:19,790][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f0842420938>
[2017-07-10 20:33:19,790][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-10 20:33:19,790][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-10 20:33:19,791][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-07-10 20:33:20,111][gdb0][DEBUG ] connection detected need for sudo
[2017-07-10 20:33:20,340][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-10 20:33:20,341][gdb0][DEBUG ] detect platform information from remote host
[2017-07-10 20:33:20,371][gdb0][DEBUG ] detect machine type
[2017-07-10 20:33:20,375][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-10 20:33:20,550][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-10 20:33:20,550][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-07-10 20:33:20,550][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-10 20:33:20,551][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-10 20:33:20,551][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-10 20:33:20,551][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-10 20:33:20,551][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-10 20:33:20,551][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-10 20:33:20,551][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-10 20:33:20,551][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-10 20:33:20,551][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-10 20:33:20,551][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-10 20:33:20,551][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-10 20:33:20,551][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-10 20:33:20,551][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fbe1b5ec998>
[2017-07-10 20:33:20,551][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-10 20:33:20,551][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-10 20:33:20,552][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fbe1b842aa0>
[2017-07-10 20:33:20,552][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-10 20:33:20,552][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-10 20:33:20,552][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-10 20:33:20,552][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-07-10 20:33:20,789][gdb0][DEBUG ] connection detected need for sudo
[2017-07-10 20:33:21,021][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-10 20:33:21,021][gdb0][DEBUG ] detect platform information from remote host
[2017-07-10 20:33:21,038][gdb0][DEBUG ] detect machine type
[2017-07-10 20:33:21,042][gdb0][DEBUG ] find the location of an executable
[2017-07-10 20:33:21,042][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-10 20:33:21,042][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-07-10 20:33:21,043][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-10 20:33:21,046][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-07-10 20:33:21,046][gdb0][DEBUG ] find the location of an executable
[2017-07-10 20:33:21,048][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-10 20:33:21,369][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-10 20:33:21,584][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-10 20:33:21,584][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-10 20:33:21,584][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-10 20:33:21,600][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-10 20:33:21,615][gdb0][WARNING] populate_data_path: Data dir /mnt/memstore already exists
[2017-07-10 20:33:26,622][gdb0][INFO  ] checking OSD status...
[2017-07-10 20:33:26,622][gdb0][DEBUG ] find the location of an executable
[2017-07-10 20:33:26,625][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-10 20:33:26,890][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-07-10 20:33:27,055][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-10 20:33:27,055][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-07-10 20:33:27,055][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-10 20:33:27,055][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-10 20:33:27,055][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-10 20:33:27,055][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-10 20:33:27,055][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-10 20:33:27,055][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-10 20:33:27,056][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f430f33f998>
[2017-07-10 20:33:27,056][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-10 20:33:27,056][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f430f595aa0>
[2017-07-10 20:33:27,056][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-10 20:33:27,056][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-10 20:33:27,056][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-10 20:33:27,056][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-07-10 20:33:27,293][gdb0][DEBUG ] connection detected need for sudo
[2017-07-10 20:33:27,521][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-10 20:33:27,521][gdb0][DEBUG ] detect platform information from remote host
[2017-07-10 20:33:27,537][gdb0][DEBUG ] detect machine type
[2017-07-10 20:33:27,541][gdb0][DEBUG ] find the location of an executable
[2017-07-10 20:33:27,542][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-10 20:33:27,542][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-07-10 20:33:27,542][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-10 20:33:27,542][gdb0][DEBUG ] find the location of an executable
[2017-07-10 20:33:27,544][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-10 20:33:27,715][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-07-10 20:33:27,715][gdb0][WARNING] activate: Cluster uuid is 7273016e-b03e-4d95-b0ee-5ed43c689535
[2017-07-10 20:33:27,715][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-10 20:33:27,715][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=radosgw-sync --show-config-value=fsid
[2017-07-10 20:33:27,715][gdb0][WARNING] Traceback (most recent call last):
[2017-07-10 20:33:27,715][gdb0][WARNING]   File "/usr/sbin/ceph-disk", line 9, in <module>
[2017-07-10 20:33:27,715][gdb0][WARNING]     load_entry_point('ceph-disk==1.0.0', 'console_scripts', 'ceph-disk')()
[2017-07-10 20:33:27,715][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5653, in run
[2017-07-10 20:33:27,715][gdb0][WARNING]     main(sys.argv[1:])
[2017-07-10 20:33:27,715][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 5604, in main
[2017-07-10 20:33:27,715][gdb0][WARNING]     args.func(args)
[2017-07-10 20:33:27,716][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3713, in main_activate
[2017-07-10 20:33:27,716][gdb0][WARNING]     init=args.mark_init,
[2017-07-10 20:33:27,716][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3533, in activate_dir
[2017-07-10 20:33:27,716][gdb0][WARNING]     (osd_id, cluster) = activate(path, activate_key_template, init)
[2017-07-10 20:33:27,716][gdb0][WARNING]   File "/usr/lib/python2.7/dist-packages/ceph_disk/main.py", line 3609, in activate
[2017-07-10 20:33:27,716][gdb0][WARNING]     ' with fsid %s' % ceph_fsid)
[2017-07-10 20:33:27,716][gdb0][WARNING] ceph_disk.main.Error: Error: No cluster conf found in /etc/ceph with fsid 7273016e-b03e-4d95-b0ee-5ed43c689535
[2017-07-10 20:33:27,716][gdb0][ERROR ] RuntimeError: command returned non-zero exit status: 1
[2017-07-10 20:33:27,716][ceph_deploy][ERROR ] RuntimeError: Failed to execute command: /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore

[2017-07-10 20:35:57,007][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-10 20:35:57,008][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb0
[2017-07-10 20:35:57,008][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-10 20:35:57,008][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-10 20:35:57,008][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-10 20:35:57,008][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-10 20:35:57,008][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-10 20:35:57,008][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f64563e05a8>
[2017-07-10 20:35:57,008][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-10 20:35:57,008][ceph_deploy.cli][INFO  ]  client                        : ['gdb0']
[2017-07-10 20:35:57,008][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f6456cf7938>
[2017-07-10 20:35:57,008][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-10 20:35:57,008][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-10 20:35:57,009][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb0
[2017-07-10 20:35:57,249][gdb0][DEBUG ] connection detected need for sudo
[2017-07-10 20:35:57,481][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-10 20:35:57,481][gdb0][DEBUG ] detect platform information from remote host
[2017-07-10 20:35:57,497][gdb0][DEBUG ] detect machine type
[2017-07-10 20:35:57,501][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-10 20:35:57,672][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-10 20:35:57,672][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb0:/mnt/memstore
[2017-07-10 20:35:57,672][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-10 20:35:57,672][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-10 20:35:57,672][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-10 20:35:57,672][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-10 20:35:57,672][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-10 20:35:57,672][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-10 20:35:57,672][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-10 20:35:57,672][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-10 20:35:57,673][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-10 20:35:57,673][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-10 20:35:57,673][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-10 20:35:57,673][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-10 20:35:57,673][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7fa469372998>
[2017-07-10 20:35:57,673][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-10 20:35:57,673][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-10 20:35:57,673][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7fa4695c8aa0>
[2017-07-10 20:35:57,673][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-10 20:35:57,673][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-10 20:35:57,673][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-10 20:35:57,673][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb0:/mnt/memstore:
[2017-07-10 20:35:57,909][gdb0][DEBUG ] connection detected need for sudo
[2017-07-10 20:35:58,104][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-10 20:35:58,105][gdb0][DEBUG ] detect platform information from remote host
[2017-07-10 20:35:58,121][gdb0][DEBUG ] detect machine type
[2017-07-10 20:35:58,125][gdb0][DEBUG ] find the location of an executable
[2017-07-10 20:35:58,126][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-10 20:35:58,126][ceph_deploy.osd][DEBUG ] Deploying osd to gdb0
[2017-07-10 20:35:58,126][gdb0][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-10 20:35:58,128][gdb0][WARNING] osd keyring does not exist yet, creating one
[2017-07-10 20:35:58,128][gdb0][DEBUG ] create a keyring file
[2017-07-10 20:35:58,130][ceph_deploy.osd][DEBUG ] Preparing host gdb0 disk /mnt/memstore journal None activate False
[2017-07-10 20:35:58,130][gdb0][DEBUG ] find the location of an executable
[2017-07-10 20:35:58,132][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-10 20:35:58,303][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-10 20:35:58,303][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-10 20:35:58,303][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-10 20:35:58,303][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-10 20:35:58,311][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-10 20:35:58,326][gdb0][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-07-10 20:35:58,342][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.3352.tmp
[2017-07-10 20:35:58,342][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.3352.tmp
[2017-07-10 20:35:58,343][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.3352.tmp
[2017-07-10 20:36:03,364][gdb0][INFO  ] checking OSD status...
[2017-07-10 20:36:03,365][gdb0][DEBUG ] find the location of an executable
[2017-07-10 20:36:03,367][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-10 20:36:03,533][ceph_deploy.osd][DEBUG ] Host gdb0 is now ready for osd use.
[2017-07-10 20:36:03,697][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-10 20:36:03,698][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb0:/mnt/memstore
[2017-07-10 20:36:03,698][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-10 20:36:03,698][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-10 20:36:03,698][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-10 20:36:03,698][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-10 20:36:03,698][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-10 20:36:03,698][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-10 20:36:03,698][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6bf62ae998>
[2017-07-10 20:36:03,698][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-10 20:36:03,698][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f6bf6504aa0>
[2017-07-10 20:36:03,699][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-10 20:36:03,699][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-10 20:36:03,699][ceph_deploy.cli][INFO  ]  disk                          : [('gdb0', '/mnt/memstore', None)]
[2017-07-10 20:36:03,699][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb0:/mnt/memstore:
[2017-07-10 20:36:03,946][gdb0][DEBUG ] connection detected need for sudo
[2017-07-10 20:36:04,176][gdb0][DEBUG ] connected to host: gdb0 
[2017-07-10 20:36:04,177][gdb0][DEBUG ] detect platform information from remote host
[2017-07-10 20:36:04,192][gdb0][DEBUG ] detect machine type
[2017-07-10 20:36:04,196][gdb0][DEBUG ] find the location of an executable
[2017-07-10 20:36:04,197][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-10 20:36:04,197][ceph_deploy.osd][DEBUG ] activating host gdb0 disk /mnt/memstore
[2017-07-10 20:36:04,197][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-10 20:36:04,197][gdb0][DEBUG ] find the location of an executable
[2017-07-10 20:36:04,199][gdb0][INFO  ] Running command: sudo /usr/sbin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-10 20:36:04,370][gdb0][WARNING] main_activate: path = /mnt/memstore
[2017-07-10 20:36:04,370][gdb0][WARNING] activate: Cluster uuid is 18df7c5e-0a65-4855-b069-07e8ad8e79b6
[2017-07-10 20:36:04,370][gdb0][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-10 20:36:04,370][gdb0][WARNING] activate: Cluster name is ceph
[2017-07-10 20:36:04,370][gdb0][WARNING] activate: OSD uuid is bd40bd7c-605f-4926-82b4-b0f29fc19c06
[2017-07-10 20:36:04,370][gdb0][WARNING] allocate_osd_id: Allocating OSD id...
[2017-07-10 20:36:04,370][gdb0][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise bd40bd7c-605f-4926-82b4-b0f29fc19c06
[2017-07-10 20:36:04,535][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.3469.tmp
[2017-07-10 20:36:04,535][gdb0][WARNING] activate: OSD id is 0
[2017-07-10 20:36:04,535][gdb0][WARNING] activate: Initializing OSD...
[2017-07-10 20:36:04,535][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-07-10 20:36:04,649][gdb0][WARNING] got monmap epoch 2
[2017-07-10 20:36:04,653][gdb0][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 0 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid bd40bd7c-605f-4926-82b4-b0f29fc19c06 --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-07-10 20:36:04,717][gdb0][WARNING] activate: Marking with init system systemd
[2017-07-10 20:36:04,717][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-07-10 20:36:04,717][gdb0][WARNING] activate: Authorizing OSD key...
[2017-07-10 20:36:04,717][gdb0][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.0 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-07-10 20:36:04,881][gdb0][WARNING] added key for osd.0
[2017-07-10 20:36:04,881][gdb0][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.3469.tmp
[2017-07-10 20:36:04,882][gdb0][WARNING] activate: ceph osd.0 data dir is ready at /mnt/memstore
[2017-07-10 20:36:04,882][gdb0][WARNING] activate_dir: Creating symlink /var/lib/ceph/osd/ceph-0 -> /mnt/memstore
[2017-07-10 20:36:04,882][gdb0][WARNING] start_daemon: Starting ceph osd.0...
[2017-07-10 20:36:04,882][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0
[2017-07-10 20:36:04,889][gdb0][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service.
[2017-07-10 20:36:04,954][gdb0][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@0 --runtime
[2017-07-10 20:36:05,018][gdb0][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@0
[2017-07-10 20:36:05,018][gdb0][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@0.service to /lib/systemd/system/ceph-osd@.service.
[2017-07-10 20:36:05,082][gdb0][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@0
[2017-07-10 20:36:10,151][gdb0][INFO  ] checking OSD status...
[2017-07-10 20:36:10,151][gdb0][DEBUG ] find the location of an executable
[2017-07-10 20:36:10,154][gdb0][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-10 20:36:10,322][gdb0][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-10 20:36:14,470][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-10 20:36:14,471][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy --overwrite-conf admin gdb1
[2017-07-10 20:36:14,471][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-10 20:36:14,471][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-10 20:36:14,471][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-10 20:36:14,471][ceph_deploy.cli][INFO  ]  overwrite_conf                : True
[2017-07-10 20:36:14,471][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-10 20:36:14,471][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f9cc01975a8>
[2017-07-10 20:36:14,471][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-10 20:36:14,471][ceph_deploy.cli][INFO  ]  client                        : ['gdb1']
[2017-07-10 20:36:14,471][ceph_deploy.cli][INFO  ]  func                          : <function admin at 0x7f9cc0aae938>
[2017-07-10 20:36:14,471][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-10 20:36:14,471][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-10 20:36:14,471][ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to gdb1
[2017-07-10 20:36:14,710][gdb1][DEBUG ] connection detected need for sudo
[2017-07-10 20:36:14,941][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-10 20:36:14,941][gdb1][DEBUG ] detect platform information from remote host
[2017-07-10 20:36:14,958][gdb1][DEBUG ] detect machine type
[2017-07-10 20:36:14,962][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-10 20:36:15,130][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-10 20:36:15,131][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd prepare gdb1:/mnt/memstore
[2017-07-10 20:36:15,131][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-10 20:36:15,131][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-10 20:36:15,131][ceph_deploy.cli][INFO  ]  block_db                      : None
[2017-07-10 20:36:15,131][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-10 20:36:15,131][ceph_deploy.cli][INFO  ]  dmcrypt                       : False
[2017-07-10 20:36:15,131][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-10 20:36:15,131][ceph_deploy.cli][INFO  ]  bluestore                     : None
[2017-07-10 20:36:15,131][ceph_deploy.cli][INFO  ]  block_wal                     : None
[2017-07-10 20:36:15,131][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-10 20:36:15,131][ceph_deploy.cli][INFO  ]  subcommand                    : prepare
[2017-07-10 20:36:15,131][ceph_deploy.cli][INFO  ]  dmcrypt_key_dir               : /etc/ceph/dmcrypt-keys
[2017-07-10 20:36:15,132][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-10 20:36:15,132][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6c6ca95998>
[2017-07-10 20:36:15,132][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-10 20:36:15,132][ceph_deploy.cli][INFO  ]  fs_type                       : xfs
[2017-07-10 20:36:15,132][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f6c6ccebaa0>
[2017-07-10 20:36:15,132][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-10 20:36:15,132][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-10 20:36:15,132][ceph_deploy.cli][INFO  ]  zap_disk                      : False
[2017-07-10 20:36:15,132][ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks gdb1:/mnt/memstore:
[2017-07-10 20:36:15,369][gdb1][DEBUG ] connection detected need for sudo
[2017-07-10 20:36:15,597][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-10 20:36:15,598][gdb1][DEBUG ] detect platform information from remote host
[2017-07-10 20:36:15,615][gdb1][DEBUG ] detect machine type
[2017-07-10 20:36:15,618][gdb1][DEBUG ] find the location of an executable
[2017-07-10 20:36:15,619][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-10 20:36:15,619][ceph_deploy.osd][DEBUG ] Deploying osd to gdb1
[2017-07-10 20:36:15,620][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-10 20:36:15,622][gdb1][WARNING] osd keyring does not exist yet, creating one
[2017-07-10 20:36:15,622][gdb1][DEBUG ] create a keyring file
[2017-07-10 20:36:15,624][ceph_deploy.osd][DEBUG ] Preparing host gdb1 disk /mnt/memstore journal None activate False
[2017-07-10 20:36:15,624][gdb1][DEBUG ] find the location of an executable
[2017-07-10 20:36:15,626][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v prepare --cluster ceph --fs-type xfs -- /mnt/memstore
[2017-07-10 20:36:15,797][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-10 20:36:15,797][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-allows-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-10 20:36:15,797][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-wants-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-10 20:36:15,797][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --check-needs-journal -i 0 --cluster ceph --setuser ceph --setgroup ceph
[2017-07-10 20:36:15,813][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=osd_journal_size
[2017-07-10 20:36:15,820][gdb1][WARNING] populate_data_path: Preparing osd data dir /mnt/memstore
[2017-07-10 20:36:15,821][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/ceph_fsid.4137.tmp
[2017-07-10 20:36:15,824][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/fsid.4137.tmp
[2017-07-10 20:36:15,840][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/magic.4137.tmp
[2017-07-10 20:36:20,852][gdb1][INFO  ] checking OSD status...
[2017-07-10 20:36:20,853][gdb1][DEBUG ] find the location of an executable
[2017-07-10 20:36:20,855][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-10 20:36:21,021][ceph_deploy.osd][DEBUG ] Host gdb1 is now ready for osd use.
[2017-07-10 20:36:21,184][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-10 20:36:21,184][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy osd activate gdb1:/mnt/memstore
[2017-07-10 20:36:21,184][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-10 20:36:21,184][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-10 20:36:21,184][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-10 20:36:21,184][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-10 20:36:21,184][ceph_deploy.cli][INFO  ]  subcommand                    : activate
[2017-07-10 20:36:21,185][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-10 20:36:21,185][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6db4772998>
[2017-07-10 20:36:21,185][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-10 20:36:21,185][ceph_deploy.cli][INFO  ]  func                          : <function osd at 0x7f6db49c8aa0>
[2017-07-10 20:36:21,185][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-10 20:36:21,185][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-10 20:36:21,185][ceph_deploy.cli][INFO  ]  disk                          : [('gdb1', '/mnt/memstore', None)]
[2017-07-10 20:36:21,185][ceph_deploy.osd][DEBUG ] Activating cluster ceph disks gdb1:/mnt/memstore:
[2017-07-10 20:36:21,426][gdb1][DEBUG ] connection detected need for sudo
[2017-07-10 20:36:21,657][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-10 20:36:21,658][gdb1][DEBUG ] detect platform information from remote host
[2017-07-10 20:36:21,674][gdb1][DEBUG ] detect machine type
[2017-07-10 20:36:21,678][gdb1][DEBUG ] find the location of an executable
[2017-07-10 20:36:21,679][ceph_deploy.osd][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-10 20:36:21,679][ceph_deploy.osd][DEBUG ] activating host gdb1 disk /mnt/memstore
[2017-07-10 20:36:21,679][ceph_deploy.osd][DEBUG ] will use init type: systemd
[2017-07-10 20:36:21,679][gdb1][DEBUG ] find the location of an executable
[2017-07-10 20:36:21,681][gdb1][INFO  ] Running command: sudo /usr/local/bin/ceph-disk -v activate --mark-init systemd --mount /mnt/memstore
[2017-07-10 20:36:21,852][gdb1][WARNING] main_activate: path = /mnt/memstore
[2017-07-10 20:36:21,852][gdb1][WARNING] activate: Cluster uuid is 18df7c5e-0a65-4855-b069-07e8ad8e79b6
[2017-07-10 20:36:21,852][gdb1][WARNING] command: Running command: /usr/bin/ceph-osd --cluster=ceph --show-config-value=fsid
[2017-07-10 20:36:21,852][gdb1][WARNING] activate: Cluster name is ceph
[2017-07-10 20:36:21,852][gdb1][WARNING] activate: OSD uuid is 3d75bb1e-119a-414b-9408-e9e0e877e452
[2017-07-10 20:36:21,852][gdb1][WARNING] allocate_osd_id: Allocating OSD id...
[2017-07-10 20:36:21,852][gdb1][WARNING] command: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring osd create --concise 3d75bb1e-119a-414b-9408-e9e0e877e452
[2017-07-10 20:36:22,217][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/whoami.4255.tmp
[2017-07-10 20:36:22,217][gdb1][WARNING] activate: OSD id is 1
[2017-07-10 20:36:22,218][gdb1][WARNING] activate: Initializing OSD...
[2017-07-10 20:36:22,218][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring mon getmap -o /mnt/memstore/activate.monmap
[2017-07-10 20:36:22,332][gdb1][WARNING] got monmap epoch 2
[2017-07-10 20:36:22,332][gdb1][WARNING] command: Running command: /usr/bin/timeout 300 ceph-osd --cluster ceph --mkfs --mkkey -i 1 --monmap /mnt/memstore/activate.monmap --osd-data /mnt/memstore --osd-journal /mnt/memstore/journal --osd-uuid 3d75bb1e-119a-414b-9408-e9e0e877e452 --keyring /mnt/memstore/keyring --setuser ceph --setgroup ceph
[2017-07-10 20:36:22,364][gdb1][WARNING] activate: Marking with init system systemd
[2017-07-10 20:36:22,364][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/systemd
[2017-07-10 20:36:22,364][gdb1][WARNING] activate: Authorizing OSD key...
[2017-07-10 20:36:22,364][gdb1][WARNING] command_check_call: Running command: /usr/bin/ceph --cluster ceph --name client.bootstrap-osd --keyring /var/lib/ceph/bootstrap-osd/ceph.keyring auth add osd.1 -i /mnt/memstore/keyring osd allow * mon allow profile osd
[2017-07-10 20:36:22,528][gdb1][WARNING] added key for osd.1
[2017-07-10 20:36:22,529][gdb1][WARNING] command: Running command: /bin/chown -R ceph:ceph /mnt/memstore/active.4255.tmp
[2017-07-10 20:36:22,529][gdb1][WARNING] activate: ceph osd.1 data dir is ready at /mnt/memstore
[2017-07-10 20:36:22,529][gdb1][WARNING] activate_dir: Creating symlink /var/lib/ceph/osd/ceph-1 -> /mnt/memstore
[2017-07-10 20:36:22,529][gdb1][WARNING] start_daemon: Starting ceph osd.1...
[2017-07-10 20:36:22,529][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@1
[2017-07-10 20:36:22,529][gdb1][WARNING] Removed symlink /etc/systemd/system/ceph-osd.target.wants/ceph-osd@1.service.
[2017-07-10 20:36:22,593][gdb1][WARNING] command_check_call: Running command: /bin/systemctl disable ceph-osd@1 --runtime
[2017-07-10 20:36:22,657][gdb1][WARNING] command_check_call: Running command: /bin/systemctl enable ceph-osd@1
[2017-07-10 20:36:22,657][gdb1][WARNING] Created symlink from /etc/systemd/system/ceph-osd.target.wants/ceph-osd@1.service to /lib/systemd/system/ceph-osd@.service.
[2017-07-10 20:36:22,689][gdb1][WARNING] command_check_call: Running command: /bin/systemctl start ceph-osd@1
[2017-07-10 20:36:27,758][gdb1][INFO  ] checking OSD status...
[2017-07-10 20:36:27,758][gdb1][DEBUG ] find the location of an executable
[2017-07-10 20:36:27,761][gdb1][INFO  ] Running command: sudo /usr/bin/ceph --cluster=ceph osd stat --format=json
[2017-07-10 20:36:27,928][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
[2017-07-10 20:37:50,484][ceph_deploy.conf][DEBUG ] found configuration file at: /home/ubuntu/.cephdeploy.conf
[2017-07-10 20:37:50,485][ceph_deploy.cli][INFO  ] Invoked (1.5.37): /home/ubuntu/bin/ceph-deploy mds create gdb1
[2017-07-10 20:37:50,485][ceph_deploy.cli][INFO  ] ceph-deploy options:
[2017-07-10 20:37:50,485][ceph_deploy.cli][INFO  ]  username                      : None
[2017-07-10 20:37:50,485][ceph_deploy.cli][INFO  ]  verbose                       : False
[2017-07-10 20:37:50,485][ceph_deploy.cli][INFO  ]  overwrite_conf                : False
[2017-07-10 20:37:50,485][ceph_deploy.cli][INFO  ]  subcommand                    : create
[2017-07-10 20:37:50,485][ceph_deploy.cli][INFO  ]  quiet                         : False
[2017-07-10 20:37:50,485][ceph_deploy.cli][INFO  ]  cd_conf                       : <ceph_deploy.conf.cephdeploy.Conf instance at 0x7f882820a200>
[2017-07-10 20:37:50,485][ceph_deploy.cli][INFO  ]  cluster                       : ceph
[2017-07-10 20:37:50,485][ceph_deploy.cli][INFO  ]  func                          : <function mds at 0x7f882845eed8>
[2017-07-10 20:37:50,485][ceph_deploy.cli][INFO  ]  ceph_conf                     : None
[2017-07-10 20:37:50,486][ceph_deploy.cli][INFO  ]  mds                           : [('gdb1', 'gdb1')]
[2017-07-10 20:37:50,486][ceph_deploy.cli][INFO  ]  default_release               : False
[2017-07-10 20:37:50,486][ceph_deploy.mds][DEBUG ] Deploying mds, cluster ceph hosts gdb1:gdb1
[2017-07-10 20:37:50,726][gdb1][DEBUG ] connection detected need for sudo
[2017-07-10 20:37:50,957][gdb1][DEBUG ] connected to host: gdb1 
[2017-07-10 20:37:50,957][gdb1][DEBUG ] detect platform information from remote host
[2017-07-10 20:37:50,974][gdb1][DEBUG ] detect machine type
[2017-07-10 20:37:50,978][ceph_deploy.mds][INFO  ] Distro info: Ubuntu 16.04 xenial
[2017-07-10 20:37:50,978][ceph_deploy.mds][DEBUG ] remote host will use systemd
[2017-07-10 20:37:50,978][ceph_deploy.mds][DEBUG ] deploying mds bootstrap to gdb1
[2017-07-10 20:37:50,978][gdb1][DEBUG ] write cluster configuration to /etc/ceph/{cluster}.conf
[2017-07-10 20:37:50,981][gdb1][WARNING] mds keyring does not exist yet, creating one
[2017-07-10 20:37:50,981][gdb1][DEBUG ] create a keyring file
[2017-07-10 20:37:50,983][gdb1][DEBUG ] create path if it doesn't exist
[2017-07-10 20:37:50,986][gdb1][INFO  ] Running command: sudo ceph --cluster ceph --name client.bootstrap-mds --keyring /var/lib/ceph/bootstrap-mds/ceph.keyring auth get-or-create mds.gdb1 osd allow rwx mds allow mon allow profile mds -o /var/lib/ceph/mds/ceph-gdb1/keyring
[2017-07-10 20:37:51,156][gdb1][INFO  ] Running command: sudo systemctl enable ceph-mds@gdb1
[2017-07-10 20:37:51,168][gdb1][WARNING] Created symlink from /etc/systemd/system/ceph-mds.target.wants/ceph-mds@gdb1.service to /lib/systemd/system/ceph-mds@.service.
[2017-07-10 20:37:51,234][gdb1][INFO  ] Running command: sudo systemctl start ceph-mds@gdb1
[2017-07-10 20:37:51,270][gdb1][INFO  ] Running command: sudo systemctl enable ceph.target
